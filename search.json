[{"url":"/2023/02/21/3.%20%E6%95%B0%E7%BB%84%E4%B8%AD%E9%87%8D%E5%A4%8D%E7%9A%84%E6%95%B0%E5%AD%97/","content":"3. 数组中重复的数字题目链接牛客网\n题目描述在一个长度为 n 的数组里的所有数字都在 0 到 n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字是重复的，也不知道每个数字重复几次。请找出数组中任意一个重复的数字。\nInput:&#123;2, 3, 1, 0, 2, 5&#125;Output:2\n\n解题思路要求时间复杂度 O(N)，空间复杂度 O(1)。因此不能使用排序的方法，也不能使用额外的标记数组。\n对于这种数组元素在 [0, n-1] 范围内的问题，可以将值为 i 的元素调整到第 i 个位置上进行求解。本题要求找出重复的数字，因此在调整过程中，如果第 i 位置上已经有一个值为 i 的元素，就可以知道 i 值重复。\n以 (2, 3, 1, 0, 2, 5) 为例，遍历到位置 4 时，该位置上的数为 2，但是第 2 个位置上已经有一个 2 的值了，因此可以知道 2 重复：\n  \n\n\npublic boolean duplicate(int[] nums, int length, int[] duplication) &#123;    if (nums == null || length &lt;= 0)        return false;    for (int i = 0; i &lt; length; i++) &#123;        while (nums[i] != i) &#123;            if (nums[i] == nums[nums[i]]) &#123;                duplication[0] = nums[i];                return true;            &#125;            swap(nums, i, nums[i]);        &#125;    &#125;    return false;&#125;private void swap(int[] nums, int i, int j) &#123;    int t = nums[i];    nums[i] = nums[j];    nums[j] = t;&#125;\n\n\n\n\n\n\n\n"},{"url":"/2023/02/21/4.%20%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E6%9F%A5%E6%89%BE/","content":"4. 二维数组中的查找题目链接牛客网\n题目描述给定一个二维数组，其每一行从左到右递增排序，从上到下也是递增排序。给定一个数，判断这个数是否在该二维数组中。\nConsider the following matrix:[  [1,   4,  7, 11, 15],  [2,   5,  8, 12, 19],  [3,   6,  9, 16, 22],  [10, 13, 14, 17, 24],  [18, 21, 23, 26, 30]]Given target = 5, return true.Given target = 20, return false.\n\n解题思路要求时间复杂度 O(M + N)，空间复杂度 O(1)。其中 M 为行数，N 为 列数。\n该二维数组中的一个数，小于它的数一定在其左边，大于它的数一定在其下边。因此，从右上角开始查找，就可以根据 target 和当前元素的大小关系来缩小查找区间，当前元素的查找区间为左下角的所有元素。\n  \n\npublic boolean Find(int target, int[][] matrix) &#123;    if (matrix == null || matrix.length == 0 || matrix[0].length == 0)        return false;    int rows = matrix.length, cols = matrix[0].length;    int r = 0, c = cols - 1; // 从右上角开始    while (r &lt;= rows - 1 &amp;&amp; c &gt;= 0) &#123;        if (target == matrix[r][c])            return true;        else if (target &gt; matrix[r][c])            r++;        else            c--;    &#125;    return false;&#125;\n\n\n\n\n\n\n\n"},{"title":"CSS资源大全中文版","url":"/2023/02/19/CSS%20%E8%B5%84%E6%BA%90%E5%A4%A7%E5%85%A8%E4%B8%AD%E6%96%87%E7%89%88/","content":"CSS 资源大全中文版我想很多程序员应该记得 GitHub 上有一个 Awesome：XXX 系列的资源整理。[awesome-css] 是 sotayamashita 发起维护的 CSS 资源列表，内容包括：CSS预处理器、框架、CSS结构、代码风格指南、命名习惯、播客、演讲视频、大网站的 CSS 开发经验等等。\nAwesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。\n\n我们要做什么？\n基于 awesome-css 列表，我们将对其中的各个资源项进行编译整理。此外还将从其他来源补充好资源。\n整理后的内容，将收录在伯乐在线资源频道。可参考已整理的内容： ：《BEM：前端命名方法论》 ：《Sass：CSS预处理器》 ：《YUI Compressor：JS&#x2F;CSS压缩工具》\n\n\n如何参与本项目？\n如何为列表贡献新资源？欢迎大家为列表贡献高质量的新资源，提交PR时请参照以下要求：\n\n请确保推荐的资源自己使用过\n提交PR时请注明推荐理由\n\n资源列表管理收到PR请求后，会定期（每周）在微博转发本周提交的PR列表，并在微博上面听取使用过这些资源的意见。确认通过后，会加入资源大全。\n感谢您的贡献！\n\n本项目的参与者\n维护者：tangyouhua\n贡献者：iLeo、伯小乐、tzstone、llhua2329、凝枫\n\n注：名单不分排名，不定期补充更新\n\nsotayamashita 发起维护的 CSS 资源大全，包括：预处理器、框架、CSS结构、代码风格指南、命名习惯、播客、演讲视频、大网站的 CSS 开发经验等等。\n\n我们要做什么？\n如何参与本项目？\n如何为列表贡献新资源？\n本项目的参与者\n\n预处理器更快地编译 CSS\n\nGCSS：一个用GO语言编写的CSS预处理器。官网\nLESS：向下兼容CSS并为当前的CSS增加额外的功能。官网\nMyth：只用写纯CSS而不用担心浏览器加载缓慢。官网\nPCSS：一个用Python语言编写的CSS预处理器。官网\nPostCSS：通过JS插件来转换CSS。PostCSS\nSass：成熟、稳定且强力的专业CSS扩展语言。官网\nStylus：用于nodejs的直观、强健、极具特色的CSS语言。官网\nYACP：另一种CSS预处理器。官网\n\n这里有一个 CSS 预处理器汇总。\n框架\n960 Grid System：简化了web开发工作流程。官网\nBlueprint：这个CSS框架为你提供易用的栅格系统、符合直觉的排版功能、有用的插件以及可打印的样式 官网\nBootstrap：最流行的HTML、CSS、JS框架 官网\ninuit.css ：强力的、可扩展的、基于Sass的、采用BEM命名的面向对象CSS框架 官网\nFoundation：一个高级响应式前端框架。官网\nMaterial Design Lite：很好的用于制作Material Design风格网站的框架。官网\nMaterialize：基于Material Design的现代响应式前端框架。官网\nPure.css：一套可用于所有web项目的小型响应式CSS模块。官网\nSemantic UI：使用人性化html的强力框架。官网\nSkeleton：一个超简单的响应式模板。官网\nUIkit：适用于手机、平板以及电脑端的栅格系统。官网\n\n工具集\nBasscss：一个基本元素样式与不可修改工具轻量级集合。官网\nBourbon：用于Sass的简单且轻量的混合库。官网\nCorpus：另一个CSS工具集。官网\nSusy：用于Sass的响应式工具集。官网\n\nCSS结构\nRSCSS：CSS样式结构的合理标准。官网\nITCSS：用于大型UI项目的稳定、可扩展、可控制的CSS架构。官网\n\nCSS标准化\nNormalize：一套提供较好的多浏览器默认样式一致性的CSS规范。官网\nNormalize OpenType：为Normalize.css添加了OpenType特性，如连字、字间距等等。官网\nReset：一套CSS标准，将全部的HTML元素调整到一致的基准线。官网\nsanitize.css：一套可立即使用的，符合当今最优实践的CSS规范。官网\n\n大型网站的CSS开发\n[Github的CSS方案](http://hao.importnew.com/htmlcss-code-guide-by-mark-otto/） by Mark Otto，英文\nCodePen的CSS方案 by Chris Coyier，英文\nLonely Planet的CSS方案 by Ian Feather，英文\nGroupon的CSS方案 by Mike Aparicio，英文\nBuffer的CSS方案 by Brian Lovin，英文\nHOOTSUITE的CSS方案 by Steve Mynett，英文\n如何精简TrelloCSS架构 by Bobby Grace，英文\nBugsnag的CSS架构 by Max Luster，英文\nGhost的CSS方案 by Paul Davis，英文\nMedium的CSS方案 by Jacob Thornton，英文\n\n代码风格指导\n编写符合语言习惯的 CSS by Nicolas Gallagher.\nCSS 指南 by Harry Roberts.\nSass 指南 by Hugo Giraudel.\nMark Otto 编写的风格指南，受「GitHub 风格」和「编写符合语言习惯的 CSS」所激发 by Mark Otto.\nThinkUp 的 CSS 风格指导，作者ThinkUp\nGoogle 的 HTML&#x2F;CSS 风格指导\nWordPress的CSS代码标准：官网\n\n风格指导\nAtlassian 官方 UI 文档；\n设计元素 by lonely planet.\nGitHub 的 CSS 风格指导\nPatterns by MailChimp 的风格指南.\nLighting Design System by Salesforce 的风格指南.\nSASS 风格指南 by Sass team.\n星巴克的风格指南 by Starbucks.\n关于网站风格指导的一些资源 by Awesome people.\n\n命名习惯和方式\nAtomic OOBEMITSCSS：官网\nBEM：官网\nSMACSS：官网\nPoint North：官网\nITCSS：官网\nOOCSS：官网\nTitle CSS：官网\nidiomatic-css：官网\nAtomic Design：官网\nSUIT CSS：官网\nKickoff CSS：官网\n\n参考\n可扩展CSS阅读清单\n\n其他资源播客编程时可以听的一些内容。\n\nShop Talk Show：Chris Coyier 和 Dave Rupert 的在线播客，涉及前端、UX的设计及开发。\nStyle Guide Podcast：由 Anna Debenham 和 Brad Frost 主持的一些访谈。\nThe Big Web Show：包含了几乎所有 Web 相关的话题，比如网络出版、艺术指导、内容策略、版面设计、Web技术等等。\nThe Web Ahead：与全世界的专家讨论 Web 技术的变化和发展。\nNon Breaking Space Show：挖掘出那些在数字艺术、设计以及开发领域最好的、最知名的并且最聪明的创客们。\nThe Changelog：这个播客的口号是：“开源发展很快，快跟上”，致力于让你跟上最新的开源技术。\n\nTwitter值得关注的活跃用户\n\nCSS Animation\nAndrey Sitnik：@Autoprefixer, http://easings.net 和 @PostCSS 的作者\nEvangelina Ferreira：web设计师，@multimedial_utn 的教授，HTML5 &amp; CSS狂热爱好者，业余翻译者。\nSara Soueidan：@Codrops CSS Reference的作者，Smashing Book #5的合著者。\nHugo Giraudel：@edenspiekermann 的 CSS 怪才以及 Sass 黑客\nGuy Routledge：前端开发者、@GA_London 的教师，http://www.atozcss.com 的视频作者，宅男，吃货。\nHeydon Pickering：爱吃大米，同时也是一个UX设计师，作者，@smashingmag 编辑以及程序员。\nAdam Morse：开源的粉丝和支持者\nDonovan Hutchinson：设计师、开发者、作家。偶尔在http://Hop.ie上写博客，目前在建设@cssanimation\nCSS Commits：最近忙于 CSSWG 的公共 Mercurial 库\nScott Jehl：responsiblerwd 的作者，现在 abookapart上 面在打折\nDudley Storey：Web开发者、作者、老师以及演说者。\nZoe M. Gillenwater：Web设计师、开发者，专注于CSS、RWD、UX以及无障碍开发。\nBen Briggs：主要研究node.js、javascript、开源模块、客户端优化、web性能相关。\nPaul Lewis：将代码与设计联系起来的谷歌员工。\nThierry Koblentz：Yahoo 的 CSS 开发者\nNicolas Gallagher：Twitter的软件工程师\nHarry Roberts- @google, @Etsy, @kickstarter, @BBC, @Deloitte, @FT等的前端设计顾问\nPhil Walton -谷歌工程师、开源拥护者、开发者、设计师、写手。\nLea Verou：MIT_CSAIL, @CSSWG IE, @OReillyMedia作者的研究助理，前W3C员工\nManoela Ilic：CSS和HTML是我的画笔，我对认知科学、AI、HCI、UI设计以及天体物理学很感兴趣，数码控。\nUna Kravets：BMDesign以及Sassvocate的前端工程师，团队建设者以及手工艺者。座右铭：所有东西都应该开源！\nChris Coyier：CodePen的设计师，Real_CSS_Tricks作者\nNicole Sullivan：极客！\nEric Bidelman：谷歌的工程师，参与项目有Chrome、web组件、Polymer\nPatrick Hamann：热爱爬山、啤酒以及美食。\nDave McFarland：Web开发者，《CSS: The Missing Manual》和《JavaScript &amp; jQuery: The Missing Manual》的作者，\nL. David Baron：Mozilla开发者，CSS以及W3C标准的「外交官」。\nDaniel Glazman：W3C的CSS工作团队联合主席，企业家，软件工程师，极客，两个孩子的爸爸，通晓多国语言，喜欢鸭子。\nThe Chris Eppstein：爱恨分明，家庭美满，写代码，主导 LinkedIn 的样式。\nNatalie Weizenbaum：女程序员，SassCSS 的主设计师和开发者，在谷歌做 Dart 语言相关工作。\nBrad Frost：Web设计师、演讲者、写手、顾问、音乐家。\nMaxime Thirouin：前端工程师，自由职业者，UI&#x2F;UX开发者。\nMark Otto：在GitHub和Bootstrap工作，曾就职于Twitter，超级书呆子。\nSimon：UI设计师，CSS开发者\nConnor Sears：GitHub设计师\nRemy Sharp：他的推都是关于CSS尺寸单元的\nJonathan Snook：设计师、开发者、写手、演讲者。我在网上做些东西，我写的SMACSS。\n\n视频一个很有用的必看视频清单，这个清单是从 908a28 的 AllThingsSmitty&#x2F;must-watch-css 复制过来的，我已经在Twitter上跟他说了，非常感谢！\n2015\nmdo-ular CSS: Mark Otto, jQuery UK 30:06.\nCSS Architecture with SMACSS: Caleb Meredith, DevTips channel 30:15. 用SMACSS搭建CSS结构\nCSS Workflow from the Ground Up: Jonathan Snook, Generate conf 2015 46:06. 从头开始学习CSS工作流\n\n2014\nWhat Is a CSS Framework Anyway? | 究竟什么是CSS框架？: Harry Roberts, Industry Conf 48:48.\nCSS Is a Mess | 乱七八糟的CSS: Jonathan Snook, Beyond Tellerand 53:49.\n10 Commandments for Efficient CSS Architecture | 高效CSS结构十诫: Kushagra Gour, CSSConf.Asia 35:55.\nSlaying the Dragon: How to Refactor CSS for Maintainability | 杀掉巨龙：从可维护性方面考虑如何重构CSS: Alicia Liu, Front-Trends 33:21.\nCSS in Your Pocket：Mobile CSS Tips from the Trenches | 口袋中的CSS-移动端CSS开发要点: Angelina Fabbro, CSSConf.US 34:19.\nStyling and Animating Scalable Vector Graphics with CSS | 用CSS制作可扩展的矢量图动画: Sara Soueidan, CSSConf.EU 29:16.\nPlay Nice With CSS Tools and Methodologies | 学会使用CSS工具和方法: Brad Westfall, HTML5DevConf 42:47.\nCSS and the Critical Path | CSS以及关键路径: Patrick Hamann, CSSConf.EU 33:42.\nAll the Right Moves: How to Put Your UI in Motion | 走好每一步：如何让你的UI动起来: Val Head, Multi-Mania 45:49.\nPresent and Future of CSS Layout | CSS布局的发展: Tab Atkins, CSS Day 49:31.\nThinking Beyond “Scalable CSS” | 关于可扩展CSS的思考: Nicolas Gallagher, dotCSS 28:46.\nWeb Components &amp; the Future of CSS | WEB组件以及CSS的将来: Philip Walton, SFHTML5 40:02.\nCSS Performance Tooling | CSS性能工具: Addy Osmani, CSSConf.EU 46:27.\n3.14 Things I Didn’t Know About CSS3 | 关于CSS，我所不知道的14件事: Mathias Bynens, CSS Day 45:35.\nEffortless Style | 轻松的样式: Heydon Pickering, CSS Day 49:51.\nCSS: Yawn to Yay! | CSS：从无聊到精彩 Kyle Simpson, Front-Trends 39:04.\n\n2013\nWhen Bootstrap Attacks | 当Bootstrap开始发力: Pamela Fox, CSSConf.US 28:48.\nCSS in the 4th Dimension | CSS是第四维: Lea Verou, JSConf.Asia 44:49.\nAutomated CSS Testing | 自动化CSS测试: Jakob Mattsson, JSConf.Asia 42:07.\nCSSConf.EU Keynote | CSSConf.EU的基调: Nicole Sullivan, CSSConf.EU 20:57.\nCSS Application Architecture | CSS的应用架构: Nicolas Gallagher, SmashingConf 38:36.\nRealigning &amp; Refactoring UI | UI的调整和重构: Jina Bolton, SassConf 48:08.\nNormalizing Designs for Better Quality CSS | 提高CSS质量的规范化设计: Harry Roberts, CSSConf.EU 43:40.\nAutomating the Removal of Unused CSS | 自动清除无用的CSS: Addy Osmani, Velocity Europe Conference 5:57.\nThe Humble Border-Radius | 低调的Border-Radius: Lea Verou, Future of Web Design 37:07.\nThe Mind-blowing Power of Sass 3.3 | Sass那印象深刻的力量: Chris Eppstein, CSSConf.EU 38:54.\nFront-End Tools for the Young Developer | 年轻开发者的前端工具: Christian Vuerings, SF HTML5 User Group 14:16.\nMaths-Powered Transforms for Creating 3D Shapes | Maths-创建3D图形的强力转换器: Ana-Maria Tudor, CSSConf.EU 30:27.\nSass and OOCSS Sitting in a Tree K-I-S-S-I-N-G | Sass和面向对象CSS完美搭配: Nicole Sullivan, TXJS 27:50.\nCSS Levels Up | 提升CSS等级: Angelina Fabbro, CSSConf.EU 31:38.\nArchitecting Scalable CSS | 搭建可扩展的CSS: Harry Roberts, Beyond Tellerand 41:57.\nMore CSS Secrets: Another 10 Things You May Not Know about CSS | 更多的CSS秘密：CSS不为人知的另外10件事: Lea Verou, W3Conf 60:39.\nAtomic Cascading Style Sheets: Renato Iwashima, HTML5DevConf 52:33.\n\n#2012\nOpen Source Tools and Libraries for Designers | 设计师的开源工具以及资源库: Julie Ann Horvath, HTML5DevConf 29:39.\nGitHub’s CSS Performance | GitHub的CSS表现: Jon Rohan, CSS Dev Conf 40:50.\n\n2010\nHandcrafted CSS | 手写CSS: Dan Cederholm, Build Conference 44:29.\nThe Top 5 Mistakes of Massive CSS | 大规模CSS中最容易出现的5个错误: Nicole Sullivan, Build Conference 37:53.\n\n有影响力的书具有广泛影响且值得阅读的前端经典书籍。\n\n待补充\n\n知名网站值得关注的前端技术站点。\n中文站点\n伯乐在线前端频道：伯乐前端分享 Web 前端开发，包括 JavaScript、CSS 和 HTML5 开发技术，前端相关的行业动态。\n\n英文站点\n待补充\n\n微博、微信公众号* 前端大全 微博：@前端大全 * 前端大全：专注分享Web前端相关的内容，包括 JavaScript、CSS 和 HTML5 技术文章、工具资源、精选课程和Web技术领域热点资讯。 * UI设计达人：分享 UI 设计精选文章、案例、行业趋势、课程和书籍。 * 网页设计精选：分享网页设计精选文章、案例、行业趋势、课程和书籍。\n博客中文博客\n待补充\n\n英文博客\n待补充\n\n","categories":["CSS资源大全"],"tags":["CSS"]},{"title":"Collection - LinkedList源码解析","url":"/2023/02/19/Collection%20-%20LinkedList%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","content":"Collection - LinkedList源码解析\n本文主要对Collection - LinkedList进行源码解析。\n\n\nJDK版本\n参考\n概述\nLinkedLists实现\n底层数据结构\n构造函数\ngetFirst(), getLast()\nremoveFirest(), removeLast(), remove(e), remove(index)\nadd()\naddAll()\nclear()\nPositional Access 方法\n查找操作\nQueue 方法\nDeque 方法\n\n\n\nJDK版本\nJDK 1.8.0_110\n\n参考\nJava LinkedList源码剖析 结合源码对LinkedList进行讲解 http://www.cnblogs.com/CarpenterLee/p/5457150.html\n\n概述LinkedList_同时实现了_List_接口和_Deque_接口，也就是说它既可以看作一个顺序容器，又可以看作一个队列(*Queue*)，同时又可以看作一个栈(*Stack*)。这样看来，*LinkedList_简直就是个全能冠军。当你需要使用栈或者队列时，可以考虑使用_LinkedList*，一方面是因为Java官方已经声明不建议使用_Stack_类，更遗憾的是，Java里根本没有一个叫做_Queue_的类(它是个接口名字)。关于栈或队列，现在的首选是_ArrayDeque，它有着比_LinkedList_(当作栈或队列使用时)有着更好的性能。\n\n_LinkedList_的实现方式决定了所有跟下标相关的操作都是线性时间，而在首段或者末尾删除元素只需要常数时间。为追求效率_LinkedList_没有实现同步(synchronized)，如果需要多个线程并发访问，可以先采用Collections.synchronizedList()方法对其进行包装。\nLinkedLists实现底层数据结构_LinkedList_底层通过双向链表实现，本节将着重讲解插入和删除元素时双向链表的维护过程，也即是之间解跟_List_接口相关的函数，而将_Queue_和_Stack_以及_Deque_相关的知识放在下一节讲。双向链表的每个节点用内部类_Node_表示。_LinkedList_通过first和last引用分别指向链表的第一个和最后一个元素。注意这里没有所谓的哑元，当链表为空的时候first和last都指向null。\ntransient int size = 0;/** * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || *            (first.prev == null &amp;&amp; first.item != null) */transient Node&lt;E&gt; first;/** * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || *            (last.next == null &amp;&amp; last.item != null) */transient Node&lt;E&gt; last;\n\n\n\n其中Node是私有的内部类:\nprivate static class Node&lt;E&gt; &#123;    E item;    Node&lt;E&gt; next;    Node&lt;E&gt; prev;    Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123;        this.item = element;        this.next = next;        this.prev = prev;    &#125;&#125;\n\n\n\n构造函数/** * Constructs an empty list. */public LinkedList() &#123;&#125;/** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection&#x27;s * iterator. * * @param  c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */public LinkedList(Collection&lt;? extends E&gt; c) &#123;    this();    addAll(c);&#125;\n\n\n\ngetFirst(), getLast()获取第一个元素， 和获取最后一个元素:\n/** * Returns the first element in this list. * * @return the first element in this list * @throws NoSuchElementException if this list is empty */public E getFirst() &#123;    final Node&lt;E&gt; f = first;    if (f == null)        throw new NoSuchElementException();    return f.item;&#125;/** * Returns the last element in this list. * * @return the last element in this list * @throws NoSuchElementException if this list is empty */public E getLast() &#123;    final Node&lt;E&gt; l = last;    if (l == null)        throw new NoSuchElementException();    return l.item;&#125;\n\n\n\nremoveFirest(), removeLast(), remove(e), remove(index)remove()方法也有两个版本，一个是删除跟指定元素相等的第一个元素remove(Object o)，另一个是删除指定下标处的元素remove(int index)。\n\n删除元素 - 指的是删除第一次出现的这个元素, 如果没有这个元素，则返回false；判读的依据是equals方法， 如果equals，则直接unlink这个node；由于LinkedList可存放null元素，故也可以删除第一次出现null的元素；\n/** * Removes the first occurrence of the specified element from this list, * if it is present.  If this list does not contain the element, it is * unchanged.  More formally, removes the element with the lowest index * &#123;@code i&#125; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt; * (if such an element exists).  Returns &#123;@code true&#125; if this list * contained the specified element (or equivalently, if this list * changed as a result of the call). * * @param o element to be removed from this list, if present * @return &#123;@code true&#125; if this list contained the specified element */public boolean remove(Object o) &#123;    if (o == null) &#123;        for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;            if (x.item == null) &#123;                unlink(x);                return true;            &#125;        &#125;    &#125; else &#123;        for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;            if (o.equals(x.item)) &#123;                unlink(x);                return true;            &#125;        &#125;    &#125;    return false;&#125;/** * Unlinks non-null node x. */E unlink(Node&lt;E&gt; x) &#123;    // assert x != null;    final E element = x.item;    final Node&lt;E&gt; next = x.next;    final Node&lt;E&gt; prev = x.prev;    if (prev == null) &#123;// 第一个元素        first = next;    &#125; else &#123;        prev.next = next;        x.prev = null;    &#125;    if (next == null) &#123;// 最后一个元素        last = prev;    &#125; else &#123;        next.prev = prev;        x.next = null;    &#125;    x.item = null; // GC    size--;    modCount++;    return element;&#125;\n\n\n\nremove(int index)使用的是下标计数， 只需要判断该index是否有元素即可，如果有则直接unlink这个node。\n/** * Removes the element at the specified position in this list.  Shifts any * subsequent elements to the left (subtracts one from their indices). * Returns the element that was removed from the list. * * @param index the index of the element to be removed * @return the element previously at the specified position * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123;    checkElementIndex(index);    return unlink(node(index));&#125;\n\n\n\n删除head元素:\n/** * Removes and returns the first element from this list. * * @return the first element from this list * @throws NoSuchElementException if this list is empty */public E removeFirst() &#123;    final Node&lt;E&gt; f = first;    if (f == null)        throw new NoSuchElementException();    return unlinkFirst(f);&#125;\n\n\n\n/** * Unlinks non-null first node f. */private E unlinkFirst(Node&lt;E&gt; f) &#123;    // assert f == first &amp;&amp; f != null;    final E element = f.item;    final Node&lt;E&gt; next = f.next;    f.item = null;    f.next = null; // help GC    first = next;    if (next == null)        last = null;    else        next.prev = null;    size--;    modCount++;    return element;&#125;\n\n\n\n删除last元素:\n/**    * Removes and returns the last element from this list.    *    * @return the last element from this list    * @throws NoSuchElementException if this list is empty    */   public E removeLast() &#123;       final Node&lt;E&gt; l = last;       if (l == null)           throw new NoSuchElementException();       return unlinkLast(l);   &#125;      /**    * Unlinks non-null last node l.    */   private E unlinkLast(Node&lt;E&gt; l) &#123;       // assert l == last &amp;&amp; l != null;       final E element = l.item;       final Node&lt;E&gt; prev = l.prev;       l.item = null;       l.prev = null; // help GC       last = prev;       if (prev == null)           first = null;       else           prev.next = null;       size--;       modCount++;       return element;   &#125;\n\n\n\nadd()_add()_方法有两个版本，一个是add(E e)，该方法在_LinkedList_的末尾插入元素，因为有last指向链表末尾，在末尾插入元素的花费是常数时间。只需要简单修改几个相关引用即可；另一个是add(int index, E element)，该方法是在指定下表处插入元素，需要先通过线性查找找到具体位置，然后修改相关引用完成插入操作。\n/** * Appends the specified element to the end of this list. * * &lt;p&gt;This method is equivalent to &#123;@link #addLast&#125;. * * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123;    linkLast(e);    return true;&#125;/** * Links e as last element. */void linkLast(E e) &#123;    final Node&lt;E&gt; l = last;    final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null);    last = newNode;    if (l == null)        first = newNode;    else        l.next = newNode;    size++;    modCount++;&#125;\n\n\n\n\nadd(int index, E element), 当index&#x3D;&#x3D;size时，等同于add(E e); 如果不是，则分两步: 1.先根据index找到要插入的位置,即node(index)方法；2.修改引用，完成插入操作。\n/** * Inserts the specified element at the specified position in this list. * Shifts the element currently at that position (if any) and any * subsequent elements to the right (adds one to their indices). * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123;    checkPositionIndex(index);    if (index == size)        linkLast(element);    else        linkBefore(element, node(index));&#125;\n\n\n\n上面代码中的node(int index)函数有一点小小的trick，因为链表双向的，可以从开始往后找，也可以从结尾往前找，具体朝那个方向找取决于条件index &lt; (size &gt;&gt; 1)，也即是index是靠近前端还是后端。从这里也可以看出，linkedList通过index检索元素的效率没有arrayList高。\n/** * Returns the (non-null) Node at the specified element index. */Node&lt;E&gt; node(int index) &#123;    // assert isElementIndex(index);    if (index &lt; (size &gt;&gt; 1)) &#123;        Node&lt;E&gt; x = first;        for (int i = 0; i &lt; index; i++)            x = x.next;        return x;    &#125; else &#123;        Node&lt;E&gt; x = last;        for (int i = size - 1; i &gt; index; i--)            x = x.prev;        return x;    &#125;&#125;\n\n\n\naddAll()addAll(index, c) 实现方式并不是直接调用add(index,e)来实现，主要是因为效率的问题，另一个是fail-fast中modCount只会增加1次；\n/** * Appends all of the elements in the specified collection to the end of * this list, in the order that they are returned by the specified * collection&#x27;s iterator.  The behavior of this operation is undefined if * the specified collection is modified while the operation is in * progress.  (Note that this will occur if the specified collection is * this list, and it&#x27;s nonempty.) * * @param c collection containing elements to be added to this list * @return &#123;@code true&#125; if this list changed as a result of the call * @throws NullPointerException if the specified collection is null */public boolean addAll(Collection&lt;? extends E&gt; c) &#123;    return addAll(size, c);&#125;/** * Inserts all of the elements in the specified collection into this * list, starting at the specified position.  Shifts the element * currently at that position (if any) and any subsequent elements to * the right (increases their indices).  The new elements will appear * in the list in the order that they are returned by the * specified collection&#x27;s iterator. * * @param index index at which to insert the first element *              from the specified collection * @param c collection containing elements to be added to this list * @return &#123;@code true&#125; if this list changed as a result of the call * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified collection is null */public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;    checkPositionIndex(index);    Object[] a = c.toArray();    int numNew = a.length;    if (numNew == 0)        return false;    Node&lt;E&gt; pred, succ;    if (index == size) &#123;        succ = null;        pred = last;    &#125; else &#123;        succ = node(index);        pred = succ.prev;    &#125;    for (Object o : a) &#123;        @SuppressWarnings(&quot;unchecked&quot;) E e = (E) o;        Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null);        if (pred == null)            first = newNode;        else            pred.next = newNode;        pred = newNode;    &#125;    if (succ == null) &#123;        last = pred;    &#125; else &#123;        pred.next = succ;        succ.prev = pred;    &#125;    size += numNew;    modCount++;    return true;&#125;\n\n\n\nclear()为了让GC更快可以回收放置的元素，需要将node之间的引用关系赋空。\n/** * Removes all of the elements from this list. * The list will be empty after this call returns. */public void clear() &#123;    // Clearing all of the links between nodes is &quot;unnecessary&quot;, but:    // - helps a generational GC if the discarded nodes inhabit    //   more than one generation    // - is sure to free memory even if there is a reachable Iterator    for (Node&lt;E&gt; x = first; x != null; ) &#123;        Node&lt;E&gt; next = x.next;        x.item = null;        x.next = null;        x.prev = null;        x = next;    &#125;    first = last = null;    size = 0;    modCount++;&#125;\n\n\n\n#Positional Access 方法通过index获取元素\n/** * Returns the element at the specified position in this list. * * @param index index of the element to return * @return the element at the specified position in this list * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E get(int index) &#123;    checkElementIndex(index);    return node(index).item;&#125;\n\n\n\n将某个位置的元素重新赋值:\n/** * Replaces the element at the specified position in this list with the * specified element. * * @param index index of the element to replace * @param element element to be stored at the specified position * @return the element previously at the specified position * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E set(int index, E element) &#123;    checkElementIndex(index);    Node&lt;E&gt; x = node(index);    E oldVal = x.item;    x.item = element;    return oldVal;&#125;\n\n\n\n将元素插入到指定index位置:\n/** * Inserts the specified element at the specified position in this list. * Shifts the element currently at that position (if any) and any * subsequent elements to the right (adds one to their indices). * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123;    checkPositionIndex(index);    if (index == size)        linkLast(element);    else        linkBefore(element, node(index));&#125;\n\n\n\n删除指定位置的元素:\n/** * Removes the element at the specified position in this list.  Shifts any * subsequent elements to the left (subtracts one from their indices). * Returns the element that was removed from the list. * * @param index the index of the element to be removed * @return the element previously at the specified position * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123;    checkElementIndex(index);    return unlink(node(index));&#125;\n\n\n\n其它位置的方法:\n/** * Tells if the argument is the index of an existing element. */private boolean isElementIndex(int index) &#123;    return index &gt;= 0 &amp;&amp; index &lt; size;&#125;/** * Tells if the argument is the index of a valid position for an * iterator or an add operation. */private boolean isPositionIndex(int index) &#123;    return index &gt;= 0 &amp;&amp; index &lt;= size;&#125;/** * Constructs an IndexOutOfBoundsException detail message. * Of the many possible refactorings of the error handling code, * this &quot;outlining&quot; performs best with both server and client VMs. */private String outOfBoundsMsg(int index) &#123;    return &quot;Index: &quot;+index+&quot;, Size: &quot;+size;&#125;private void checkElementIndex(int index) &#123;    if (!isElementIndex(index))        throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;private void checkPositionIndex(int index) &#123;    if (!isPositionIndex(index))        throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;\n\n\n\n\n\n查找操作查找操作的本质是查找元素的下标:\n查找第一次出现的index, 如果找不到返回-1；\n/** * Returns the index of the first occurrence of the specified element * in this list, or -1 if this list does not contain the element. * More formally, returns the lowest index &#123;@code i&#125; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt;, * or -1 if there is no such index. * * @param o element to search for * @return the index of the first occurrence of the specified element in *         this list, or -1 if this list does not contain the element */public int indexOf(Object o) &#123;    int index = 0;    if (o == null) &#123;        for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;            if (x.item == null)                return index;            index++;        &#125;    &#125; else &#123;        for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;            if (o.equals(x.item))                return index;            index++;        &#125;    &#125;    return -1;&#125;\n\n\n\n查找最后一次出现的index, 如果找不到返回-1；\n/** * Returns the index of the last occurrence of the specified element * in this list, or -1 if this list does not contain the element. * More formally, returns the highest index &#123;@code i&#125; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt;, * or -1 if there is no such index. * * @param o element to search for * @return the index of the last occurrence of the specified element in *         this list, or -1 if this list does not contain the element */public int lastIndexOf(Object o) &#123;    int index = size;    if (o == null) &#123;        for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123;            index--;            if (x.item == null)                return index;        &#125;    &#125; else &#123;        for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123;            index--;            if (o.equals(x.item))                return index;        &#125;    &#125;    return -1;&#125;\n\n\n\nQueue 方法/** * Retrieves, but does not remove, the head (first element) of this list. * * @return the head of this list, or &#123;@code null&#125; if this list is empty * @since 1.5 */public E peek() &#123;    final Node&lt;E&gt; f = first;    return (f == null) ? null : f.item;&#125;/** * Retrieves, but does not remove, the head (first element) of this list. * * @return the head of this list * @throws NoSuchElementException if this list is empty * @since 1.5 */public E element() &#123;    return getFirst();&#125;/** * Retrieves and removes the head (first element) of this list. * * @return the head of this list, or &#123;@code null&#125; if this list is empty * @since 1.5 */public E poll() &#123;    final Node&lt;E&gt; f = first;    return (f == null) ? null : unlinkFirst(f);&#125;/** * Retrieves and removes the head (first element) of this list. * * @return the head of this list * @throws NoSuchElementException if this list is empty * @since 1.5 */public E remove() &#123;    return removeFirst();&#125;/** * Adds the specified element as the tail (last element) of this list. * * @param e the element to add * @return &#123;@code true&#125; (as specified by &#123;@link Queue#offer&#125;) * @since 1.5 */public boolean offer(E e) &#123;    return add(e);&#125;\n\n\n\nDeque 方法/** * Inserts the specified element at the front of this list. * * @param e the element to insert * @return &#123;@code true&#125; (as specified by &#123;@link Deque#offerFirst&#125;) * @since 1.6 */public boolean offerFirst(E e) &#123;    addFirst(e);    return true;&#125;/** * Inserts the specified element at the end of this list. * * @param e the element to insert * @return &#123;@code true&#125; (as specified by &#123;@link Deque#offerLast&#125;) * @since 1.6 */public boolean offerLast(E e) &#123;    addLast(e);    return true;&#125;/** * Retrieves, but does not remove, the first element of this list, * or returns &#123;@code null&#125; if this list is empty. * * @return the first element of this list, or &#123;@code null&#125; *         if this list is empty * @since 1.6 */public E peekFirst() &#123;    final Node&lt;E&gt; f = first;    return (f == null) ? null : f.item; &#125;/** * Retrieves, but does not remove, the last element of this list, * or returns &#123;@code null&#125; if this list is empty. * * @return the last element of this list, or &#123;@code null&#125; *         if this list is empty * @since 1.6 */public E peekLast() &#123;    final Node&lt;E&gt; l = last;    return (l == null) ? null : l.item;&#125;/** * Retrieves and removes the first element of this list, * or returns &#123;@code null&#125; if this list is empty. * * @return the first element of this list, or &#123;@code null&#125; if *     this list is empty * @since 1.6 */public E pollFirst() &#123;    final Node&lt;E&gt; f = first;    return (f == null) ? null : unlinkFirst(f);&#125;/** * Retrieves and removes the last element of this list, * or returns &#123;@code null&#125; if this list is empty. * * @return the last element of this list, or &#123;@code null&#125; if *     this list is empty * @since 1.6 */public E pollLast() &#123;    final Node&lt;E&gt; l = last;    return (l == null) ? null : unlinkLast(l);&#125;/** * Pushes an element onto the stack represented by this list.  In other * words, inserts the element at the front of this list. * * &lt;p&gt;This method is equivalent to &#123;@link #addFirst&#125;. * * @param e the element to push * @since 1.6 */public void push(E e) &#123;    addFirst(e);&#125;/** * Pops an element from the stack represented by this list.  In other * words, removes and returns the first element of this list. * * &lt;p&gt;This method is equivalent to &#123;@link #removeFirst()&#125;. * * @return the element at the front of this list (which is the top *         of the stack represented by this list) * @throws NoSuchElementException if this list is empty * @since 1.6 */public E pop() &#123;    return removeFirst();&#125;/** * Removes the first occurrence of the specified element in this * list (when traversing the list from head to tail).  If the list * does not contain the element, it is unchanged. * * @param o element to be removed from this list, if present * @return &#123;@code true&#125; if the list contained the specified element * @since 1.6 */public boolean removeFirstOccurrence(Object o) &#123;    return remove(o);&#125;/** * Removes the last occurrence of the specified element in this * list (when traversing the list from head to tail).  If the list * does not contain the element, it is unchanged. * * @param o element to be removed from this list, if present * @return &#123;@code true&#125; if the list contained the specified element * @since 1.6 */public boolean removeLastOccurrence(Object o) &#123;    if (o == null) &#123;        for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123;            if (x.item == null) &#123;                unlink(x);                return true;            &#125;        &#125;    &#125; else &#123;        for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123;            if (o.equals(x.item)) &#123;                unlink(x);                return true;            &#125;        &#125;    &#125;    return false;&#125;\n\n","categories":["Java集合框架"],"tags":["Collection LinkedList"]},{"title":"Collection - PriorityQueue源码解析","url":"/2023/02/19/Collection%20-%20PriorityQueue%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","content":"Collection - PriorityQueue源码解析\n本文主要对Collection - PriorityQueue进行源码解析。\n\n\nJDK版本\n参考\n概述\n方法剖析\nadd()和offer()\nelement()和peek()\nremove()和poll()\nremove(Object o)\n\n\n\nJDK版本\nJDK 1.8.0_110\n\n参考\n深入理解Java PriorityQueue 结合源码对PriorityQueue进行讲解 http://www.cnblogs.com/CarpenterLee/p/5488070.html\n\n概述前面以Java ArrayDeque_为例讲解了_Stack_和_Queue，其实还有一种特殊的队列叫做_PriorityQueue_，即优先队列。优先队列的作用是能保证每次取出的元素都是队列中权值最小的(Java的优先队列每次取最小元素，C++的优先队列每次取最大元素)。这里牵涉到了大小关系，元素大小的评判可以通过元素本身的自然顺序(*natural ordering*)，也可以通过构造时传入的比较器(Comparator，类似于C++的仿函数)。\nJava中_PriorityQueue_实现了_Queue_接口，不允许放入null元素；其通过堆实现，具体说是通过完全二叉树(complete binary tree)实现的小顶堆(任意一个非叶子节点的权值，都不大于其左右子节点的权值)，也就意味着可以通过数组来作为_PriorityQueue_的底层实现。\n\n上图中我们给每个元素按照层序遍历的方式进行了编号，如果你足够细心，会发现父节点和子节点的编号是有联系的，更确切的说父子节点的编号之间有如下关系:\nleftNo = parentNo*2+1rightNo = parentNo*2+2parentNo = (nodeNo-1)/2\n\n通过上述三个公式，可以轻易计算出某个节点的父节点以及子节点的下标。这也就是为什么可以直接用数组来存储堆的原因。\n*PriorityQueue_的peek()和element操作是常数时间，add(), offer(), 无参数的remove()以及poll()方法的时间复杂度都是_log(N)*。\n方法剖析add()和offer()add(E e)和offer(E e)的语义相同，都是向优先队列中插入元素，只是Queue接口规定二者对插入失败时的处理不同，前者在插入失败时抛出异常，后则则会返回false。对于_PriorityQueue_这两个方法其实没什么差别。\n\n新加入的元素可能会破坏小顶堆的性质，因此需要进行必要的调整。\n//offer(E e)public boolean offer(E e) &#123;    if (e == null)//不允许放入null元素        throw new NullPointerException();    modCount++;    int i = size;    if (i &gt;= queue.length)        grow(i + 1);//自动扩容    size = i + 1;    if (i == 0)//队列原来为空，这是插入的第一个元素        queue[0] = e;    else        siftUp(i, e);//调整    return true;&#125;\n\n\n\n上述代码中，扩容函数grow()类似于ArrayList里的grow()函数，就是再申请一个更大的数组，并将原数组的元素复制过去，这里不再赘述。需要注意的是siftUp(int k, E x)方法，该方法用于插入元素x并维持堆的特性。\n//siftUp()private void siftUp(int k, E x) &#123;    while (k &gt; 0) &#123;        int parent = (k - 1) &gt;&gt;&gt; 1;//parentNo = (nodeNo-1)/2        Object e = queue[parent];        if (comparator.compare(x, (E) e) &gt;= 0)//调用比较器的比较方法            break;        queue[k] = e;        k = parent;    &#125;    queue[k] = x;&#125;\n\n\n\n新加入的元素x可能会破坏小顶堆的性质，因此需要进行调整。调整的过程为** : 从k指定的位置开始，将x逐层与当前点的parent进行比较并交换，直到满足x &gt;= queue[parent]为止**。注意这里的比较可以是元素的自然顺序，也可以是依靠比较器的顺序。\nelement()和peek()element()和peek()的语义完全相同，都是获取但不删除队首元素，也就是队列中权值最小的那个元素，二者唯一的区别是当方法失败时前者抛出异常，后者返回null。根据小顶堆的性质，堆顶那个元素就是全局最小的那个；由于堆用数组表示，根据下标关系，0下标处的那个元素既是堆顶元素。所以直接返回数组0下标处的那个元素即可。\n\n代码也就非常简洁:\n//peek()public E peek() &#123;    if (size == 0)        return null;    return (E) queue[0];//0下标处的那个元素就是最小的那个&#125;\n\n\n\nremove()和poll()remove()和poll()方法的语义也完全相同，都是获取并删除队首元素，区别是当方法失败时前者抛出异常，后者返回null。由于删除操作会改变队列的结构，为维护小顶堆的性质，需要进行必要的调整。\n 代码如下:\npublic E poll() &#123;    if (size == 0)        return null;    int s = --size;    modCount++;    E result = (E) queue[0];//0下标处的那个元素就是最小的那个    E x = (E) queue[s];    queue[s] = null;    if (s != 0)        siftDown(0, x);//调整    return result;&#125;\n\n\n\n上述代码首先记录0下标处的元素，并用最后一个元素替换0下标位置的元素，之后调用siftDown()方法对堆进行调整，最后返回原来0下标处的那个元素(也就是最小的那个元素)。重点是siftDown(int k, E x)方法，该方法的作用是从k指定的位置开始，将x逐层向下与当前点的左右孩子中较小的那个交换，直到x小于或等于左右孩子中的任何一个为止。\n//siftDown()private void siftDown(int k, E x) &#123;    int half = size &gt;&gt;&gt; 1;    while (k &lt; half) &#123;    \t//首先找到左右孩子中较小的那个，记录到c里，并用child记录其下标        int child = (k &lt;&lt; 1) + 1;//leftNo = parentNo*2+1        Object c = queue[child];        int right = child + 1;        if (right &lt; size &amp;&amp;            comparator.compare((E) c, (E) queue[right]) &gt; 0)            c = queue[child = right];        if (comparator.compare(x, (E) c) &lt;= 0)            break;        queue[k] = c;//然后用c取代原来的值        k = child;    &#125;    queue[k] = x;&#125;\n\n\n\nremove(Object o)remove(Object o)方法用于删除队列中跟o相等的某一个元素(如果有多个相等，只删除一个)，该方法不是_Queue_接口内的方法，而是_Collection_接口的方法。由于删除操作会改变队列结构，所以要进行调整；又由于删除元素的位置可能是任意的，所以调整过程比其它函数稍加繁琐。具体来说，remove(Object o)可以分为2种情况: 1. 删除的是最后一个元素。直接删除即可，不需要调整。2. 删除的不是最后一个元素，从删除点开始以最后一个元素为参照调用一次siftDown()即可。此处不再赘述。\n\n具体代码如下:\n//remove(Object o)public boolean remove(Object o) &#123;\t//通过遍历数组的方式找到第一个满足o.equals(queue[i])元素的下标    int i = indexOf(o);    if (i == -1)        return false;    int s = --size;    if (s == i) //情况1        queue[i] = null;    else &#123;        E moved = (E) queue[s];        queue[s] = null;        siftDown(i, moved);//情况2        ......    &#125;    return true;&#125;\n\n","categories":["Java集合框架"],"tags":["Collection - PriorityQueue"]},{"title":"Collection - ArrayList 源码解析","url":"/2023/02/19/Collection%20-%20ArrayList%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","content":"Collection - ArrayList 源码解析\n\n本文主要对Collection - ArrayList进行源码解析。\n\n\nJDK版本\n参考\n概述\nArrayList的实现\n底层数据结构\n构造函数\n自动扩容\nadd(), addAll()\nset()\nget()\nremove()\ntrimToSize()\nindexOf(), lastIndexOf()\nFail-Fast机制:\n\n\n\nJDK版本\nJDK 1.8.0_110\n\n参考\n深入Java集合学习系列: ArrayList的实现原理 http://zhangshixi.iteye.com/blog/674856\nJava ArrayList源码剖析 结合源码对ArrayList进行讲解 http://www.cnblogs.com/CarpenterLee/p/5419880.html\n\n概述_ArrayList_实现了_List_接口，是顺序容器，即元素存放的数据与放进去的顺序相同，允许放入null元素，底层通过数组实现。除该类未实现同步外，其余跟_Vector_大致相同。每个_ArrayList_都有一个容量(capacity)，表示底层数组的实际大小，容器内存储元素的个数不能多于当前容量。当向容器中添加元素时，如果容量不足，容器会自动增大底层数组的大小。前面已经提过，Java泛型只是编译器提供的语法糖，所以这里的数组是一个Object数组，以便能够容纳任何类型的对象。\n\nsize(), isEmpty(), get(), set()方法均能在常数时间内完成，add()方法的时间开销跟插入位置有关，addAll()方法的时间开销跟添加元素的个数成正比。其余方法大都是线性时间。\n为追求效率，ArrayList没有实现同步(synchronized)，如果需要多个线程并发访问，用户可以手动同步，也可使用Vector替代。\nArrayList的实现底层数据结构/**    * The array buffer into which the elements of the ArrayList are stored.    * The capacity of the ArrayList is the length of this array buffer. Any    * empty ArrayList with elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA    * will be expanded to DEFAULT_CAPACITY when the first element is added.    */   transient Object[] elementData; // non-private to simplify nested class access   /**    * The size of the ArrayList (the number of elements it contains).    *    * @serial    */   private int size;\n\n\n\n构造函数/**    * Constructs an empty list with the specified initial capacity.    *    * @param  initialCapacity  the initial capacity of the list    * @throws IllegalArgumentException if the specified initial capacity    *         is negative    */   public ArrayList(int initialCapacity) &#123;       if (initialCapacity &gt; 0) &#123;           this.elementData = new Object[initialCapacity];       &#125; else if (initialCapacity == 0) &#123;           this.elementData = EMPTY_ELEMENTDATA;       &#125; else &#123;           throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+                                              initialCapacity);       &#125;   &#125;   /**    * Constructs an empty list with an initial capacity of ten.    */   public ArrayList() &#123;       this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;   &#125;   /**    * Constructs a list containing the elements of the specified    * collection, in the order they are returned by the collection&#x27;s    * iterator.    *    * @param c the collection whose elements are to be placed into this list    * @throws NullPointerException if the specified collection is null    */   public ArrayList(Collection&lt;? extends E&gt; c) &#123;       elementData = c.toArray();       if ((size = elementData.length) != 0) &#123;           // c.toArray might (incorrectly) not return Object[] (see 6260652)           if (elementData.getClass() != Object[].class)               elementData = Arrays.copyOf(elementData, size, Object[].class);       &#125; else &#123;           // replace with empty array.           this.elementData = EMPTY_ELEMENTDATA;       &#125;   &#125;\n\n\n\n自动扩容每当向数组中添加元素时，都要去检查添加后元素的个数是否会超出当前数组的长度，如果超出，数组将会进行扩容，以满足添加数据的需求。数组扩容通过一个公开的方法ensureCapacity(int minCapacity)来实现。在实际添加大量元素前，我也可以使用ensureCapacity来手动增加ArrayList实例的容量，以减少递增式再分配的数量。\n数组进行扩容时，会将老数组中的元素重新拷贝一份到新的数组中，每次数组容量的增长大约是其原容量的1.5倍。这种操作的代价是很高的，因此在实际使用时，我们应该尽量避免数组容量的扩张。当我们可预知要保存的元素的多少时，要在构造ArrayList实例时，就指定其容量，以避免数组扩容的发生。或者根据实际需求，通过调用ensureCapacity方法来手动增加ArrayList实例的容量。\n/** * Increases the capacity of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance, if * necessary, to ensure that it can hold at least the number of elements * specified by the minimum capacity argument. * * @param   minCapacity   the desired minimum capacity */public void ensureCapacity(int minCapacity) &#123;    int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA)        // any size if not default element table        ? 0        // larger than default for default empty table. It&#x27;s already        // supposed to be at default size.        : DEFAULT_CAPACITY;    if (minCapacity &gt; minExpand) &#123;        ensureExplicitCapacity(minCapacity);    &#125;&#125;private void ensureCapacityInternal(int minCapacity) &#123;    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);    &#125;    ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123;    modCount++;    // overflow-conscious code    if (minCapacity - elementData.length &gt; 0)        grow(minCapacity);&#125;/** * The maximum size of array to allocate. * Some VMs reserve some header words in an array. * Attempts to allocate larger arrays may result in * OutOfMemoryError: Requested array size exceeds VM limit */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/** * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity */private void grow(int minCapacity) &#123;    // overflow-conscious code    int oldCapacity = elementData.length;    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);    if (newCapacity - minCapacity &lt; 0)        newCapacity = minCapacity;    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)        newCapacity = hugeCapacity(minCapacity);    // minCapacity is usually close to size, so this is a win:    elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123;    if (minCapacity &lt; 0) // overflow        throw new OutOfMemoryError();    return (minCapacity &gt; MAX_ARRAY_SIZE) ?        Integer.MAX_VALUE :        MAX_ARRAY_SIZE;&#125;\n\n\n\n\nadd(), addAll()跟C++ 的_vector_不同，_ArrayList_没有push_back()方法，对应的方法是add(E e)，_ArrayList_也没有insert()方法，对应的方法是add(int index, E e)。这两个方法都是向容器中添加新元素，这可能会导致_capacity_不足，因此在添加元素之前，都需要进行剩余空间检查，如果需要则自动扩容。扩容操作最终是通过grow()方法完成的。\n/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123;    ensureCapacityInternal(size + 1);  // Increments modCount!!    elementData[size++] = e;    return true;&#125;/** * Inserts the specified element at the specified position in this * list. Shifts the element currently at that position (if any) and * any subsequent elements to the right (adds one to their indices). * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123;    rangeCheckForAdd(index);    ensureCapacityInternal(size + 1);  // Increments modCount!!    System.arraycopy(elementData, index, elementData, index + 1,                     size - index);    elementData[index] = element;    size++;&#125;\n\n\n\n\nadd(int index, E e)需要先对元素进行移动，然后完成插入操作，也就意味着该方法有着线性的时间复杂度。\naddAll()方法能够一次添加多个元素，根据位置不同也有两个把本，一个是在末尾添加的addAll(Collection&lt;? extends E&gt; c)方法，一个是从指定位置开始插入的addAll(int index, Collection&lt;? extends E&gt; c)方法。跟add()方法类似，在插入之前也需要进行空间检查，如果需要则自动扩容；如果从指定位置插入，也会存在移动元素的情况。 addAll()的时间复杂度不仅跟插入元素的多少有关，也跟插入的位置相关。\n/** * Appends all of the elements in the specified collection to the end of * this list, in the order that they are returned by the * specified collection&#x27;s Iterator.  The behavior of this operation is * undefined if the specified collection is modified while the operation * is in progress.  (This implies that the behavior of this call is * undefined if the specified collection is this list, and this * list is nonempty.) * * @param c collection containing elements to be added to this list * @return &lt;tt&gt;true&lt;/tt&gt; if this list changed as a result of the call * @throws NullPointerException if the specified collection is null */public boolean addAll(Collection&lt;? extends E&gt; c) &#123;    Object[] a = c.toArray();    int numNew = a.length;    ensureCapacityInternal(size + numNew);  // Increments modCount    System.arraycopy(a, 0, elementData, size, numNew);    size += numNew;    return numNew != 0;&#125;/** * Inserts all of the elements in the specified collection into this * list, starting at the specified position.  Shifts the element * currently at that position (if any) and any subsequent elements to * the right (increases their indices).  The new elements will appear * in the list in the order that they are returned by the * specified collection&#x27;s iterator. * * @param index index at which to insert the first element from the *              specified collection * @param c collection containing elements to be added to this list * @return &lt;tt&gt;true&lt;/tt&gt; if this list changed as a result of the call * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified collection is null */public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;    rangeCheckForAdd(index);    Object[] a = c.toArray();    int numNew = a.length;    ensureCapacityInternal(size + numNew);  // Increments modCount    int numMoved = size - index;    if (numMoved &gt; 0)        System.arraycopy(elementData, index, elementData, index + numNew,                         numMoved);    System.arraycopy(a, 0, elementData, index, numNew);    size += numNew;    return numNew != 0;&#125;\n\n\n\nset()既然底层是一个数组_ArrayList_的set()方法也就变得非常简单，直接对数组的指定位置赋值即可。\npublic E set(int index, E element) &#123;    rangeCheck(index);//下标越界检查    E oldValue = elementData(index);    elementData[index] = element;//赋值到指定位置，复制的仅仅是引用    return oldValue;&#125;\n\n\n\nget()get()方法同样很简单，唯一要注意的是由于底层数组是Object[]，得到元素后需要进行类型转换。\npublic E get(int index) &#123;    rangeCheck(index);    return (E) elementData[index];//注意类型转换&#125;\n\n\n\nremove()remove()方法也有两个版本，一个是remove(int index)删除指定位置的元素，另一个是remove(Object o)删除第一个满足o.equals(elementData[index])的元素。删除操作是add()操作的逆过程，需要将删除点之后的元素向前移动一个位置。需要注意的是为了让GC起作用，必须显式的为最后一个位置赋null值。\npublic E remove(int index) &#123;    rangeCheck(index);    modCount++;    E oldValue = elementData(index);    int numMoved = size - index - 1;    if (numMoved &gt; 0)        System.arraycopy(elementData, index+1, elementData, index, numMoved);    elementData[--size] = null; //清除该位置的引用，让GC起作用    return oldValue;&#125;\n\n\n\n关于Java GC这里需要特别说明一下，有了垃圾收集器并不意味着一定不会有内存泄漏。对象能否被GC的依据是是否还有引用指向它，上面代码中如果不手动赋null值，除非对应的位置被其他元素覆盖，否则原来的对象就一直不会被回收。\ntrimToSize()ArrayList还给我们提供了将底层数组的容量调整为当前列表保存的实际元素的大小的功能。它可以通过trimToSize方法来实现。代码如下:\n/** * Trims the capacity of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance to be the * list&#x27;s current size.  An application can use this operation to minimize * the storage of an &lt;tt&gt;ArrayList&lt;/tt&gt; instance. */public void trimToSize() &#123;    modCount++;    if (size &lt; elementData.length) &#123;        elementData = (size == 0)          ? EMPTY_ELEMENTDATA          : Arrays.copyOf(elementData, size);    &#125;&#125;\n\n\n\nindexOf(), lastIndexOf()获取元素的第一次出现的index:\n/**     * Returns the index of the first occurrence of the specified element     * in this list, or -1 if this list does not contain the element.     * More formally, returns the lowest index &lt;tt&gt;i&lt;/tt&gt; such that     * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt;,     * or -1 if there is no such index.     */    public int indexOf(Object o) &#123;        if (o == null) &#123;            for (int i = 0; i &lt; size; i++)                if (elementData[i]==null)                    return i;        &#125; else &#123;            for (int i = 0; i &lt; size; i++)                if (o.equals(elementData[i]))                    return i;        &#125;        return -1;    &#125;\n\n\n\n获取元素的最后一次出现的index:\n/** * Returns the index of the last occurrence of the specified element * in this list, or -1 if this list does not contain the element. * More formally, returns the highest index &lt;tt&gt;i&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt;, * or -1 if there is no such index. */public int lastIndexOf(Object o) &#123;    if (o == null) &#123;        for (int i = size-1; i &gt;= 0; i--)            if (elementData[i]==null)                return i;    &#125; else &#123;        for (int i = size-1; i &gt;= 0; i--)            if (o.equals(elementData[i]))                return i;    &#125;    return -1;&#125;\n\n\n\nFail-Fast机制:ArrayList也采用了快速失败的机制，通过记录modCount参数来实现。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。\n","categories":["Java集合框架"],"tags":["Collection ArrayList"]},{"title":"Collection 类关系图","url":"/2023/02/19/Collection%20%E7%B1%BB%E5%85%B3%E7%B3%BB%E5%9B%BE/","content":"Collection 类关系图\n\n本文主要介绍JDK中Collection和Map相关知识体系，后续章节将对主要对类进行源码解读。\n\n#知识体系结构\n介绍容器，就是可以容纳其他Java对象的对象。*Java Collections Framework(JCF)*为Java开发者提供了通用的容器，其始于JDK 1.2，优点是:\n\n降低编程难度\n提高程序性能\n提高API间的互操作性\n降低学习难度\n降低设计和实现相关API的难度\n增加程序的重用性\n\nJava容器里只能放对象，对于基本类型(int, long, float, double等)，需要将其包装成对象类型后(Integer, Long, Float, Double等)才能放到容器里。很多时候拆包装和解包装能够自动完成。这虽然会导致额外的性能和空间开销，但简化了设计和编程。\nCollection\n容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对(两个对象)的映射表。\n\nSetTreeSet基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。\nHashSet基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。\nLinkedHashSet具有 HashSet 的查找效率，且内部使用双向链表维护元素的插入顺序。\nListArrayList基于动态数组实现，支持随机访问。\nVector和 ArrayList 类似，但它是线程安全的。\nLinkedList基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。\nQueueLinkedList可以用它来实现双向队列。\nPriorityQueue基于堆结构实现，可以用它来实现优先队列。\nMapTreeMap基于红黑树实现。\nHashMap基于哈希表实现。\nHashTable和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程可以同时写入 HashTable 并且不会导致数据不一致。它是遗留类，不应该去使用它。现在可以使用 ConcurrentHashMap 来支持线程安全，并且 ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。\nLinkedHashMap使用双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用(LRU)顺序。\n参考内容\n\nCarpenterLee&#x2F;JCFInternals https://github.com/CarpenterLee/JCFInternals\n\n","categories":["Java集合框架"],"tags":["Collection"]},{"title":"Collection - Stack & Queue 源码解析","url":"/2023/02/19/Collection%20-%20Stack%20&%20Queue%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","content":"Collection - Stack &amp; Queue 源码解析\n本文主要对Collection - Stack &amp; Queue进行源码解析。\n\n\nJDK版本\n参考\nStack &amp; Queue概述\nQueue\nDeque\n方法剖析\naddFirst()\naddLast()\npollFirst()\npollLast()\npeekFirst()\npeekLast()\n\n\n\nJDK版本\nJDK 1.8.0_110\n\n参考Stack &amp; Queue概述Java里有一个叫做_Stack_的类，却没有叫做_Queue_的类(它是个接口名字)。当需要使用栈时，Java已不推荐使用_Stack_，而是推荐使用更高效的_ArrayDeque_；既然_Queue_只是一个接口，当需要使用队列时也就首选_ArrayDeque_了(次选是_LinkedList_)。\nQueueQueue_接口继承自Collection接口，除了最基本的Collection的方法之外，它还支持额外的_insertion, _extraction_和_inspection_操作。这里有两组格式，共6个方法，一组是抛出异常的实现；另外一组是返回值的实现(没有则返回null)。\nThrows exception\nReturns special value\nInsert\nadd(e)\noffer(e)\nRemove\nremove()\npoll()\nExamine\nelement()\npeek()\nDequeDeque是”double ended queue”, 表示双向的队列，英文读作”deck”. Deque 继承自 Queue接口，除了支持Queue的方法之外，还支持insert, remove和examine操作，由于Deque是双向的，所以可以对队列的头和尾都进行操作，它同时也支持两组格式，一组是抛出异常的实现；另外一组是返回值的实现(没有则返回null)。共12个方法如下:\n||First Element - Head|| Last Element - Tail || |——–|——–|——–|——–| ||Throws exception| Special value| Throws exception| Special value | |Insert| addFirst(e)| offerFirst(e)| addLast(e)| offerLast(e) | |Remove| removeFirst()| pollFirst()| removeLast()| pollLast() | |Examine| getFirst()| peekFirst()| getLast()| peekLast() |\n当把Deque当做FIFO的queue来使用时，元素是从deque的尾部添加，从头部进行删除的； 所以deque的部分方法是和queue是等同的。具体如下:\nQueue Method\nEquivalent Deque Method\nadd(e)\naddLast(e)\noffer(e)\nofferLast(e)\nremove()\nremoveFirst()\npoll()\npollFirst()\nelement()\ngetFirst()\npeek()\npeekFirst()\n_Deque_的含义是“double ended queue”，即双端队列，它既可以当作栈使用，也可以当作队列使用。下表列出了_Deque_与_Queue_相对应的接口:\nQueue Method\nEquivalent Deque Method\n说明\nadd(e)addLast(e)\n\n向队尾插入元素，失败则抛出异常\noffer(e)offerLast(e)\n\n向队尾插入元素，失败则返回false\nremove()removeFirst()\n\n获取并删除队首元素，失败则抛出异常\npoll()pollFirst()\n\n获取并删除队首元素，失败则返回null\nelement()getFirst()\n\n获取但不删除队首元素，失败则抛出异常\npeek()peekFirst()\n\n获取但不删除队首元素，失败则返回null\n下表列出了_Deque_与_Stack_对应的接口:\nStack Method\nEquivalent Deque Method\n说明\npush(e)addFirst(e)\n\n向栈顶插入元素，失败则抛出异常\n无\nofferFirst(e)\n\n向栈顶插入元素，失败则返回false\npop()removeFirst()\n\n获取并删除栈顶元素，失败则抛出异常\n无\npollFirst()\n\n获取并删除栈顶元素，失败则返回null\npeek()peekFirst()\n\n获取但不删除栈顶元素，失败则抛出异常\n无\npeekFirst()\n\n获取但不删除栈顶元素，失败则返回null\n上面两个表共定义了_Deque_的12个接口。添加，删除，取值都有两套接口，它们功能相同，区别是对失败情况的处理不同。一套接口遇到失败就会抛出异常，另一套遇到失败会返回特殊值(false或null)。除非某种实现对容量有限制，大多数情况下，添加操作是不会失败的。虽然_Deque_的接口有12个之多，但无非就是对容器的两端进行操作，或添加，或删除，或查看。明白了这一点讲解起来就会非常简单。\nArrayDeque_和_LinkedList_是_Deque_的两个通用实现，由于官方更推荐使用_AarryDeque_用作栈和队列，加之上一篇已经讲解过_LinkedList，本文将着重讲解_ArrayDeque_的具体实现。\n从名字可以看出_ArrayDeque_底层通过数组实现，为了满足可以同时在数组两端插入或删除元素的需求，该数组还必须是循环的，即**循环数组(circular array)**，也就是说数组的任何一点都可能被看作起点或者终点。_ArrayDeque_是非线程安全的(not thread-safe)，当多个线程同时使用的时候，需要程序员手动同步；另外，该容器不允许放入null元素。\n\n上图中我们看到，**head指向首端第一个有效元素，tail指向尾端第一个可以插入元素的空位**。因为是循环数组，所以head不一定总等于0，tail也不一定总是比head大。\n方法剖析addFirst()addFirst(E e)的作用是在_Deque_的首端插入元素，也就是在head的前面插入元素，在空间足够且下标没有越界的情况下，只需要将elements[--head] = e即可。\n\n实际需要考虑: 1.空间是否够用，以及2.下标是否越界的问题。上图中，如果head为0之后接着调用addFirst()，虽然空余空间还够用，但head为-1，下标越界了。下列代码很好的解决了这两个问题。\n//addFirst(E e)public void addFirst(E e) &#123;    if (e == null)//不允许放入null        throw new NullPointerException();    elements[head = (head - 1) &amp; (elements.length - 1)] = e;//2.下标是否越界    if (head == tail)//1.空间是否够用        doubleCapacity();//扩容&#125;\n\n\n\n上述代码我们看到，空间问题是在插入之后解决的，因为tail总是指向下一个可插入的空位，也就意味着elements数组至少有一个空位，所以插入元素的时候不用考虑空间问题。\n下标越界的处理解决起来非常简单，head = (head - 1) &amp; (elements.length - 1)就可以了，这段代码相当于取余，同时解决了head为负值的情况。因为elements.length必需是2的指数倍，elements - 1就是二进制低位全1，跟head - 1相与之后就起到了取模的作用，如果head - 1为负数(其实只可能是-1)，则相当于对其取相对于elements.length的补码。\n下面再说说扩容函数doubleCapacity()，其逻辑是申请一个更大的数组(原数组的两倍)，然后将原数组复制过去。过程如下图所示:\n\n图中我们看到，复制分两次进行，第一次复制head右边的元素，第二次复制head左边的元素。\n//doubleCapacity()private void doubleCapacity() &#123;    assert head == tail;    int p = head;    int n = elements.length;    int r = n - p; // head右边元素的个数    int newCapacity = n &lt;&lt; 1;//原空间的2倍    if (newCapacity &lt; 0)        throw new IllegalStateException(&quot;Sorry, deque too big&quot;);    Object[] a = new Object[newCapacity];    System.arraycopy(elements, p, a, 0, r);//复制右半部分，对应上图中绿色部分    System.arraycopy(elements, 0, a, r, p);//复制左半部分，对应上图中灰色部分    elements = (E[])a;    head = 0;    tail = n;&#125;\n\n\n\naddLast()addLast(E e)的作用是在_Deque_的尾端插入元素，也就是在tail的位置插入元素，由于tail总是指向下一个可以插入的空位，因此只需要elements[tail] = e;即可。插入完成后再检查空间，如果空间已经用光，则调用doubleCapacity()进行扩容。\n\npublic void addLast(E e) &#123;    if (e == null)//不允许放入null        throw new NullPointerException();    elements[tail] = e;//赋值    if ( (tail = (tail + 1) &amp; (elements.length - 1)) == head)//下标越界处理        doubleCapacity();//扩容&#125;\n\n\n\n下标越界处理方式addFirt()中已经讲过，不再赘述。\npollFirst()pollFirst()的作用是删除并返回_Deque_首端元素，也即是head位置处的元素。如果容器不空，只需要直接返回elements[head]即可，当然还需要处理下标的问题。由于ArrayDeque中不允许放入null，当elements[head] == null时，意味着容器为空。\npublic E pollFirst() &#123;    E result = elements[head];    if (result == null)//null值意味着deque为空        return null;    elements[h] = null;//let GC work    head = (head + 1) &amp; (elements.length - 1);//下标越界处理    return result;&#125;\n\n\n\npollLast()pollLast()的作用是删除并返回_Deque_尾端元素，也即是tail位置前面的那个元素。\npublic E pollLast() &#123;    int t = (tail - 1) &amp; (elements.length - 1);//tail的上一个位置是最后一个元素    E result = elements[t];    if (result == null)//null值意味着deque为空        return null;    elements[t] = null;//let GC work    tail = t;    return result;&#125;\n\n\n\npeekFirst()peekFirst()的作用是返回但不删除_Deque_首端元素，也即是head位置处的元素，直接返回elements[head]即可。\npublic E peekFirst() &#123;    return elements[head]; // elements[head] is null if deque empty&#125;\n\n\n\npeekLast()peekLast()的作用是返回但不删除_Deque_尾端元素，也即是tail位置前面的那个元素。\npublic E peekLast() &#123;    return elements[(tail - 1) &amp; (elements.length - 1)];&#125;","categories":["Java集合框架"],"tags":["Collection - Stack & Queue"]},{"title":"Docker 搭建私服仓库","url":"/2023/03/22/Docker-%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%8D%E4%BB%93%E5%BA%93/","content":"Docker 搭建私服仓库1.安装gogs# 需要创建 gogs 数据库 # 拉取镜像docker pull gogs/gogs# 创建映射文件目录mkdir -p /var/gogsdocker run --name=gogs --restart always -p 122:22 -p 3000:3000 -/var/gogs:/data gogs/gogsdocker start gogs# 踩坑记录 切记http 要填写3000端口 不要更改，不然无法访问\n\n\n\n2.安装gitea# 需要创建 gitea 数据库 docker pull gitea/giteamkdir -p /var/giteadocker run -d --name=gitea --restart always -p 121:22 -p 3000:3000 -v /var/gitea:/data gitea/giteadocker start gitea# 踩坑记录 切记http 要填写3000端口 不要更改，不然无法访问\n\n\n\n3.安装gitblitdocker pull gitblit/gitblit:rpcmkdir -p /var/gitblit# https访问docker run -d --name gitblit -p 8443:8443 -p 29418:29418 -v /var/gitblit:/data gitblit/gitblit# https和http访问docker run -d --name gitblit --restart always -p 8180:8080 -p 8443:8443 -p 9418:9418 -p 29418:29418 -v /var/gitblit:/data gitblit/gitblitdocker start gitblit\n\n\n\n安装MySQL5.7docker pull mysql:5.7docker run --name mysql5.7 -p 13306:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7\n\n","categories":["Gogs Gitea Gitblit"],"tags":["Gogs Gitea Gitblit 部署"]},{"title":"Docker","url":"/2023/02/19/Docker/","content":"Docker学习目标：\n\n掌握Docker基础知识，能够理解Docker镜像与容器的概念\n\n完成Docker安装与启动\n\n掌握Docker镜像与容器相关命令\n\n掌握Tomcat Nginx 等软件的常用应用的安装\n\n掌握docker迁移与备份相关命令\n\n能够运用Dockerfile编写创建容器的脚本\n\n能够搭建与使用docker私有仓库\n\n\n1 Docker简介1.1 什么是虚拟化 在计算机中，虚拟化（英语：Virtualization）是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以比原本的组态更好的方式来应用这些资源。这些资源的新虚拟部份是不受现有资源的架设方式，地域或物理组态所限制。一般所指的虚拟化资源包括计算能力和资料存储。\n 在实际的生产环境中，虚拟化技术主要用来解决高性能的物理硬件产能过剩和老的旧的硬件产能过低的重组重用，透明化底层物理硬件，从而最大化的利用物理硬件  对资源充分利用\n 虚拟化技术种类很多，例如：软件虚拟化、硬件虚拟化、内存虚拟化、网络虚拟化(vip)、桌面虚拟化、服务虚拟化、虚拟机等等。\n1.2 什么是Docker Docker 是一个开源项目，诞生于 2013 年初，最初是 dotCloud 公司内部的一个业余项目。它基于 Google 公司推出的 Go 语言实现。 项目后来加入了 Linux 基金会，遵从了 Apache 2.0 协议，项目代码在 GitHub 上进行维护。\n \n Docker 自开源后受到广泛的关注和讨论，以至于 dotCloud 公司后来都改名为 Docker Inc。Redhat 已经在其 RHEL6.5 中集中支持 Docker；Google 也在其 PaaS 产品中广泛应用。\n Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。\n 在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单。\n为什么选择Docker?\n（1）上手快。\n 用户只需要几分钟，就可以把自己的程序“Docker化”。Docker依赖于“写时复制”（copy-on-write）模型，使修改应用程序也非常迅速，可以说达到“随心所致，代码即改”的境界。\n随后，就可以创建容器来运行应用程序了。大多数Docker容器只需要不到1秒中即可启动。由于去除了管理程序的开销，Docker容器拥有很高的性能，同时同一台宿主机中也可以运行更多的容器，使用户尽可能的充分利用系统资源。\n（2）职责的逻辑分类\n 使用Docker，开发人员只需要关心容器中运行的应用程序，而运维人员只需要关心如何管理容器。Docker设计的目的就是要加强开发人员写代码的开发环境与应用程序要部署的生产环境一致性。从而降低那种“开发时一切正常，肯定是运维的问题（测试环境都是正常的，上线后出了问题就归结为肯定是运维的问题）”\n（3）快速高效的开发生命周期\n Docker的目标之一就是缩短代码从开发、测试到部署、上线运行的周期，让你的应用程序具备可移植性，易于构建，并易于协作。（通俗一点说，Docker就像一个盒子，里面可以装很多物件，如果需要这些物件的可以直接将该大盒子拿走，而不需要从该盒子中一件件的取。）\n（4）鼓励使用面向服务的架构\n Docker还鼓励面向服务的体系结构和微服务架构。Docker推荐单个容器只运行一个应用程序或进程，这样就形成了一个分布式的应用程序模型，在这种模型下，应用程序或者服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序，扩展或调试应用程序都变得非常简单，同时也提高了程序的内省性。（当然，可以在一个容器中运行多个应用程序）\n1.3 容器与虚拟机比较 下面的图片比较了 Docker 和传统虚拟化方式的不同之处，可见容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，而传统方式则是在硬件层面实现。\n与传统的虚拟机相比，Docker优势体现为启动速度快、占用体积小。\n1.4 Docker 组件1.4.1 Docker服务器与客户端 Docker是一个客户端-服务器（C&#x2F;S）架构程序。Docker客户端只需要向Docker服务器或者守护进程发出请求，服务器或者守护进程将完成所有工作并返回结果。Docker提供了一个命令行工具Docker以及一整套RESTful API。你可以在同一台宿主机上运行Docker守护进程和客户端，也可以从本地的Docker客户端连接到运行在另一台宿主机上的远程Docker守护进程。\n\n1.4.2 Docker镜像与容器 镜像是构建Docker的基石。用户基于镜像来运行自己的容器。镜像也是Docker生命周期中的“构建”部分。镜像是基于联合文件系统的一种层式结构，由一系列指令一步一步构建出来。例如：\n添加一个文件；\n执行一个命令；\n打开一个窗口。\n也可以将镜像当作容器的“源代码”。镜像体积很小，非常“便携”，易于分享、存储和更新。\n Docker可以帮助你构建和部署容器，你只需要把自己的应用程序或者服务打包放进容器即可。容器是基于镜像启动起来的，容器中可以运行一个或多个进程。我们可以认为，镜像是Docker生命周期中的构建或者打包阶段，而容器则是启动或者执行阶段。 容器基于镜像启动，一旦容器启动完成后，我们就可以登录到容器中安装自己需要的软件或者服务。\n所以Docker容器就是：\n 一个镜像格式；\n 一些列标准操作；\n 一个执行环境。\n Docker借鉴了标准集装箱的概念。标准集装箱将货物运往世界各地，Docker将这个模型运用到自己的设计中，唯一不同的是：集装箱运输货物，而Docker运输软件。\n和集装箱一样，Docker在执行上述操作时，并不关心容器中到底装了什么，它不管是web服务器，还是数据库，或者是应用程序服务器什么的。所有的容器都按照相同的方式将内容“装载”进去。\nDocker也不关心你要把容器运到何方：我们可以在自己的笔记本中构建容器，上传到Registry，然后下载到一个物理的或者虚拟的服务器来测试，在把容器部署到具体的主机中。像标准集装箱一样，Docker容器方便替换，可以叠加，易于分发，并且尽量通用。\n1.4.3 Registry（注册中心） Docker用Registry来保存用户构建的镜像。Registry分为公共和私有两种。Docker公司运营公共的Registry叫做Docker Hub。用户可以在Docker Hub注册账号，分享并保存自己的镜像（说明：在Docker Hub下载镜像巨慢，可以自己构建私有的Registry）。\n https://hub.docker.com/\n2 Docker安装与启动2.1 安装Docker Docker官方建议在Ubuntu中安装，因为Docker是基于Ubuntu发布的，而且一般Docker出现的问题Ubuntu是最先更新或者打补丁的。在很多版本的CentOS中是不支持更新最新的一些补丁包的。\n 由于我们学习的环境都使用的是CentOS，因此这里我们将Docker安装到CentOS上。注意：这里建议安装在CentOS7.x以上的版本，在CentOS6.x的版本中，安装前需要安装其他很多的环境而且Docker很多补丁不支持更新。\n 请直接挂载课程配套的Centos7.x镜像\n（1）yum 包更新到最新\nsudo yum update\n\n（2）安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的\nsudo yum install -y yum-utils device-mapper-persistent-data lvm2\n\n（3）设置yum源为阿里云\nsudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\n（4）安装docker\nsudo yum install docker-ce\n\n（5）安装后查看docker版本\ndocker -v\n\n2.2 设置ustc的镜像ustc是老牌的linux镜像服务提供者了，还在遥远的ubuntu 5.04版本的时候就在用。ustc的docker镜像加速器速度很快。ustc docker mirror的优势之一就是不需要注册，是真正的公共服务。\nhttps://lug.ustc.edu.cn/wiki/mirrors/help/docker\n编辑该文件：\nvi /etc/docker/daemon.json  \n\n在该文件中输入如下内容：\n&#123;&quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;]&#125;\n\n2.3 Docker的启动与停止systemctl命令是系统服务管理器指令\n启动docker：\nsystemctl start docker\n\n停止docker：\nsystemctl stop docker\n\n重启docker：\nsystemctl restart docker\n\n查看docker状态：\nsystemctl status docker\n\n开机启动：\nsystemctl enable docker\n\n查看docker概要信息\ndocker info\n\n查看docker帮助文档\ndocker --help\n\n3 常用命令3.1 镜像相关命令3.1.1 查看镜像docker images\n\n\n\nREPOSITORY：镜像名称\nTAG：镜像标签\nIMAGE ID：镜像ID\nCREATED：镜像的创建日期（不是获取该镜像的日期）\nSIZE：镜像大小\n这些镜像都是存储在Docker宿主机的&#x2F;var&#x2F;lib&#x2F;docker目录下\n3.1.2 搜索镜像如果你需要从网络中查找需要的镜像，可以通过以下命令搜索\ndocker search 镜像名称\n\n\n\nNAME：仓库名称\nDESCRIPTION：镜像描述\nSTARS：用户评价，反应一个镜像的受欢迎程度\nOFFICIAL：是否官方\nAUTOMATED：自动构建，表示该镜像由Docker Hub自动构建流程创建的\n3.1.3 拉取镜像拉取镜像就是从中央仓库中下载镜像到本地\ndocker pull 镜像名称\n\n\n\n例如，我要下载centos7镜像\ndocker pull centos:7\n\n\n\n3.1.4 删除镜像按镜像ID删除镜像\ndocker rmi 镜像ID\n\n\n\n删除所有镜像\ndocker rmi `docker images -q`\n\n\n\n3.2 容器相关命令3.2.1 查看容器查看正在运行的容器\ndocker ps\n\n查看所有容器\ndocker ps –a\n\n查看最后一次运行的容器\ndocker ps –l\n\n查看停止的容器\ndocker ps -f status=exited\n\n3.2.2 创建与启动容器创建容器常用的参数说明：\n创建容器命令：docker run\n-i：表示运行容器\n-t：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。\n–name :为创建的容器命名。\n-v：表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个－v做多个目录或文件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。\n-d：在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t两个参数，创建后就会自动进去容器）。\n-p：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射\n（1）交互式方式创建容器\ndocker run -it --name=容器名称 镜像名称:标签 /bin/bash\n\n这时我们通过ps命令查看，发现可以看到启动的容器，状态为启动状态\n退出当前容器\nexit\n\n（2）守护式方式创建容器：\ndocker run -di --name=容器名称 镜像名称:标签\n\n登录守护式容器方式：\ndocker exec -it 容器名称 (或者容器ID)  /bin/bash\n\n3.2.3 停止与启动容器停止容器：\ndocker stop 容器名称（或者容器ID）\n\n启动容器：\ndocker start 容器名称（或者容器ID）\n\n3.2.4 文件拷贝如果我们需要将文件拷贝到容器内可以使用cp命令\ndocker cp 需要拷贝的文件或目录 容器名称:容器目录\n\n也可以将文件从容器内拷贝出来\ndocker cp 容器名称:容器目录 需要拷贝的文件或目录\n\n3.2.5 目录挂载我们可以在创建容器的时候，将宿主机的目录与容器内的目录进行映射，这样我们就可以通过修改宿主机某个目录的文件从而去影响容器。 创建容器 添加-v参数 后边为 宿主机目录:容器目录，例如：\ndocker run -di -v /usr/local/myhtml:/usr/local/myhtml --name=mycentos3 centos:7\n\n如果你共享的是多级的目录，可能会出现权限不足的提示。\n这是因为CentOS7中的安全模块selinux把权限禁掉了，我们需要添加参数 –privileged&#x3D;true 来解决挂载的目录没有权限的问题\n3.2.6 查看容器IP地址我们可以通过以下命令查看容器运行的各种数据\ndocker inspect 容器名称（容器ID） \n\n也可以直接执行下面的命令直接输出IP地址\ndocker inspect --format=&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27; 容器名称（容器ID）\n\n3.2.7 删除容器删除指定的容器：\ndocker rm 容器名称（容器ID）\n\n4 应用部署4.1 MySQL部署（1）拉取mysql镜像\ndocker pull centos/mysql-57-centos7\n\n（2）创建容器\ndocker run -di --name=tensquare_mysql -p 33306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql\n\n-p 代表端口映射，格式为 宿主机映射端口:容器运行端口\n-e 代表添加环境变量 MYSQL_ROOT_PASSWORD 是root用户的登陆密码\n（3）远程登录mysql\n连接宿主机的IP ,指定端口为33306\n4.2 tomcat部署（1）拉取镜像\ndocker pull tomcat:7-jre7\n\n（2）创建容器\n创建容器 -p表示地址映射\ndocker run -di --name=mytomcat -p 9000:8080 -v /usr/local/webapps:/usr/local/tomcat/webapps tomcat:7-jre7\n\n\n\n4.3 Nginx部署（1）拉取镜像\ndocker pull nginx\n\n（2）创建Nginx容器\ndocker run -di --name=mynginx -p 80:80 nginx\n\n4.4 Redis部署（1）拉取镜像\ndocker pull redis\n\n（2）创建容器\ndocker run -di --name=myredis -p 6379:6379 redis\n\n5 迁移与备份5.1 容器保存为镜像我们可以通过以下命令将容器保存为镜像\ndocker commit mynginx mynginx_i\n\n5.2 镜像备份我们可以通过以下命令将镜像保存为tar 文件\ndocker  save -o mynginx.tar mynginx_i\n\n\n\n5.3 镜像恢复与迁移首先我们先删除掉mynginx_img镜像 然后执行此命令进行恢复\ndocker load -i mynginx.tar\n\n-i 输入的文件\n执行后再次查看镜像，可以看到镜像已经恢复\n6 Dockerfile6.1 什么是DockerfileDockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。\n1、对于开发人员：可以为开发团队提供一个完全一致的开发环境； 2、对于测试人员：可以直接拿开发时所构建的镜像或者通过Dockerfile文件构建一个新的镜像开始工作了； 3、对于运维人员：在部署时，可以实现应用的无缝移植。\n6.2 常用命令\n\n\n命令\n作用\n\n\n\nFROM image_name:tag\n定义了使用哪个基础镜像启动构建流程\n\n\nMAINTAINER user_name\n声明镜像的创建者\n\n\nENV key value\n设置环境变量 (可以写多条)\n\n\nRUN command\n是Dockerfile的核心部分(可以写多条)\n\n\nADD source_dir&#x2F;file dest_dir&#x2F;file\n将宿主机的文件复制到容器内，如果是一个压缩文件，将会在复制后自动解压\n\n\nCOPY source_dir&#x2F;file dest_dir&#x2F;file\n和ADD相似，但是如果有压缩文件并不能解压\n\n\nWORKDIR path_dir\n设置工作目录\n\n\n6.3 使用脚本创建镜像步骤：\n（1）创建目录\nmkdir –p /usr/local/dockerjdk8\n\n（2）下载jdk-8u171-linux-x64.tar.gz并上传到服务器（虚拟机）中的&#x2F;usr&#x2F;local&#x2F;dockerjdk8目录\n（3）创建文件Dockerfile vi Dockerfile\n#依赖镜像名称和IDFROM centos:7#指定镜像创建者信息MAINTAINER ITCAST#切换工作目录WORKDIR /usrRUN mkdir  /usr/local/java#ADD 是相对路径jar,把java添加到容器中ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/#配置java环境变量ENV JAVA_HOME /usr/local/java/jdk1.8.0_171ENV JRE_HOME $JAVA_HOME/jreENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATHENV PATH $JAVA_HOME/bin:$PATH\n\n\n\n（4）执行命令构建镜像\ndocker build -t=&#x27;jdk1.8&#x27; .\n\n注意后边的空格和点，不要省略\n（5）查看镜像是否建立完成\ndocker images\n\n7 Docker私有仓库7.1 私有仓库搭建与配置（1）拉取私有仓库镜像（此步省略）\ndocker pull registry\n\n（2）启动私有仓库容器\ndocker run -di --name=registry -p 5000:5000 registry\n\n（3）打开浏览器 输入地址http://192.168.184.141:5000/v2/_catalog看到`{&quot;repositories&quot;:[]}` 表示私有仓库搭建成功并且内容为空\n（4）修改daemon.json\nvi /etc/docker/daemon.json\n\n添加以下内容，保存退出。\n&#123;&quot;insecure-registries&quot;:[&quot;192.168.184.141:5000&quot;]&#125; \n\n此步用于让 docker信任私有仓库地址\n（5）重启docker 服务\nsystemctl restart docker\n\n7.2 镜像上传至私有仓库（1）标记此镜像为私有仓库的镜像\ndocker tag jdk1.8 192.168.184.141:5000/jdk1.8\n\n（2）再次启动私服容器\ndocker start registry\n\n（3）上传标记的镜像\ndocker push 192.168.184.141:5000/jdk1.8\n\n\n\n","categories":["Docker容器"],"tags":["Docker容器"]},{"title":"git clone 推送报错","url":"/2023/03/22/Git%20%E6%8E%A8%E9%80%81%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93ssl%E8%AE%A4%E8%AF%81%20/","content":"git clone报错——SSL certificate problem: self signed certificate in certificate chain问题描述使用Git工具进行git clone项目时，弹出框提示信息为“fatal: unable to access ‘https:&#x2F;&#x2F;…git&#x2F;’: SSL certificate problem: self signed certificate in certificate chain”\n问题分析提示信息为SSL认证失败，可以关闭SSL的认证。公司bitbucket只支持https地址，需要client配置忽略https证书检验。\n解决方案打开Git Bash运行如下命令\nexport GIT_SSL_NO_VERIFY=truegit config --global http.sslVerify &quot;false&quot;\n\n在windows的命令行中，进入到git命令所在的磁盘位置，执行下面的git命令\ngit config --global http.sslVerify false\n\n\n\ngitlab 域名与克隆地址不一致修改1.gitlab替换https#配置gitlab替换https://域名 ,如：&#x27;https://xxx.com&#x27;vim /etc/gitlab/gitlab.rb   #打开配置文件external_url &#x27;external_url &#x27;https://192.168.1.12:8089&#x27;  # 注：一定要HTTPS\n\n2.添加ssl 证书#创建一个ssl文件 把申请的证书放在这个文件夹里mkdir /etc/gitlab/ssl  #打开配置文件vim  /etc/gitlab/gitlab.rb  #取消注释改为 truenginx[&#x27;redirect_http_to_https&#x27;]= true#放置对应的证书名称nginx[&#x27;ssl_certificate&#x27;] = &quot;/etc/gitlab/ssl/xxxx.crt&quot;  #放置对应的证书名称nginx[&#x27;ssl_certificate_key&#x27;] = &quot;/etc/gitlab/ssl/xxxx.key&quot; #使配置生效gitlab-ctl reconfigure \n\n3.修改clone 地址vim /var/opt/gitlab/gitlab-rails/etc/gitlab.yml  #打开配置文件，参考图修改后重启gitlab-ctl restart  # 重起生效 # \n\n","categories":["git push 报错"],"tags":["git push 认证"]},{"title":"IDEA的日常快捷键及Linux命令","url":"/2023/03/13/IDEA%20%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%8F%8ALInux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","content":"IntelliJ IDEA 常用快捷键一览表\n1-IDEA的日常快捷键第1组：通用型\n\n\n说明\n快捷键\n\n\n\n复制代码-copy\nctrl + c\n\n\n粘贴-paste\nctrl + v\n\n\n剪切-cut\nctrl + x\n\n\n撤销-undo\nctrl + z\n\n\n反撤销-redo\nctrl + shift + z\n\n\n保存-save all\nctrl + s\n\n\n全选-select all\nctrl + a\n\n\n第2组：提高编写速度（上）\n\n\n说明\n快捷键\n\n\n\n智能提示-edit\nalt + enter\n\n\n提示代码模板-insert live template\nctrl+j\n\n\n使用xx块环绕-surround with …\nctrl+alt+t\n\n\n调出生成getter&#x2F;setter&#x2F;构造器等结构-generate …\nalt+insert\n\n\n自动生成返回值变量-introduce variable …\nctrl+alt+v\n\n\n复制指定行的代码-duplicate line or selection\nctrl+d\n\n\n删除指定行的代码-delete line\nctrl+y\n\n\n切换到下一行代码空位-start new line\nshift + enter\n\n\n切换到上一行代码空位-start new line before current\nctrl +alt+ enter\n\n\n向上移动代码-move statement up\nctrl+shift+↑\n\n\n向下移动代码-move statement down\nctrl+shift+↓\n\n\n向上移动一行-move line up\nalt+shift+↑\n\n\n向下移动一行-move line down\nalt+shift+↓\n\n\n方法的形参列表提醒-parameter info\nctrl+p\n\n\n第3组：提高编写速度（下）\n\n\n说明\n快捷键\n\n\n\n批量修改指定的变量名、方法名、类名等-rename\nshift+f6\n\n\n抽取代码重构方法-extract method …\nctrl+alt+m\n\n\n重写父类的方法-override methods …\nctrl+o\n\n\n实现接口的方法-implements methods …\nctrl+i\n\n\n选中的结构的大小写的切换-toggle case\nctrl+shift+u\n\n\n批量导包-optimize imports\nctrl+alt+o\n\n\n第4组：类结构、查找和查看源码\n\n\n说明\n快捷键\n\n\n\n如何查看源码-go to class…\nctrl + 选中指定的结构 或 ctrl+n\n\n\n显示当前类结构，支持搜索指定的方法、属性等-file structure\nctrl+f12\n\n\n退回到前一个编辑的页面-back\nctrl+alt+←\n\n\n进入到下一个编辑的页面-forward\nctrl+alt+→\n\n\n打开的类文件之间切换-select previous&#x2F;next tab\nalt+←&#x2F;→\n\n\n光标选中指定的类，查看继承树结构-Type Hierarchy\nctrl+h\n\n\n查看方法文档-quick documentation\nctrl+q\n\n\n类的UML关系图-show uml popup\nctrl+alt+u\n\n\n定位某行-go to line&#x2F;column\nctrl+g\n\n\n回溯变量或方法的来源-go to implementation(s)\nctrl+alt+b\n\n\n折叠方法实现-collapse all\nctrl+shift+ -\n\n\n展开方法实现-expand all\nctrl+shift+ +\n\n\n第5组：查找、替换与关闭\n\n\n说明\n快捷键\n\n\n\n查找指定的结构\nctlr+f\n\n\n快速查找：选中的Word快速定位到下一个-find next\nctrl+l\n\n\n查找与替换-replace\nctrl+r\n\n\n直接定位到当前行的首位-move caret to line start\nhome\n\n\n直接定位到当前行的末位 -move caret to line end\nend\n\n\n查询当前元素在当前文件中的引用，然后按 F3 可以选择\nctrl+f7\n\n\n全项目搜索文本-find in path …\nctrl+shift+f\n\n\n关闭当前窗口-close\nctrl+f4\n\n\n第6组：调整格式\n\n\n说明\n快捷键\n\n\n\n格式化代码-reformat code\nctrl+alt+l\n\n\n使用单行注释-comment with line comment\nctrl + &#x2F;\n\n\n使用&#x2F;取消多行注释-comment with block comment\nctrl + shift + &#x2F;\n\n\n选中数行，整体往后移动-tab\ntab\n\n\n选中数行，整体往前移动-prev tab\nshift + tab\n\n\n2-Debug快捷键\n\n\n说明\n快捷键\n\n\n\n单步调试（不进入函数内部）- step over\nF8\n\n\n单步调试（进入函数内部）- step into\nF7\n\n\n强制单步调试（进入函数内部） - force step into\nalt+shift+f7\n\n\n选择要进入的函数 - smart step into\nshift + F7\n\n\n跳出函数 - step out\nshift + F8\n\n\n运行到断点 - run to cursor\nalt + F9\n\n\n继续执行，进入下一个断点或执行完程序 - resume program\nF9\n\n\n停止 - stop\nCtrl+F2\n\n\n查看断点 - view breakpoints\nCtrl+Shift+F8\n\n\n关闭 - close\nCtrl+F4\n\n\n3- 常用代码模板1、非空判断\n变量.null：if(变量 &#x3D;&#x3D; null)\n变量.nn：if(变量 !&#x3D; null) \n变量.notnull：if(变量 !&#x3D; null) \nifn：if(xx  &#x3D;&#x3D; null)\ninn：if(xx  !&#x3D; null)\n\n2、遍历数组和集合\n数组或集合变量.fori：for循环\n数组或集合变量.for：增强for循环\n数组或集合变量.forr：反向for循环\n数组或集合变量.iter：增强for循环遍历数组或集合\n\n3、输出语句\nsout：相当于System.out.println\nsoutm：打印当前方法的名称\nsoutp：打印当前方法的形参及形参对应的实参值\nsoutv：打印方法中声明的最近的变量的值\n变量.sout：打印当前变量值\n变量.soutv：打印当前变量名及变量值\n\n4、对象操作\n创建对象\nXxx.new  .var ：创建Xxx类的对象，并赋给相应的变量\nXxx.new  .field：会将方法内刚创建的Xxx对象抽取为一个属性\n\n\n强转\n对象.cast：将对象进行强转\n对象.castvar：将对象强转后，并赋给一个变量\n\n\n\n5、静态常量声明\npsf：public static final\npsfi：public static final int\npsfs：public static final String\nprsf：private static final\n\nLinux常用命令\nLinux命令大全(手册)\n","categories":["IDEA 快捷键"],"tags":["IDEA Linux"]},{"title":"GitLab 部署及管理员账号初始化","url":"/2023/03/18/GitLab%20%E9%83%A8%E7%BD%B2%E5%BF%98%E8%AE%B0root%E5%AF%86%E7%A0%81%E4%BF%AE%E6%94%B9/","content":"GitLab 部署及管理员账号初始化1.首先登录gitlab服务器执行以下命令：# 切换到gitlab安装目录cd /opt/gitlab/binsudo  gitlab-rails console -e production\n\n2.通过命令查找，确定用户为“root”# 以下这两个命令都可以，随便输入一个user = User.where(id: 1).first user = User.where(name: &quot;root&quot;).first\n\n3.将root用户密码重置为admin123!# 输入重置密码命令user.password=&quot;admin123&quot;# 再次确认密码user.password_confirmation=&quot;admin123&quot;\n\n4.保存重置信息，并结束# 输入保存命令，以便使更改信息生效user.save# 退出修改窗口exit\n\n如果看到上面截图中的true ，恭喜你已经成功了，执行 exit 或quit退出当前设置流程即可。\n回到gitlab ,可以通过 root&#x2F;admin123 这一超级管理员账号登录了\n","categories":["GitLab"],"tags":["GitLab 部署"]},{"title":"Java 并发 - 知识体系","url":"/2023/02/19/Java%20%E5%B9%B6%E5%8F%91%20-%20%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/","content":"Java 并发 - 知识体系\nJava 并发相关知识体系详解。\n\n#知识体系\n参考文档官方文档 https://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html\n并发官方教程 https://docs.oracle.com/javase/tutorial/essential/concurrency/atomic.html\nDoug Lea并发编程文章全部译文 http://ifeve.com/doug-lea/\nJava并发知识点总结 https://github.com/CL0610/Java-concurrency\n线程与多线程必知必会(基础篇) https://zhuanlan.zhihu.com/p/33616143\n","categories":["Java多线程"],"tags":["Java高并发"]},{"title":"Java 并发 - 理论基础","url":"/2023/02/19/Java%20%E5%B9%B6%E5%8F%91%20-%20%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/","content":"Java 并发 - 理论基础\n本文从理论的角度引入并发安全问题以及JMM应对并发问题的原理。\n\n\n带着BAT大厂的面试问题去理解\n为什么需要多线程\n线程不安全示例\n并发出现问题的根源: 并发三要素\n可见性: CPU缓存引起\n原子性: 分时复用引起\n有序性: 重排序引起\n\n\nJAVA是怎么解决并发问题的: JMM(Java内存模型)\n关键字: volatile、synchronized 和 final\nHappens-Before 规则\n\n\n线程安全: 不是一个非真即假的命题\n\n不可变\n\n\n\n绝对线程安全\n\n\n\n相对线程安全\n\n\n\n线程兼容\n\n\n\n线程对立\n\n\n\n\n线程安全的实现方法\n\n互斥同步\n\n\n\n非阻塞同步\n\n\n\n无同步方案\n\n\n\n\n\n带着BAT大厂的面试问题去理解:::\nTIP\n请带着这些问题继续后文，会很大程度上帮助你更好的理解并发理论基础。\n:::\n\n多线程的出现是要解决什么问题的?\n线程不安全是指什么? 举例说明\n并发出现线程不安全的本质什么? 可见性，原子性和有序性。\nJava是怎么解决并发问题的? 3个关键字，JMM和8个Happens-Before\n线程安全是不是非真即假? 不是\n线程安全有哪些实现思路?\n如何理解并发和并行的区别?\n\n为什么需要多线程众所周知，CPU、内存、I&#x2F;O 设备的速度是有极大差异的，为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为:\n\nCPU 增加了缓存，以均衡与内存的速度差异；&#x2F;&#x2F; 导致 可见性问题\n操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I&#x2F;O 设备的速度差异；&#x2F;&#x2F; 导致 原子性问题\n编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。&#x2F;&#x2F; 导致 有序性问题\n\n线程不安全示例如果多个线程对同一个共享数据进行访问而不采取同步操作的话，那么操作的结果是不一致的。\n以下代码演示了 1000 个线程同时对 cnt 执行自增操作，操作结束之后它的值有可能小于 1000。\npublic class ThreadUnsafeExample &#123;    private int cnt = 0;    public void add() &#123;        cnt++;    &#125;    public int get() &#123;        return cnt;    &#125;&#125;\n\n\n\npublic static void main(String[] args) throws InterruptedException &#123;    final int threadSize = 1000;    ThreadUnsafeExample example = new ThreadUnsafeExample();    final CountDownLatch countDownLatch = new CountDownLatch(threadSize);    ExecutorService executorService = Executors.newCachedThreadPool();    for (int i = 0; i &lt; threadSize; i++) &#123;        executorService.execute(() -&gt; &#123;            example.add();            countDownLatch.countDown();        &#125;);    &#125;    countDownLatch.await();    executorService.shutdown();    System.out.println(example.get());&#125;\n\n\n\n997 // 结果总是小于1000\n\n\n\n并发出现问题的根源: 并发三要素上述代码输出为什么不是1000? 并发出现问题的根源是什么?\n可见性: CPU缓存引起可见性：一个线程对共享变量的修改，另外一个线程能够立刻看到。\n举个简单的例子，看下面这段代码：\n//线程1执行的代码int i = 0;i = 10; //线程2执行的代码j = i;\n\n\n\n假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i &#x3D;10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。\n此时线程2执行 j &#x3D; i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10.\n这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。\n原子性: 分时复用引起原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。\n经典的转账问题：比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。\n试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。\n所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。\n有序性: 重排序引起有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码：\nint i = 0;              boolean flag = false;i = 1;                //语句1  flag = true;          //语句2\n\n\n\n上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗? 不一定，为什么呢? 这里可能会发生指令重排序（Instruction Reorder）。\n在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：\n\n编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。\n指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。\n内存系统的重排序。由于处理器使用缓存和读 &#x2F; 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。\n\n从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序：\n\n上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。\n具体可以参看：Java 内存模型详解的重排序章节。\nJAVA是怎么解决并发问题的: JMM(Java内存模型)Java 内存模型是个很复杂的规范，强烈推荐你看后续（应该是网上能找到最好的材料之一了）：Java 内存模型详解。\n理解的第一个维度：核心知识点\nJMM本质上可以理解为，Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括：\n\nvolatile、synchronized 和 final 三个关键字\nHappens-Before 规则\n\n理解的第二个维度：可见性，有序性，原子性\n\n原子性\n\n在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 请分析以下哪些操作是原子性操作：\nx = 10;        //语句1: 直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中y = x;         //语句2: 包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。x++;           //语句3： x++包括3个操作：读取x的值，进行加1操作，写入新的值。x = x + 1;     //语句4： 同语句3\n\n\n\n上面4个语句只有语句1的操作具备原子性。\n也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。\n\n从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。\n\n\n可见性\n\nJava提供了volatile关键字来保证可见性。\n当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。\n而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。\n\n另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。\n\n\n有序性\n\n在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。当然JMM是通过Happens-Before 规则来保证有序性的。\n关键字: volatile、synchronized 和 final以下三篇文章详细分析了这三个关键字：\n\n关键字: synchronized详解\n关键字: volatile详解\n关键字: final详解\n\nHappens-Before 规则上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。\n1. 单一线程原则\nSingle Thread rule\n\n在一个线程内，在程序前面的操作先行发生于后面的操作。\n\n2. 管程锁定规则\nMonitor Lock Rule\n\n一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。\n\n3. volatile 变量规则\nVolatile Variable Rule\n\n对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。\n\n4. 线程启动规则\nThread Start Rule\n\nThread 对象的 start() 方法调用先行发生于此线程的每一个动作。\n\n5. 线程加入规则\nThread Join Rule\n\nThread 对象的结束先行发生于 join() 方法返回。\n\n6. 线程中断规则\nThread Interruption Rule\n\n对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。\n7. 对象终结规则\nFinalizer Rule\n\n一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始。\n8. 传递性\nTransitivity\n\n如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。\n线程安全: 不是一个非真即假的命题一个类在可以被多个线程安全调用时就是线程安全的。\n线程安全不是一个非真即假的命题，可以将共享数据按照安全程度的强弱顺序分成以下五类: 不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。\n1. 不可变不可变(Immutable)的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。\n多线程环境下，应当尽量使对象成为不可变，来满足线程安全。\n不可变的类型:\n\nfinal 关键字修饰的基本数据类型\nString\n枚举类型\nNumber 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。\n\n对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。\npublic class ImmutableExample &#123;    public static void main(String[] args) &#123;        Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();        Map&lt;String, Integer&gt; unmodifiableMap = Collections.unmodifiableMap(map);        unmodifiableMap.put(&quot;a&quot;, 1);    &#125;&#125;\n\n\n\nException in thread &quot;main&quot; java.lang.UnsupportedOperationException    at java.util.Collections$UnmodifiableMap.put(Collections.java:1457)    at ImmutableExample.main(ImmutableExample.java:9)\n\n\n\nCollections.unmodifiableXXX() 先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常。\npublic V put(K key, V value) &#123;    throw new UnsupportedOperationException();&#125;\n\n\n\n2. 绝对线程安全不管运行时环境如何，调用者都不需要任何额外的同步措施。\n3. 相对线程安全相对线程安全需要保证对这个对象单独的操作是线程安全的，在调用的时候不需要做额外的保障措施。但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。\n在 Java 语言中，大部分的线程安全类都属于这种类型，例如 Vector、HashTable、Collections 的 synchronizedCollection() 方法包装的集合等。\n对于下面的代码，如果删除元素的线程删除了 Vector 的一个元素，而获取元素的线程试图访问一个已经被删除的元素，那么就会抛出 ArrayIndexOutOfBoundsException。\npublic class VectorUnsafeExample &#123;    private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;();    public static void main(String[] args) &#123;        while (true) &#123;            for (int i = 0; i &lt; 100; i++) &#123;                vector.add(i);            &#125;            ExecutorService executorService = Executors.newCachedThreadPool();            executorService.execute(() -&gt; &#123;                for (int i = 0; i &lt; vector.size(); i++) &#123;                    vector.remove(i);                &#125;            &#125;);            executorService.execute(() -&gt; &#123;                for (int i = 0; i &lt; vector.size(); i++) &#123;                    vector.get(i);                &#125;            &#125;);            executorService.shutdown();        &#125;    &#125;&#125;\n\n\n\n\nException in thread &quot;Thread-159738&quot; java.lang.ArrayIndexOutOfBoundsException: Array index out of range: 3    at java.util.Vector.remove(Vector.java:831)    at VectorUnsafeExample.lambda$main$0(VectorUnsafeExample.java:14)    at VectorUnsafeExample$$Lambda$1/713338599.run(Unknown Source)    at java.lang.Thread.run(Thread.java:745)\n\n\n\n如果要保证上面的代码能正确执行下去，就需要对删除元素和获取元素的代码进行同步。\nexecutorService.execute(() -&gt; &#123;    synchronized (vector) &#123;        for (int i = 0; i &lt; vector.size(); i++) &#123;            vector.remove(i);        &#125;    &#125;&#125;);executorService.execute(() -&gt; &#123;    synchronized (vector) &#123;        for (int i = 0; i &lt; vector.size(); i++) &#123;            vector.get(i);        &#125;    &#125;&#125;);\n\n\n\n4. 线程兼容线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用，我们平常说一个类不是线程安全的，绝大多数时候指的是这一种情况。Java API 中大部分的类都是属于线程兼容的，如与前面的 Vector 和 HashTable 相对应的集合类 ArrayList 和 HashMap 等。\n5. 线程对立线程对立是指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码。由于 Java 语言天生就具备多线程特性，线程对立这种排斥多线程的代码是很少出现的，而且通常都是有害的，应当尽量避免。\n线程安全的实现方法1. 互斥同步synchronized 和 ReentrantLock。\n初步了解你可以看：\n\nJava 并发 - 线程基础：线程互斥同步\n\n详细分析请看：\n\n关键字: Synchronized详解\nJUC锁: ReentrantLock详解\n\n2. 非阻塞同步互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。\n互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁(这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁)、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。\n(一)CAS\n随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略: 先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施(不断地重试，直到成功为止)。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。\n乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是: 比较并交换(Compare-and-Swap，CAS)。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。\n(二)AtomicInteger\nJ.U.C 包里面的整数原子类 AtomicInteger，其中的 compareAndSet() 和 getAndIncrement() 等方法都使用了 Unsafe 类的 CAS 操作。\n以下代码使用了 AtomicInteger 执行了自增的操作。\nprivate AtomicInteger cnt = new AtomicInteger();public void add() &#123;    cnt.incrementAndGet();&#125;\n\n\n\n以下代码是 incrementAndGet() 的源码，它调用了 unsafe 的 getAndAddInt() 。\npublic final int incrementAndGet() &#123;    return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;\n\n\n\n以下代码是 getAndAddInt() 源码，var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 getIntVolatile(var1, var2) 得到旧的预期值，通过调用 compareAndSwapInt() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4。\n可以看到 getAndAddInt() 在一个循环中进行，发生冲突的做法是不断的进行重试。\npublic final int getAndAddInt(Object var1, long var2, int var4) &#123;    int var5;    do &#123;        var5 = this.getIntVolatile(var1, var2);    &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));    return var5;&#125;\n\n\n\n(三)ABA\n如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。\nJ.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。\nCAS, Unsafe和原子类详细分析请看：\n\nJUC原子类: CAS, Unsafe和原子类详解\n\n3. 无同步方案要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。\n(一)栈封闭\n多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。\nimport java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class StackClosedExample &#123;    public void add100() &#123;        int cnt = 0;        for (int i = 0; i &lt; 100; i++) &#123;            cnt++;        &#125;        System.out.println(cnt);    &#125;&#125;\n\n\n\npublic static void main(String[] args) &#123;    StackClosedExample example = new StackClosedExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; example.add100());    executorService.execute(() -&gt; example.add100());    executorService.shutdown();&#125;\n\n\n\n100100\n\n\n\n更详细的分析请看J.U.C中线程池相关内容详解：\n\nJUC线程池: FutureTask详解\nJUC线程池: ThreadPoolExecutor详解\nJUC线程池: ScheduledThreadPool详解\nJUC线程池: Fork&#x2F;Join框架详解\n\n(二)线程本地存储(Thread Local Storage)\n如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。\n符合这种特点的应用并不少见，大部分使用消费队列的架构模式(如“生产者-消费者”模式)都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”(Thread-per-Request)的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。\n可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。\n对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。\npublic class ThreadLocalExample &#123;    public static void main(String[] args) &#123;        ThreadLocal threadLocal = new ThreadLocal();        Thread thread1 = new Thread(() -&gt; &#123;            threadLocal.set(1);            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(threadLocal.get());            threadLocal.remove();        &#125;);        Thread thread2 = new Thread(() -&gt; &#123;            threadLocal.set(2);            threadLocal.remove();        &#125;);        thread1.start();        thread2.start();    &#125;&#125;\n\n\n\n输出结果\n1\n\n\n\n为了理解 ThreadLocal，先看以下代码:\npublic class ThreadLocalExample1 &#123;    public static void main(String[] args) &#123;        ThreadLocal threadLocal1 = new ThreadLocal();        ThreadLocal threadLocal2 = new ThreadLocal();        Thread thread1 = new Thread(() -&gt; &#123;            threadLocal1.set(1);            threadLocal2.set(1);        &#125;);        Thread thread2 = new Thread(() -&gt; &#123;            threadLocal1.set(2);            threadLocal2.set(2);        &#125;);        thread1.start();        thread2.start();    &#125;&#125;\n\n\n\n\n它所对应的底层结构图为:\n\n每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象，Thread 类中就定义了 ThreadLocal.ThreadLocalMap 成员。\n/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null;\n\n\n\n当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-&gt;value 键值对插入到该 Map 中。\npublic void set(T value) &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null)        map.set(this, value);    else        createMap(t, value);&#125;\n\n\n\nget() 方法类似。\npublic T get() &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null) &#123;        ThreadLocalMap.Entry e = map.getEntry(this);        if (e != null) &#123;            @SuppressWarnings(&quot;unchecked&quot;)            T result = (T)e.value;            return result;        &#125;    &#125;    return setInitialValue();&#125;\n\n\n\nThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。\n在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。\n更详细的分析看：Java 并发 - ThreadLocal详解\n(三)可重入代码(Reentrant Code)\n这种代码也叫做纯代码(Pure Code)，可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制权返回后，原来的程序不会出现任何错误。\n可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。\n","categories":["Java多线程"],"tags":["Java高并发"]},{"title":"Java资源大全","url":"/2023/02/19/Java%E8%B5%84%E6%BA%90%E5%A4%A7%E5%85%A8/","content":"Java资源大全\n\n\n\n算法\n操作系统\n网络\n面向对象\n数据库\nJava\n系统设计\n工具\n编码实践\n后记\n\n\n\n✏️\n💻\n☁️\n🎨\n💾\n☕️\n💡\n🔧\n🍉\n📝\n\n\n我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。awesome-java 就是 akullpp 发起维护的 Java 资源列表，内容包括：构建工具、数据库、框架、模板、安全、代码分析、日志、第三方库、书籍、Java 站点等等。伯乐在线已经把 awesome-java 资源列表翻成中文后发布于 ImportNew。\nAwesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。\n\n我们要做什么？\n基于 awesome-java 资源列表，我们将对各个资源项进行编译整理。\n\n整理后的内容，将收录在\n伯乐在线资源频道\n。可参考已整理的内容：\n\n《OWNER：Java配置文件解决方案》\n《Spring Boot：简化Spring应用初始搭建以及开发过程》\n《SonarQube：开源的代码质量管理工具》\n\n\n\n\n如何参与本项目？\n如何为列表贡献新资源？欢迎大家为列表贡献高质量的新资源，提交PR时请参照以下要求：\n\n请确保推荐的资源自己使用过\n提交PR时请注明推荐理由\n\n资源列表管理收到PR请求后，会定期（每周）在微博转发本周提交的PR列表，并在微博上面听取使用过这些资源的意见。确认通过后，会加入资源大全。\n感谢您的贡献！\n\n本项目的参与者\n维护者：tangyouhua\n贡献者：tangyouhua、kingzone、llhua2329、BadCoderChou、anankun、贺贺、大彭、superXiaoFan、javayrf、[John Smith](http://www.importnew.com/members/John Smith&#x2F;)、Jaler、JM、dreamkidd、cheenlie、zhangQian1991、王涛、马、vvkee、凝枫、haixunlu、milly、Hodur、FakeHank、连乐、UncleTim、sunbiaobiao、zhiguo、光光头去打酱油、云中游、Zemo、sdcuike、danielwii、oneDay、邢敏、heikehuan、fgcui1204、wenxueliu、Gentle Yang、黄小非、wangtg、百焱、胡不GUI、Another_mt、Rainbow、super^糖、黄余粮、Sun、李伟高、lixiaobao、許中、You\n\n注：名单不分排名，不定期补充更新\n\n\n我们要做什么？\n如何参与本项目？\n如何为列表贡献新资源？\n本项目的参与者\n\n古董级工具这些工具伴随着Java一起出现，在各自辉煌之后还在一直使用。\n\nApache Ant：基于XML的构建管理工具。官网\ncglib：字节码生成库。官网\nGlassFish：应用服务器，由Oracle赞助支持的Java EE参考实现。官网\nHudson：持续集成服务器，目前仍在活跃开发。官网\nJavaServer Faces：Mojarra是JSF标准的一个开源实现，由Oracle开发。官网\nJavaServer Pages：支持自定义标签库的网站通用模板库。官网\nLiquibase：与具体数据库独立的追踪、管理和应用数据库Scheme变化的工具。官网\n\n构建工具构建及应用依赖关系处理工具。\n\nApache Maven：Maven是一款声明式构建及依赖管理工具，采用约定优于配置方式进行管理。相对Apache Ant更推荐使用Maven，前者采用了过程式管理，维护相对困难。官网\nBazel：来自Google的构建工具，可以快速、可靠地构建代码。官网\nGradle：使用Groovy（非XML）进行增量构建，可以很好地与Maven依赖管理配合工作。官网\nBuck：Facebook构建工具。官网\n\n字节码操作编程方式操作字节码的开发库。\n\nASM：通用底层字节码操作和分析开发库。官网\nByte Buddy：使用流式API进一步简化字节码生成。官网\nByteman：在运行时通过DSL（规则）操作字节码进行测试和故障排除。官网\nJavassist：一个简化字节码编辑尝试。官网\n\n集群管理在集群内动态管理应用程序的框架。\n\nApache Aurora：Apache Aurora是一个Mesos框架，用于长时间运行服务和定时任务（cron job）。官网\nSingularity：Singularity是一个Mesos框架，方便部署和操作。它支持Web Service、后台运行、调度作业和一次性任务。官网\n\n代码分析测量代码指标和质量工具。\n\nCheckstyle：代码编写规范和标准静态分析工具。官网\nError Prone：将常见编程错误作为运行时错误报告。官网\nFindBugs：通过字节码静态分析查找隐藏bug。官网\njQAssistant：使用基于Neo4J查询语言进行代码静态分析。官网\nPMD：对源代码分析查找不良的编程习惯。官网\nSonarQube：通过插件集成其它分析组件，对过去一段时间内的数据进行统计。官网\n\n编译器生成工具用来创建解析器、解释器或编译器的框架。\n\nANTLR：复杂的全功能自顶向下解析框架。官网\nJavaCC：JavaCC是更加专门的轻量级工具，易于上手且支持语法超前预测。官网\n\n外部配置工具支持外部配置的开发库。\n\nconfig：针对JVM语言的配置库。官网\nowner：减少冗余配置属性。官网\n\n约束满足问题求解程序帮助解决约束满足问题的开发库。\n\nChoco：可直接使用的约束满足问题求解程序，使用了约束规划技术。官网\nJaCoP：为FlatZinc语言提供了一个接口，可以执行MiniZinc模型。官网\nOptaPlanner：业务规划与资源调度优化求解程序。官网\nSat4J：逻辑代数与优化问题最先进的求解程序。官网\n\n持续集成\nBamboo：Atlassian解决方案，可以很好地集成Atlassian的其他产品。可以选择开源许可，也可以购买商业版。官网\nCircleCI：提供托管服务，可以免费试用。官网\nCodeship：提供托管服务，提供有限的免费模式。官网\nfabric8：容器集成平台。官网\nGo：ThoughtWork开源解决方案。官网\nJenkins：支持基于服务器的部署服务。官网\nTeamCity：JetBrain的持续集成解决方案，有免费版。官网\nTravis：通常用作开源项目的托管服务。官网\nBuildkite: 持续集成工具，用简单的脚本就能设置pipeline，而且能快速构建，可以免费试用。官网\n\nCSV解析简化CSV数据读写的框架与开发库\n\nuniVocity-parsers：速度最快功能最全的CSV开发库之一，同时支持TSV与固定宽度记录的读写。官网\n\n数据库简化数据库交互的相关工具。\n\nApache Phoenix：HBase针对低延时应用程序的高性能关系数据库层。官网\nCrate：实现了数据同步、分片、缩放、复制的分布式数据存储。除此之外还可以使用基于SQL的语法跨集群查询。官网\nFlyway：简单的数据库迁移工具。官网\nH2：小型SQL数据库，以可以作为内存数据库使用著称。官网\nHikariCP：高性能JDBC连接工具。官网\nJDBI：便捷的JDBC抽象。官网\njOOQ：为SQL schema生成typesafe代码。官网\nMapDB：以磁盘或堆内存中并发集合为基础的嵌入式数据库引擎。官网\nPresto：针对大数据的分布式SQL查询引擎。官网\nQuerydsl：Typesafe统一查询。官网\n\n数据结构\nApache Parquet：Google Dremel论文中发布的基于组装算法的列式（Columnar）存储格式。官网\nProtobuf：Google数据交换格式。官网\nSBE：简单二进制编码，是最快速的消息格式之一。官网\nWire：整洁轻量级协议缓存。官网\n\n时间日期工具库处理时间和日期的开发库。\n\nJoda-Time：在Java 8发布前，Joda-Time是实际使用的时间日期库标准。官网\nTime4J：高级时间和日期库。官网\nThreeTen：JSR-310实现，为JDK提供更具特点的时间和日期API。官网\n\n依赖注入帮实现依赖翻转范式的开发库。 官网\n\nApache DeltaSpike：CDI扩展框架。官网\nDagger2：编译时注入框架，不需要使用反射。官网\nGuice：可以匹敌Dagger的轻量级注入框架。官网\nHK2：轻量级动态依赖注入框架。官网\n\n开发流程增强工具从最基本的层面增强开发流程。\n\nADT4J：针对代数数据类型的JSR-269代码生成器。官网\nAspectJ：面向切面编程（AOP）的无缝扩展。官网\nAuto：源代码生成器集合。官网\nDCEVM：通过修改JVM在运行时支持对已加载的类进行无限次重定义。官网\nHotswapAgent：支持无限次重定义运行时类与资源。官网\nImmutables：类似Scala的条件类。官网\nJHipster：基于Spring Boot与AngularJS应用程序的Yeoman源代码生成器。官网\nJRebel：无需重新部署，可以即时重新加载代码与配置的商业软件。官网\nLombok：减少冗余的代码生成器。官网\nSpring Loaded：类重载代理。官网\nvert.x：多语言事件驱动应用框架。官网\n\n分布式应用用来编写分布式容错应用的开发库和框架。\n\nAkka：用来编写分布式容错并发事件驱动应用程序的工具和运行时。官网\nApache Storm：实时计算系统。官网\nApache ZooKeeper：针对大型分布式系统的协调服务，支持分布式配置、同步和名称注册。官网\nHazelcast：高可扩展内存数据网格。官网\nHystrix：提供延迟和容错。官网\nJGroups：提供可靠的消息传递和集群创建的工具。官网\nOrbit：支持虚拟角色（Actor），在传统角色的基础上增加了另外一层抽象。官网\nQuasar：为JVM提供轻量级线程和角色。官网\n\n分布式数据库对应用程序而言，在分布式系统中的数据库看起来就像是只有一个数据源。\n\nApache Cassandra：列式数据库，可用性高且没有单点故障。官网\nApache HBase：针对大数据的Hadoop数据库。官网\nDruid：实时和历史OLAP数据存储，在聚集查询和近似查询方面表现不俗。官网\nInfinispan：针对缓存的高并发键值对数据存储。官网\nTiDB：开源分布式HTAP数据库，结合了传统的RDBMS和NoSQL的最佳特性。官网\n\n发布以本机格式发布应用程序的工具。\n\nBintray：发布二进制文件版本控制工具。可以于Maven或Gradle一起配合使用。提供开源免费版本和几种商业收费版本。官网\nCentral Repository：最大的二进制组件仓库，面向开源社区提供免费服务。Apache Maven默认使用Central 官网Repository，也可以在所有其他构建工具中使用。\nIzPack：为跨平台部署建立创作工具（Authoring Tool）。官网\nJitPack：打包GitHub仓库的便捷工具。可根据需要构建Maven、Gradle项目，发布可立即使用的组件。官网\nLaunch4j：将JAR包装为轻量级本机Windows可执行程序。官网\nNexus：支持代理和缓存功能的二进制管理工具。官网\npackr：将JAR、资源和JVM打包成Windows、Linux和Mac OS X本地发布文件。官网\n\n文档处理工具处理Office文档的开发库。\n\nApache POI：支持OOXML规范（XLSX、DOCX、PPTX）以及OLE2规范（XLS、DOC、PPT）。官网\ndocuments4j：使用第三方转换器进行文档格式转换，转成类似MS Word这样的格式。官网\njOpenDocument：处理OpenDocument格式（由Sun公司提出基于XML的文档格式）。官网\n\n函数式编程函数式编程支持库。\n\nCyclops：支持一元（Monad）操作和流操作工具类、comprehension（List语法）、模式匹配、trampoline等特性。官网\nFugue：Guava的函数式编程扩展。官网\nFunctional Java：实现了多种基础和高级编程抽象，用来辅助面向组合开发（composition-oriented development）。官网\nJavaslang：一个函数式组件库，提供持久化数据类型和函数式控制结构。官网\njOOλ：旨在填补Java 8 lambda差距的扩展，提供了众多缺失的类型和一组丰富的顺序流API。官网\n\n游戏开发游戏开发框架。\n\njMonkeyEngine：现代3D游戏开发引擎。官网\nlibGDX：全面的跨平台高级框架。官网\nLWJGL：对OpenGL&#x2F;CL&#x2F;AL等技术进行抽象的健壮框架。官网\njPCT：基于OpenGL技术开发的3D图形引擎。纯Java的3D引擎。官网\n\nGUI现代图形化用户界面开发库。\n\nJavaFX：Swing的后继者。官网\nScene Builder：开发JavaFX应用的可视化布局工具。官网\n\n高性能计算涵盖了从集合到特定开发库的高性能计算相关工具。\n\nAgrona：高性能应用中常见的数据结构和工具方法。官网\nDisruptor：线程间消息传递开发库。官网\nfastutil：快速紧凑的特定类型集合（Collection）。官网\nGS Collections：受Smalltalk启发的集合框架。官网\nHPPC：基础类型集合。官网\nJavolution：实时和嵌入式系统的开发库。官网\nJCTools：JDK中缺失的并发工具。官网\nKoloboke：Hash set和hash map。官网\nTrove：基础类型集合。官网\nHigh-scale-lib:Cliff Click 个人开发的高性能并发库官网\n\nIDE简化开发的集成开发环境。\n\nEclipse：老牌开源项目，支持多种插件和编程语言。官网\nIntelliJ IDEA：支持众多JVM语言，是安卓开发者好的选择。商业版主要针对企业客户。官网\nNetBeans：为多种技术提供集成化支持，包括Java SE、Java EE、数据库访问、HTML5等。官网\nScala IDE：一款基于Eclipse开源平台打造的Scala集成开发环境。官网\nSpringSource Tool Suite（STS）:一款基于Eclipse开源平台打造的Spring应用开发环境。官网\n\n图像处理创建、评价和操作图片的支持库。\n\nImgscalr：纯Java 2D实现，简单、高效、支持硬件加速的图像缩放开发库。官网\nPicasso：安卓图片下载和图片缓存开发库。官网\nThumbnailator：Thumbnailator是一个高质量Java缩略图开发库。官网\nZXing：支持多种格式的一维、二维条形码图片处理开发库。官网\nim4java: 基于ImageMagick或GraphicsMagick命令行的图片处理开发库，基本上ImageMagick能够支持的图片格式和处理方式都能够处理。官网\nApache Batik：在Java应用中程序以SVG格式显示、生成及处理图像的工具集，包括SVG解析器、SVG生成器、SVG DOM等模块，可以集成使用也可以单独使用，还可以扩展自定义的SVG标签。官网\n\nJSON简化JSON处理的开发库。\n\nGenson：强大且易于使用的Java到JSON转换开发库。官网\nGson：谷歌官方推出的JSON处理库，支持在对象与JSON之间双向序列化，性能良好且可以实时调用。官网\nJackson：与GSON类似，在频繁使用时性能更佳。官网\nLoganSquare：基于Jackson流式API，提供对JSON解析和序列化。比GSON与Jackson组合方式效果更好。官网\nFastjson：一个Java语言编写的高性能功能完善的JSON库。官网\nKyro：快速、高效、自动化的Java对象序列化和克隆库。官网\n\nJVM与JDK目前的JVM和JDK实现。\n\nJDK 9：JDK 9的早期访问版本。官网\nOpenJDK：JDK开源实现。官网\n\n基于JVM的语言除Java外，可以用来编写JVM应用程序的编程语言。\n\nScala：融合了面向对象和函数式编程思想的静态类型编程语言。官网\nGroovy：类型可选（Optionally typed）的动态语言，支持静态类型和静态编译。目前是一个Apache孵化器项目。官网\nClojure：可看做现代版Lisp的动态类型语言。官网\nCeylon：RedHat开发的面向对象静态类型编程语言。官网\nKotlin：JetBrain针对JVM、安卓和浏览器提供的静态类型编程语言。官网\nXtend：一种静态编程语言，能够将其代码转换为简洁高效的Java代码，并基于JVM运行。官网\n\n日志记录应用程序行为日志的开发库。\n\nApache Log4j 2：使用强大的插件和配置架构进行完全重写。官网\nkibana：分析及可视化日志文件。官网\nLogback：强健的日期开发库，通过Groovy提供很多有趣的选项。官网\nlogstash：日志文件管理工具。官网\nMetrics：通过JMX或HTTP发布参数，并且支持存储到数据库。官网\nSLF4J：日志抽象层，需要与具体的实现配合使用。官网\n\n机器学习提供具体统计算法的工具。其算法可从数据中学习。\n\nApache Flink：快速、可靠的大规模数据处理引擎。官网\nApache Hadoop：在商用硬件集群上用来进行大规模数据存储的开源软件框架。官网\nApache Mahout：专注协同过滤、聚类和分类的可扩展算法。官网\nApache Spark：开源数据分析集群计算框架。官网\nDeepDive：从非结构化数据建立结构化信息并集成到已有数据库的工具。官网\nDeeplearning4j：分布式多线程深度学习开发库。官网\nH2O：用作大数据统计的分析引擎。官网\nWeka：用作数据挖掘的算法集合，包括从预处理到可视化的各个层次。官网\nQuickML：高效机器学习库。官网、GitHub\n\n消息传递在客户端之间进行消息传递，确保协议独立性的工具。\n\nAeron：高效可扩展的单播、多播消息传递工具。官网\nApache ActiveMQ：实现JMS的开源消息代理（broker），可将同步通讯转为异步通讯。官网\nApache Camel：通过企业级整合模式（Enterprise Integration Pattern EIP）将不同的消息传输API整合在一起。官网\nApache Kafka：高吞吐量分布式消息系统。官网\nHermes：快速、可靠的消息代理（Broker），基于Kafka构建。官网\nJBoss HornetQ：清晰、准确、模块化，可以方便嵌入的消息工具。官网\nJeroMQ：ZeroMQ的纯Java实现。官网\nSmack：跨平台XMPP客户端函数库。官网\nOpenfire：是开源的、基于XMPP、采用Java编程语言开发的实时协作服务器。 Openfire安装和使用都非常简单，并可利用Web界面进行管理。 官网 GitHub\nSpark：是一个开源，跨平台IM客户端。它的特性支持集组聊天，电话集成和强大安全性能。如果企业内部部署IM使用Openfire+Spark是最佳的组合。 官网 GitHub\nTigase： 是一个轻量级的可伸缩的 Jabber&#x2F;XMPP 服务器。无需其他第三方库支持，可以处理非常高的复杂和大量的用户数，可以根据需要进行水平扩展。 官网\n\n杂项未分类其它资源。\n\nDesign Patterns：实现并解释了最常见的设计模式。官网\nJimfs：内存文件系统。官网\nLanterna：类似curses的简单console文本GUI函数库。官网\nLightAdmin：可插入式CRUD UI函数库，可用来快速应用开发。官网\nOpenRefine：用来处理混乱数据的工具，包括清理、转换、使用Web Service进行扩展并将其关联到数据库。官网\nRoboVM：Java编写原生iOS应用。官网\nQuartz：强大的任务调度库.官网\n\n应用监控工具监控生产环境中应用程序的工具。\n\nAppDynamics：性能监测商业工具。官网\nJavaMelody：性能监测和分析工具。官网\nKamon：Kamon用来监测在JVM上运行的应用程序。官网\nNew Relic：性能监测商业工具。官网\nSPM：支持对JVM应用程序进行分布式事务追踪的性能监测商业工具。官网\nOverOps(Takipi)：产品运行时错误监测及调试商业工具。官网\n\n原生开发库用来进行特定平台开发的原生开发库。\n\nJNA：不使用JNI就可以使用原生开发库。此外，还为常见系统函数提供了接口。官网\n\n自然语言处理用来专门处理文本的函数库。\n\nApache OpenNLP：处理类似分词等常见任务的工具。官网\nCoreNLP：斯坦佛CoreNLP提供了一组基础工具，可以处理类似标签、实体名识别和情感分析这样的任务。官网\nLingPipe：一组可以处理各种任务的工具集，支持POS标签、情感分析等。官网\nMallet：统计学自然语言处理、文档分类、聚类、主题建模等。官网\n\n网络网络编程函数库。\n\nAsync Http Client：异步HTTP和WebSocket客户端函数库。官网\nGrizzly：NIO框架，在Glassfish中作为网络层使用。官网\nNetty：构建高性能网络应用程序开发框架。官网\nOkHttp：一个Android和Java应用的HTTP+SPDY客户端。官网\nUndertow：基于NIO实现了阻塞和非阻塞API的Web服务器，在WildFly中作为网络层使用。官网\nunirest-java: Unirest 是一个轻量级的 HTTP 请求库，涵盖 Node、Ruby、Java、PHP、Python、Objective-C、.NET 等多种语言。可发起 GET, POST, PUT, PATCH, DELETE, HEAD, OPTIONS 请求。官网\nbrpc-java: java版baidu rpc框架，高性能、多协议、易扩展、低耦合。官网\n\nORM处理对象持久化的API。\n\nEbean：支持快速数据访问和编码的ORM框架。官网\nEclipseLink：支持许多持久化标准，JPA、JAXB、JCA和SDO。官网\nHibernate：广泛使用、强健的持久化框架。Hibernate的技术社区非常活跃。官网\nMyBatis：带有存储过程或者SQL语句的耦合对象（Couples object）。官网\nOrmLite：轻量级开发包，免除了其它ORM产品中的复杂性和开销。官网\nNutz：另一个SSH。官网，Github，论坛\nJFinal：JAVA WEB + ORM框架。官网，Github\nApache OpenJPA: 实现了 EJB 3.0 中的 JPA 标准,为开发者提供功能强大、使用简单的持久化数据管理框架。 官网\n\nPDF用来帮助创建PDF文件的资源。\n\nApache FOP：从XSL-FO创建PDF。官网\nApache PDFBox：用来创建和操作PDF的工具集。官网\nDynamicReports：JasperReports的精简版。官网\nflyingsaucer：XML&#x2F;XHTML和CSS 2.1渲染器。官网\niText：一个易于使用的PDF函数库，用来编程创建PDF文件。注意，用于商业用途时需要许可证。官网\nJasperReports：一个复杂的报表引擎。官网\n\n性能分析性能分析、性能剖析及基准测试工具。\n\njHiccup：提供平台中JVM暂停的日志和记录。官网\nJMH：JVM基准测试工具。官网\nJProfiler：商业分析器。官网\nLatencyUtils：测量和报告延迟的工具。官网\nVisualVM：对运行中的应用程序信息提供了可视化界面。官网\nYourKit Java Profiler：商业分析器。官网\n\n响应式开发库用来开发响应式应用程序的开发库。\n\nReactive Streams：异步流处理标准，支持非阻塞式反向压力（backpressure）。官网\nReactor：构建响应式快速数据（fast-data）应用程序的开发库。官网\nRxJava：通过JVM可观察序列（observable sequence）构建异步和基于事件的程序。官网\n\nREST框架用来创建RESTful 服务的框架。\n\nDropwizard：偏向于自己使用的Web框架。用来构建Web应用程序，使用了Jetty、Jackson、Jersey和Metrics。官网\nFeign：受Retrofit、JAXRS-2.0和WebSocket启发的HTTP客户端连接器（binder）。官网\nJersey：JAX-RS参考实现。官网\nRESTEasy：经过JAX-RS规范完全认证的可移植实现。官网\nRestExpress：一个Java类型安全的REST客户端。官网\nRestX：基于注解处理和编译时源码生成的框架。官网\nRetrofit：类型安全的REST客户端。官网\nSpark：受到Sinatra启发的Java REST框架。官网\nSwagger：Swagger是一个规范且完整的框架，提供描述、生产、消费和可视化RESTful Web Service。官网\nBlade：国人开发的一个轻量级的MVC框架. 它拥有简洁的代码，优雅的设计。官网\n\n科学计算与分析用于科学计算和分析的函数库。\n\nDataMelt：用于科学计算、数据分析及数据可视化的开发环境。官网\nJGraphT：支持数学图论对象和算法的图形库。官网\nJScience：用来进行科学测量和单位的一组类。官网\n\n搜索引擎文档索引引擎，用于搜索和分析。\n\nApache Solr：一个完全的企业搜索引擎。为高吞吐量通信进行了优化。官网\nElasticsearch：一个分布式、支持多租户（multitenant）全文本搜索引擎。提供了RESTful Web接口和无schema的JSON文档。官网\nApache Lucene：是一个开放源代码的全文检索引擎工具包，是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。官网\n\n安全用于处理安全、认证、授权或会话管理的函数库。\n\nApache Shiro：执行认证、授权、加密和会话管理。官网\nBouncy Castle，涵盖了从基础的帮助函数到PGP&#x2F;SMIME操作。官网：多途加密开发库。支持JCA提供者（JCA provider)\nCryptomator：在云上进行客户端跨平台透明加密。官网\nKeycloak：为浏览器应用和RESTful Web Service集成SSO和IDM。目前还处于beta版本，但是看起来非常有前途。官网\nPicketLink：PicketLink是一个针对Java应用进行安全和身份认证管理的大型项目（Umbrella Project）。官网\n\n序列化用来高效处理序列化的函数库。\n\nFlatBuffers：高效利用内存的序列化函数库，无需解包和解析即可高效访问序列化数据。官网\nKryo：快速、高效的对象图形序列化框架。官网\nFST：提供兼容JDK的高性能对象图形序列化。官网\nMessagePack：一种高效的二进制序列化格式。官网\n\n应用服务器用来部署应用程序的服务器。\n\nApache Tomcat：针对Servlet和JSP的应用服务器，健壮性好且适用性强。官网\nApache TomEE：Tomcat加Java EE。官网\nJetty：轻量级、小巧的应用服务器，通常会嵌入到项目中。官网\nWebSphere Liberty：轻量级、模块化应用服务器，由IBM开发。官网\nWildFly：之前被称作JBoss，由Red Hat开发。支持很多Java EE功能。官网\n\n模板引擎在模板中替换表达式的工具。\n\nApache Velocity：提供HTML页面模板、email模板和通用开源代码生成器模板。官网\nFreeMarker：通用模板引擎，不需要任何重量级或自己使用的依赖关系。官网\nHandlebars.java：使用Java编写的模板引擎，逻辑简单，支持语义扩展（semantic Mustache）。官网\nThymeleaf：旨在替换JSP，支持XML文件的工具。官网\nBeetl：新一代的模板引擎，功能强大，性能良好，超过当前流行的模板引擎。而且还易学易用。官网\n\n测试测试内容从对象到接口，涵盖性能测试和基准测试工具。\n\nApache JMeter：功能性测试和性能评测。官网\nArquillian：集成测试和功能行测试平台，集成Java EE容器。官网\nAssertJ：支持流式断言提高测试的可读性。官网\nAwaitility：用来同步异步操作的DSL。官网\nCucumber：BDD测试框架。官网\nGatling：设计为易于使用、可维护的和高性能负载测试工具。官网\nHamcrest：可用来灵活创建意图（intent）表达式的匹配器。官网\nJMockit：用来模拟静态、final方法等。官网\nJUnit：通用测试框架。官网\nMockito：在自动化单元测试中创建测试对象，为TDD或BDD提供支持。官网\nPowerMock： 支持模拟静态方法、构造函数、final类和方法、私有方法以及移除静态初始化器的模拟工具。官网\nREST Assured：为REST&#x2F;HTTP服务提供方便测试的Java DSL。官网\nSelenide：为Selenium提供精准的周边API，用来编写稳定且可读的UI测试。官网\nSelenium：为Web应用程序提供可移植软件测试框架。官网\nSpock：JUnit-compatible framework featuring an expressive Groovy-derived specification language.官网兼容JUnit框架，支持衍生的Groovy范的语言。\nTestNG：测试框架。官网\nTruth：Google的断言和命题（proposition）框架。官网\nUnitils：模块化测试函数库，支持单元测试和集成测试。官网\nWireMock：Web Service测试桩（Stub）和模拟函数。官网\n\n通用工具库通用工具类函数库。\n\nApache Commons：提供各种用途的函数，比如配置、验证、集合、文件上传或XML处理等。官网\nargs4j：命令行参数解析器。官网\nCRaSH：为运行进行提供CLI。官网\nGephi：可视化跨平台网络图形化操作程序。官网\nGuava：集合、缓存、支持基本类型、并发函数库、通用注解、字符串处理、I&#x2F;O等。官网\nJADE：构建、调试多租户系统的框架和环境。官网\njavatuples：正如名字表示的那样，提供tuple支持。尽管目前tuple的概念还有留有争议。官网\nJCommander：命令行参数解析器。官网\nProtégé：提供存在论（ontology）编辑器以及构建知识系统的框架。官网\nHutool：一个Java工具集，缓存、HTTP、加密解密、DFA、JSON、分组配置文件、数据库操作、图片验证码、Excel读写、定时任务、模板引擎、邮件、Servlet、二维码、Emoji、分词等一系列工具类。官网\n\n网络爬虫用于分析网站内容的函数库。\n\nApache Nutch：可用于生产环境的高度可扩展、可伸缩的网络爬虫。官网\nCrawler4j：简单的轻量级网络爬虫。官网\nJSoup：刮取、解析、操作和清理HTML。官网\nwebmagic：一个可扩展的Java爬虫框架，架构类似Python的Scrapy。\n\nWeb框架用于处理Web应用程序不同层次间通讯的框架。\n\nApache Tapestry：基于组件的框架，使用Java创建动态、强健的、高度可扩展的Web应用程序。官网\nApache Wicket：基于组件的Web应用框架，与Tapestry类似带有状态显示GUI。官网\nGoogle Web Toolkit：一组Web开发工具集，包含在客户端将Java代码转为JavaScript的编译器、XML解析器、RCP 官网API、JUnit集成、国际化支持和GUI控件。\nGrails：Groovy框架，旨在提供一个高效开发环境，使用约定而非配置、没有XML并支持混入（mixin）。官网\nNinja：Java全栈Web开发框架。非常稳固、快速和高效。官网\nPippo：小型、高度模块化的类Sinatra框架。官网\nPlay：使用约定而非配置，支持代码热加载并在浏览器中显示错误。官网\nPrimeFaces：JSF框架，提供免费和带支持的商业版本。包括若干前端组件。官网\nRatpack：一组Java开发函数库，用于构建快速、高效、可扩展且测试完备的HTTP应用程序。官网\nSpring Boot：微框架，简化了Spring新程序的开发过程。官网\nSpring：旨在简化Java EE的开发过程，提供依赖注入相关组件并支持面向切面编程。官网\nVaadin：基于GWT构建的事件驱动框架。使用服务端架构，客户端使用Ajax。官网\nBlade：国人开发的一个轻量级的MVC框架. 它拥有简洁的代码，优雅的设计。官网\n\n业务流程管理套件流程驱动的软件系统构建。\n\njBPM：非常灵活的业务流程管理框架，致力于构建开发与业务分析人员之间的桥梁。官网\nActivity：轻量级工作流和业务流程管理框架。官网 github\n\n资源社区\nr&#x2F;java：Reddit的Java子社区。官网\nstackoverflow：问答平台。官网\nvJUG：虚拟Java用户组。官网\njava8 新特性教程例子。github\n\n有影响力的书具有广泛影响且值得阅读的Java经典书籍。\n\nEffective Java (2nd Edition)\nJava 8 in Action\nJava Concurrency in Practice | Java并发编程实战\nThinking in Java | Java编程思想\nJava Puzzlers | Java解惑\n\n播客可以一边编程一边听的东西。\n\nJava Council：官网\nJava Posse：Discontinued as of 02&#x2F;2015.官网\n\n微博、微信公众号\nImportNew：是最受欢迎的、专注Java技术分享的微信公众号。专注Java技术分享，包括Java基础技术、进阶技能、架构设计和Java技术领域动态等。\nImportNew 微博：@ImportNew\n\nTwitter\nAdam Bien：自由职业者、作家、JavaONE明星演讲者、顾问、Java Champion。\nAntonio Goncalves：Java Champion、JUG Leader、Devoxx France、Java EE 6&#x2F;7、JCP、作家。\nArun Gupta：Java Champion、JavaONE明星演讲者、JUG Leader、Devoxx4Kids成员、Red Hatter。\nBruno Borges：Oracle产品经理、Java Jock。\nEd Burns：Oracle技术团队顾问。\nEugen Paraschiv：Spring安全课程作者。\nJames Weaver：Java、JavaFX、IoT开发者、作者和演讲者。\nJava EE：Java EE Twitter官方账号。\nJava Magazine：Java杂志官方账号。\nJava.net：Java.net官方账号。\nJava：Java Twitter官方账号。\nJavin Paul：知名Java博客作者。\nLukas Eder：Data Geekery（jOOQ）创始人兼CEO。\nMario Fusco：RedHatter、JUG协调、活跃讲师和作者。\nMark Reinhold：Oracle首席架构师、Java平台开发组。\nMartijn Verburg：London JUG co-leader、演讲者、作家、Java Champion等。\nOpenJDK：OpenJDK官方账号。\nReza Rahman：Java EE、GlassFish、WebLogic传道者、作家、演讲者、开源黑客。\nSimon Maple：Java Champion、virtualJUG创始人、LJC leader、RebelLabs作者。\nStephen Colebourne： Java Champion、演讲者。\nTim Boudreau：作家、NetBeans大牛。\nTrisha Gee：Java Champion、演讲者。\n\n微博、微信公众号\nImportNew 微博：@ImportNew\nImportNew：最受欢迎的、专注Java技术分享的微信公众号。专注Java技术分享，包括Java基础技术、进阶技能、架构设计和Java技术领域动态等。\n\n知名网站值得关注的Java技术站点。\n中文站点\nImportNew（ImportNew 专注 Java 技术）\n\n英文站点\nAndroid Arsenal\nGoogle Java Style：官网\nInfoQ：官网\nJava Code Geeks\nJava, SQL, and jOOQ\nJava.net\nJavalobby\nJavaWorld：官网\nJAXenter：官网\nRebelLabs\nThe Java Specialist’ Newsletter：官网\nThe Takipi Blog\nTheServerSide.com：服务器编程交流平台是一个老牌的IT信息网站，关注服务器端编程的，以Java和.Net周边信息为主。官网\nThoughts On Java\nVanilla Java\nVlad Mihalcea on Hibernate\nVoxxed\nOnJava：O’Reilly Java包含最新的Java技术资讯，优质代码，完全的实例和详解。官网\n\n","categories":["Java资源大全"],"tags":["Java资源"]},{"title":"Linux 配置静态IP","url":"/2023/03/16/Linux%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81IP/","content":"Linux 配置静态IPCentOS 7 为例    修改网卡配置文件vim /etc/sysconfig/network-scripts/ifcfg-ens33# 配置的IP地址IPADDR=192.168.1.30# 配置子网掩码NETMASK=255.255.255.0# 配置网关GATEWAY=192.168.1.2# 配置DNS服务器# 114 DNSDNS1=114.114.114.114# 阿里DNSDNS2=233.5.5.5# 谷歌DNSDNS3=8.8.8.8重启网卡service network restart\n\n\n\nRocky 9.0 NetworkManager 配置文件位置（ens160网卡名称）修改网卡配置文件\nvim &#x2F;etc&#x2F;NetworkManager&#x2F;system-connections&#x2F;ens160.nmconnection\n[ipv4]\n &#x2F;&#x2F;添加ip&#x2F;子网掩码,网关\naddress1&#x3D;192.168.1.30&#x2F;24,192.168.1.254 \n&#x2F;&#x2F;添加dns地址（多个用;隔开）\ndns&#x3D;8.8.8.8;114.114.114.114;                \nmay-fail&#x3D;false\nmethod&#x3D;manual\n重新加载配置文件nmcli connection load &#x2F;etc&#x2F;NetworkManager&#x2F;system-connections&#x2F;ens160.nmconnectioni\n激活配置文件nmcli connection up &#x2F;etc&#x2F;NetworkManager&#x2F;system-connections&#x2F;ens160.nmconnection\n","categories":["Linux 静态IP"],"tags":["Linux"]},{"title":"MQTT协议中文版","url":"/2023/02/19/MQTT%E5%8D%8F%E8%AE%AE%E4%B8%AD%E6%96%87%E7%89%88/","content":"\nMQTT协议中文版by mcxiaoke\n最新版本: v1.0.5 2019.10.30\n文档地址\nMQTT Monitor\nMQTT项目文档\nGitBook阅读\nWiki文档地址\nPDF和ePub下载\n中文翻译项目\n\n概述MQTT是一个客户端服务端架构的发布&#x2F;订阅模式的消息传输协议。它的设计思想是轻巧、开放、简单、规范，易于实现。这些特点使得它对很多场景来说都是很好的选择，特别是对于受限的环境如机器与机器的通信（M2M）以及物联网环境（IoT）。\n目录发现任何翻译问题或格式问题欢迎提PR帮忙完善。\n\n说明\n前言\n目录\n第一章 - MQTT介绍\n第二章 – MQTT控制报文格式\n第三章 – MQTT控制报文\n3.1 CONNECT – 连接服务端\n3.2 CONNACK – 确认连接请求\n3.3 PUBLISH – 发布消息\n3.4 PUBACK –发布确认\n3.5 PUBREC – 发布收到（QoS 2，第一步）\n3.6 PUBREL – 发布释放（QoS 2，第二步）\n3.7 PUBCOMP – 发布完成（QoS 2，第三步）\n3.8 SUBSCRIBE - 订阅主题\n3.9 SUBACK – 订阅确认\n3.10 UNSUBSCRIBE –取消订阅\n3.11 UNSUBACK – 取消订阅确认\n3.12 PINGREQ – 心跳请求\n3.13 PINGRESP – 心跳响应\n3.14 DISCONNECT –断开连接\n\n\n第四章 – 操作行为\n第五章 – 安全\n第六章 – 使用WebSocket\n第七章 – 一致性目标\n附录B - 强制性规范声明\n\n\n旧版文档\n已过期，建议使用GitBook版本 最新版本: v1.0.1 2015.10.22\n\n\n\n\n文档\n连接\n\n\n\n中文版 HTML\nMQTT 3.1.1 中文版\n\n\n中文版 PDF\nMQTT 3.1.1 中文版\n\n\n英文版 HTML\nMQTT Version 3.1.1\n\n\n英文版 PDF\nMQTT Version 3.1.1\n\n\n许可协议\n署名-非商业性使用-相同方式共享 4.0 国际\n\n\n联系方式\nBlog: http://blog.mcxiaoke.com\nGithub: https://github.com/mcxiaoke\nEmail: github@mcxiaoke.com\n\n开源项目\nMQTT Monitor: https://github.com/mcxiaoke/mqtt-monitor\nRx文档中文翻译: https://github.com/mcxiaoke/RxDocs\nMQTT协议中文版: https://github.com/mcxiaoke/mqtt\nAwesome-Kotlin: https://github.com/mcxiaoke/awesome-kotlin\nKotlin-Koi: https://github.com/mcxiaoke/kotlin-koi\nNext公共组件库: https://github.com/mcxiaoke/Android-Next\nPackerNg极速打包: https://github.com/mcxiaoke/packer-ng-plugin\nGradle渠道打包: https://github.com/mcxiaoke/gradle-packer-plugin\nEventBus实现xBus: https://github.com/mcxiaoke/xBus\n蘑菇饭App: https://github.com/mcxiaoke/minicat\n饭否客户端: https://github.com/mcxiaoke/fanfouapp-opensource\nVolley镜像: https://github.com/mcxiaoke/android-volley\n\n\n","categories":["MQTT协议中文版"],"tags":["MQTT协议"]},{"title":"Map - HashSet & HashMap 源码解析","url":"/2023/02/19/Map%20-%20HashSet%20&%20HashMap%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","content":"Map - HashSet &amp; HashMap 源码解析\n\n本文主要对Map - HashSet &amp; HashMap进行源码解析。\n\n\nJDK版本\n参考\n概述\nHashMap实现\nget()\nput()\nremove()\n\nJDK版本\nJDK 1.8.0_110\n\n参考\nJava HashSet &amp; HashMap 源码解析 结合源码对HashSet和HashMap进行讲解 https://www.cnblogs.com/CarpenterLee/p/5440428.html\n\n概述之所以把_HashSet_和_HashMap_放在一起讲解，是因为二者在Java里有着相同的实现，前者仅仅是对后者做了一层包装，也就是说___HashSet_里面有一个_HashMap_(适配器模式)**。因此本文将重点分析_HashMap_。\n_HashMap_实现了_Map_接口，即允许放入key为null的元素，也允许插入value为null的元素；除该类未实现同步外，其余跟Hashtable大致相同；跟_TreeMap_不同，该容器不保证元素顺序，根据需要该容器可能会对元素重新哈希，元素的顺序也会被重新打散，因此不同时间迭代同一个_HashMap_的顺序可能会不同。 根据对冲突的处理方式不同，哈希表有两种实现方式，一种开放地址方式(Open addressing)，另一种是冲突链表方式(Separate chaining with linked lists)。Java _HashMap_采用的是冲突链表方式。\n\n从上图容易看出，如果选择合适的哈希函数，put()和get()方法可以在常数时间内完成。但在对_HashMap_进行迭代时，需要遍历整个table以及后面跟的冲突链表。因此对于迭代比较频繁的场景，不宜将_HashMap_的初始大小设的过大。\n有两个参数可以影响_HashMap_的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。\n将对象放入到_HashMap_或_HashSet_中时，有两个方法需要特别关心: hashCode()和equals()。**hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到HashMap或HashSet中，需要@OverridehashCode()和equals()方法。\nHashMap实现get()get(Object key)方法根据指定的key值返回对应的value，该方法调用了getEntry(Object key)得到相应的entry，然后返回entry.getValue()。因此getEntry()是算法的核心。 算法思想是首先通过hash()函数得到对应bucket的下标，然后依次遍历冲突链表，通过key.equals(k)方法来判断是否是要找的那个entry。\n\n上图中hash(k)&amp;(table.length-1)等价于hash(k)%table.length，原因是_HashMap_要求table.length必须是2的指数，因此table.length-1就是二进制低位全是1，跟hash(k)相与会将哈希值的高位全抹掉，剩下的就是余数了。\n//getEntry()方法final Entry&lt;K,V&gt; getEntry(Object key) &#123;\t......\tint hash = (key == null) ? 0 : hash(key);    for (Entry&lt;K,V&gt; e = table[hash&amp;(table.length-1)];//得到冲突链表         e != null; e = e.next) &#123;//依次遍历冲突链表中的每个entry        Object k;        //依据equals()方法判断是否相等        if (e.hash == hash &amp;&amp;            ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))            return e;    &#125;    return null;&#125;\n\nput()put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于getEntry()方法；如果没有找到，则会通过addEntry(int hash, K key, V value, int bucketIndex)方法插入新的entry，插入方式为头插法。\n\n//addEntry()void addEntry(int hash, K key, V value, int bucketIndex) &#123;    if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123;        resize(2 * table.length);//自动扩容，并重新哈希        hash = (null != key) ? hash(key) : 0;        bucketIndex = hash &amp; (table.length-1);//hash%table.length    &#125;    //在冲突链表头部插入新的entry    Entry&lt;K,V&gt; e = table[bucketIndex];    table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e);    size++;&#125;\n\n\n\nremove()remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry(修改链表的相应引用)。查找过程跟getEntry()过程类似。\n\n//removeEntryForKey()final Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123;\t......\tint hash = (key == null) ? 0 : hash(key);    int i = indexFor(hash, table.length);//hash&amp;(table.length-1)    Entry&lt;K,V&gt; prev = table[i];//得到冲突链表    Entry&lt;K,V&gt; e = prev;    while (e != null) &#123;//遍历冲突链表        Entry&lt;K,V&gt; next = e.next;        Object k;        if (e.hash == hash &amp;&amp;            ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123;//找到要删除的entry            modCount++; size--;            if (prev == e) table[i] = next;//删除的是冲突链表的第一个entry            else prev.next = next;            return e;        &#125;        prev = e; e = next;    &#125;    return e;&#125;\n\n\n\nHashSet前面已经说过_HashSet_是对_HashMap_的简单包装，对_HashSet_的函数调用都会转换成合适的_HashMap_方法，因此_HashSet_的实现非常简单，只有不到300行代码。这里不再赘述。\n//HashSet是对HashMap的简单包装public class HashSet&lt;E&gt;&#123;\t......\tprivate transient HashMap&lt;E,Object&gt; map;//HashSet里面有一个HashMap    // Dummy value to associate with an Object in the backing Map    private static final Object PRESENT = new Object();    public HashSet() &#123;        map = new HashMap&lt;&gt;();    &#125;    ......    public boolean add(E e) &#123;//简单的方法转换        return map.put(e, PRESENT)==null;    &#125;    ......&#125;\n\n","categories":["Java集合框架"],"tags":["Map"]},{"title":"Map - TreeSet & TreeMap 源码解析","url":"/2023/02/19/Map%20-%20TreeSet%20&%20TreeMap%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","content":"Map - TreeSet &amp; TreeMap 源码解析\n本文主要对Map - TreeSet &amp; TreeMap 源码解析。\n\n\nJDK版本\n总体介绍\n预备知识\n左旋\n右旋\n寻找节点后继\n\n\n方法剖析\nget()\nput()\nremove()\n\n\nTreeSet\n\nJDK版本\nJDK 1.8.0_110\n\n总体介绍之所以把_TreeSet_和_TreeMap_放在一起讲解，是因为二者在Java里有着相同的实现，前者仅仅是对后者做了一层包装，也就是说___TreeSet_里面有一个_TreeMap_(适配器模式)**。因此本文将重点分析_TreeMap_。\nJava _TreeMap_实现了_SortedMap_接口，也就是说会按照key的大小顺序对_Map_中的元素进行排序，key大小的评判可以通过其本身的自然顺序(natural ordering)，也可以通过构造时传入的比较器(Comparator)。\n_TreeMap_底层通过红黑树(Red-Black tree)实现，也就意味着containsKey(), get(), put(), remove()都有着log(n)的时间复杂度。其具体算法实现参照了《算法导论》。\n\n出于性能原因，_TreeMap_是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将_TreeMap_包装成(wrapped)同步的:\nSortedMap m = Collections.synchronizedSortedMap(new TreeMap(...));\n\n红黑树是一种近似平衡的二叉查找树，它能够确保任何一个节点的左右子树的高度差不会超过二者中较低那个的一陪。具体来说，红黑树是满足如下条件的二叉查找树(binary search tree):\n\n每个节点要么是红色，要么是黑色。\n根节点必须是黑色\n红色节点不能连续(也即是，红色节点的孩子和父亲都不能是红色)。\n对于每个节点，从该点至null(树尾端)的任何路径，都含有相同个数的黑色节点。\n\n在树的结构发生改变时(插入或者删除操作)，往往会破坏上述条件3或条件4，需要通过调整使得查找树重新满足红黑树的约束条件。\n预备知识前文说到当查找树的结构发生改变时，红黑树的约束条件可能被破坏，需要通过调整使得查找树重新满足红黑树的约束条件。调整可以分为两类: 一类是颜色调整，即改变某个节点的颜色；另一类是结构调整，集改变检索树的结构关系。结构调整过程包含两个基本操作** : 左旋(Rotate Left)，右旋(RotateRight)**。\n左旋左旋的过程是将x的右子树绕x逆时针旋转，使得x的右子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。\n\n_TreeMap_中左旋代码如下:\n//Rotate Leftprivate void rotateLeft(Entry&lt;K,V&gt; p) &#123;    if (p != null) &#123;        Entry&lt;K,V&gt; r = p.right;        p.right = r.left;        if (r.left != null)            r.left.parent = p;        r.parent = p.parent;        if (p.parent == null)            root = r;        else if (p.parent.left == p)            p.parent.left = r;        else            p.parent.right = r;        r.left = p;        p.parent = r;    &#125;&#125;\n\n\n\n右旋右旋的过程是将x的左子树绕x顺时针旋转，使得x的左子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。\n\n_TreeMap_中右旋代码如下:\n//Rotate Rightprivate void rotateRight(Entry&lt;K,V&gt; p) &#123;    if (p != null) &#123;        Entry&lt;K,V&gt; l = p.left;        p.left = l.right;        if (l.right != null) l.right.parent = p;        l.parent = p.parent;        if (p.parent == null)            root = l;        else if (p.parent.right == p)            p.parent.right = l;        else p.parent.left = l;        l.right = p;        p.parent = l;    &#125;&#125;\n\n\n\n寻找节点后继对于一棵二叉查找树，给定节点t，其后继(树中比大于t的最小的那个元素)可以通过如下方式找到:\n\n\nt的右子树不空，则t的后继是其右子树中最小的那个元素。\nt的右孩子为空，则t的后继是其第一个向左走的祖先。\n\n\n后继节点在红黑树的删除操作中将会用到。\n\n_TreeMap_中寻找节点后继的代码如下:\n// 寻找节点后继函数successor()static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) &#123;    if (t == null)        return null;    else if (t.right != null) &#123;// 1. t的右子树不空，则t的后继是其右子树中最小的那个元素        Entry&lt;K,V&gt; p = t.right;        while (p.left != null)            p = p.left;        return p;    &#125; else &#123;// 2. t的右孩子为空，则t的后继是其第一个向左走的祖先        Entry&lt;K,V&gt; p = t.parent;        Entry&lt;K,V&gt; ch = t;        while (p != null &amp;&amp; ch == p.right) &#123;            ch = p;            p = p.parent;        &#125;        return p;    &#125;&#125;\n\n\n\n方法剖析get()get(Object key)方法根据指定的key值返回对应的value，该方法调用了getEntry(Object key)得到相应的entry，然后返回entry.value。因此getEntry()是算法的核心。算法思想是根据key的自然顺序(或者比较器顺序)对二叉查找树进行查找，直到找到满足k.compareTo(p.key) == 0的entry。\n\n具体代码如下:\n//getEntry()方法final Entry&lt;K,V&gt; getEntry(Object key) &#123;    ......    if (key == null)//不允许key值为null        throw new NullPointerException();    Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;//使用元素的自然顺序    Entry&lt;K,V&gt; p = root;    while (p != null) &#123;        int cmp = k.compareTo(p.key);        if (cmp &lt; 0)//向左找            p = p.left;        else if (cmp &gt; 0)//向右找            p = p.right;        else            return p;    &#125;    return null;&#125;\n\n\n\nput()put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于getEntry()方法；如果没有找到则会在红黑树中插入新的entry，如果插入之后破坏了红黑树的约束条件，还需要进行调整(旋转，改变某些节点的颜色)。\npublic V put(K key, V value) &#123;\t......    int cmp;    Entry&lt;K,V&gt; parent;    if (key == null)        throw new NullPointerException();    Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;//使用元素的自然顺序    do &#123;        parent = t;        cmp = k.compareTo(t.key);        if (cmp &lt; 0) t = t.left;//向左找        else if (cmp &gt; 0) t = t.right;//向右找        else return t.setValue(value);    &#125; while (t != null);    Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent);//创建并插入新的entry    if (cmp &lt; 0) parent.left = e;    else parent.right = e;    fixAfterInsertion(e);//调整    size++;    return null;&#125;\n\n\n\n上述代码的插入部分并不难理解: 首先在红黑树上找到合适的位置，然后创建新的entry并插入(当然，新插入的节点一定是树的叶子)。难点是调整函数fixAfterInsertion()，前面已经说过，调整往往需要1.改变某些节点的颜色，2.对某些节点进行旋转。\n\n调整函数fixAfterInsertion()的具体代码如下，其中用到了上文中提到的rotateLeft()和rotateRight()函数。通过代码我们能够看到，情况2其实是落在情况3内的。情况4～情况6跟前三种情况是对称的，因此图解中并没有画出后三种情况，读者可以参考代码自行理解。\n//红黑树调整函数fixAfterInsertion()private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123;    x.color = RED;    while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123;        if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123;            Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x)));            if (colorOf(y) == RED) &#123;                setColor(parentOf(x), BLACK);              // 情况1                setColor(y, BLACK);                        // 情况1                setColor(parentOf(parentOf(x)), RED);      // 情况1                x = parentOf(parentOf(x));                 // 情况1            &#125; else &#123;                if (x == rightOf(parentOf(x))) &#123;                    x = parentOf(x);                       // 情况2                    rotateLeft(x);                         // 情况2                &#125;                setColor(parentOf(x), BLACK);              // 情况3                setColor(parentOf(parentOf(x)), RED);      // 情况3                rotateRight(parentOf(parentOf(x)));        // 情况3            &#125;        &#125; else &#123;            Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x)));            if (colorOf(y) == RED) &#123;                setColor(parentOf(x), BLACK);              // 情况4                setColor(y, BLACK);                        // 情况4                setColor(parentOf(parentOf(x)), RED);      // 情况4                x = parentOf(parentOf(x));                 // 情况4            &#125; else &#123;                if (x == leftOf(parentOf(x))) &#123;                    x = parentOf(x);                       // 情况5                    rotateRight(x);                        // 情况5                &#125;                setColor(parentOf(x), BLACK);              // 情况6                setColor(parentOf(parentOf(x)), RED);      // 情况6                rotateLeft(parentOf(parentOf(x)));         // 情况6            &#125;        &#125;    &#125;    root.color = BLACK;&#125;\n\n\n\nremove()remove(Object key)的作用是删除key值对应的entry，该方法首先通过上文中提到的getEntry(Object key)方法找到key值对应的entry，然后调用deleteEntry(Entry&lt;K,V&gt; entry)删除对应的entry。由于删除操作会改变红黑树的结构，有可能破坏红黑树的约束条件，因此有可能要进行调整。\ngetEntry()函数前面已经讲解过，这里重点放deleteEntry()上，该函数删除指定的entry并在红黑树的约束被破坏时进行调用fixAfterDeletion(Entry&lt;K,V&gt; x)进行调整。\n由于红黑树是一棵增强版的二叉查找树，红黑树的删除操作跟普通二叉查找树的删除操作也就非常相似，唯一的区别是红黑树在节点删除之后可能需要进行调整。现在考虑一棵普通二叉查找树的删除过程，可以简单分为两种情况:\n\n\n删除点p的左右子树都为空，或者只有一棵子树非空。\n删除点p的左右子树都非空。\n\n\n对于上述情况1，处理起来比较简单，直接将p删除(左右子树都为空时)，或者用非空子树替代p(只有一棵子树非空时)；对于情况2，可以用p的后继s(树中大于x的最小的那个元素)代替p，然后使用情况1删除s(此时s一定满足情况1.可以画画看)。\n基于以上逻辑，红黑树的节点删除函数deleteEntry()代码如下:\n// 红黑树entry删除函数deleteEntry()private void deleteEntry(Entry&lt;K,V&gt; p) &#123;    modCount++;    size--;    if (p.left != null &amp;&amp; p.right != null) &#123;// 2. 删除点p的左右子树都非空。        Entry&lt;K,V&gt; s = successor(p);// 后继        p.key = s.key;        p.value = s.value;        p = s;    &#125;    Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right);    if (replacement != null) &#123;// 1. 删除点p只有一棵子树非空。        replacement.parent = p.parent;        if (p.parent == null)            root = replacement;        else if (p == p.parent.left)            p.parent.left  = replacement;        else            p.parent.right = replacement;        p.left = p.right = p.parent = null;        if (p.color == BLACK)            fixAfterDeletion(replacement);// 调整    &#125; else if (p.parent == null) &#123;        root = null;    &#125; else &#123; // 1. 删除点p的左右子树都为空        if (p.color == BLACK)            fixAfterDeletion(p);// 调整        if (p.parent != null) &#123;            if (p == p.parent.left)                p.parent.left = null;            else if (p == p.parent.right)                p.parent.right = null;            p.parent = null;        &#125;    &#125;&#125;\n\n\n\n上述代码中占据大量代码行的，是用来修改父子节点间引用关系的代码，其逻辑并不难理解。下面着重讲解删除后调整函数fixAfterDeletion()。首先请思考一下，删除了哪些点才会导致调整？只有删除点是BLACK的时候，才会触发调整函数，因为删除RED节点不会破坏红黑树的任何约束，而删除BLACK节点会破坏规则4。\n跟上文中讲过的fixAfterInsertion()函数一样，这里也要分成若干种情况。记住，无论有多少情况，具体的调整操作只有两种: 1.改变某些节点的颜色，2.对某些节点进行旋转。\n\n上述图解的总体思想是: 将情况1首先转换成情况2，或者转换成情况3和情况4。当然，该图解并不意味着调整过程一定是从情况1开始。通过后续代码我们还会发现几个有趣的规则: a).如果是由情况1之后紧接着进入的情况2，那么情况2之后一定会退出循环(因为x为红色)；b).一旦进入情况3和情况4，一定会退出循环(因为x为root)。\n删除后调整函数fixAfterDeletion()的具体代码如下，其中用到了上文中提到的rotateLeft()和rotateRight()函数。通过代码我们能够看到，情况3其实是落在情况4内的。情况5～情况8跟前四种情况是对称的，因此图解中并没有画出后四种情况，读者可以参考代码自行理解。\nprivate void fixAfterDeletion(Entry&lt;K,V&gt; x) &#123;    while (x != root &amp;&amp; colorOf(x) == BLACK) &#123;        if (x == leftOf(parentOf(x))) &#123;            Entry&lt;K,V&gt; sib = rightOf(parentOf(x));            if (colorOf(sib) == RED) &#123;                setColor(sib, BLACK);                   // 情况1                setColor(parentOf(x), RED);             // 情况1                rotateLeft(parentOf(x));                // 情况1                sib = rightOf(parentOf(x));             // 情况1            &#125;            if (colorOf(leftOf(sib))  == BLACK &amp;&amp;                colorOf(rightOf(sib)) == BLACK) &#123;                setColor(sib, RED);                     // 情况2                x = parentOf(x);                        // 情况2            &#125; else &#123;                if (colorOf(rightOf(sib)) == BLACK) &#123;                    setColor(leftOf(sib), BLACK);       // 情况3                    setColor(sib, RED);                 // 情况3                    rotateRight(sib);                   // 情况3                    sib = rightOf(parentOf(x));         // 情况3                &#125;                setColor(sib, colorOf(parentOf(x)));    // 情况4                setColor(parentOf(x), BLACK);           // 情况4                setColor(rightOf(sib), BLACK);          // 情况4                rotateLeft(parentOf(x));                // 情况4                x = root;                               // 情况4            &#125;        &#125; else &#123; // 跟前四种情况对称            Entry&lt;K,V&gt; sib = leftOf(parentOf(x));            if (colorOf(sib) == RED) &#123;                setColor(sib, BLACK);                   // 情况5                setColor(parentOf(x), RED);             // 情况5                rotateRight(parentOf(x));               // 情况5                sib = leftOf(parentOf(x));              // 情况5            &#125;            if (colorOf(rightOf(sib)) == BLACK &amp;&amp;                colorOf(leftOf(sib)) == BLACK) &#123;                setColor(sib, RED);                     // 情况6                x = parentOf(x);                        // 情况6            &#125; else &#123;                if (colorOf(leftOf(sib)) == BLACK) &#123;                    setColor(rightOf(sib), BLACK);      // 情况7                    setColor(sib, RED);                 // 情况7                    rotateLeft(sib);                    // 情况7                    sib = leftOf(parentOf(x));          // 情况7                &#125;                setColor(sib, colorOf(parentOf(x)));    // 情况8                setColor(parentOf(x), BLACK);           // 情况8                setColor(leftOf(sib), BLACK);           // 情况8                rotateRight(parentOf(x));               // 情况8                x = root;                               // 情况8            &#125;        &#125;    &#125;    setColor(x, BLACK);&#125;\n\n\n\n\nTreeSet前面已经说过TreeSet是对TreeMap的简单包装，对TreeSet的函数调用都会转换成合适的TreeMap方法，因此TreeSet的实现非常简单。这里不再赘述。\n// TreeSet是对TreeMap的简单包装public class TreeSet&lt;E&gt; extends AbstractSet&lt;E&gt;    implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable&#123;\t......    private transient NavigableMap&lt;E,Object&gt; m;    // Dummy value to associate with an Object in the backing Map    private static final Object PRESENT = new Object();    public TreeSet() &#123;        this.m = new TreeMap&lt;E,Object&gt;();// TreeSet里面有一个TreeMap    &#125;    ......    public boolean add(E e) &#123;        return m.put(e, PRESENT)==null;    &#125;    ......&#125;","categories":["Java集合框架"],"tags":["Map"]},{"title":"Map - LinkedHashSet&Map源码解析","url":"/2023/02/19/Map%20-%20LinkedHashSet&Map%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","content":"Map - LinkedHashSet&amp;Map源码解析\n本文主要对Map - LinkedHashSet&amp;Map 源码解析。\n\n\nJDK版本\n总体介绍\n方法剖析\nget()\nput()\nremove()\n\n\nLinkedHashSet\nLinkedHashMap经典用法\n\nJDK版本\nJDK 1.8.0_110\n\n总体介绍如果你已看过前面关于_HashSet_和_HashMap_，以及_TreeSet_和_TreeMap_的讲解，一定能够想到本文将要讲解的_LinkedHashSet_和_LinkedHashMap_其实也是一回事。LinkedHashSet_和_LinkedHashMap_在Java里也有着相同的实现，前者仅仅是对后者做了一层包装，也就是说___LinkedHashSet_里面有一个_LinkedHashMap(适配器模式)**。因此本文将重点分析_LinkedHashMap_。\nLinkedHashMap_实现了_Map_接口，即允许放入key为null的元素，也允许插入value为null的元素。从名字上可以看出该容器是_linked list_和_HashMap_的混合体，也就是说它同时满足_HashMap_和_linked list_的某些特性。**可将_LinkedHashMap_看作采用_linked list_增强的_HashMap。**\n\n事实上_LinkedHashMap_是_HashMap_的直接子类，二者唯一的区别是_LinkedHashMap_在_HashMap_的基础上，采用双向链表(doubly-linked list)的形式将所有entry连接起来，这样是为保证元素的迭代顺序跟插入顺序相同。上图给出了_LinkedHashMap_的结构图，主体部分跟_HashMap_完全一样，多了header指向双向链表的头部(是一个哑元)，该双向链表的迭代顺序就是entry的插入顺序。\n除了可以保迭代历顺序，这种结构还有一个好处** : 迭代_LinkedHashMap_时不需要像_HashMap_那样遍历整个table，而只需要直接遍历header指向的双向链表即可**，也就是说_LinkedHashMap_的迭代时间就只跟entry的个数相关，而跟table的大小无关。\n有两个参数可以影响_LinkedHashMap_的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。\n将对象放入到_LinkedHashMap_或_LinkedHashSet_中时，有两个方法需要特别关心: hashCode()和equals()。**hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到LinkedHashMap或LinkedHashSet中，需要@OverridehashCode()和equals()方法。\n通过如下方式可以得到一个跟源_Map_ 迭代顺序一样的_LinkedHashMap_:\nvoid foo(Map m) &#123;    Map copy = new LinkedHashMap(m);    ...&#125;\n\n\n\n出于性能原因，_LinkedHashMap_是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将_LinkedHashMap_包装成(wrapped)同步的:\nMap m = Collections.synchronizedMap(new LinkedHashMap(...));\n\n方法剖析get()get(Object key)方法根据指定的key值返回对应的value。该方法跟HashMap.get()方法的流程几乎完全一样，读者可自行[参考前文](https://github.com/CarpenterLee/JCFInternals/blob/master/markdown/6-HashSet and HashMap.md#get) ，这里不再赘述。\nput()put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于get()方法；如果没有找到，则会通过addEntry(int hash, K key, V value, int bucketIndex)方法插入新的entry。\n注意，这里的插入有两重含义:\n\n\n从table的角度看，新的entry需要插入到对应的bucket里，当有哈希冲突时，采用头插法将新的entry插入到冲突链表的头部。\n从header的角度看，新的entry需要插入到双向链表的尾部。\n\n\n\naddEntry()代码如下:\n// LinkedHashMap.addEntry()void addEntry(int hash, K key, V value, int bucketIndex) &#123;    if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123;        resize(2 * table.length);// 自动扩容，并重新哈希        hash = (null != key) ? hash(key) : 0;        bucketIndex = hash &amp; (table.length-1);// hash%table.length    &#125;    // 1.在冲突链表头部插入新的entry    HashMap.Entry&lt;K,V&gt; old = table[bucketIndex];    Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old);    table[bucketIndex] = e;    // 2.在双向链表的尾部插入新的entry    e.addBefore(header);    size++;&#125;\n\n\n\n上述代码中用到了addBefore()方法将新entry e插入到双向链表头引用header的前面，这样e就成为双向链表中的最后一个元素。addBefore()的代码如下:\n// LinkedHashMap.Entry.addBefor()，将this插入到existingEntry的前面private void addBefore(Entry&lt;K,V&gt; existingEntry) &#123;    after  = existingEntry;    before = existingEntry.before;    before.after = this;    after.before = this;&#125;\n\n\n\n上述代码只是简单修改相关entry的引用而已。\nremove()remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry(修改链表的相应引用)。查找过程跟get()方法类似。\n注意，这里的删除也有两重含义:\n\n\n从table的角度看，需要将该entry从对应的bucket里删除，如果对应的冲突链表不空，需要修改冲突链表的相应引用。\n从header的角度来看，需要将该entry从双向链表中删除，同时修改链表中前面以及后面元素的相应引用。\n\n\n\nremoveEntryForKey()对应的代码如下:\n// LinkedHashMap.removeEntryForKey()，删除key值对应的entryfinal Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123;\t......\tint hash = (key == null) ? 0 : hash(key);    int i = indexFor(hash, table.length);// hash&amp;(table.length-1)    Entry&lt;K,V&gt; prev = table[i];// 得到冲突链表    Entry&lt;K,V&gt; e = prev;    while (e != null) &#123;// 遍历冲突链表        Entry&lt;K,V&gt; next = e.next;        Object k;        if (e.hash == hash &amp;&amp;            ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123;// 找到要删除的entry            modCount++; size--;            // 1. 将e从对应bucket的冲突链表中删除            if (prev == e) table[i] = next;            else prev.next = next;            // 2. 将e从双向链表中删除            e.before.after = e.after;            e.after.before = e.before;            return e;        &#125;        prev = e; e = next;    &#125;    return e;&#125;\n\n\n\nLinkedHashSet前面已经说过_LinkedHashSet_是对_LinkedHashMap_的简单包装，对_LinkedHashSet_的函数调用都会转换成合适的_LinkedHashMap_方法，因此_LinkedHashSet_的实现非常简单，这里不再赘述。\npublic class LinkedHashSet&lt;E&gt;    extends HashSet&lt;E&gt;    implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123;    ......    // LinkedHashSet里面有一个LinkedHashMap    public LinkedHashSet(int initialCapacity, float loadFactor) &#123;        map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);    &#125;\t......    public boolean add(E e) &#123;//简单的方法转换        return map.put(e, PRESENT)==null;    &#125;    ......&#125;\n\n\n\nLinkedHashMap经典用法_LinkedHashMap_除了可以保证迭代顺序外，还有一个非常有用的用法: 可以轻松实现一个采用了FIFO替换策略的缓存。具体说来，LinkedHashMap有一个子类方法protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest)，该方法的作用是告诉Map是否要删除“最老”的Entry，所谓最老就是当前Map中最早插入的Entry，如果该方法返回true，最老的那个元素就会被删除。在每次插入新元素的之后LinkedHashMap会自动询问removeEldestEntry()是否要删除最老的元素。这样只需要在子类中重载该方法，当元素个数超过一定数量时让removeEldestEntry()返回true，就能够实现一个固定大小的FIFO策略的缓存。示例代码如下:\n/** 一个固定大小的FIFO替换策略的缓存 */class FIFOCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt;&#123;    private final int cacheSize;    public FIFOCache(int cacheSize)&#123;        this.cacheSize = cacheSize;    &#125;    // 当Entry个数超过cacheSize时，删除最老的Entry    @Override    protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123;       return size() &gt; cacheSize;    &#125;&#125;","categories":["Java集合框架"],"tags":["Map"]},{"title":"Map - WeakHashMap源码解析","url":"/2023/02/19/Map%20-%20WeakHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","content":"Map - WeakHashMap源码解析\n贰拾 • 张颜齐\n所以我松开拳头用手握紧笔，作为自己作为人类也作为你。\n\n本文主要对Map - WeakHashMap源码解析 源码解析。\n\n\nJDK版本\n参考文章\n总体介绍\n具体实现\nWeak HashSet?\n\nJDK版本\nJDK 1.8.0_110\n\n参考文章\n浅谈WeakHashMap \n\n总体介绍在Java集合框架系列文章的最后，笔者打算介绍一个特殊的成员: WeakHashMap，从名字可以看出它是某种 Map。它的特殊之处在于 WeakHashMap 里的entry可能会被GC自动删除，即使程序员没有调用remove()或者clear()方法。\n更直观的说，当使用 WeakHashMap 时，即使没有显示的添加或删除任何元素，也可能发生如下情况:\n\n\n调用两次size()方法返回不同的值；\n两次调用isEmpty()方法，第一次返回false，第二次返回true；\n两次调用containsKey()方法，第一次返回true，第二次返回false，尽管两次使用的是同一个key；\n两次调用get()方法，第一次返回一个value，第二次返回null，尽管两次使用的是同一个对象。\n\n\n遇到这么奇葩的现象，你是不是觉得使用者一定会疯掉? 其实不然，*WeekHashMap* 的这个特点特别适用于需要缓存的场景。在缓存场景下，由于内存是有限的，不能缓存所有对象；对象缓存命中可以提高系统效率，但缓存MISS也不会造成错误，因为可以通过计算重新得到。\n要明白 WeekHashMap 的工作原理，还需要引入一个概念** : 弱引用(WeakReference)。我们都知道Java中内存是通过GC自动管理的，GC会在程序运行过程中自动判断哪些对象是可以被回收的，并在合适的时机进行内存释放。GC判断某个对象是否可被回收的依据是，**是否有有效的引用指向该对象**。如果没有有效引用指向该对象(基本意味着不存在访问该对象的方式)，那么该对象就是可回收的。这里的**“有效引用”并不包括弱引用。也就是说，虽然弱引用可以用来访问对象，但进行垃圾回收时弱引用并不会被考虑在内，仅有弱引用指向的对象仍然会被GC回收。\nWeakHashMap 内部是通过弱引用来管理entry的，弱引用的特性对应到 WeakHashMap 上意味着什么呢？将一对key, value放入到 *WeakHashMap* 里并不能避免该key值被GC回收，除非在 *WeakHashMap* 之外还有对该key的强引用。\n关于强引用，弱引用等概念以后再具体讲解，这里只需要知道Java中引用也是分种类的，并且不同种类的引用对GC的影响不同就够了。\n#具体实现WeakHashMap的存储结构类似于Map - HashSet &amp; HashMap 源码解析，这里不再赘述。\n关于强弱引用的管理方式，博主将会另开专题单独讲解。\n#Weak HashSet?如果你看过前几篇关于 Map 和 Set 的讲解，一定会问: 既然有 WeekHashMap，是否有 WeekHashSet 呢? 答案是没有:( 。不过Java _Collections_工具类给出了解决方案，Collections.newSetFromMap(Map&lt;E,Boolean&gt; map)方法可以将任何 Map_包装成一个_Set。通过如下方式可以快速得到一个 Weak HashSet:\n// 将WeakHashMap包装成一个SetSet&lt;Object&gt; weakHashSet = Collections.newSetFromMap(        new WeakHashMap&lt;Object, Boolean&gt;());\n\n\n\n不出你所料，newSetFromMap()方法只是对传入的 _Map_做了简单包装:\n// Collections.newSetFromMap()用于将任何Map包装成一个Setpublic static &lt;E&gt; Set&lt;E&gt; newSetFromMap(Map&lt;E, Boolean&gt; map) &#123;    return new SetFromMap&lt;&gt;(map);&#125;private static class SetFromMap&lt;E&gt; extends AbstractSet&lt;E&gt;    implements Set&lt;E&gt;, Serializable&#123;    private final Map&lt;E, Boolean&gt; m;  // The backing map    private transient Set&lt;E&gt; s;       // Its keySet    SetFromMap(Map&lt;E, Boolean&gt; map) &#123;        if (!map.isEmpty())            throw new IllegalArgumentException(&quot;Map is non-empty&quot;);        m = map;        s = map.keySet();    &#125;    public void clear()               &#123;        m.clear(); &#125;    public int size()                 &#123; return m.size(); &#125;    public boolean isEmpty()          &#123; return m.isEmpty(); &#125;    public boolean contains(Object o) &#123; return m.containsKey(o); &#125;    public boolean remove(Object o)   &#123; return m.remove(o) != null; &#125;    public boolean add(E e) &#123; return m.put(e, Boolean.TRUE) == null; &#125;    public Iterator&lt;E&gt; iterator()     &#123; return s.iterator(); &#125;    public Object[] toArray()         &#123; return s.toArray(); &#125;    public &lt;T&gt; T[] toArray(T[] a)     &#123; return s.toArray(a); &#125;    public String toString()          &#123; return s.toString(); &#125;    public int hashCode()             &#123; return s.hashCode(); &#125;    public boolean equals(Object o)   &#123; return o == this || s.equals(o); &#125;    public boolean containsAll(Collection&lt;?&gt; c) &#123;return s.containsAll(c);&#125;    public boolean removeAll(Collection&lt;?&gt; c)   &#123;return s.removeAll(c);&#125;    public boolean retainAll(Collection&lt;?&gt; c)   &#123;return s.retainAll(c);&#125;    // addAll is the only inherited implementation    ......&#125;\n\n","categories":["Java集合框架"],"tags":["Map"]},{"title":"MySQL远程连接授权","url":"/2023/03/16/MySQL%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E6%8E%88%E6%9D%83/","content":"MySQL中grant all privileges on赋给用户远程权限当你的帐号不允许从远程登陆，只能在localhost连接时。这个时候只要在mysql服务器上，更改 mysql 数据库里的 user 表里的 host 项，从localhost&quot;改成%即可实现用户远程登录\n1.授权法MySQL 5.0+版本\nmysql -u root -p-- 给root账户授权（root默认只有本机访问的权限，要通过其他机器访问，必须授权）grant all privileges on *.* to root@&#x27;%&#x27; identified by &#x27;密码&#x27; with grant option;-- 最后刷新数据库服务flush privileges;\n\n\n\n模板： grant all privileges on 库名.表名 to ‘用户名‘@’IP地址’ identified by ‘密码’ with grant option; \nflush privileges;\n注意授权后必须FLUSH PRIVILEGES;否则无法立即生效。\n高版本8.0数据库不能按照grant all privileges on *.* to &quot;root&quot;@&quot;%&quot; identified by &quot;xxxx&quot;;去修改用户权限\nmysql&gt; SELECT @@VERSION;+-----------+| @@VERSION |+-----------+| 8.0.14    |+-----------+1 row in set (0.00 sec)\n\nMySQL 8.0+版本\n查看用户账号信息：\nmysql&gt; select User, host from mysql.user;+------------------+-----------+| User             | host      |+------------------+-----------+| mysql.infoschema | localhost || mysql.session    | localhost || mysql.sys        | localhost || root             | localhost |+------------------+-----------+4 rows in set (0.00 sec)\n\n先创建远程用户，再授权\ncreate user &#x27;root&#x27;@&#x27;%&#x27; identified by  &#x27;password&#x27;;grant all privileges on *.* to &#x27;root&#x27;@&#x27;%&#x27; with grant option;flush privileges;\n\n再次查看发现有了root %\nmysql&gt; select User, host from mysql.user;+------------------+-----------+| User             | Host      |+------------------+-----------+| root             | %         || mysql.infoschema | localhost || mysql.session    | localhost || mysql.sys        | localhost || root             | localhost |+------------------+-----------+5 rows in set (0.00 sec)————————————————\n\n","categories":["MySQL连接"],"tags":["MySQL远程连接授权"]},{"title":"RocketMQ-01","url":"/2023/02/19/RocketMQ-01/","content":"RocketMQ-01\n1.2 MQ的优点和缺点\n1.3 各种MQ产品的比较\n2.1 准备工作\n2.1.1 下载RocketMQ\n2.2.2 环境要求\n\n\n2.2 安装RocketMQ\n2.2.1 安装步骤\n2.2.2 目录介绍\n\n\n2.3 启动RocketMQ\n2.4 测试RocketMQ\n2.4.1 发送消息\n2.4.2 接收消息\n\n\n2.5 关闭RocketMQ\n3.1 各角色介绍\n3.2 集群搭建方式\n3.2.1 集群特点\n3.2.3 集群模式\n\n\n3.3 双主双从集群搭建\n3.3.1 总体架构\n3.3.2 集群工作流程\n3.3.3 服务器环境\n3.3.4 Host添加信息\n3.3.5 防火墙配置\n3.3.6 环境变量配置\n3.3.7 创建消息存储路径\n3.3.8 broker配置文件\n3.3.9 修改启动脚本文件\n3.3.10 服务启动\n3.3.11 查看进程状态\n3.3.12 查看日志\n\n\n3.4 mqadmin管理工具\n3.4.1 使用方式\n3.4.3 注意事项\n\n\n3.5 集群监控平台搭建\n3.5.1 概述\n3.5.2 下载并编译打包\n\n\n4.1 基本样例\n4.1.1 消息发送\n4.1.2 消费消息\n\n\n4.2 顺序消息\n4.2.1 顺序消息生产\n4.2.2 顺序消费消息\n\n\n4.3 延时消息\n4.3.1 启动消息消费者\n4.3.2 发送延时消息\n4.3.4 使用限制\n\n\n4.4 批量消息\n4.4.1 发送批量消息\n\n\n4.5 过滤消息\n4.5.1 SQL基本语法\n4.5.2 消息生产者\n4.5.3 消息消费者\n\n\n4.6 事务消息\n4.6.2 使用限制\n\n\n\n1. MQ介绍##1.1 为什么要用MQ\n消息队列是一种“先进先出”的数据结构\n\n其应用场景主要包含以下3个方面\n\n应用解耦\n\n系统的耦合性越高，容错性就越低。以电商应用为例，用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障或者因为升级等原因暂时不可用，都会造成下单操作异常，影响用户使用体验。\n\n使用消息队列解耦合，系统的耦合性就会提高了。比如物流系统发生故障，需要几分钟才能来修复，在这段时间内，物流系统要处理的数据被缓存到消息队列中，用户的下单操作正常完成。当物流系统回复后，补充处理存在消息队列中的订单消息即可，终端系统感知不到物流系统发生过几分钟故障。\n\n\n流量削峰\n\n\n应用系统如果遇到系统请求流量的瞬间猛增，有可能会将系统压垮。有了消息队列可以将大量请求缓存起来，分散到很长一段时间处理，这样可以大大提到系统的稳定性和用户体验。\n\n一般情况，为了保证系统的稳定性，如果系统负载超过阈值，就会阻止用户请求，这会影响用户体验，而如果使用消息队列将请求缓存起来，等待系统处理完毕后通知用户下单完毕，这样总不能下单体验要好。\n处于经济考量目的：\n业务系统正常时段的QPS如果是1000，流量最高峰是10000，为了应对流量高峰配置高性能的服务器显然不划算，这时可以使用消息队列对峰值流量削峰\n\n数据分发\n\n\n通过消息队列可以让数据在多个系统更加之间进行流通。数据的产生方不需要关心谁来使用数据，只需要将数据发送到消息队列，数据使用方直接在消息队列中直接获取数据即可\n\n1.2 MQ的优点和缺点优点：解耦、削峰、数据分发\n缺点包含以下几点：\n\n系统可用性降低\n系统引入的外部依赖越多，系统稳定性越差。一旦MQ宕机，就会对业务造成影响。\n如何保证MQ的高可用？\n\n系统复杂度提高\nMQ的加入大大增加了系统的复杂度，以前系统间是同步的远程调用，现在是通过MQ进行异步调用。\n如何保证消息没有被重复消费？怎么处理消息丢失情况？那么保证消息传递的顺序性？\n\n一致性问题\nA系统处理完业务，通过MQ给B、C、D三个系统发消息数据，如果B系统、C系统处理成功，D系统处理失败。\n如何保证消息数据处理的一致性？\n\n\n1.3 各种MQ产品的比较常见的MQ产品包括Kafka、ActiveMQ、RabbitMQ、RocketMQ。\n\n2. RocketMQ快速入门RocketMQ是阿里巴巴2016年MQ中间件，使用Java语言开发，在阿里内部，RocketMQ承接了例如“双11”等高并发场景的消息流转，能够处理万亿级别的消息。\n2.1 准备工作2.1.1 下载RocketMQRocketMQ最新版本：4.5.1\n下载地址\n2.2.2 环境要求\nLinux64位系统\nJDK1.8(64位)\n源码安装需要安装Maven 3.2.x\n\n2.2 安装RocketMQ2.2.1 安装步骤本教程以二进制包方式安装\n\n解压安装包\n进入安装目录\n\n2.2.2 目录介绍\nbin：启动脚本，包括shell脚本和CMD脚本\nconf：实例配置文件 ，包括broker配置文件、logback配置文件等\nlib：依赖jar包，包括Netty、commons-lang、FastJSON等\n\n2.3 启动RocketMQ\n启动NameServer\n\n# 1.启动NameServernohup sh bin/mqnamesrv &amp;# 2.查看启动日志tail -f ~/logs/rocketmqlogs/namesrv.log\n\n\n\n\n启动Broker\n\n# 1.启动Brokernohup sh bin/mqbroker -n localhost:9876 &amp;# 2.查看启动日志tail -f ~/logs/rocketmqlogs/broker.log \n\n\n\n\n问题描述：\nRocketMQ默认的虚拟机内存较大，启动Broker如果因为内存不足失败，需要编辑如下两个配置文件，修改JVM内存大小\n\n\n# 编辑runbroker.sh和runserver.sh修改默认JVM大小vi runbroker.shvi runserver.sh\n\n\n\n\n参考设置：\n\nJAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;\n\n2.4 测试RocketMQ2.4.1 发送消息# 1.设置环境变量export NAMESRV_ADDR=localhost:9876# 2.使用安装包的Demo发送消息sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer\n\n\n\n2.4.2 接收消息# 1.设置环境变量export NAMESRV_ADDR=localhost:9876# 2.接收消息sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer\n\n\n\n2.5 关闭RocketMQ# 1.关闭NameServersh bin/mqshutdown namesrv# 2.关闭Brokersh bin/mqshutdown broker\n\n\n\n3. RocketMQ集群搭建3.1 各角色介绍\nProducer：消息的发送者；举例：发信者\nConsumer：消息接收者；举例：收信者\nBroker：暂存和传输消息；举例：邮局\nNameServer：管理Broker；举例：各个邮局的管理机构\nTopic：区分消息的种类；一个发送者可以发送消息给一个或者多个Topic；一个消息的接收者可以订阅一个或者多个Topic消息\nMessage Queue：相当于是Topic的分区；用于并行发送和接收消息\n\n\n3.2 集群搭建方式3.2.1 集群特点\nNameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。\nBroker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。\nProducer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。\nConsumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。\n\n3.2.3 集群模式1）单Master模式这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。不建议线上环境使用,可以用于本地测试。\n2）多Master模式一个集群无Slave，全是Master，例如2个Master或者3个Master，这种模式的优缺点如下：\n\n优点：配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），性能最高；\n缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。\n\n3）多Master多Slave模式（异步）每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下：\n\n优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样；\n缺点：Master宕机，磁盘损坏情况下会丢失少量消息。\n\n4）多Master多Slave模式（同步）每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功，才向应用返回成功，这种模式的优缺点如下：\n\n优点：数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高；\n缺点：性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。\n\n3.3 双主双从集群搭建3.3.1 总体架构消息高可用采用2m-2s（同步双写）方式\n\n3.3.2 集群工作流程\n启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。\nBroker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。\n收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。\nProducer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列，然后与队列所在的Broker建立长连接从而向Broker发消息。\nConsumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。\n\n3.3.3 服务器环境\n\n\n序号\nIP\n角色\n架构模式\n\n\n\n1\n192.168.25.135\nnameserver、brokerserver\nMaster1、Slave2\n\n\n2\n192.168.25.138\nnameserver、brokerserver\nMaster2、Slave1\n\n\n3.3.4 Host添加信息vim /etc/hosts\n\n\n\n配置如下:\n# nameserver192.168.25.135 rocketmq-nameserver1192.168.25.138 rocketmq-nameserver2# broker192.168.25.135 rocketmq-master1192.168.25.135 rocketmq-slave2192.168.25.138 rocketmq-master2192.168.25.138 rocketmq-slave1\n\n\n\n配置完成后, 重启网卡\nsystemctl restart network\n\n\n\n3.3.5 防火墙配置宿主机需要远程访问虚拟机的rocketmq服务和web服务，需要开放相关的端口号，简单粗暴的方式是直接关闭防火墙\n# 关闭防火墙systemctl stop firewalld.service # 查看防火墙的状态firewall-cmd --state # 禁止firewall开机启动systemctl disable firewalld.service\n\n\n\n或者为了安全，只开放特定的端口号，RocketMQ默认使用3个端口：9876 、10911 、11011 。如果防火墙没有关闭的话，那么防火墙就必须开放这些端口：\n\nnameserver 默认使用 9876 端口\nmaster 默认使用 10911 端口\nslave 默认使用11011 端口\n\n执行以下命令：\n# 开放name server默认端口firewall-cmd --remove-port=9876/tcp --permanent# 开放master默认端口firewall-cmd --remove-port=10911/tcp --permanent# 开放slave默认端口 (当前集群模式可不开启)firewall-cmd --remove-port=11011/tcp --permanent # 重启防火墙firewall-cmd --reload\n\n\n\n3.3.6 环境变量配置vim /etc/profile\n\n\n\n在profile文件的末尾加入如下命令\n#set rocketmqROCKETMQ_HOME=/usr/local/rocketmq/rocketmq-all-4.4.0-bin-releasePATH=$PATH:$ROCKETMQ_HOME/binexport ROCKETMQ_HOME PATH\n\n\n\n输入:wq! 保存并退出， 并使得配置立刻生效：\nsource /etc/profile\n\n\n\n3.3.7 创建消息存储路径mkdir /usr/local/rocketmq/storemkdir /usr/local/rocketmq/store/commitlogmkdir /usr/local/rocketmq/store/consumequeuemkdir /usr/local/rocketmq/store/index\n\n\n\n3.3.8 broker配置文件1）master1服务器：192.168.25.135\nvi /usr/soft/rocketmq/conf/2m-2s-sync/broker-a.properties\n\n\n\n修改配置如下：\n#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=SYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128\n\n\n\n2）slave2服务器：192.168.25.135\nvi /usr/soft/rocketmq/conf/2m-2s-sync/broker-b-s.properties\n\n\n\n修改配置如下：\n#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-b#0 表示 Master，&gt;0 表示 SlavebrokerId=1#nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=11011#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SLAVE#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128\n\n\n\n\n3）master2服务器：192.168.25.138\nvi /usr/soft/rocketmq/conf/2m-2s-sync/broker-b.properties\n\n\n\n修改配置如下：\n#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-b#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=SYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128\n\n\n\n4）slave1服务器：192.168.25.138\nvi /usr/soft/rocketmq/conf/2m-2s-sync/broker-a-s.properties\n\n\n\n修改配置如下：\n#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=1#nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=11011#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SLAVE#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128\n\n\n\n3.3.9 修改启动脚本文件1）runbroker.shvi /usr/local/rocketmq/bin/runbroker.sh\n\n\n\n需要根据内存大小进行适当的对JVM参数进行调整：\n#===================================================# 开发环境配置 JVM ConfigurationJAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn128m&quot;\n\n####2）runserver.sh\nvim /usr/local/rocketmq/bin/runserver.sh\n\n\n\nJAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;\n\n\n\n3.3.10 服务启动1）启动NameServe集群分别在192.168.25.135和192.168.25.138启动NameServer\ncd /usr/local/rocketmq/binnohup sh mqnamesrv &amp;\n\n\n\n2）启动Broker集群\n在192.168.25.135上启动master1和slave2\n\nmaster1：\ncd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-2s-syncbroker-a.properties &amp;\n\n\n\nslave2：\ncd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-2s-sync/broker-b-s.properties &amp;\n\n\n\n\n在192.168.25.138上启动master2和slave2\n\nmaster2\ncd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-2s-sync/broker-b.properties &amp;\n\n\n\nslave1\ncd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-2s-sync/broker-a-s.properties &amp;\n\n\n\n3.3.11 查看进程状态启动后通过JPS查看启动进程\n\n3.3.12 查看日志# 查看nameServer日志tail -500f ~/logs/rocketmqlogs/namesrv.log# 查看broker日志tail -500f ~/logs/rocketmqlogs/broker.log\n\n3.4 mqadmin管理工具3.4.1 使用方式进入RocketMQ安装位置，在bin目录下执行./mqadmin &#123;command&#125; &#123;args&#125;\n###3.4.2 命令介绍\n####1）Topic相关\n\n\n\n名称\n含义\n命令选项\n说明\n\n\n\nupdateTopic\n创建更新Topic配置\n-b\nBroker 地址，表示 topic 所在 Broker，只支持单台Broker，地址为ip:port\n\n\n-c\ncluster 名称，表示 topic 所在集群（集群可通过 clusterList 查询）\n\n\n\n\n-h-\n打印帮助\n\n\n\n\n-n\nNameServer服务地址，格式 ip:port\n\n\n\n\n-p\n指定新topic的读写权限( W&#x3D;2|R&#x3D;4|WR&#x3D;6 )\n\n\n\n\n-r\n可读队列数（默认为 8）\n\n\n\n\n-w\n可写队列数（默认为 8）\n\n\n\n\n-t\ntopic 名称（名称只能使用字符 ^[a-zA-Z0-9_-]+$ ）\n\n\n\n\ndeleteTopic\n删除Topic\n-c\ncluster 名称，表示删除某集群下的某个 topic （集群 可通过 clusterList 查询）\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-t\ntopic 名称（名称只能使用字符 ^[a-zA-Z0-9_-]+$ ）\n\n\n\n\ntopicList\n查看 Topic 列表信息\n-h\n打印帮助\n\n\n-c\n不配置-c只返回topic列表，增加-c返回clusterName, topic, consumerGroup信息，即topic的所属集群和订阅关系，没有参数\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\ntopicRoute\n查看 Topic 路由信息\n-t\ntopic 名称\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\ntopicStatus\n查看 Topic 消息队列offset\n-t\ntopic 名称\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\ntopicClusterList\n查看 Topic 所在集群列表\n-t\ntopic 名称\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\nupdateTopicPerm\n更新 Topic 读写权限\n-t\ntopic 名称\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-b\nBroker 地址，表示 topic 所在 Broker，只支持单台Broker，地址为ip:port\n\n\n\n\n-p\n指定新 topic 的读写权限( W&#x3D;2|R&#x3D;4|WR&#x3D;6 )\n\n\n\n\n-c\ncluster 名称，表示 topic 所在集群（集群可通过 clusterList 查询），-b优先，如果没有-b，则对集群中所有Broker执行命令\n\n\n\n\nupdateOrderConf\n从NameServer上创建、删除、获取特定命名空间的kv配置，目前还未启用\n-h\n打印帮助\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-t\ntopic，键\n\n\n\n\n-v\norderConf，值\n\n\n\n\n-m\nmethod，可选get、put、delete\n\n\n\n\nallocateMQ\n以平均负载算法计算消费者列表负载消息队列的负载结果\n-t\ntopic 名称\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-i\nipList，用逗号分隔，计算这些ip去负载Topic的消息队列\n\n\n\n\nstatsAll\n打印Topic订阅关系、TPS、积累量、24h读写总量等信息\n-h\n打印帮助\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-a\n是否只打印活跃topic\n\n\n\n\n-t\n指定topic\n\n\n\n\n####2）集群相关\n\n\n\n名称\n含义\n命令选项\n说明\n\n\n\nclusterList\n查看集群信息，集群、BrokerName、BrokerId、TPS等信息\n-m\n打印更多信息 (增加打印出如下信息 #InTotalYest, #OutTotalYest, #InTotalToday ,#OutTotalToday)\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-i\n打印间隔，单位秒\n\n\n\n\nclusterRT\n发送消息检测集群各Broker RT。消息发往${BrokerName} Topic。\n-a\namount，每次探测的总数，RT &#x3D; 总时间 &#x2F; amount\n\n\n-s\n消息大小，单位B\n\n\n\n\n-c\n探测哪个集群\n\n\n\n\n-p\n是否打印格式化日志，以|分割，默认不打印\n\n\n\n\n-h\n打印帮助\n\n\n\n\n-m\n所属机房，打印使用\n\n\n\n\n-i\n发送间隔，单位秒\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n####3）Broker相关\n\n\n\n名称\n含义\n命令选项\n说明\n\n\n\nupdateBrokerConfig\n更新 Broker 配置文件，会修改Broker.conf\n-b\nBroker 地址，格式为ip:port\n\n\n-c\ncluster 名称\n\n\n\n\n-k\nkey 值\n\n\n\n\n-v\nvalue 值\n\n\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\nbrokerStatus\n查看 Broker 统计信息、运行状态（你想要的信息几乎都在里面）\n-b\nBroker 地址，地址为ip:port\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\nbrokerConsumeStats\nBroker中各个消费者的消费情况，按Message Queue维度返回Consume Offset，Broker Offset，Diff，TImestamp等信息\n-b\nBroker 地址，地址为ip:port\n\n\n-t\n请求超时时间\n\n\n\n\n-l\ndiff阈值，超过阈值才打印\n\n\n\n\n-o\n是否为顺序topic，一般为false\n\n\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\ngetBrokerConfig\n获取Broker配置\n-b\nBroker 地址，地址为ip:port\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\nwipeWritePerm\n从NameServer上清除 Broker写权限\n-b\nBroker 地址，地址为ip:port\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-h\n打印帮助\n\n\n\n\ncleanExpiredCQ\n清理Broker上过期的Consume Queue，如果手动减少对列数可能产生过期队列\n-n\nNameServer 服务地址，格式 ip:port\n\n\n-h\n打印帮助\n\n\n\n\n-b\nBroker 地址，地址为ip:port\n\n\n\n\n-c\n集群名称\n\n\n\n\ncleanUnusedTopic\n清理Broker上不使用的Topic，从内存中释放Topic的Consume Queue，如果手动删除Topic会产生不使用的Topic\n-n\nNameServer 服务地址，格式 ip:port\n\n\n-h\n打印帮助\n\n\n\n\n-b\nBroker 地址，地址为ip:port\n\n\n\n\n-c\n集群名称\n\n\n\n\nsendMsgStatus\n向Broker发消息，返回发送状态和RT\n-n\nNameServer 服务地址，格式 ip:port\n\n\n-h\n打印帮助\n\n\n\n\n-b\nBrokerName，注意不同于Broker地址\n\n\n\n\n-s\n消息大小，单位B\n\n\n\n\n-c\n发送次数\n\n\n\n\n####4）消息相关\n\n\n\n名称\n含义\n命令选项\n说明\n\n\n\nqueryMsgById\n根据offsetMsgId查询msg，如果使用开源控制台，应使用offsetMsgId，此命令还有其他参数，具体作用请阅读QueryMsgByIdSubCommand。\n-i\nmsgId\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\nqueryMsgByKey\n根据消息 Key 查询消息\n-k\nmsgKey\n\n\n-t\nTopic 名称\n\n\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\nqueryMsgByOffset\n根据 Offset 查询消息\n-b\nBroker 名称，（这里需要注意 填写的是 Broker 的名称，不是 Broker 的地址，Broker 名称可以在 clusterList 查到）\n\n\n-i\nquery 队列 id\n\n\n\n\n-o\noffset 值\n\n\n\n\n-t\ntopic 名称\n\n\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\nqueryMsgByUniqueKey\n根据msgId查询，msgId不同于offsetMsgId，区别详见常见运维问题。-g，-d配合使用，查到消息后尝试让特定的消费者消费消息并返回消费结果\n-h\n打印帮助\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-i\nuniqe msg id\n\n\n\n\n-g\nconsumerGroup\n\n\n\n\n-d\nclientId\n\n\n\n\n-t\ntopic名称\n\n\n\n\ncheckMsgSendRT\n检测向topic发消息的RT，功能类似clusterRT\n-h\n打印帮助\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-t\ntopic名称\n\n\n\n\n-a\n探测次数\n\n\n\n\n-s\n消息大小\n\n\n\n\nsendMessage\n发送一条消息，可以根据配置发往特定Message Queue，或普通发送。\n-h\n打印帮助\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-t\ntopic名称\n\n\n\n\n-p\nbody，消息体\n\n\n\n\n-k\nkeys\n\n\n\n\n-c\ntags\n\n\n\n\n-b\nBrokerName\n\n\n\n\n-i\nqueueId\n\n\n\n\nconsumeMessage\n消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。\n-h\n打印帮助\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-t\ntopic名称\n\n\n\n\n-b\nBrokerName\n\n\n\n\n-o\n从offset开始消费\n\n\n\n\n-i\nqueueId\n\n\n\n\n-g\n消费者分组\n\n\n\n\n-s\n开始时间戳，格式详见-h\n\n\n\n\n-d\n结束时间戳\n\n\n\n\n-c\n消费多少条消息\n\n\n\n\nprintMsg\n从Broker消费消息并打印，可选时间段\n-h\n打印帮助\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-t\ntopic名称\n\n\n\n\n-c\n字符集，例如UTF-8\n\n\n\n\n-s\nsubExpress，过滤表达式\n\n\n\n\n-b\n开始时间戳，格式参见-h\n\n\n\n\n-e\n结束时间戳\n\n\n\n\n-d\n是否打印消息体\n\n\n\n\nprintMsgByQueue\n类似printMsg，但指定Message Queue\n-h\n打印帮助\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-t\ntopic名称\n\n\n\n\n-i\nqueueId\n\n\n\n\n-a\nBrokerName\n\n\n\n\n-c\n字符集，例如UTF-8\n\n\n\n\n-s\nsubExpress，过滤表达式\n\n\n\n\n-b\n开始时间戳，格式参见-h\n\n\n\n\n-e\n结束时间戳\n\n\n\n\n-p\n是否打印消息\n\n\n\n\n-d\n是否打印消息体\n\n\n\n\n-f\n是否统计tag数量并打印\n\n\n\n\nresetOffsetByTime\n按时间戳重置offset，Broker和consumer都会重置\n-h\n打印帮助\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-g\n消费者分组\n\n\n\n\n-t\ntopic名称\n\n\n\n\n-s\n重置为此时间戳对应的offset\n\n\n\n\n-f\n是否强制重置，如果false，只支持回溯offset，如果true，不管时间戳对应offset与consumeOffset关系\n\n\n\n\n-c\n是否重置c++客户端offset\n\n\n\n\n#5）消费者、消费组相关\n\n\n名称\n含义\n命令选项\n说明\n\n\n\nconsumerProgress\n查看订阅组消费状态，可以查看具体的client IP的消息积累量\n-g\n消费者所属组名\n\n\n-s\n是否打印client IP\n\n\n\n\n-h\n打印帮助\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\nconsumerStatus\n查看消费者状态，包括同一个分组中是否都是相同的订阅，分析Process Queue是否堆积，返回消费者jstack结果，内容较多，使用者参见ConsumerStatusSubCommand\n-h\n打印帮助\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-g\nconsumer group\n\n\n\n\n-i\nclientId\n\n\n\n\n-s\n是否执行jstack\n\n\n\n\ngetConsumerStatus\n获取 Consumer 消费进度\n-g\n消费者所属组名\n\n\n-t\n查询主题\n\n\n\n\n-i\nConsumer 客户端 ip\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-h\n打印帮助\n\n\n\n\nupdateSubGroup\n更新或创建订阅关系\n-n\nNameServer 服务地址，格式 ip:port\n\n\n-h\n打印帮助\n\n\n\n\n-b\nBroker地址\n\n\n\n\n-c\n集群名称\n\n\n\n\n-g\n消费者分组名称\n\n\n\n\n-s\n分组是否允许消费\n\n\n\n\n-m\n是否从最小offset开始消费\n\n\n\n\n-d\n是否是广播模式\n\n\n\n\n-q\n重试队列数量\n\n\n\n\n-r\n最大重试次数\n\n\n\n\n-i\n当slaveReadEnable开启时有效，且还未达到从slave消费时建议从哪个BrokerId消费，可以配置备机id，主动从备机消费\n\n\n\n\n-w\n如果Broker建议从slave消费，配置决定从哪个slave消费，配置BrokerId，例如1\n\n\n\n\n-a\n当消费者数量变化时是否通知其他消费者负载均衡\n\n\n\n\ndeleteSubGroup\n从Broker删除订阅关系\n-n\nNameServer 服务地址，格式 ip:port\n\n\n-h\n打印帮助\n\n\n\n\n-b\nBroker地址\n\n\n\n\n-c\n集群名称\n\n\n\n\n-g\n消费者分组名称\n\n\n\n\ncloneGroupOffset\n在目标群组中使用源群组的offset\n-n\nNameServer 服务地址，格式 ip:port\n\n\n-h\n打印帮助\n\n\n\n\n-s\n源消费者组\n\n\n\n\n-d\n目标消费者组\n\n\n\n\n-t\ntopic名称\n\n\n\n\n-o\n暂未使用\n\n\n\n\n6）连接相关\n\n\n名称\n含义\n命令选项\n说明\n\n\n\nconsumerConnec tion\n查询 Consumer 的网络连接\n-g\n消费者所属组名\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-h\n打印帮助\n\n\n\n\nproducerConnec tion\n查询 Producer 的网络连接\n-g\n生产者所属组名\n\n\n-t\n主题名称\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-h\n打印帮助\n\n\n\n\n7）NameServer相关\n\n\n名称\n含义\n命令选项\n说明\n\n\n\nupdateKvConfig\n更新NameServer的kv配置，目前还未使用\n-s\n命名空间\n\n\n-k\nkey\n\n\n\n\n-v\nvalue\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-h\n打印帮助\n\n\n\n\ndeleteKvConfig\n删除NameServer的kv配置\n-s\n命名空间\n\n\n-k\nkey\n\n\n\n\n-n\nNameServer 服务地址，格式 ip:port\n\n\n\n\n-h\n打印帮助\n\n\n\n\ngetNamesrvConfig\n获取NameServer配置\n-n\nNameServer 服务地址，格式 ip:port\n\n\n-h\n打印帮助\n\n\n\n\nupdateNamesrvConfig\n修改NameServer配置\n-n\nNameServer 服务地址，格式 ip:port\n\n\n-h\n打印帮助\n\n\n\n\n-k\nkey\n\n\n\n\n-v\nvalue\n\n\n\n\n8）其他\n\n\n名称\n含义\n命令选项\n说明\n\n\n\nstartMonitoring\n开启监控进程，监控消息误删、重试队列消息数等\n-n\nNameServer 服务地址，格式 ip:port\n\n\n-h\n打印帮助\n\n\n\n\n3.4.3 注意事项\n几乎所有命令都需要配置-n表示NameServer地址，格式为ip:port\n几乎所有命令都可以通过-h获取帮助\n如果既有Broker地址（-b）配置项又有clusterName（-c）配置项，则优先以Broker地址执行命令；如果不配置Broker地址，则对集群中所有主机执行命令\n\n3.5 集群监控平台搭建3.5.1 概述RocketMQ有一个对其扩展的开源项目incubator-rocketmq-externals，这个项目中有一个子模块叫rocketmq-console，这个便是管理控制台项目了，先将incubator-rocketmq-externals拉到本地，因为我们需要自己对rocketmq-console进行编译打包运行。\n\n3.5.2 下载并编译打包git clone https://github.com/apache/rocketmq-externalscd rocketmq-consolemvn clean package -Dmaven.test.skip=true\n\n\n\n注意：打包前在rocketmq-console中配置namesrv集群地址：\nrocketmq.config.namesrvAddr=192.168.25.135:9876;192.168.25.138:9876\n\n\n\n启动rocketmq-console：\njava -jar rocketmq-console-ng-1.0.0.jar\n\n\n\n启动成功后，我们就可以通过浏览器访问http://localhost:8080进入控制台界面了，如下图：\n\n集群状态：\n\n4. 消息发送样例\n导入MQ客户端依赖\n\n&lt;dependency&gt;    &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt;    &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt;    &lt;version&gt;4.4.0&lt;/version&gt;&lt;/dependency&gt;\n\n\n\n\n消息发送者步骤分析r\n\n1.创建消息生产者producer，并制定生产者组名2.指定Nameserver地址3.启动producer4.创建消息对象，指定主题Topic、Tag和消息体5.发送消息6.关闭生产者producer\n\n\n\n\n消息消费者步骤分析\n\n1.创建消费者Consumer，制定消费者组名2.指定Nameserver地址3.订阅主题Topic和Tag4.设置回调函数，处理消息5.启动消费者consumer\n\n\n\n4.1 基本样例4.1.1 消息发送1）发送同步消息这种可靠性同步地发送方式使用的比较广泛，比如：重要的消息通知，短信通知。\npublic class SyncProducer &#123;\tpublic static void main(String[] args) throws Exception &#123;    \t// 实例化消息生产者Producer        DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);    \t// 设置NameServer的地址    \tproducer.setNamesrvAddr(&quot;localhost:9876&quot;);    \t// 启动Producer实例        producer.start();    \tfor (int i = 0; i &lt; 100; i++) &#123;    \t    // 创建消息，并指定Topic，Tag和消息体    \t    Message msg = new Message(&quot;TopicTest&quot; /* Topic */,        \t&quot;TagA&quot; /* Tag */,        \t(&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */        \t);        \t// 发送消息到一个Broker            SendResult sendResult = producer.send(msg);            // 通过sendResult返回消息是否成功送达            System.out.printf(&quot;%s%n&quot;, sendResult);    \t&#125;    \t// 如果不再发送消息，关闭Producer实例。    \tproducer.shutdown();    &#125;&#125;\n\n\n\n2）发送异步消息异步消息通常用在对响应时间敏感的业务场景，即发送端不能容忍长时间地等待Broker的响应。\npublic class AsyncProducer &#123;\tpublic static void main(String[] args) throws Exception &#123;    \t// 实例化消息生产者Producer        DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);    \t// 设置NameServer的地址        producer.setNamesrvAddr(&quot;localhost:9876&quot;);    \t// 启动Producer实例        producer.start();        producer.setRetryTimesWhenSendAsyncFailed(0);    \tfor (int i = 0; i &lt; 100; i++) &#123;                final int index = i;            \t// 创建消息，并指定Topic，Tag和消息体                Message msg = new Message(&quot;TopicTest&quot;,                    &quot;TagA&quot;,                    &quot;OrderID188&quot;,                    &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET));                // SendCallback接收异步返回结果的回调                producer.send(msg, new SendCallback() &#123;                    @Override                    public void onSuccess(SendResult sendResult) &#123;                        System.out.printf(&quot;%-10d OK %s %n&quot;, index,                            sendResult.getMsgId());                    &#125;                    @Override                    public void onException(Throwable e) &#123;      \t              System.out.printf(&quot;%-10d Exception %s %n&quot;, index, e);      \t              e.printStackTrace();                    &#125;            \t&#125;);    \t&#125;    \t// 如果不再发送消息，关闭Producer实例。    \tproducer.shutdown();    &#125;&#125;\n\n\n\n3）单向发送消息这种方式主要用在不特别关心发送结果的场景，例如日志发送。\npublic class OnewayProducer &#123;\tpublic static void main(String[] args) throws Exception&#123;    \t// 实例化消息生产者Producer        DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);    \t// 设置NameServer的地址        producer.setNamesrvAddr(&quot;localhost:9876&quot;);    \t// 启动Producer实例        producer.start();    \tfor (int i = 0; i &lt; 100; i++) &#123;        \t// 创建消息，并指定Topic，Tag和消息体        \tMessage msg = new Message(&quot;TopicTest&quot; /* Topic */,                &quot;TagA&quot; /* Tag */,                (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */        \t);        \t// 发送单向消息，没有任何返回结果        \tproducer.sendOneway(msg);    \t&#125;    \t// 如果不再发送消息，关闭Producer实例。    \tproducer.shutdown();    &#125;&#125;\n\n\n\n4.1.2 消费消息1）负载均衡模式消费者采用负载均衡方式消费消息，多个消费者共同消费队列消息，每个消费者处理的消息不同\npublic static void main(String[] args) throws Exception &#123;    // 实例化消息生产者,指定组名    DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;group1&quot;);    // 指定Namesrv地址信息.    consumer.setNamesrvAddr(&quot;localhost:9876&quot;);    // 订阅Topic    consumer.subscribe(&quot;Test&quot;, &quot;*&quot;);    //负载均衡模式消费    consumer.setMessageModel(MessageModel.CLUSTERING);    // 注册回调函数，处理消息    consumer.registerMessageListener(new MessageListenerConcurrently() &#123;        @Override        public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs,                                                        ConsumeConcurrentlyContext context) &#123;            System.out.printf(&quot;%s Receive New Messages: %s %n&quot;,                               Thread.currentThread().getName(), msgs);            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;        &#125;    &#125;);    //启动消息者    consumer.start();    System.out.printf(&quot;Consumer Started.%n&quot;);&#125;\n\n\n\n2）广播模式消费者采用广播的方式消费消息，每个消费者消费的消息都是相同的\npublic static void main(String[] args) throws Exception &#123;    // 实例化消息生产者,指定组名    DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;group1&quot;);    // 指定Namesrv地址信息.    consumer.setNamesrvAddr(&quot;localhost:9876&quot;);    // 订阅Topic    consumer.subscribe(&quot;Test&quot;, &quot;*&quot;);    //广播模式消费    consumer.setMessageModel(MessageModel.BROADCASTING);    // 注册回调函数，处理消息    consumer.registerMessageListener(new MessageListenerConcurrently() &#123;        @Override        public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs,                                                        ConsumeConcurrentlyContext context) &#123;            System.out.printf(&quot;%s Receive New Messages: %s %n&quot;,                               Thread.currentThread().getName(), msgs);            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;        &#125;    &#125;);    //启动消息者    consumer.start();    System.out.printf(&quot;Consumer Started.%n&quot;);&#125;\n\n\n\n4.2 顺序消息消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。\n顺序消费的原理解析，在默认的情况下消息发送会采取Round Robin轮询方式把消息发送到不同的queue(分区队列)；而消费消息的时候从多个queue上拉取消息，这种情况发送和消费是不能保证顺序。但是如果控制发送的顺序消息只依次发送到同一个queue中，消费的时候只从这个queue上依次拉取，则就保证了顺序。当发送和消费参与的queue只有一个，则是全局有序；如果多个queue参与，则为分区有序，即相对每个queue，消息都是有序的。\n下面用订单进行分区有序的示例。一个订单的顺序流程是：创建、付款、推送、完成。订单号相同的消息会被先后发送到同一个队列中，消费时，同一个OrderId获取到的肯定是同一个队列。\n4.2.1 顺序消息生产/*** Producer，发送顺序消息*/public class Producer &#123;   public static void main(String[] args) throws Exception &#123;       DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);       producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);       producer.start();       String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagC&quot;, &quot;TagD&quot;&#125;;       // 订单列表       List&lt;OrderStep&gt; orderList = new Producer().buildOrders();       Date date = new Date();       SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);       String dateStr = sdf.format(date);       for (int i = 0; i &lt; 10; i++) &#123;           // 加个时间前缀           String body = dateStr + &quot; Hello RocketMQ &quot; + orderList.get(i);           Message msg = new Message(&quot;TopicTest&quot;, tags[i % tags.length], &quot;KEY&quot; + i, body.getBytes());           SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123;               @Override               public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123;                   Long id = (Long) arg;  //根据订单id选择发送queue                   long index = id % mqs.size();                   return mqs.get((int) index);               &#125;           &#125;, orderList.get(i).getOrderId());//订单id           System.out.println(String.format(&quot;SendResult status:%s, queueId:%d, body:%s&quot;,               sendResult.getSendStatus(),               sendResult.getMessageQueue().getQueueId(),               body));       &#125;       producer.shutdown();   &#125;   /**    * 订单的步骤    */   private static class OrderStep &#123;       private long orderId;       private String desc;       public long getOrderId() &#123;           return orderId;       &#125;       public void setOrderId(long orderId) &#123;           this.orderId = orderId;       &#125;       public String getDesc() &#123;           return desc;       &#125;       public void setDesc(String desc) &#123;           this.desc = desc;       &#125;       @Override       public String toString() &#123;           return &quot;OrderStep&#123;&quot; +               &quot;orderId=&quot; + orderId +               &quot;, desc=&#x27;&quot; + desc + &#x27;\\&#x27;&#x27; +               &#x27;&#125;&#x27;;       &#125;   &#125;   /**    * 生成模拟订单数据    */   private List&lt;OrderStep&gt; buildOrders() &#123;       List&lt;OrderStep&gt; orderList = new ArrayList&lt;OrderStep&gt;();       OrderStep orderDemo = new OrderStep();       orderDemo.setOrderId(15103111039L);       orderDemo.setDesc(&quot;创建&quot;);       orderList.add(orderDemo);       orderDemo = new OrderStep();       orderDemo.setOrderId(15103111065L);       orderDemo.setDesc(&quot;创建&quot;);       orderList.add(orderDemo);       orderDemo = new OrderStep();       orderDemo.setOrderId(15103111039L);       orderDemo.setDesc(&quot;付款&quot;);       orderList.add(orderDemo);       orderDemo = new OrderStep();       orderDemo.setOrderId(15103117235L);       orderDemo.setDesc(&quot;创建&quot;);       orderList.add(orderDemo);       orderDemo = new OrderStep();       orderDemo.setOrderId(15103111065L);       orderDemo.setDesc(&quot;付款&quot;);       orderList.add(orderDemo);       orderDemo = new OrderStep();       orderDemo.setOrderId(15103117235L);       orderDemo.setDesc(&quot;付款&quot;);       orderList.add(orderDemo);       orderDemo = new OrderStep();       orderDemo.setOrderId(15103111065L);       orderDemo.setDesc(&quot;完成&quot;);       orderList.add(orderDemo);       orderDemo = new OrderStep();       orderDemo.setOrderId(15103111039L);       orderDemo.setDesc(&quot;推送&quot;);       orderList.add(orderDemo);       orderDemo = new OrderStep();       orderDemo.setOrderId(15103117235L);       orderDemo.setDesc(&quot;完成&quot;);       orderList.add(orderDemo);       orderDemo = new OrderStep();       orderDemo.setOrderId(15103111039L);       orderDemo.setDesc(&quot;完成&quot;);       orderList.add(orderDemo);       return orderList;   &#125;&#125;\n\n\n\n4.2.2 顺序消费消息/*** 顺序消息消费，带事务方式（应用可控制Offset什么时候提交）*/public class ConsumerInOrder &#123;   public static void main(String[] args) throws Exception &#123;       DefaultMQPushConsumer consumer = new            DefaultMQPushConsumer(&quot;please_rename_unique_group_name_3&quot;);       consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);       /**        * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&lt;br&gt;        * 如果非第一次启动，那么按照上次消费的位置继续消费        */       consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);       consumer.subscribe(&quot;TopicTest&quot;, &quot;TagA || TagC || TagD&quot;);       consumer.registerMessageListener(new MessageListenerOrderly() &#123;           Random random = new Random();           @Override           public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123;               context.setAutoCommit(true);               for (MessageExt msg : msgs) &#123;                   // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序                   System.out.println(&quot;consumeThread=&quot; + Thread.currentThread().getName() + &quot;queueId=&quot; + msg.getQueueId() + &quot;, content:&quot; + new String(msg.getBody()));               &#125;               try &#123;                   //模拟业务逻辑处理中...                   TimeUnit.SECONDS.sleep(random.nextInt(10));               &#125; catch (Exception e) &#123;                   e.printStackTrace();               &#125;               return ConsumeOrderlyStatus.SUCCESS;           &#125;       &#125;);       consumer.start();       System.out.println(&quot;Consumer Started.&quot;);   &#125;&#125;\n\n\n\n4.3 延时消息比如电商里，提交了一个订单就可以发送一个延时消息，1h后去检查这个订单的状态，如果还是未付款就取消订单释放库存。\n4.3.1 启动消息消费者public class ScheduledMessageConsumer &#123;   public static void main(String[] args) throws Exception &#123;      // 实例化消费者      DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;ExampleConsumer&quot;);      // 订阅Topics      consumer.subscribe(&quot;TestTopic&quot;, &quot;*&quot;);      // 注册消息监听者      consumer.registerMessageListener(new MessageListenerConcurrently() &#123;          @Override          public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context) &#123;              for (MessageExt message : messages) &#123;                  // Print approximate delay time period                  System.out.println(&quot;Receive message[msgId=&quot; + message.getMsgId() + &quot;] &quot; + (System.currentTimeMillis() - message.getStoreTimestamp()) + &quot;ms later&quot;);              &#125;              return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;          &#125;      &#125;);      // 启动消费者      consumer.start();  &#125;&#125;\n\n\n\n4.3.2 发送延时消息public class ScheduledMessageProducer &#123;   public static void main(String[] args) throws Exception &#123;      // 实例化一个生产者来产生延时消息      DefaultMQProducer producer = new DefaultMQProducer(&quot;ExampleProducerGroup&quot;);      // 启动生产者      producer.start();      int totalMessagesToSend = 100;      for (int i = 0; i &lt; totalMessagesToSend; i++) &#123;          Message message = new Message(&quot;TestTopic&quot;, (&quot;Hello scheduled message &quot; + i).getBytes());          // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel)          message.setDelayTimeLevel(3);          // 发送消息          producer.send(message);      &#125;       // 关闭生产者      producer.shutdown();  &#125;&#125;\n\n\n\n###4.3.3 验证\n您将会看到消息的消费比存储时间晚10秒\n4.3.4 使用限制// org/apache/rocketmq/store/config/MessageStoreConfig.javaprivate String messageDelayLevel = &quot;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h&quot;;\n\n\n\n现在RocketMq并不支持任意时间的延时，需要设置几个固定的延时等级，从1s到2h分别对应着等级1到18\n4.4 批量消息批量发送消息能显著提高传递小消息的性能。限制是这些批量消息应该有相同的topic，相同的waitStoreMsgOK，而且不能是延时消息。此外，这一批消息的总大小不应超过4MB。\n4.4.1 发送批量消息如果您每次只发送不超过4MB的消息，则很容易使用批处理，样例如下：\nString topic = &quot;BatchTest&quot;;List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, &quot;TagA&quot;, &quot;OrderID001&quot;, &quot;Hello world 0&quot;.getBytes()));messages.add(new Message(topic, &quot;TagA&quot;, &quot;OrderID002&quot;, &quot;Hello world 1&quot;.getBytes()));messages.add(new Message(topic, &quot;TagA&quot;, &quot;OrderID003&quot;, &quot;Hello world 2&quot;.getBytes()));try &#123;   producer.send(messages);&#125; catch (Exception e) &#123;   e.printStackTrace();   //处理error&#125;\n\n\n\n如果消息的总长度可能大于4MB时，这时候最好把消息进行分割\npublic class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123;   private final int SIZE_LIMIT = 1024 * 1024 * 4;   private final List&lt;Message&gt; messages;   private int currIndex;   public ListSplitter(List&lt;Message&gt; messages) &#123;           this.messages = messages;   &#125;    @Override     public boolean hasNext() &#123;       return currIndex &lt; messages.size();   &#125;   \t@Override     public List&lt;Message&gt; next() &#123;       int nextIndex = currIndex;       int totalSize = 0;       for (; nextIndex &lt; messages.size(); nextIndex++) &#123;           Message message = messages.get(nextIndex);           int tmpSize = message.getTopic().length() + message.getBody().length;           Map&lt;String, String&gt; properties = message.getProperties();           for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123;               tmpSize += entry.getKey().length() + entry.getValue().length();           &#125;           tmpSize = tmpSize + 20; // 增加日志的开销20字节           if (tmpSize &gt; SIZE_LIMIT) &#123;               //单个消息超过了最大的限制               //忽略,否则会阻塞分裂的进程               if (nextIndex - currIndex == 0) &#123;                  //假如下一个子列表没有元素,则添加这个子列表然后退出循环,否则只是退出循环                  nextIndex++;               &#125;               break;           &#125;           if (tmpSize + totalSize &gt; SIZE_LIMIT) &#123;               break;           &#125; else &#123;               totalSize += tmpSize;           &#125;       &#125;       List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex);       currIndex = nextIndex;       return subList;   &#125;&#125;//把大的消息分裂成若干个小的消息ListSplitter splitter = new ListSplitter(messages);while (splitter.hasNext()) &#123;  try &#123;      List&lt;Message&gt;  listItem = splitter.next();      producer.send(listItem);  &#125; catch (Exception e) &#123;      e.printStackTrace();      //处理error  &#125;&#125;\n\n\n\n4.5 过滤消息在大多数情况下，TAG是一个简单而有用的设计，其可以来选择您想要的消息。例如：\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;CID_EXAMPLE&quot;);consumer.subscribe(&quot;TOPIC&quot;, &quot;TAGA || TAGB || TAGC&quot;);\n\n\n\n消费者将接收包含TAGA或TAGB或TAGC的消息。但是限制是一个消息只能有一个标签，这对于复杂的场景可能不起作用。在这种情况下，可以使用SQL表达式筛选消息。SQL特性可以通过发送消息时的属性来进行计算。在RocketMQ定义的语法下，可以实现一些简单的逻辑。下面是一个例子：\n------------| message  ||----------|  a &gt; 5 AND b = &#x27;abc&#x27;| a = 10   |  --------------------&gt; Gotten| b = &#x27;abc&#x27;|| c = true |------------------------| message  ||----------|   a &gt; 5 AND b = &#x27;abc&#x27;| a = 1    |  --------------------&gt; Missed| b = &#x27;abc&#x27;|| c = true |------------\n\n\n\n4.5.1 SQL基本语法RocketMQ只定义了一些基本语法来支持这个特性。你也可以很容易地扩展它。\n\n数值比较，比如：**&gt;，&gt;&#x3D;，&lt;，&lt;&#x3D;，BETWEEN，&#x3D;；**\n字符比较，比如：**&#x3D;，&lt;&gt;，IN；**\nIS NULL 或者 IS NOT NULL；\n逻辑符号 AND，OR，NOT；\n\n常量支持类型为：\n\n数值，比如：123，3.1415；\n字符，比如：**’abc’，必须用单引号包裹起来；**\nNULL，特殊的常量\n布尔值，TRUE 或 FALSE\n\n只有使用push模式的消费者才能用使用SQL92标准的sql语句，接口如下：\npublic void subscribe(finalString topic, final MessageSelector messageSelector)\n\n\n\n4.5.2 消息生产者发送消息时，你能通过putUserProperty来设置消息的属性\nDefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.start();Message msg = new Message(&quot;TopicTest&quot;,   tag,   (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET));// 设置一些属性msg.putUserProperty(&quot;a&quot;, String.valueOf(i));SendResult sendResult = producer.send(msg);producer.shutdown();\n\n\n\n4.5.3 消息消费者用MessageSelector.bySql来使用sql筛选消息\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_4&quot;);// 只有订阅的消息有这个属性a, a &gt;=0 and a &lt;= 3consumer.subscribe(&quot;TopicTest&quot;, MessageSelector.bySql(&quot;a between 0 and 3&quot;);consumer.registerMessageListener(new MessageListenerConcurrently() &#123;   @Override   public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123;       return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;   &#125;&#125;);consumer.start();\n\n\n\n4.6 事务消息###4.6.1 流程分析\n\n上图说明了事务消息的大致方案，其中分为两个流程：正常事务消息的发送及提交、事务消息的补偿流程。\n####1）事务消息发送及提交\n(1) 发送消息（half消息）。\n(2) 服务端响应消息写入结果。\n(3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。\n(4) 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见）\n2）事务补偿(1) 对没有Commit&#x2F;Rollback的事务消息（pending状态的消息），从服务端发起一次“回查”\n(2) Producer收到回查消息，检查回查消息对应的本地事务的状态\n(3) 根据本地事务状态，重新Commit或者Rollback\n其中，补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。\n3）事务消息状态事务消息共有三种状态，提交状态、回滚状态、中间状态：\n\nTransactionStatus.CommitTransaction: 提交事务，它允许消费者消费此消息。\nTransactionStatus.RollbackTransaction: 回滚事务，它代表该消息将被删除，不允许被消费。\nTransactionStatus.Unknown: 中间状态，它代表需要检查消息队列来确定状态。\n\n###4.6.1 发送事务消息\n1) 创建事务性生产者使用 TransactionMQProducer类创建生产者，并指定唯一的 ProducerGroup，就可以设置自定义线程池来处理这些检查请求。执行本地事务后、需要根据执行结果对消息队列进行回复。回传的事务状态在请参考前一节。\npublic class Producer &#123;    public static void main(String[] args) throws MQClientException, InterruptedException &#123;        //创建事务监听器        TransactionListener transactionListener = new TransactionListenerImpl();        //创建消息生产者        TransactionMQProducer producer = new TransactionMQProducer(&quot;group6&quot;);        producer.setNamesrvAddr(&quot;192.168.25.135:9876;192.168.25.138:9876&quot;);        //生产者这是监听器        producer.setTransactionListener(transactionListener);        //启动消息生产者        producer.start();        String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;&#125;;        for (int i = 0; i &lt; 3; i++) &#123;            try &#123;                Message msg = new Message(&quot;TransactionTopic&quot;, tags[i % tags.length], &quot;KEY&quot; + i,                        (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET));                SendResult sendResult = producer.sendMessageInTransaction(msg, null);                System.out.printf(&quot;%s%n&quot;, sendResult);                TimeUnit.SECONDS.sleep(1);            &#125; catch (MQClientException | UnsupportedEncodingException e) &#123;                e.printStackTrace();            &#125;        &#125;        //producer.shutdown();    &#125;&#125;\n\n\n\n2）实现事务的监听接口当发送半消息成功时，我们使用 executeLocalTransaction 方法来执行本地事务。它返回前一节中提到的三个事务状态之一。checkLocalTranscation 方法用于检查本地事务状态，并回应消息队列的检查请求。它也是返回前一节中提到的三个事务状态之一。\npublic class TransactionListenerImpl implements TransactionListener &#123;    @Override    public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123;        System.out.println(&quot;执行本地事务&quot;);        if (StringUtils.equals(&quot;TagA&quot;, msg.getTags())) &#123;            return LocalTransactionState.COMMIT_MESSAGE;        &#125; else if (StringUtils.equals(&quot;TagB&quot;, msg.getTags())) &#123;            return LocalTransactionState.ROLLBACK_MESSAGE;        &#125; else &#123;            return LocalTransactionState.UNKNOW;        &#125;    &#125;    @Override    public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123;        System.out.println(&quot;MQ检查消息Tag【&quot;+msg.getTags()+&quot;】的本地事务执行结果&quot;);        return LocalTransactionState.COMMIT_MESSAGE;    &#125;&#125;\n\n\n\n4.6.2 使用限制\n事务消息不支持延时消息和批量消息。\n为了避免单个消息被检查太多次而导致半队列消息累积，我们默认将单个消息的检查次数限制为 15 次，但是用户可以通过 Broker 配置文件的 transactionCheckMax参数来修改此限制。如果已经检查某条消息超过 N 次的话（ N &#x3D; transactionCheckMax ） 则 Broker 将丢弃此消息，并在默认情况下同时打印错误日志。用户可以通过重写 AbstractTransactionCheckListener 类来修改这个行为。\n事务消息将在 Broker 配置文件中的参数 transactionMsgTimeout 这样的特定时间长度之后被检查。当发送事务消息时，用户还可以通过设置用户属性 CHECK_IMMUNITY_TIME_IN_SECONDS 来改变这个限制，该参数优先于 transactionMsgTimeout 参数。\n事务性消息可能不止一次被检查或消费。\n提交给用户的目标主题消息可能会失败，目前这依日志的记录而定。它的高可用性通过 RocketMQ 本身的高可用性机制来保证，如果希望确保事务消息不丢失、并且事务完整性得到保证，建议使用同步的双重写入机制。\n事务消息的生产者 ID 不能与其他类型消息的生产者 ID 共享。与其他类型的消息不同，事务消息允许反向查询、MQ服务器能通过它们的生产者 ID 查询到消费者。\n\n","categories":["RocketMQ"],"tags":["消息中间件"]},{"title":"RocketMQ-02","url":"/2023/02/19/RocketMQ-02/","content":"RocketMQ-02\n1.1 业务分析\n1.2 问题分析\n问题1\n\n\n2.1 技术选型\n2.2 SpringBoot整合RocketMQ\n2.2.1 消息生产者\n2.2.2 消息消费者\n\n\n2.3 SpringBoot整合Dubbo\n2.3.1 搭建Zookeeper集群\n2.3.2 RPC服务接口\n2.3.3 服务提供者\n2.3.4 服务消费者\n\n\n3.1 数据库\n1）优惠券表\n2）商品表\n3）订单表\n4）订单商品日志表\n5）用户表\n6）用户余额日志表\n7）订单支付表\n8）MQ消息生产表\n\n\n3.2 项目初始化\n3.1.1 工程浏览\n3.1.2 工程关系\n\n\n3.3 Mybatis逆向工程使用\n1）代码生成\n\n\n3.4 公共类介绍\n4.1 下单基本流程\n1）接口定义\n9）小结\n\n\n4.2 失败补偿机制\n4.2.1 消息发送方\n4.2.2 消费接收方\n\n\n4.3 测试\n1）准备测试环境\n\n\n5.1 创建支付订单\n5.2 支付回调\n5.2.1 流程分析\n5.2.2 代码实现\n5.2.3\n处理消息\n\n\n6.1 准备工作\n1）配置RestTemplate类\n2）配置请求地址\n\n\n6.2 下单测试\n6.3 支付测试\n\n1. 案例介绍1.1 业务分析模拟电商网站购物场景中的【下单】和【支付】业务\n###1）下单\n\n\n用户请求订单系统下单\n订单系统通过RPC调用订单服务下单\n订单服务调用优惠券服务，扣减优惠券\n订单服务调用调用库存服务，校验并扣减库存\n订单服务调用用户服务，扣减用户余额\n订单服务完成确认订单\n\n\n###2）支付\n\n\n用户请求支付系统\n支付系统调用第三方支付平台API进行发起支付流程\n用户通过第三方支付平台支付成功后，第三方支付平台回调通知支付系统\n支付系统调用订单服务修改订单状态\n支付系统调用积分服务添加积分\n支付系统调用日志服务记录日志\n\n1.2 问题分析问题1用户提交订单后，扣减库存成功、扣减优惠券成功、使用余额成功，但是在确认订单操作失败，需要对库存、库存、余额进行回退。\n如何保证数据的完整性？\n\n使用MQ保证在下单失败后系统数据的完整性\n\n###问题2\n用户通过第三方支付平台（支付宝、微信）支付成功后，第三方支付平台要通过回调API异步通知商家支付系统用户支付结果，支付系统根据支付结果修改订单状态、记录支付日志和给用户增加积分。\n商家支付系统如何保证在收到第三方支付平台的异步通知时，如何快速给第三方支付凭条做出回应？\n\n通过MQ进行数据分发，提高系统处理性能\n\n2. 技术分析2.1 技术选型\nSpringBoot\nDubbo\nZookeeper\nRocketMQ\nMysql\n\n\n2.2 SpringBoot整合RocketMQ下载rocketmq-spring项目\n将rocketmq-spring安装到本地仓库\nmvn install -Dmaven.skip.test=true\n\n\n\n2.2.1 消息生产者1）添加依赖&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt;    &lt;rocketmq-spring-boot-starter-version&gt;2.0.3&lt;/rocketmq-spring-boot-starter-version&gt;&lt;/properties&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt;        &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;$&#123;rocketmq-spring-boot-starter-version&#125;&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;version&gt;1.18.6&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n\n\n2）配置文件# application.propertiesrocketmq.name-server=192.168.25.135:9876;192.168.25.138:9876rocketmq.producer.group=my-group\n\n\n\n3）启动类@SpringBootApplicationpublic class MQProducerApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(MQSpringBootApplication.class);    &#125;&#125;\n\n\n\n4）测试类@RunWith(SpringRunner.class)@SpringBootTest(classes = &#123;MQSpringBootApplication.class&#125;)public class ProducerTest &#123;    @Autowired    private RocketMQTemplate rocketMQTemplate;    @Test    public void test1()&#123;        rocketMQTemplate.convertAndSend(&quot;springboot-mq&quot;,&quot;hello springboot rocketmq&quot;);    &#125;&#125;\n\n\n\n2.2.2 消息消费者1）添加依赖同消息生产者\n2）配置文件同消息生产者\n3）启动类@SpringBootApplicationpublic class MQConsumerApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(MQSpringBootApplication.class);    &#125;&#125;\n\n\n\n4）消息监听器@Slf4j@Component@RocketMQMessageListener(topic = &quot;springboot-mq&quot;,consumerGroup = &quot;springboot-mq-consumer-1&quot;)public class Consumer implements RocketMQListener&lt;String&gt; &#123;    @Override    public void onMessage(String message) &#123;        log.info(&quot;Receive message：&quot;+message);    &#125;&#125;\n\n\n\n2.3 SpringBoot整合Dubbo下载dubbo-spring-boot-starter依赖包\n将dubbo-spring-boot-starter安装到本地仓库\nmvn install -Dmaven.skip.test=true\n\n1\n\n2.3.1 搭建Zookeeper集群1）准备工作\n安装JDK\n将Zookeeper上传到服务器\n解压Zookeeper，并创建data目录，将conf下的zoo_sample.cfg文件改名为zoo.cfg\n建立/user/local/zookeeper-cluster,将解压后的Zookeeper复制到以下三个目录\n\n/usr/local/zookeeper-cluster/zookeeper-1/usr/local/zookeeper-cluster/zookeeper-2/usr/local/zookeeper-cluster/zookeeper-3\n\n\n\n\n配置每一个 Zookeeper 的 dataDir（zoo.cfg） clientPort 分别为 2181 2182 2183\n修改/usr/local/zookeeper-cluster/zookeeper-1/conf/zoo.cfg\n\n\nclientPort=2181dataDir=/usr/local/zookeeper-cluster/zookeeper-1/data\n\n\n\n 修改&#x2F;usr&#x2F;local&#x2F;zookeeper-cluster&#x2F;zookeeper-2&#x2F;conf&#x2F;zoo.cfg\nclientPort=2182dataDir=/usr/local/zookeeper-cluster/zookeeper-2/data\n\n\n\n 修改&#x2F;usr&#x2F;local&#x2F;zookeeper-cluster&#x2F;zookeeper-3&#x2F;conf&#x2F;zoo.cfg\nclientPort=2183dataDir=/usr/local/zookeeper-cluster/zookeeper-3/data\n\n\n\n2）配置集群\n在每个 zookeeper 的 data 目录下创建一个 myid 文件，内容分别是 1、2、3 。这个文件就是记录每个服务器的 ID\n\n在每一个 zookeeper 的 zoo.cfg 配置客户端访问端口（clientPort）和集群服务器 IP 列表。\n集群服务器 IP 列表如下\n\n\nserver.1=192.168.25.140:2881:3881server.2=192.168.25.140:2882:3882server.3=192.168.25.140:2883:3883\n\n\n\n解释：server.服务器 ID&#x3D;服务器 IP 地址：服务器之间通信端口：服务器之间投票选举端口\n3）启动集群启动集群就是分别启动每个实例。\n\n2.3.2 RPC服务接口public interface IUserService &#123;    public String sayHello(String name);&#125;\n\n\n\n2.3.3 服务提供者1）添加依赖&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt;    &lt;!--dubbo--&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.spring.boot&lt;/groupId&gt;        &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;2.0.0&lt;/version&gt;    &lt;/dependency&gt;\t&lt;!--spring-boot-stater--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt;                &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;\t&lt;!--zookeeper--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;        &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;        &lt;version&gt;3.4.10&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;groupId&gt;org.slf4j&lt;/groupId&gt;                &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;            &lt;/exclusion&gt;            &lt;exclusion&gt;                &lt;groupId&gt;log4j&lt;/groupId&gt;                &lt;artifactId&gt;log4j&lt;/artifactId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.101tec&lt;/groupId&gt;        &lt;artifactId&gt;zkclient&lt;/artifactId&gt;        &lt;version&gt;0.9&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;                &lt;groupId&gt;org.slf4j&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;\t&lt;!--API--&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.itheima.demo&lt;/groupId&gt;        &lt;artifactId&gt;dubbo-api&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n\n\n2）配置文件# application.propertiesspring.application.name=dubbo-demo-providerspring.dubbo.application.id=dubbo-demo-providerspring.dubbo.application.name=dubbo-demo-providerspring.dubbo.registry.address=zookeeper://192.168.25.140:2181;zookeeper://192.168.25.140:2182;zookeeper://192.168.25.140:2183spring.dubbo.server=truespring.dubbo.protocol.name=dubbospring.dubbo.protocol.port=20880\n\n\n\n3）启动类@EnableDubboConfiguration@SpringBootApplicationpublic class ProviderBootstrap &#123;    public static void main(String[] args) throws IOException &#123;        SpringApplication.run(ProviderBootstrap.class,args);    &#125;&#125;\n\n\n\n4）服务实现@Component@Service(interfaceClass = IUserService.class)public class UserServiceImpl implements IUserService&#123;    @Override    public String sayHello(String name) &#123;        return &quot;hello:&quot;+name;    &#125;&#125;\n\n\n\n2.3.4 服务消费者1）添加依赖&lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;    &lt;/parent&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!--dubbo--&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.spring.boot&lt;/groupId&gt;        &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;2.0.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt;                &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;!--zookeeper--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;        &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;        &lt;version&gt;3.4.10&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;groupId&gt;org.slf4j&lt;/groupId&gt;                &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;            &lt;/exclusion&gt;            &lt;exclusion&gt;                &lt;groupId&gt;log4j&lt;/groupId&gt;                &lt;artifactId&gt;log4j&lt;/artifactId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.101tec&lt;/groupId&gt;        &lt;artifactId&gt;zkclient&lt;/artifactId&gt;        &lt;version&gt;0.9&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;                &lt;groupId&gt;org.slf4j&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;!--API--&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.itheima.demo&lt;/groupId&gt;        &lt;artifactId&gt;dubbo-api&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n\n\n2）配置文件# application.propertiesspring.application.name=dubbo-demo-consumerspring.dubbo.application.name=dubbo-demo-consumerspring.dubbo.application.id=dubbo-demo-consumer    spring.dubbo.registry.address=zookeeper://192.168.25.140:2181;zookeeper://192.168.25.140:2182;zookeeper://192.168.25.140:2183\n\n\n\n动类@EnableDubboConfiguration@SpringBootApplicationpublic class ConsumerBootstrap &#123;    public static void main(String[] args) &#123;        SpringApplication.run(ConsumerBootstrap.class);    &#125;&#125;\n\n\n\n4）Controller@RestController@RequestMapping(&quot;/user&quot;)public class UserController &#123;    @Reference    private IUserService userService;    @RequestMapping(&quot;/sayHello&quot;)    public String sayHello(String name)&#123;        return userService.sayHello(name);    &#125;&#125;\n\n\n\n3. 环境搭建3.1 数据库1）优惠券表\n\n\nField\nType\nComment\n\n\n\ncoupon_id\nbigint(50) NOT NULL\n优惠券ID\n\n\ncoupon_price\ndecimal(10,2) NULL\n优惠券金额\n\n\nuser_id\nbigint(50) NULL\n用户ID\n\n\norder_id\nbigint(32) NULL\n订单ID\n\n\nis_used\nint(1) NULL\n是否使用 0未使用 1已使用\n\n\nused_time\ntimestamp NULL\n使用时间\n\n\n2）商品表\n\n\nField\nType\nComment\n\n\n\ngoods_id\nbigint(50) NOT NULL\n主键\n\n\ngoods_name\nvarchar(255) NULL\n商品名称\n\n\ngoods_number\nint(11) NULL\n商品库存\n\n\ngoods_price\ndecimal(10,2) NULL\n商品价格\n\n\ngoods_desc\nvarchar(255) NULL\n商品描述\n\n\nadd_time\ntimestamp NULL\n添加时间\n\n\n3）订单表\n\n\nField\nType\nComment\n\n\n\norder_id\nbigint(50) NOT NULL\n订单ID\n\n\nuser_id\nbigint(50) NULL\n用户ID\n\n\norder_status\nint(1) NULL\n订单状态 0未确认 1已确认 2已取消 3无效 4退款\n\n\npay_status\nint(1) NULL\n支付状态 0未支付 1支付中 2已支付\n\n\nshipping_status\nint(1) NULL\n发货状态 0未发货 1已发货 2已退货\n\n\naddress\nvarchar(255) NULL\n收货地址\n\n\nconsignee\nvarchar(255) NULL\n收货人\n\n\ngoods_id\nbigint(50) NULL\n商品ID\n\n\ngoods_number\nint(11) NULL\n商品数量\n\n\ngoods_price\ndecimal(10,2) NULL\n商品价格\n\n\ngoods_amount\ndecimal(10,0) NULL\n商品总价\n\n\nshipping_fee\ndecimal(10,2) NULL\n运费\n\n\norder_amount\ndecimal(10,2) NULL\n订单价格\n\n\ncoupon_id\nbigint(50) NULL\n优惠券ID\n\n\ncoupon_paid\ndecimal(10,2) NULL\n优惠券\n\n\nmoney_paid\ndecimal(10,2) NULL\n已付金额\n\n\npay_amount\ndecimal(10,2) NULL\n支付金额\n\n\nadd_time\ntimestamp NULL\n创建时间\n\n\nconfirm_time\ntimestamp NULL\n订单确认时间\n\n\npay_time\ntimestamp NULL\n支付时间\n\n\n4）订单商品日志表\n\n\nField\nType\nComment\n\n\n\ngoods_id\nint(11) NOT NULL\n商品ID\n\n\norder_id\nvarchar(32) NOT NULL\n订单ID\n\n\ngoods_number\nint(11) NULL\n库存数量\n\n\nlog_time\ndatetime NULL\n记录时间\n\n\n5）用户表\n\n\nField\nType\nComment\n\n\n\nuser_id\nbigint(50) NOT NULL\n用户ID\n\n\nuser_name\nvarchar(255) NULL\n用户姓名\n\n\nuser_password\nvarchar(255) NULL\n用户密码\n\n\nuser_mobile\nvarchar(255) NULL\n手机号\n\n\nuser_score\nint(11) NULL\n积分\n\n\nuser_reg_time\ntimestamp NULL\n注册时间\n\n\nuser_money\ndecimal(10,0) NULL\n用户余额\n\n\n6）用户余额日志表\n\n\nField\nType\nComment\n\n\n\nuser_id\nbigint(50) NOT NULL\n用户ID\n\n\norder_id\nbigint(50) NOT NULL\n订单ID\n\n\nmoney_log_type\nint(1) NOT NULL\n日志类型 1订单付款 2 订单退款\n\n\nuse_money\ndecimal(10,2) NULL\n操作金额\n\n\ncreate_time\ntimestamp NULL\n日志时间\n\n\n7）订单支付表\n\n\nField\nType\nComment\n\n\n\npay_id\nbigint(50) NOT NULL\n支付编号\n\n\norder_id\nbigint(50) NULL\n订单编号\n\n\npay_amount\ndecimal(10,2) NULL\n支付金额\n\n\nis_paid\nint(1) NULL\n是否已支付 1否 2是\n\n\n8）MQ消息生产表\n\n\nField\nType\nComment\n\n\n\nid\nvarchar(100) NOT NULL\n主键\n\n\ngroup_name\nvarchar(100) NULL\n生产者组名\n\n\nmsg_topic\nvarchar(100) NULL\n消息主题\n\n\nmsg_tag\nvarchar(100) NULL\nTag\n\n\nmsg_key\nvarchar(100) NULL\nKey\n\n\nmsg_body\nvarchar(500) NULL\n消息内容\n\n\nmsg_status\nint(1) NULL\n0:未处理;1:已经处理\n\n\ncreate_time\ntimestamp NOT NULL\n记录时间\n\n\n###9）MQ消息消费表\n\n\n\nField\nType\nComment\n\n\n\nmsg_id\nvarchar(50) NULL\n消息ID\n\n\ngroup_name\nvarchar(100) NOT NULL\n消费者组名\n\n\nmsg_tag\nvarchar(100) NOT NULL\nTag\n\n\nmsg_key\nvarchar(100) NOT NULL\nKey\n\n\nmsg_body\nvarchar(500) NULL\n消息体\n\n\nconsumer_status\nint(1) NULL\n0:正在处理;1:处理成功;2:处理失败\n\n\nconsumer_times\nint(1) NULL\n消费次数\n\n\nconsumer_timestamp\ntimestamp NULL\n消费时间\n\n\nremark\nvarchar(500) NULL\n备注\n\n\n3.2 项目初始化shop系统基于Maven进行项目管理\n3.1.1 工程浏览\n\n父工程：shop-parent\n订单系统：shop-order-web\n支付系统：shop-pay-web\n优惠券服务：shop-coupon-service\n订单服务：shop-order-service\n支付服务：shop-pay-service\n商品服务：shop-goods-service\n用户服务：shop-user-service\n实体类：shop-pojo\n持久层：shop-dao\n接口层：shop-api\n工具工程：shop-common\n\n共12个系统\n3.1.2 工程关系\n3.3 Mybatis逆向工程使用1）代码生成使用Mybatis逆向工程针对数据表生成CURD持久层代码\n###2）代码导入\n\n将实体类导入到shop-pojo工程\n在服务层工程中导入对应的Mapper类和对应配置文件\n\n3.4 公共类介绍\nID生成器\nIDWorker：Twitter雪花算法\n\n异常处理类\nCustomerException：自定义异常类\nCastException：异常抛出类\n\n常量类\nShopCode：系统状态类\n\n响应实体类\nResult：封装响应状态和响应信息\n\n\n4. 下单业务\n4.1 下单基本流程1）接口定义\nIOrderService\n\npublic interface IOrderService &#123;    /**     * 确认订单     * @param order     * @return Result     */    Result confirmOrder(TradeOrder order);&#125;\n\n\n\n###2）业务类实现\n@Slf4j@Component@Service(interfaceClass = IOrderService.class)public class OrderServiceImpl implements IOrderService &#123;    @Override    public Result confirmOrder(TradeOrder order) &#123;        //1.校验订单               //2.生成预订单               try &#123;            //3.扣减库存                        //4.扣减优惠券                       //5.使用余额                       //6.确认订单                        //7.返回成功状态                   &#125; catch (Exception e) &#123;            //1.确认订单失败,发送消息                        //2.返回失败状态        &#125;    &#125;&#125;\n\n\n\n###3）校验订单\n\nprivate void checkOrder(TradeOrder order) &#123;        //1.校验订单是否存在        if(order==null)&#123;            CastException.cast(ShopCode.SHOP_ORDER_INVALID);        &#125;        //2.校验订单中的商品是否存在        TradeGoods goods = goodsService.findOne(order.getGoodsId());        if(goods==null)&#123;            CastException.cast(ShopCode.SHOP_GOODS_NO_EXIST);        &#125;        //3.校验下单用户是否存在        TradeUser user = userService.findOne(order.getUserId());        if(user==null)&#123;            CastException.cast(ShopCode.SHOP_USER_NO_EXIST);        &#125;        //4.校验商品单价是否合法        if(order.getGoodsPrice().compareTo(goods.getGoodsPrice())!=0)&#123;            CastException.cast(ShopCode.SHOP_GOODS_PRICE_INVALID);        &#125;        //5.校验订单商品数量是否合法        if(order.getGoodsNumber()&gt;=goods.getGoodsNumber())&#123;            CastException.cast(ShopCode.SHOP_GOODS_NUM_NOT_ENOUGH);        &#125;        log.info(&quot;校验订单通过&quot;);&#125;\n\n\n\n###4）生成预订单\n\nprivate Long savePreOrder(TradeOrder order) &#123;        //1.设置订单状态为不可见        order.setOrderStatus(ShopCode.SHOP_ORDER_NO_CONFIRM.getCode());        //2.订单ID        order.setOrderId(idWorker.nextId());        //核算运费是否正确        BigDecimal shippingFee = calculateShippingFee(order.getOrderAmount());        if (order.getShippingFee().compareTo(shippingFee) != 0) &#123;            CastException.cast(ShopCode.SHOP_ORDER_SHIPPINGFEE_INVALID);        &#125;        //3.计算订单总价格是否正确        BigDecimal orderAmount = order.getGoodsPrice().multiply(new BigDecimal(order.getGoodsNumber()));        orderAmount.add(shippingFee);        if (orderAmount.compareTo(order.getOrderAmount()) != 0) &#123;            CastException.cast(ShopCode.SHOP_ORDERAMOUNT_INVALID);        &#125;        //4.判断优惠券信息是否合法        Long couponId = order.getCouponId();        if (couponId != null) &#123;            TradeCoupon coupon = couponService.findOne(couponId);            //优惠券不存在            if (coupon == null) &#123;                CastException.cast(ShopCode.SHOP_COUPON_NO_EXIST);            &#125;            //优惠券已经使用            if ((ShopCode.SHOP_COUPON_ISUSED.getCode().toString())                .equals(coupon.getIsUsed().toString())) &#123;                CastException.cast(ShopCode.SHOP_COUPON_INVALIED);            &#125;            order.setCouponPaid(coupon.getCouponPrice());        &#125; else &#123;            order.setCouponPaid(BigDecimal.ZERO);        &#125;        //5.判断余额是否正确        BigDecimal moneyPaid = order.getMoneyPaid();        if (moneyPaid != null) &#123;            //比较余额是否大于0            int r = order.getMoneyPaid().compareTo(BigDecimal.ZERO);            //余额小于0            if (r == -1) &#123;                CastException.cast(ShopCode.SHOP_MONEY_PAID_LESS_ZERO);            &#125;            //余额大于0            if (r == 1) &#123;                //查询用户信息                TradeUser user = userService.findOne(order.getUserId());                if (user == null) &#123;                    CastException.cast(ShopCode.SHOP_USER_NO_EXIST);                &#125;            //比较余额是否大于用户账户余额            if (user.getUserMoney().compareTo(order.getMoneyPaid().longValue()) == -1) &#123;                CastException.cast(ShopCode.SHOP_MONEY_PAID_INVALID);            &#125;            order.setMoneyPaid(order.getMoneyPaid());        &#125;    &#125; else &#123;        order.setMoneyPaid(BigDecimal.ZERO);    &#125;    //计算订单支付总价    order.setPayAmount(orderAmount.subtract(order.getCouponPaid())                       .subtract(order.getMoneyPaid()));    //设置订单添加时间    order.setAddTime(new Date());    //保存预订单    int r = orderMapper.insert(order);    if (ShopCode.SHOP_SUCCESS.getCode() != r) &#123;        CastException.cast(ShopCode.SHOP_ORDER_SAVE_ERROR);    &#125;    log.info(&quot;订单:[&quot;+order.getOrderId()+&quot;]预订单生成成功&quot;);    return order.getOrderId();&#125;\n\n\n\n###5）扣减库存\n\n通过dubbo调用商品服务完成扣减库存\n\nprivate void reduceGoodsNum(TradeOrder order) &#123;        TradeGoodsNumberLog goodsNumberLog = new TradeGoodsNumberLog();        goodsNumberLog.setGoodsId(order.getGoodsId());        goodsNumberLog.setOrderId(order.getOrderId());        goodsNumberLog.setGoodsNumber(order.getGoodsNumber());        Result result = goodsService.reduceGoodsNum(goodsNumberLog);        if (result.getSuccess().equals(ShopCode.SHOP_FAIL.getSuccess())) &#123;            CastException.cast(ShopCode.SHOP_REDUCE_GOODS_NUM_FAIL);        &#125;        log.info(&quot;订单:[&quot;+order.getOrderId()+&quot;]扣减库存[&quot;+order.getGoodsNumber()+&quot;个]成功&quot;);    &#125;\n\n\n\n\n商品服务GoodsService扣减库存\n\n@Overridepublic Result reduceGoodsNum(TradeGoodsNumberLog goodsNumberLog) &#123;    if (goodsNumberLog == null ||            goodsNumberLog.getGoodsNumber() == null ||            goodsNumberLog.getOrderId() == null ||            goodsNumberLog.getGoodsNumber() == null ||            goodsNumberLog.getGoodsNumber().intValue() &lt;= 0) &#123;        CastException.cast(ShopCode.SHOP_REQUEST_PARAMETER_VALID);    &#125;    TradeGoods goods = goodsMapper.selectByPrimaryKey(goodsNumberLog.getGoodsId());    if(goods.getGoodsNumber()&lt;goodsNumberLog.getGoodsNumber())&#123;        //库存不足        CastException.cast(ShopCode.SHOP_GOODS_NUM_NOT_ENOUGH);    &#125;    //减库存    goods.setGoodsNumber(goods.getGoodsNumber()-goodsNumberLog.getGoodsNumber());    goodsMapper.updateByPrimaryKey(goods);    //记录库存操作日志    goodsNumberLog.setGoodsNumber(-(goodsNumberLog.getGoodsNumber()));    goodsNumberLog.setLogTime(new Date());    goodsNumberLogMapper.insert(goodsNumberLog);    return new Result(ShopCode.SHOP_SUCCESS.getSuccess(),ShopCode.SHOP_SUCCESS.getMessage());&#125;\n\n\n\n###6）扣减优惠券\n\n通过dubbo完成扣减优惠券\n\nprivate void changeCoponStatus(TradeOrder order) &#123;    //判断用户是否使用优惠券    if (!StringUtils.isEmpty(order.getCouponId())) &#123;        //封装优惠券对象        TradeCoupon coupon = couponService.findOne(order.getCouponId());        coupon.setIsUsed(ShopCode.SHOP_COUPON_ISUSED.getCode());        coupon.setUsedTime(new Date());        coupon.setOrderId(order.getOrderId());        Result result = couponService.changeCouponStatus(coupon);        //判断执行结果        if (result.getSuccess().equals(ShopCode.SHOP_FAIL.getSuccess())) &#123;            //优惠券使用失败            CastException.cast(ShopCode.SHOP_COUPON_USE_FAIL);        &#125;        log.info(&quot;订单:[&quot;+order.getOrderId()+&quot;]使用扣减优惠券[&quot;+coupon.getCouponPrice()+&quot;元]成功&quot;);    &#125;&#125;\n\n\n\n\n优惠券服务CouponService更改优惠券状态\n\n@Overridepublic Result changeCouponStatus(TradeCoupon coupon) &#123;    try &#123;        //判断请求参数是否合法        if (coupon == null || StringUtils.isEmpty(coupon.getCouponId())) &#123;            CastException.cast(ShopCode.SHOP_REQUEST_PARAMETER_VALID);        &#125;\t\t//更新优惠券状态为已使用        couponMapper.updateByPrimaryKey(coupon);        return new Result(ShopCode.SHOP_SUCCESS.getSuccess(), ShopCode.SHOP_SUCCESS.getMessage());    &#125; catch (Exception e) &#123;        return new Result(ShopCode.SHOP_FAIL.getSuccess(), ShopCode.SHOP_FAIL.getMessage());    &#125;&#125;\n\n\n\n###7）扣减用户余额\n\n通过用户服务完成扣减余额\n\nprivate void reduceMoneyPaid(TradeOrder order) &#123;    //判断订单中使用的余额是否合法    if (order.getMoneyPaid() != null &amp;&amp; order.getMoneyPaid().compareTo(BigDecimal.ZERO) == 1) &#123;        TradeUserMoneyLog userMoneyLog = new TradeUserMoneyLog();        userMoneyLog.setOrderId(order.getOrderId());        userMoneyLog.setUserId(order.getUserId());        userMoneyLog.setUseMoney(order.getMoneyPaid());        userMoneyLog.setMoneyLogType(ShopCode.SHOP_USER_MONEY_PAID.getCode());        //扣减余额        Result result = userService.changeUserMoney(userMoneyLog);        if (result.getSuccess().equals(ShopCode.SHOP_FAIL.getSuccess())) &#123;            CastException.cast(ShopCode.SHOP_USER_MONEY_REDUCE_FAIL);        &#125;        log.info(&quot;订单:[&quot;+order.getOrderId()+&quot;扣减余额[&quot;+order.getMoneyPaid()+&quot;元]成功]&quot;);    &#125;&#125;\n\n\n\n\n用户服务UserService,更新余额\n\n\n@Overridepublic Result changeUserMoney(TradeUserMoneyLog userMoneyLog) &#123;    //判断请求参数是否合法    if (userMoneyLog == null            || userMoneyLog.getUserId() == null            || userMoneyLog.getUseMoney() == null            || userMoneyLog.getOrderId() == null            || userMoneyLog.getUseMoney().compareTo(BigDecimal.ZERO) &lt;= 0) &#123;        CastException.cast(ShopCode.SHOP_REQUEST_PARAMETER_VALID);    &#125;    //查询该订单是否存在付款记录    TradeUserMoneyLogExample userMoneyLogExample = new TradeUserMoneyLogExample();    userMoneyLogExample.createCriteria()            .andUserIdEqualTo(userMoneyLog.getUserId())            .andOrderIdEqualTo(userMoneyLog.getOrderId());   int count = userMoneyLogMapper.countByExample(userMoneyLogExample);   TradeUser tradeUser = new TradeUser();   tradeUser.setUserId(userMoneyLog.getUserId());   tradeUser.setUserMoney(userMoneyLog.getUseMoney().longValue());   //判断余额操作行为   //【付款操作】   if (userMoneyLog.getMoneyLogType().equals(ShopCode.SHOP_USER_MONEY_PAID.getCode())) &#123;           //订单已经付款，则抛异常           if (count &gt; 0) &#123;                CastException.cast(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY);            &#125;       \t   //用户账户扣减余额           userMapper.reduceUserMoney(tradeUser);       &#125;    //【退款操作】    if (userMoneyLog.getMoneyLogType().equals(ShopCode.SHOP_USER_MONEY_REFUND.getCode())) &#123;         //如果订单未付款,则不能退款,抛异常         if (count == 0) &#123;         CastException.cast(ShopCode.SHOP_ORDER_PAY_STATUS_NO_PAY);     &#125;     //防止多次退款     userMoneyLogExample = new TradeUserMoneyLogExample();     userMoneyLogExample.createCriteria()             .andUserIdEqualTo(userMoneyLog.getUserId())                .andOrderIdEqualTo(userMoneyLog.getOrderId())                .andMoneyLogTypeEqualTo(ShopCode.SHOP_USER_MONEY_REFUND.getCode());     count = userMoneyLogMapper.countByExample(userMoneyLogExample);     if (count &gt; 0) &#123;         CastException.cast(ShopCode.SHOP_USER_MONEY_REFUND_ALREADY);     &#125;     \t//用户账户添加余额        userMapper.addUserMoney(tradeUser);    &#125;    //记录用户使用余额日志    userMoneyLog.setCreateTime(new Date());    userMoneyLogMapper.insert(userMoneyLog);    return new Result(ShopCode.SHOP_SUCCESS.getSuccess(),ShopCode.SHOP_SUCCESS.getMessage());&#125;\n\n\n\n###8）确认订单\nprivate void updateOrderStatus(TradeOrder order) &#123;    order.setOrderStatus(ShopCode.SHOP_ORDER_CONFIRM.getCode());    order.setPayStatus(ShopCode.SHOP_ORDER_PAY_STATUS_NO_PAY.getCode());    order.setConfirmTime(new Date());    int r = orderMapper.updateByPrimaryKey(order);    if (r &lt;= 0) &#123;        CastException.cast(ShopCode.SHOP_ORDER_CONFIRM_FAIL);    &#125;    log.info(&quot;订单:[&quot;+order.getOrderId()+&quot;]状态修改成功&quot;);&#125;\n\n\n\n9）小结@Overridepublic Result confirmOrder(TradeOrder order) &#123;    //1.校验订单    checkOrder(order);    //2.生成预订单    Long orderId = savePreOrder(order);    order.setOrderId(orderId);    try &#123;        //3.扣减库存        reduceGoodsNum(order);        //4.扣减优惠券        changeCoponStatus(order);        //5.使用余额        reduceMoneyPaid(order);        //6.确认订单        updateOrderStatus(order);        log.info(&quot;订单:[&quot;+orderId+&quot;]确认成功&quot;);        return new Result(ShopCode.SHOP_SUCCESS.getSuccess(), ShopCode.SHOP_SUCCESS.getMessage());    &#125; catch (Exception e) &#123;        //确认订单失败,发送消息        ...        return new Result(ShopCode.SHOP_FAIL.getSuccess(), ShopCode.SHOP_FAIL.getMessage());    &#125;&#125;\n\n\n\n4.2 失败补偿机制4.2.1 消息发送方\n配置RocketMQ属性值\n\nrocketmq.name-server=192.168.25.135:9876;192.168.25.138:9876rocketmq.producer.group=orderProducerGroupmq.order.consumer.group.name=order_orderTopic_cancel_groupmq.order.topic=orderTopicmq.order.tag.confirm=order_confirmmq.order.tag.cancel=order_cancel\n\n\n\n\n注入模板类和属性值信息\n\n@Autowiredprivate RocketMQTemplate rocketMQTemplate;@Value(&quot;$&#123;mq.order.topic&#125;&quot;)private String topic;@Value(&quot;$&#123;mq.order.tag.cancel&#125;&quot;)private String cancelTag;\n\n\n\n\n发送下单失败消息\n\n@Overridepublic Result confirmOrder(TradeOrder order) &#123;    //1.校验订单    //2.生成预订    try &#123;        //3.扣减库存        //4.扣减优惠券        //5.使用余额        //6.确认订单    &#125; catch (Exception e) &#123;        //确认订单失败,发送消息        CancelOrderMQ cancelOrderMQ = new CancelOrderMQ();        cancelOrderMQ.setOrderId(order.getOrderId());        cancelOrderMQ.setCouponId(order.getCouponId());        cancelOrderMQ.setGoodsId(order.getGoodsId());        cancelOrderMQ.setGoodsNumber(order.getGoodsNumber());        cancelOrderMQ.setUserId(order.getUserId());        cancelOrderMQ.setUserMoney(order.getMoneyPaid());        try &#123;            sendMessage(topic,                         cancelTag,                         cancelOrderMQ.getOrderId().toString(),                     JSON.toJSONString(cancelOrderMQ));    &#125; catch (Exception e1) &#123;        e1.printStackTrace();            CastException.cast(ShopCode.SHOP_MQ_SEND_MESSAGE_FAIL);        &#125;        return new Result(ShopCode.SHOP_FAIL.getSuccess(), ShopCode.SHOP_FAIL.getMessage());    &#125;&#125;\n\n\n\nprivate void sendMessage(String topic, String tags, String keys, String body) throws Exception &#123;    //判断Topic是否为空    if (StringUtils.isEmpty(topic)) &#123;        CastException.cast(ShopCode.SHOP_MQ_TOPIC_IS_EMPTY);    &#125;    //判断消息内容是否为空    if (StringUtils.isEmpty(body)) &#123;        CastException.cast(ShopCode.SHOP_MQ_MESSAGE_BODY_IS_EMPTY);    &#125;    //消息体    Message message = new Message(topic, tags, keys, body.getBytes());    //发送消息    rocketMQTemplate.getProducer().send(message);&#125;\n\n\n\n4.2.2 消费接收方\n配置RocketMQ属性值\n\nrocketmq.name-server=192.168.25.135:9876;192.168.25.138:9876mq.order.consumer.group.name=order_orderTopic_cancel_groupmq.order.topic=orderTopic\n\n\n\n\n创建监听类，消费消息\n\n@Slf4j@Component@RocketMQMessageListener(topic = &quot;$&#123;mq.order.topic&#125;&quot;,                          consumerGroup = &quot;$&#123;mq.order.consumer.group.name&#125;&quot;,                         messageModel = MessageModel.BROADCASTING)public class CancelOrderConsumer implements RocketMQListener&lt;MessageExt&gt;&#123;    @Override    public void onMessage(MessageExt messageExt) &#123;        ...    &#125;&#125;\n\n\n\n1）回退库存\n流程分析\n\n\n\n消息消费者\n\n@Slf4j@Component@RocketMQMessageListener(topic = &quot;$&#123;mq.order.topic&#125;&quot;,consumerGroup = &quot;$&#123;mq.order.consumer.group.name&#125;&quot;,messageModel = MessageModel.BROADCASTING )public class CancelMQListener implements RocketMQListener&lt;MessageExt&gt;&#123;    @Value(&quot;$&#123;mq.order.consumer.group.name&#125;&quot;)    private String groupName;    @Autowired    private TradeGoodsMapper goodsMapper;    @Autowired    private TradeMqConsumerLogMapper mqConsumerLogMapper;    @Autowired    private TradeGoodsNumberLogMapper goodsNumberLogMapper;    @Override    public void onMessage(MessageExt messageExt) &#123;        String msgId=null;        String tags=null;        String keys=null;        String body=null;        try &#123;            //1. 解析消息内容            msgId = messageExt.getMsgId();            tags= messageExt.getTags();            keys= messageExt.getKeys();            body= new String(messageExt.getBody(),&quot;UTF-8&quot;);            log.info(&quot;接受消息成功&quot;);            //2. 查询消息消费记录            TradeMqConsumerLogKey primaryKey = new TradeMqConsumerLogKey();            primaryKey.setMsgTag(tags);            primaryKey.setMsgKey(keys);            primaryKey.setGroupName(groupName);            TradeMqConsumerLog mqConsumerLog = mqConsumerLogMapper.selectByPrimaryKey(primaryKey);            if(mqConsumerLog!=null)&#123;                //3. 判断如果消费过...                //3.1 获得消息处理状态                Integer status = mqConsumerLog.getConsumerStatus();                //处理过...返回                if(ShopCode.SHOP_MQ_MESSAGE_STATUS_SUCCESS.getCode().intValue()==status.intValue())&#123;                    log.info(&quot;消息:&quot;+msgId+&quot;,已经处理过&quot;);                    return;                &#125;                //正在处理...返回                if(ShopCode.SHOP_MQ_MESSAGE_STATUS_PROCESSING.getCode().intValue()==status.intValue())&#123;                    log.info(&quot;消息:&quot;+msgId+&quot;,正在处理&quot;);                    return;                &#125;                //处理失败                if(ShopCode.SHOP_MQ_MESSAGE_STATUS_FAIL.getCode().intValue()==status.intValue())&#123;                    //获得消息处理次数                    Integer times = mqConsumerLog.getConsumerTimes();                    if(times&gt;3)&#123;                        log.info(&quot;消息:&quot;+msgId+&quot;,消息处理超过3次,不能再进行处理了&quot;);                        return;                    &#125;                    mqConsumerLog.setConsumerStatus(ShopCode.SHOP_MQ_MESSAGE_STATUS_PROCESSING.getCode());                    //使用数据库乐观锁更新                    TradeMqConsumerLogExample example = new TradeMqConsumerLogExample();                    TradeMqConsumerLogExample.Criteria criteria = example.createCriteria();                    criteria.andMsgTagEqualTo(mqConsumerLog.getMsgTag());                    criteria.andMsgKeyEqualTo(mqConsumerLog.getMsgKey());                    criteria.andGroupNameEqualTo(groupName);                    criteria.andConsumerTimesEqualTo(mqConsumerLog.getConsumerTimes());                    int r = mqConsumerLogMapper.updateByExampleSelective(mqConsumerLog, example);                    if(r&lt;=0)&#123;                        //未修改成功,其他线程并发修改                        log.info(&quot;并发修改,稍后处理&quot;);                    &#125;                &#125;            &#125;else&#123;                //4. 判断如果没有消费过...                mqConsumerLog = new TradeMqConsumerLog();                mqConsumerLog.setMsgTag(tags);                mqConsumerLog.setMsgKey(keys);                mqConsumerLog.setConsumerStatus(ShopCode.SHOP_MQ_MESSAGE_STATUS_PROCESSING.getCode());                mqConsumerLog.setMsgBody(body);                mqConsumerLog.setMsgId(msgId);                mqConsumerLog.setConsumerTimes(0);                //将消息处理信息添加到数据库                mqConsumerLogMapper.insert(mqConsumerLog);            &#125;            //5. 回退库存            MQEntity mqEntity = JSON.parseObject(body, MQEntity.class);            Long goodsId = mqEntity.getGoodsId();            TradeGoods goods = goodsMapper.selectByPrimaryKey(goodsId);            goods.setGoodsNumber(goods.getGoodsNumber()+mqEntity.getGoodsNum());            goodsMapper.updateByPrimaryKey(goods);            //记录库存操作日志            TradeGoodsNumberLog goodsNumberLog = new TradeGoodsNumberLog();            goodsNumberLog.setOrderId(mqEntity.getOrderId());            goodsNumberLog.setGoodsId(goodsId);            goodsNumberLog.setGoodsNumber(mqEntity.getGoodsNum());            goodsNumberLog.setLogTime(new Date());            goodsNumberLogMapper.insert(goodsNumberLog);            //6. 将消息的处理状态改为成功            mqConsumerLog.setConsumerStatus(ShopCode.SHOP_MQ_MESSAGE_STATUS_SUCCESS.getCode());            mqConsumerLog.setConsumerTimestamp(new Date());            mqConsumerLogMapper.updateByPrimaryKey(mqConsumerLog);            log.info(&quot;回退库存成功&quot;);        &#125; catch (Exception e) &#123;            e.printStackTrace();            TradeMqConsumerLogKey primaryKey = new TradeMqConsumerLogKey();            primaryKey.setMsgTag(tags);            primaryKey.setMsgKey(keys);            primaryKey.setGroupName(groupName);            TradeMqConsumerLog mqConsumerLog = mqConsumerLogMapper.selectByPrimaryKey(primaryKey);            if(mqConsumerLog==null)&#123;                //数据库未有记录                mqConsumerLog = new TradeMqConsumerLog();                mqConsumerLog.setMsgTag(tags);                mqConsumerLog.setMsgKey(keys);                mqConsumerLog.setConsumerStatus(ShopCode.SHOP_MQ_MESSAGE_STATUS_FAIL.getCode());                mqConsumerLog.setMsgBody(body);                mqConsumerLog.setMsgId(msgId);                mqConsumerLog.setConsumerTimes(1);                mqConsumerLogMapper.insert(mqConsumerLog);            &#125;else&#123;                mqConsumerLog.setConsumerTimes(mqConsumerLog.getConsumerTimes()+1);                mqConsumerLogMapper.updateByPrimaryKeySelective(mqConsumerLog);            &#125;        &#125;    &#125;&#125;\n\n\n\n2）回退优惠券@Slf4j@Component@RocketMQMessageListener(topic = &quot;$&#123;mq.order.topic&#125;&quot;,consumerGroup = &quot;$&#123;mq.order.consumer.group.name&#125;&quot;,messageModel = MessageModel.BROADCASTING )public class CancelMQListener implements RocketMQListener&lt;MessageExt&gt;&#123;    @Autowired    private TradeCouponMapper couponMapper;    @Override    public void onMessage(MessageExt message) &#123;        try &#123;            //1. 解析消息内容            String body = new String(message.getBody(), &quot;UTF-8&quot;);            MQEntity mqEntity = JSON.parseObject(body, MQEntity.class);            log.info(&quot;接收到消息&quot;);            //2. 查询优惠券信息            TradeCoupon coupon = couponMapper.selectByPrimaryKey(mqEntity.getCouponId());            //3.更改优惠券状态            coupon.setUsedTime(null);            coupon.setIsUsed(ShopCode.SHOP_COUPON_UNUSED.getCode());            coupon.setOrderId(null);            couponMapper.updateByPrimaryKey(coupon);            log.info(&quot;回退优惠券成功&quot;);        &#125; catch (UnsupportedEncodingException e) &#123;            e.printStackTrace();            log.error(&quot;回退优惠券失败&quot;);        &#125;    &#125;&#125;\n\n\n\n3）回退余额@Slf4j@Component@RocketMQMessageListener(topic = &quot;$&#123;mq.order.topic&#125;&quot;,consumerGroup = &quot;$&#123;mq.order.consumer.group.name&#125;&quot;,messageModel = MessageModel.BROADCASTING )public class CancelMQListener implements RocketMQListener&lt;MessageExt&gt;&#123;    @Autowired    private IUserService userService;    @Override    public void onMessage(MessageExt messageExt) &#123;        try &#123;            //1.解析消息            String body = new String(messageExt.getBody(), &quot;UTF-8&quot;);            MQEntity mqEntity = JSON.parseObject(body, MQEntity.class);            log.info(&quot;接收到消息&quot;);            if(mqEntity.getUserMoney()!=null &amp;&amp; mqEntity.getUserMoney().compareTo(BigDecimal.ZERO)&gt;0)&#123;                //2.调用业务层,进行余额修改                TradeUserMoneyLog userMoneyLog = new TradeUserMoneyLog();                userMoneyLog.setUseMoney(mqEntity.getUserMoney());                userMoneyLog.setMoneyLogType(ShopCode.SHOP_USER_MONEY_REFUND.getCode());                userMoneyLog.setUserId(mqEntity.getUserId());                userMoneyLog.setOrderId(mqEntity.getOrderId());                userService.updateMoneyPaid(userMoneyLog);                log.info(&quot;余额回退成功&quot;);            &#125;        &#125; catch (UnsupportedEncodingException e) &#123;            e.printStackTrace();            log.error(&quot;余额回退失败&quot;);        &#125;    &#125;&#125;\n\n\n\n4）取消订单@Override    public void onMessage(MessageExt messageExt) &#123;        String body = new String(messageExt.getBody(), &quot;UTF-8&quot;);        String msgId = messageExt.getMsgId();        String tags = messageExt.getTags();        String keys = messageExt.getKeys();        log.info(&quot;CancelOrderProcessor receive message:&quot;+messageExt);        CancelOrderMQ cancelOrderMQ = JSON.parseObject(body, CancelOrderMQ.class);        TradeOrder order = orderService.findOne(cancelOrderMQ.getOrderId());\t\torder.setOrderStatus(ShopCode.SHOP_ORDER_CANCEL.getCode());        orderService.changeOrderStatus(order);        log.info(&quot;订单:[&quot;+order.getOrderId()+&quot;]状态设置为取消&quot;);        return order;    &#125;\n\n\n\n4.3 测试1）准备测试环境@RunWith(SpringRunner.class)@SpringBootTest(classes = ShopOrderServiceApplication.class)public class OrderTest &#123;    @Autowired    private IOrderService orderService;&#125;\n\n\n\n###1）准备测试数据\n\n用户数据\n商品数据\n优惠券数据\n\n###2）测试下单成功流程\n@Test    public void add()&#123;    Long goodsId=XXXL;    Long userId=XXXL;    Long couponId=XXXL;    TradeOrder order = new TradeOrder();    order.setGoodsId(goodsId);    order.setUserId(userId);    order.setGoodsNumber(1);    order.setAddress(&quot;北京&quot;);    order.setGoodsPrice(new BigDecimal(&quot;5000&quot;));    order.setOrderAmount(new BigDecimal(&quot;5000&quot;));    order.setMoneyPaid(new BigDecimal(&quot;100&quot;));    order.setCouponId(couponId);    order.setShippingFee(new BigDecimal(0));    orderService.confirmOrder(order);&#125;\n\n\n\n执行完毕后,查看数据库中用户的余额、优惠券数据，及订单的状态数据\n###3）测试下单失败流程\n代码同上。\n执行完毕后，查看用户的余额、优惠券数据是否发生更改，订单的状态是否为取消。\n5. 支付业务5.1 创建支付订单\npublic Result createPayment(TradePay tradePay) &#123;    //查询订单支付状态    try &#123;        TradePayExample payExample = new TradePayExample();        TradePayExample.Criteria criteria = payExample.createCriteria();        criteria.andOrderIdEqualTo(tradePay.getOrderId());        criteria.andIsPaidEqualTo(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY.getCode());        int count = tradePayMapper.countByExample(payExample);        if (count &gt; 0) &#123;            CastException.cast(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY);        &#125;        long payId = idWorker.nextId();        tradePay.setPayId(payId);        tradePay.setIsPaid(ShopCode.SHOP_ORDER_PAY_STATUS_NO_PAY.getCode());        tradePayMapper.insert(tradePay);        log.info(&quot;创建支付订单成功:&quot; + payId);    &#125; catch (Exception e) &#123;        return new Result(ShopCode.SHOP_FAIL.getSuccess(), ShopCode.SHOP_FAIL.getMessage());    &#125;    return new Result(ShopCode.SHOP_SUCCESS.getSuccess(), ShopCode.SHOP_SUCCESS.getMessage());&#125;\n\n\n\n5.2 支付回调5.2.1 流程分析\n5.2.2 代码实现public Result callbackPayment(TradePay tradePay) &#123;    if (tradePay.getIsPaid().equals(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY.getCode())) &#123;        tradePay = tradePayMapper.selectByPrimaryKey(tradePay.getPayId());        if (tradePay == null) &#123;            CastException.cast(ShopCode.SHOP_PAYMENT_NOT_FOUND);        &#125;        tradePay.setIsPaid(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY.getCode());        int i = tradePayMapper.updateByPrimaryKeySelective(tradePay);        //更新成功代表支付成功        if (i == 1) &#123;            TradeMqProducerTemp mqProducerTemp = new TradeMqProducerTemp();            mqProducerTemp.setId(String.valueOf(idWorker.nextId()));            mqProducerTemp.setGroupName(&quot;payProducerGroup&quot;);            mqProducerTemp.setMsgKey(String.valueOf(tradePay.getPayId()));            mqProducerTemp.setMsgTag(topic);            mqProducerTemp.setMsgBody(JSON.toJSONString(tradePay));            mqProducerTemp.setCreateTime(new Date());            mqProducerTempMapper.insert(mqProducerTemp);            TradePay finalTradePay = tradePay;            executorService.submit(new Runnable() &#123;                @Override                public void run() &#123;                    try &#123;                        SendResult sendResult = sendMessage(topic,                                                             tag,                                                             finalTradePay.getPayId(),                                                             JSON.toJSONString(finalTradePay));                        log.info(JSON.toJSONString(sendResult));                        if (SendStatus.SEND_OK.equals(sendResult.getSendStatus())) &#123;                            mqProducerTempMapper.deleteByPrimaryKey(mqProducerTemp.getId());                            System.out.println(&quot;删除消息表成功&quot;);                        &#125;                    &#125; catch (Exception e) &#123;                        e.printStackTrace();                    &#125;                &#125;            &#125;);        &#125; else &#123;            CastException.cast(ShopCode.SHOP_PAYMENT_IS_PAID);        &#125;    &#125;    return new Result(ShopCode.SHOP_SUCCESS.getSuccess(), ShopCode.SHOP_SUCCESS.getMessage());&#125;\n\n\n\n#线程池优化消息发送逻辑\n创建线程池对象\n\n@Beanpublic ThreadPoolTaskExecutor getThreadPool() &#123;    ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();    executor.setCorePoolSize(4);    executor.setMaxPoolSize(8);    executor.setQueueCapacity(100);    executor.setKeepAliveSeconds(60);    executor.setThreadNamePrefix(&quot;Pool-A&quot;);    executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());    executor.initialize();    return executor;&#125;\n\n\n\n\n使用线程池\n\n@Autowiredprivate ThreadPoolTaskExecutor executorService;executorService.submit(new Runnable() &#123;    @Override    public void run() &#123;        try &#123;            SendResult sendResult = sendMessage(topic, tag, finalTradePay.getPayId(), JSON.toJSONString(finalTradePay));            log.info(JSON.toJSONString(sendResult));            if (SendStatus.SEND_OK.equals(sendResult.getSendStatus())) &#123;                mqProducerTempMapper.deleteByPrimaryKey(mqProducerTemp.getId());                System.out.println(&quot;删除消息表成功&quot;);            &#125;        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;);\n\n\n\n5.2.3处理消息支付成功后，支付服务payService发送MQ消息，订单服务、用户服务、日志服务需要订阅消息进行处理\n\n订单服务修改订单状态为已支付\n日志服务记录支付日志\n用户服务负责给用户增加积分\n\n以下用订单服务为例说明消息的处理情况\n1）配置RocketMQ属性值mq.pay.topic=payTopicmq.pay.consumer.group.name=pay_payTopic_group\n\n\n\n2）消费消息\n在订单服务中，配置公共的消息处理类\n\npublic class BaseConsumer &#123;    public TradeOrder handleMessage(IOrderService                                     orderService,                                     MessageExt messageExt,Integer code) throws Exception &#123;        //解析消息内容        String body = new String(messageExt.getBody(), &quot;UTF-8&quot;);        String msgId = messageExt.getMsgId();        String tags = messageExt.getTags();        String keys = messageExt.getKeys();        OrderMQ orderMq = JSON.parseObject(body, OrderMQ.class);                //查询        TradeOrder order = orderService.findOne(orderMq.getOrderId());        if(ShopCode.SHOP_ORDER_MESSAGE_STATUS_CANCEL.getCode().equals(code))&#123;            order.setOrderStatus(ShopCode.SHOP_ORDER_CANCEL.getCode());        &#125;        if(ShopCode.SHOP_ORDER_MESSAGE_STATUS_ISPAID.getCode().equals(code))&#123;            order.setPayStatus(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY.getCode());        &#125;        orderService.changeOrderStatus(order);        return order;    &#125;&#125;\n\n\n\n\n接受订单支付成功消息\n\n@Slf4j@Component@RocketMQMessageListener(topic = &quot;$&#123;mq.pay.topic&#125;&quot;,                          consumerGroup = &quot;$&#123;mq.pay.consumer.group.name&#125;&quot;)public class PayConsumer extends BaseConsumer implements RocketMQListener&lt;MessageExt&gt; &#123;    @Autowired    private IOrderService orderService;    @Override    public void onMessage(MessageExt messageExt) &#123;        try &#123;            log.info(&quot;CancelOrderProcessor receive message:&quot;+messageExt);            TradeOrder order = handleMessage(orderService,                                              messageExt,                                              ShopCode.SHOP_ORDER_MESSAGE_STATUS_ISPAID.getCode());            log.info(&quot;订单:[&quot;+order.getOrderId()+&quot;]支付成功&quot;);        &#125; catch (Exception e) &#123;            e.printStackTrace();            log.error(&quot;订单支付失败&quot;);        &#125;    &#125;&#125;\n\n\n\n6. 整体联调通过Rest客户端请求shop-order-web和shop-pay-web完成下单和支付操作\n6.1 准备工作1）配置RestTemplate类@Configurationpublic class RestTemplateConfig &#123;    @Bean    @ConditionalOnMissingBean(&#123; RestOperations.class, RestTemplate.class &#125;)    public RestTemplate restTemplate(ClientHttpRequestFactory factory) &#123;        RestTemplate restTemplate = new RestTemplate(factory);        // 使用 utf-8 编码集的 conver 替换默认的 conver（默认的 string conver 的编码集为&quot;ISO-8859-1&quot;）        List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters = restTemplate.getMessageConverters();        Iterator&lt;HttpMessageConverter&lt;?&gt;&gt; iterator = messageConverters.iterator();        while (iterator.hasNext()) &#123;            HttpMessageConverter&lt;?&gt; converter = iterator.next();            if (converter instanceof StringHttpMessageConverter) &#123;                iterator.remove();            &#125;        &#125;        messageConverters.add(new StringHttpMessageConverter(Charset.forName(&quot;UTF-8&quot;)));        return restTemplate;    &#125;    @Bean    @ConditionalOnMissingBean(&#123;ClientHttpRequestFactory.class&#125;)    public ClientHttpRequestFactory simpleClientHttpRequestFactory() &#123;        SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory();        // ms        factory.setReadTimeout(15000);        // ms        factory.setConnectTimeout(15000);        return factory;    &#125;&#125;\n\n\n\n2）配置请求地址\n订单系统\n\nserver.host=http://localhostserver.servlet.path=/order-webserver.port=8080shop.order.baseURI=$&#123;server.host&#125;:$&#123;server.port&#125;$&#123;server.servlet.path&#125;shop.order.confirm=/order/confirm\n\n\n\n\n支付系统\n\nserver.host=http://localhostserver.servlet.path=/pay-webserver.port=9090shop.pay.baseURI=$&#123;server.host&#125;:$&#123;server.port&#125;$&#123;server.servlet.path&#125;shop.pay.createPayment=/pay/createPaymentshop.pay.callbackPayment=/pay/callbackPayment\n\n\n\n6.2 下单测试@RunWith(SpringRunner.class)@ContextConfiguration(classes = ShopOrderWebApplication.class)@TestPropertySource(&quot;classpath:application.properties&quot;)public class OrderTest &#123;   @Autowired   private RestTemplate restTemplate;   @Value(&quot;$&#123;shop.order.baseURI&#125;&quot;)   private String baseURI;   @Value(&quot;$&#123;shop.order.confirm&#125;&quot;)   private String confirmOrderPath;   @Autowired   private IDWorker idWorker;    /**    * 下单    */   @Test   public void confirmOrder()&#123;       Long goodsId=XXXL;       Long userId=XXXL;       Long couponId=XXXL;       TradeOrder order = new TradeOrder();       order.setGoodsId(goodsId);       order.setUserId(userId);       order.setGoodsNumber(1);       order.setAddress(&quot;北京&quot;);       order.setGoodsPrice(new BigDecimal(&quot;5000&quot;));       order.setOrderAmount(new BigDecimal(&quot;5000&quot;));       order.setMoneyPaid(new BigDecimal(&quot;100&quot;));       order.setCouponId(couponId);       order.setShippingFee(new BigDecimal(0));       Result result = restTemplate.postForEntity(baseURI + confirmOrderPath, order, Result.class).getBody();       System.out.println(result);   &#125;&#125;\n\n\n\n6.3 支付测试@RunWith(SpringRunner.class)@ContextConfiguration(classes = ShopPayWebApplication.class)@TestPropertySource(&quot;classpath:application.properties&quot;)public class PayTest &#123;    @Autowired    private RestTemplate restTemplate;    @Value(&quot;$&#123;shop.pay.baseURI&#125;&quot;)    private String baseURI;    @Value(&quot;$&#123;shop.pay.createPayment&#125;&quot;)    private String createPaymentPath;    @Value(&quot;$&#123;shop.pay.callbackPayment&#125;&quot;)    private String callbackPaymentPath;    @Autowired    private IDWorker idWorker;   /**     * 创建支付订单     */    @Test    public void createPayment()&#123;        Long orderId = 346321587315814400L;        TradePay pay = new TradePay();        pay.setOrderId(orderId);        pay.setPayAmount(new BigDecimal(4800));        Result result = restTemplate.postForEntity(baseURI + createPaymentPath, pay, Result.class).getBody();        System.out.println(result);    &#125;       /**     * 支付回调     */    @Test    public void callbackPayment()&#123;        Long payId = 346321891507720192L;        TradePay pay = new TradePay();        pay.setPayId(payId);        pay.setIsPaid(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY.getCode());        Result result = restTemplate.postForEntity(baseURI + callbackPaymentPath, pay, Result.class).getBody();        System.out.println(result);    &#125;&#125;\n\n\n\n","categories":["RocketMQ"],"tags":["消息中间件"]},{"title":"SpringBoot 全家桶","url":"/2023/02/19/SpringBoot%20%E5%85%A8%E5%AE%B6%E6%A1%B6/","content":"SpringBoot 全家桶 [![License][licensesvg]][license]  \nSpring Boot 现在已经成为Java 开发领域的一颗璀璨明珠，它本身是包容万象的，可以跟各种技术集成。\n本项目对目前Web开发中常用的各个技术，通过和SpringBoot的集成，并且对各种技术通过“一篇博客 + 一个可运行项目”的形式来详细说明。\n每个子项目都会使用最小依赖，大家拿来即可使用，自己可以根据业务需求自由组合搭配不同的技术构建项目。\n加粗提醒：\n\nmaster分支基于最新Spring Boot 2构建！\nspring1.5分支基于Spring Boot 1.5.10构建！\n\n项目简介\n子项目列表每个子项目会配有一篇博客文章的详细讲解 👉\n\n\n\n项目名称\n文章地址\n\n\n\nspringboot-thymeleaf\n集成Thymeleaf构建Web应用\n\n\nspringboot-mybatis\n集成MyBatis\n\n\nspringboot-hibernate\n集成Hibernate\n\n\nspringboot-mongodb\n集成MongoDB\n\n\nspringboot-restful\n实现RESTful接口\n\n\nspringboot-resttemplate\n使用RestTemplate\n\n\nspringboot-shiro\n集成Shiro权限管理\n\n\nspringboot-swagger2\n集成Swagger2自动生成API文档\n\n\nspringboot-jwt\n集成JWT实现接口权限认证\n\n\nspringboot-multisource\n多数据源配置\n\n\nspringboot-schedule\n定时任务\n\n\nspringboot-cxf\ncxf实现WebService\n\n\nspringboot-websocket\n使用WebScoket实时通信\n\n\nspringboot-socketio\n集成SocketIO实时通信\n\n\nspringboot-async\n异步线程池\n\n\nspringboot-starter\n教你自己写starter\n\n\nspringboot-aop\n使用AOP\n\n\nspringboot-transaction\n声明式事务\n\n\nspringboot-cache\n使用缓存\n\n\nspringboot-redis\nRedis数据库\n\n\nspringboot-batch\n批处理\n\n\nspringboot-rabbitmq\n使用消息队列RabbitMQ\n\n\nspringboot-echarts\n集成Echarts导出图片\n\n\n环境\nJDK 1.8\nMaven latest\nSpring Boot 2.0.4\nIntellij IDEA\nmysql 5.7\nmongodb\ngit 版本管理\nnginx 反向代理\nredis 缓存\nrabbitmq 消息队列\n\n运行每个子项目都可以单独运行，都是打包成jar包后，通过使用内置jetty容器执行，有3种方式运行。👉\n\n在IDEA里面直接运行Application.java的main函数。\n另一种方式是执行mvn clean package命令后传到linux服务器上面，通过命令java -Xms64m -Xmx1024m -jar xxx.jar方式运行\n在linux服务器上面，配置好jdk、maven、git命令后，通过git clone sb-xxx拉取工程后，执行./run.sh start test命令来执行\n\n注：每个子项目有自己的README.md文件，告诉你该怎么初始化环境，比如准备好数据库SQL文件等。\n另外，如果你需要打包成war包放到tomcat容器中运行，可修改pom.xml文件，将打包类型从jar改成war，打包后再放到容器中运行：\n&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;springboot-cache&lt;/artifactId&gt;&lt;packaging&gt;war&lt;/packaging&gt;","categories":["Springboot"],"tags":["Springboot"]},{"title":"RocketMQ-03","url":"/2023/02/19/RocketMQ-03/","content":"RocketMQ-03\n1.1 消息存储\n1.1.1 存储介质\n1.1.3 消息的存储和发送\n1.1.4 消息存储结构\n1.1.5 刷盘机制\n\n\n1.2 高可用性机制\n1.2.1 消息消费高可用\n1.2.2 消息发送高可用\n1.2.3 消息主从复制\n\n\n1.3 负载均衡\n1.3.1 Producer负载均衡\n1.3.2 Consumer负载均衡\n\n\n1.4 消息重试\n1.4.1 顺序消息的重试\n1.4.2 无序消息的重试\n\n\n1.5 死信队列\n1.5.1 死信特性\n1.5.2 查看死信信息\n\n\n1.6 消费幂等\n1.6.1 消费幂等的必要性\n1.6.2 处理方式\n\n\n2.1 环境搭建\n2.1.1 源码拉取\n2.1.3 调试\n\n\n2.2 NameServer\n2.2.1 架构设计\n2.2.2 启动流程\n2.2.3 路由管理\n2.2.4 小结\n\n\n2.3 Producer\n2.3.2 启动流程\n2.3.3 消息发送\n2.3.4 批量消息发送\n\n\n2.4 消息存储\n2.4.2 消息存储流程\n2.4.3 存储文件\n2.4.4 存储文件内存映射\n2.4.5 实时更新消息消费队列与索引文件\n2.4.6 消息队列和索引文件恢复\n2.4.7 刷盘机制\n2.4.8 过期文件删除机制\n2.4.9 小结\n\n\n2.5 Consumer\n2.5.1 消息消费概述\n2.5.3 消费者启动流程\n2.5.4 消息拉取\n2.5.5 消息队列负载与重新分布机制\n2.5.6 消息消费过程\n2.5.7 定时消息机制\n2.5.8 顺序消息\n2.5.9 小结\n\n\n\n1. 高级功能1.1 消息存储分布式队列因为有高可靠性的要求，所以数据要进行持久化存储。\n\n\n消息生成者发送消息\nMQ收到消息，将消息进行持久化，在存储中新增一条记录\n返回ACK给生产者\nMQ push 消息给对应的消费者，然后等待消费者返回ACK\n如果消息消费者在指定时间内成功返回ack，那么MQ认为消息消费成功，在存储中删除消息，即执行第6步；如果MQ在指定时间内没有收到ACK，则认为消息消费失败，会尝试重新push消息,重复执行4、5、6步骤\nMQ删除消息\n\n1.1.1 存储介质\n关系型数据库DB\n\nApache下开源的另外一款MQ—ActiveMQ（默认采用的KahaDB做消息存储）可选用JDBC的方式来做消息持久化，通过简单的xml配置信息即可实现JDBC消息存储。由于，普通关系型数据库（如Mysql）在单表数据量达到千万级别的情况下，其IO读写性能往往会出现瓶颈。在可靠性方面，该种方案非常依赖DB，如果一旦DB出现故障，则MQ的消息就无法落盘存储会导致线上故障\n\n\n文件系统\n目前业界较为常用的几款产品（RocketMQ&#x2F;Kafka&#x2F;RabbitMQ）均采用的是消息刷盘至所部署虚拟机&#x2F;物理机的文件系统来做持久化（刷盘一般可以分为异步刷盘和同步刷盘两种模式）。消息刷盘为消息存储提供了一种高效率、高可靠性和高性能的数据持久化方式。除非部署MQ机器本身或是本地磁盘挂了，否则一般是不会出现无法持久化的故障问题。\n\n\n\n###1.1.2 性能对比\n文件系统&gt;关系型数据库DB\n1.1.3 消息的存储和发送1）消息存储磁盘如果使用得当，磁盘的速度完全可以匹配上网络 的数据传输速度。目前的高性能磁盘，顺序写速度可以达到600MB&#x2F;s， 超过了一般网卡的传输速度。但是磁盘随机写的速度只有大概100KB&#x2F;s，和顺序写的性能相差6000倍！因为有如此巨大的速度差别，好的消息队列系统会比普通的消息队列系统速度快多个数量级。RocketMQ的消息用顺序写,保证了消息存储的速度。\n####2）消息发送\nLinux操作系统分为【用户态】和【内核态】，文件操作、网络操作需要涉及这两种形态的切换，免不了进行数据复制。\n一台服务器 把本机磁盘文件的内容发送到客户端，一般分为两个步骤：\n1）read；读取本地文件内容；\n2）write；将读取的内容通过网络发送出去。\n这两个看似简单的操作，实际进行了4 次数据复制，分别是：\n\n从磁盘复制数据到内核态内存；\n从内核态内存复 制到用户态内存；\n然后从用户态 内存复制到网络驱动的内核态内存；\n最后是从网络驱动的内核态内存复 制到网卡中进行传输。\n\n通过使用mmap的方式，可以省去向用户态的内存复制，提高速度。这种机制在Java中是通过MappedByteBuffer实现的\nRocketMQ充分利用了上述特性，也就是所谓的“零拷贝”技术，提高消息存盘和网络发送的速度。\n\n这里需要注意的是，采用MappedByteBuffer这种内存映射的方式有几个限制，其中之一是一次只能映射1.5~2G 的文件至用户态的虚拟内存，这也是为何RocketMQ默认设置单个CommitLog日志数据文件为1G的原因了\n\n1.1.4 消息存储结构RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成 的，消息真正的物理存储文件是CommitLog，ConsumeQueue是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储的地址。每 个Topic下的每个Message Queue都有一个对应的ConsumeQueue文件。\n\n\nCommitLog：存储消息的元数据\nConsumerQueue：存储消息在CommitLog的索引\nIndexFile：为了消息查询提供了一种通过key或时间区间来查询消息的方法，这种通过IndexFile来查找消息的方法不影响发送与消费消息的主流程\n\n1.1.5 刷盘机制RocketMQ的消息是存储到磁盘上的，这样既能保证断电后恢复， 又可以让存储的消息量超出内存的限制。RocketMQ为了提高性能，会尽可能地保证磁盘的顺序写。消息在通过Producer写入RocketMQ的时 候，有两种写磁盘方式，分布式同步刷盘和异步刷盘。\n\n1）同步刷盘在返回写成功状态时，消息已经被写入磁盘。具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘， 然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写 成功的状态。\n2）异步刷盘在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入。\n3）配置同步刷盘还是异步刷盘，都是通过Broker配置文件里的flushDiskType 参数设置的，这个参数被配置成SYNC_FLUSH、ASYNC_FLUSH中的 一个。\n1.2 高可用性机制\nRocketMQ分布式集群是通过Master和Slave的配合达到高可用性的。\nMaster和Slave的区别：在Broker的配置文件中，参数 brokerId的值为0表明这个Broker是Master，大于0表明这个Broker是 Slave，同时brokerRole参数也会说明这个Broker是Master还是Slave。\nMaster角色的Broker支持读和写，Slave角色的Broker仅支持读，也就是 Producer只能和Master角色的Broker连接写入消息；Consumer可以连接 Master角色的Broker，也可以连接Slave角色的Broker来读取消息。\n1.2.1 消息消费高可用在Consumer的配置文件中，并不需要设置是从Master读还是从Slave 读，当Master不可用或者繁忙的时候，Consumer会被自动切换到从Slave 读。有了自动切换Consumer这种机制，当一个Master角色的机器出现故障后，Consumer仍然可以从Slave读取消息，不影响Consumer程序。这就达到了消费端的高可用性。\n1.2.2 消息发送高可用在创建Topic的时候，把Topic的多个Message Queue创建在多个Broker组上（相同Broker名称，不同 brokerId的机器组成一个Broker组），这样当一个Broker组的Master不可 用后，其他组的Master仍然可用，Producer仍然可以发送消息。 RocketMQ目前还不支持把Slave自动转成Master，如果机器资源不足， 需要把Slave转成Master，则要手动停止Slave角色的Broker，更改配置文 件，用新的配置文件启动Broker。\n\n1.2.3 消息主从复制如果一个Broker组有Master和Slave，消息需要从Master复制到Slave 上，有同步和异步两种复制方式。\n####1）同步复制\n同步复制方式是等Master和Slave均写 成功后才反馈给客户端写成功状态；\n在同步复制方式下，如果Master出故障， Slave上有全部的备份数据，容易恢复，但是同步复制会增大数据写入 延迟，降低系统吞吐量。\n####2）异步复制\n异步复制方式是只要Master写成功 即可反馈给客户端写成功状态。\n在异步复制方式下，系统拥有较低的延迟和较高的吞吐量，但是如果Master出了故障，有些数据因为没有被写 入Slave，有可能会丢失；\n####3）配置\n同步复制和异步复制是通过Broker配置文件里的brokerRole参数进行设置的，这个参数可以被设置成ASYNC_MASTER、 SYNC_MASTER、SLAVE三个值中的一个。\n####4）总结\n\n实际应用中要结合业务场景，合理设置刷盘方式和主从复制方式， 尤其是SYNC_FLUSH方式，由于频繁地触发磁盘写动作，会明显降低 性能。通常情况下，应该把Master和Save配置成ASYNC_FLUSH的刷盘 方式，主从之间配置成SYNC_MASTER的复制方式，这样即使有一台 机器出故障，仍然能保证数据不丢，是个不错的选择。\n1.3 负载均衡1.3.1 Producer负载均衡Producer端，每个实例在发消息的时候，默认会轮询所有的message queue发送，以达到让消息平均落在不同的queue上。而由于queue可以散落在不同的broker，所以消息就发送到不同的broker下，如下图：\n\n图中箭头线条上的标号代表顺序，发布方会把第一条消息发送至 Queue 0，然后第二条消息发送至 Queue 1，以此类推。\n1.3.2 Consumer负载均衡1）集群模式在集群消费模式下，每条消息只需要投递到订阅这个topic的Consumer Group下的一个实例即可。RocketMQ采用主动拉取的方式拉取并消费消息，在拉取的时候需要明确指定拉取哪一条message queue。\n而每当实例的数量有变更，都会触发一次所有实例的负载均衡，这时候会按照queue的数量和实例的数量平均分配queue给每个实例。\n默认的分配算法是AllocateMessageQueueAveragely，如下图：\n\n还有另外一种平均的算法是AllocateMessageQueueAveragelyByCircle，也是平均分摊每一条queue，只是以环状轮流分queue的形式，如下图：\n\n需要注意的是，集群模式下，queue都是只允许分配只一个实例，这是由于如果多个实例同时消费一个queue的消息，由于拉取哪些消息是consumer主动控制的，那样会导致同一个消息在不同的实例下被消费多次，所以算法上都是一个queue只分给一个consumer实例，一个consumer实例可以允许同时分到不同的queue。\n通过增加consumer实例去分摊queue的消费，可以起到水平扩展的消费能力的作用。而有实例下线的时候，会重新触发负载均衡，这时候原来分配到的queue将分配到其他实例上继续消费。\n但是如果consumer实例的数量比message queue的总数量还多的话，多出来的consumer实例将无法分到queue，也就无法消费到消息，也就无法起到分摊负载的作用了。所以需要控制让queue的总数量大于等于consumer的数量。\n####2）广播模式\n由于广播模式下要求一条消息需要投递到一个消费组下面所有的消费者实例，所以也就没有消息被分摊消费的说法。\n在实现上，其中一个不同就是在consumer分配queue的时候，所有consumer都分到所有的queue。\n\n1.4 消息重试1.4.1 顺序消息的重试对于顺序消息，当消费者消费消息失败后，消息队列 RocketMQ 会自动不断进行消息重试（每次间隔时间为 1 秒），这时，应用会出现消息消费被阻塞的情况。因此，在使用顺序消息时，务必保证应用能够及时监控并处理消费失败的情况，避免阻塞现象的发生。\n1.4.2 无序消息的重试对于无序消息（普通、定时、延时、事务消息），当消费者消费消息失败时，您可以通过设置返回状态达到消息重试的结果。\n无序消息的重试只针对集群消费方式生效；广播方式不提供失败重试特性，即消费失败后，失败消息不再重试，继续消费新的消息。\n1）重试次数消息队列 RocketMQ 默认允许每条消息最多重试 16 次，每次重试的间隔时间如下：\n\n\n\n第几次重试\n与上次重试的间隔时间\n第几次重试\n与上次重试的间隔时间\n\n\n\n1\n10 秒\n9\n7 分钟\n\n\n2\n30 秒\n10\n8 分钟\n\n\n3\n1 分钟\n11\n9 分钟\n\n\n4\n2 分钟\n12\n10 分钟\n\n\n5\n3 分钟\n13\n20 分钟\n\n\n6\n4 分钟\n14\n30 分钟\n\n\n7\n5 分钟\n15\n1 小时\n\n\n8\n6 分钟\n16\n2 小时\n\n\n如果消息重试 16 次后仍然失败，消息将不再投递。如果严格按照上述重试时间间隔计算，某条消息在一直消费失败的前提下，将会在接下来的 4 小时 46 分钟之内进行 16 次重试，超过这个时间范围消息将不再重试投递。\n注意： 一条消息无论重试多少次，这些重试消息的 Message ID 不会改变。\n2）配置方式消费失败后，重试配置方式\n集群消费方式下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置（三种方式任选一种）：\n\n返回 Action.ReconsumeLater （推荐）\n返回 Null\n抛出异常\n\npublic class MessageListenerImpl implements MessageListener &#123;    @Override    public Action consume(Message message, ConsumeContext context) &#123;        //处理消息        doConsumeMessage(message);        //方式1：返回 Action.ReconsumeLater，消息将重试        return Action.ReconsumeLater;        //方式2：返回 null，消息将重试        return null;        //方式3：直接抛出异常， 消息将重试        throw new RuntimeException(&quot;Consumer Message exceotion&quot;);    &#125;&#125;\n\n\n\n消费失败后，不重试配置方式\n集群消费方式下，消息失败后期望消息不重试，需要捕获消费逻辑中可能抛出的异常，最终返回 Action.CommitMessage，此后这条消息将不会再重试。\npublic class MessageListenerImpl implements MessageListener &#123;    @Override    public Action consume(Message message, ConsumeContext context) &#123;        try &#123;            doConsumeMessage(message);        &#125; catch (Throwable e) &#123;            //捕获消费逻辑中的所有异常，并返回 Action.CommitMessage;            return Action.CommitMessage;        &#125;        //消息处理正常，直接返回 Action.CommitMessage;        return Action.CommitMessage;    &#125;&#125;\n\n\n\n自定义消息最大重试次数\n消息队列 RocketMQ 允许 Consumer 启动的时候设置最大重试次数，重试时间间隔将按照如下策略：\n\n最大重试次数小于等于 16 次，则重试时间间隔同上表描述。\n最大重试次数大于 16 次，超过 16 次的重试时间间隔均为每次 2 小时。\n\nProperties properties = new Properties();//配置对应 Group ID 的最大消息重试次数为 20 次properties.put(PropertyKeyConst.MaxReconsumeTimes,&quot;20&quot;);Consumer consumer =ONSFactory.createConsumer(properties);\n\n\n\n\n注意：\n\n\n消息最大重试次数的设置对相同 Group ID 下的所有 Consumer 实例有效。\n如果只对相同 Group ID 下两个 Consumer 实例中的其中一个设置了 MaxReconsumeTimes，那么该配置对两个 Consumer 实例均生效。\n配置采用覆盖的方式生效，即最后启动的 Consumer 实例会覆盖之前的启动实例的配置\n\n获取消息重试次数\n消费者收到消息后，可按照如下方式获取消息的重试次数：\npublic class MessageListenerImpl implements MessageListener &#123;    @Override    public Action consume(Message message, ConsumeContext context) &#123;        //获取消息的重试次数        System.out.println(message.getReconsumeTimes());        return Action.CommitMessage;    &#125;&#125;\n\n\n\n1.5 死信队列当一条消息初次消费失败，消息队列 RocketMQ 会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 RocketMQ 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。\n在消息队列 RocketMQ 中，这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。\n1.5.1 死信特性死信消息具有以下特性\n\n不会再被消费者正常消费。\n有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3 天内及时处理。\n\n死信队列具有以下特性：\n\n一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。\n如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列。\n一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic。\n\n1.5.2 查看死信信息\n在控制台查询出现死信队列的主题信息\n\n\n\n在消息界面根据主题查询死信消息\n\n\n\n选择重新发送消息\n\n一条消息进入死信队列，意味着某些因素导致消费者无法正常消费该消息，因此，通常需要您对其进行特殊处理。排查可疑因素并解决问题后，可以在消息队列 RocketMQ 控制台重新发送该消息，让消费者重新消费一次。\n1.6 消费幂等消息队列 RocketMQ 消费者在接收到消息以后，有必要根据业务上的唯一 Key 对消息做幂等处理的必要性。\n1.6.1 消费幂等的必要性在互联网应用中，尤其在网络不稳定的情况下，消息队列 RocketMQ 的消息有可能会出现重复，这个重复简单可以概括为以下情况：\n\n发送时消息重复\n当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败。 如果此时生产者意识到消息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。\n\n投递时消息重复\n消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。 为了保证消息至少被消费一次，消息队列 RocketMQ 的服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。\n\n负载均衡时消息重复（包括但不限于网络抖动、Broker 重启以及订阅方应用重启）\n当消息队列 RocketMQ 的 Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息。\n\n\n1.6.2 处理方式因为 Message ID 有可能出现冲突（重复）的情况，所以真正安全的幂等处理，不建议以 Message ID 作为处理依据。 最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息 Key 进行设置：\nMessage message = new Message();message.setKey(&quot;ORDERID_100&quot;);SendResult sendResult = producer.send(message);\n\n\n\n订阅方收到消息时可以根据消息的 Key 进行幂等处理：\nconsumer.subscribe(&quot;ons_test&quot;, &quot;*&quot;, new MessageListener() &#123;    public Action consume(Message message, ConsumeContext context) &#123;        String key = message.getKey()        // 根据业务唯一标识的 key 做幂等处理    &#125;&#125;);\n\n\n\n2. 源码分析2.1 环境搭建依赖工具\n\nJDK ：1.8+\nMaven\nIntelliJ IDEA\n\n2.1.1 源码拉取从官方仓库 https://github.com/apache/rocketmq clone或者download源码。\n\n源码目录结构：\n\nbroker: broker 模块（broke 启动进程）\nclient ：消息客户端，包含消息生产者、消息消费者相关类\ncommon ：公共包\ndev ：开发者信息（非源代码）\ndistribution ：部署实例文件夹（非源代码）\nexample: RocketMQ 例代码\nfilter ：消息过滤相关基础类\nfiltersrv：消息过滤服务器实现相关类（Filter启动进程）\nlogappender：日志实现相关类\nnamesrv：NameServer实现相关类（NameServer启动进程）\nopenmessageing：消息开放标准\nremoting：远程通信模块，给予Netty\nsrcutil：服务工具类\nstore：消息存储实现相关类\nstyle：checkstyle相关实现\ntest：测试相关类\ntools：工具类，监控命令相关实现类\n\n###2.1.2 导入IDEA\n\n执行安装\nclean install -Dmaven.test.skip=true\n\n\n\n2.1.3 调试创建conf配置文件夹,从distribution拷贝broker.conf和logback_broker.xml和logback_namesrv.xml\n\n1）启动NameServer\n展开namesrv模块，右键NamesrvStartup.java\n\n\n\n配置ROCKETMQ_HOME\n\n\n\n\n重新启动\n控制台打印结果\n\n\nThe Name Server boot success. serializeType=JSON\n\n1\n2）启动Broker\nbroker.conf配置文件内容\n\nbrokerClusterName = DefaultClusterbrokerName = broker-abrokerId = 0# namesrvAddr地址namesrvAddr=127.0.0.1:9876deleteWhen = 04fileReservedTime = 48brokerRole = ASYNC_MASTERflushDiskType = ASYNC_FLUSHautoCreateTopicEnable=true# 存储路径storePathRootDir=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir# commitLog路径storePathCommitLog=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir\\\\commitlog# 消息队列存储路径storePathConsumeQueue=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir\\\\consumequeue# 消息索引存储路径storePathIndex=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir\\\\index# checkpoint文件路径storeCheckpoint=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir\\\\checkpoint# abort文件存储路径abortFile=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir\\\\abort\n\n\n\n\n创建数据文件夹dataDir\n启动BrokerStartup,配置broker.conf和ROCKETMQ_HOME\n\n\n\n3）发送消息\n进入example模块的org.apache.rocketmq.example.quickstart\n指定Namesrv地址\n\nDefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);\n\n\n\n\n运行main方法，发送消息\n\n4）消费消息\n进入example模块的org.apache.rocketmq.example.quickstart\n指定Namesrv地址\n\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_4&quot;);consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);\n\n\n\n\n运行main方法，消费消息\n\n2.2 NameServer2.2.1 架构设计消息中间件的设计思路一般是基于主题订阅发布的机制，消息生产者（Producer）发送某一个主题到消息服务器，消息服务器负责将消息持久化存储，消息消费者（Consumer）订阅该兴趣的主题，消息服务器根据订阅信息（路由信息）将消息推送到消费者（Push模式）或者消费者主动向消息服务器拉去（Pull模式），从而实现消息生产者与消息消费者解耦。为了避免消息服务器的单点故障导致的整个系统瘫痪，通常会部署多台消息服务器共同承担消息的存储。那消息生产者如何知道消息要发送到哪台消息服务器呢？如果某一台消息服务器宕机了，那么消息生产者如何在不重启服务情况下感知呢？\nNameServer就是为了解决以上问题设计的。\n\nBroker消息服务器在启动的时向所有NameServer注册，消息生产者（Producer）在发送消息时之前先从NameServer获取Broker服务器地址列表，然后根据负载均衡算法从列表中选择一台服务器进行发送。NameServer与每台Broker保持长连接，并间隔30S检测Broker是否存活，如果检测到Broker宕机，则从路由注册表中删除。但是路由变化不会马上通知消息生产者。这样设计的目的是为了降低NameServer实现的复杂度，在消息发送端提供容错机制保证消息发送的可用性。\nNameServer本身的高可用是通过部署多台NameServer来实现，但彼此之间不通讯，也就是NameServer服务器之间在某一个时刻的数据并不完全相同，但这对消息发送并不会造成任何影响，这也是NameServer设计的一个亮点，总之，RocketMQ设计追求简单高效。\n2.2.2 启动流程\n启动类：org.apache.rocketmq.namesrv.NamesrvStartup\n####步骤一\n解析配置文件，填充NameServerConfig、NettyServerConfig属性值，并创建NamesrvController\n代码：NamesrvController#createNamesrvController\n//创建NamesrvConfigfinal NamesrvConfig namesrvConfig = new NamesrvConfig();//创建NettyServerConfigfinal NettyServerConfig nettyServerConfig = new NettyServerConfig();//设置启动端口号nettyServerConfig.setListenPort(9876);//解析启动-c参数if (commandLine.hasOption(&#x27;c&#x27;)) &#123;    String file = commandLine.getOptionValue(&#x27;c&#x27;);    if (file != null) &#123;        InputStream in = new BufferedInputStream(new FileInputStream(file));        properties = new Properties();        properties.load(in);        MixAll.properties2Object(properties, namesrvConfig);        MixAll.properties2Object(properties, nettyServerConfig);        namesrvConfig.setConfigStorePath(file);        System.out.printf(&quot;load config properties file OK, %s%n&quot;, file);        in.close();    &#125;&#125;//解析启动-p参数if (commandLine.hasOption(&#x27;p&#x27;)) &#123;    InternalLogger console = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_CONSOLE_NAME);    MixAll.printObjectProperties(console, namesrvConfig);    MixAll.printObjectProperties(console, nettyServerConfig);    System.exit(0);&#125;//将启动参数填充到namesrvConfig,nettyServerConfigMixAll.properties2Object(ServerUtil.commandLine2Properties(commandLine), namesrvConfig);//创建NameServerControllerfinal NamesrvController controller = new NamesrvController(namesrvConfig, nettyServerConfig);\n\n\n\nNamesrvConfig属性\nprivate String rocketmqHome = System.getProperty(MixAll.ROCKETMQ_HOME_PROPERTY, System.getenv(MixAll.ROCKETMQ_HOME_ENV));private String kvConfigPath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;kvConfig.json&quot;;private String configStorePath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;namesrv.properties&quot;;private String productEnvName = &quot;center&quot;;private boolean clusterTest = false;private boolean orderMessageEnable = false;\n\n\n\nrocketmqHome：rocketmq主目录\nkvConfig：NameServer存储KV配置属性的持久化路径\nconfigStorePath：nameServer默认配置文件路径\norderMessageEnable：是否支持顺序消息\nNettyServerConfig属性\nprivate int listenPort = 8888;private int serverWorkerThreads = 8;private int serverCallbackExecutorThreads = 0;private int serverSelectorThreads = 3;private int serverOnewaySemaphoreValue = 256;private int serverAsyncSemaphoreValue = 64;private int serverChannelMaxIdleTimeSeconds = 120;private int serverSocketSndBufSize = NettySystemConfig.socketSndbufSize;private int serverSocketRcvBufSize = NettySystemConfig.socketRcvbufSize;private boolean serverPooledByteBufAllocatorEnable = true;private boolean useEpollNativeSelector = false;\n\n\n\nlistenPort：NameServer监听端口，该值默认会被初始化为9876 serverWorkerThreads：Netty业务线程池线程个数 serverCallbackExecutorThreads：Netty public任务线程池线程个数，Netty网络设计，根据业务类型会创建不同的线程池，比如处理消息发送、消息消费、心跳检测等。如果该业务类型未注册线程池，则由public线程池执行。 serverSelectorThreads：IO线程池个数，主要是NameServer、Broker端解析请求、返回相应的线程个数，这类线程主要是处理网路请求的，解析请求包，然后转发到各个业务线程池完成具体的操作，然后将结果返回给调用方; serverOnewaySemaphoreValue：send oneway消息请求并发读（Broker端参数）; serverAsyncSemaphoreValue：异步消息发送最大并发度; serverChannelMaxIdleTimeSeconds ：网络连接最大的空闲时间，默认120s。 serverSocketSndBufSize：网络socket发送缓冲区大小。 serverSocketRcvBufSize： 网络接收端缓存区大小。 serverPooledByteBufAllocatorEnable：ByteBuffer是否开启缓存; useEpollNativeSelector：是否启用Epoll IO模型。\n步骤二根据启动属性创建NamesrvController实例，并初始化该实例。NameServerController实例为NameServer核心控制器\n代码：NamesrvController#initialize\npublic boolean initialize() &#123;\t//加载KV配置    this.kvConfigManager.load();\t//创建NettyServer网络处理对象    this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService);\t//开启定时任务:每隔10s扫描一次Broker,移除不活跃的Broker    this.remotingExecutor =        Executors.newFixedThreadPool(nettyServerConfig.getServerWorkerThreads(), new ThreadFactoryImpl(&quot;RemotingExecutorThread_&quot;));    this.registerProcessor();    this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;        @Override        public void run() &#123;            NamesrvController.this.routeInfoManager.scanNotActiveBroker();        &#125;    &#125;, 5, 10, TimeUnit.SECONDS);\t//开启定时任务:每隔10min打印一次KV配置\tthis.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;        @Override        public void run() &#123;            NamesrvController.this.kvConfigManager.printAllPeriodically();        &#125;    &#125;, 1, 10, TimeUnit.MINUTES);    return true;&#125;\n\n\n\n步骤三在JVM进程关闭之前，先将线程池关闭，及时释放资源\n代码：NamesrvStartup#start\n//注册JVM钩子函数代码Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, new Callable&lt;Void&gt;() &#123;    @Override    public Void call() throws Exception &#123;        //释放资源        controller.shutdown();        return null;    &#125;&#125;));\n\n\n\n2.2.3 路由管理NameServer的主要作用是为消息的生产者和消息消费者提供关于主题Topic的路由信息，那么NameServer需要存储路由的基础信息，还要管理Broker节点，包括路由注册、路由删除等。\n2.2.3.1 路由元信息代码：RouteInfoManager\nprivate final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable;\n\n\n\n\ntopicQueueTable：Topic消息队列路由信息，消息发送时根据路由表进行负载均衡\nbrokerAddrTable：Broker基础信息，包括brokerName、所属集群名称、主备Broker地址\nclusterAddrTable：Broker集群信息，存储集群中所有Broker名称\nbrokerLiveTable：Broker状态信息，NameServer每次收到心跳包是会替换该信息\nfilterServerTable：Broker上的FilterServer列表，用于类模式消息过滤。\n\nRocketMQ基于定于发布机制，一个Topic拥有多个消息队列，一个Broker为每一个主题创建4个读队列和4个写队列。多个Broker组成一个集群，集群由相同的多台Broker组成Master-Slave架构，brokerId为0代表Master，大于0为Slave。BrokerLiveInfo中的lastUpdateTimestamp存储上次收到Broker心跳包的时间。\n\n\n\n2.2.3.2 路由注册1）发送心跳包\nRocketMQ路由注册是通过Broker与NameServer的心跳功能实现的。Broker启动时向集群中所有的NameServer发送心跳信息，每隔30s向集群中所有NameServer发送心跳包，NameServer收到心跳包时会更新brokerLiveTable缓存中BrokerLiveInfo的lastUpdataTimeStamp信息，然后NameServer每隔10s扫描brokerLiveTable，如果连续120S没有收到心跳包，NameServer将移除Broker的路由信息同时关闭Socket连接。\n代码：BrokerController#start\n//注册Broker信息this.registerBrokerAll(true, false, true);//每隔30s上报Broker信息到NameServerthis.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;    @Override    public void run() &#123;        try &#123;            BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister());        &#125; catch (Throwable e) &#123;            log.error(&quot;registerBrokerAll Exception&quot;, e);        &#125;    &#125;&#125;, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)),                                                   TimeUnit.MILLISECONDS);\n\n\n\n代码：BrokerOuterAPI#registerBrokerAll\n//获得nameServer地址信息List&lt;String&gt; nameServerAddressList = this.remotingClient.getNameServerAddressList();//遍历所有nameserver列表if (nameServerAddressList != null &amp;&amp; nameServerAddressList.size() &gt; 0) &#123;    //封装请求头    final RegisterBrokerRequestHeader requestHeader = new RegisterBrokerRequestHeader();    requestHeader.setBrokerAddr(brokerAddr);    requestHeader.setBrokerId(brokerId);    requestHeader.setBrokerName(brokerName);    requestHeader.setClusterName(clusterName);    requestHeader.setHaServerAddr(haServerAddr);    requestHeader.setCompressed(compressed);\t//封装请求体    RegisterBrokerBody requestBody = new RegisterBrokerBody();    requestBody.setTopicConfigSerializeWrapper(topicConfigWrapper);    requestBody.setFilterServerList(filterServerList);    final byte[] body = requestBody.encode(compressed);    final int bodyCrc32 = UtilAll.crc32(body);    requestHeader.setBodyCrc32(bodyCrc32);    final CountDownLatch countDownLatch = new CountDownLatch(nameServerAddressList.size());    for (final String namesrvAddr : nameServerAddressList) &#123;        brokerOuterExecutor.execute(new Runnable() &#123;            @Override            public void run() &#123;                try &#123;                    //分别向NameServer注册                    RegisterBrokerResult result = registerBroker(namesrvAddr,oneway, timeoutMills,requestHeader,body);                    if (result != null) &#123;                        registerBrokerResultList.add(result);                    &#125;                    log.info(&quot;register broker[&#123;&#125;]to name server &#123;&#125; OK&quot;, brokerId, namesrvAddr);                &#125; catch (Exception e) &#123;                    log.warn(&quot;registerBroker Exception, &#123;&#125;&quot;, namesrvAddr, e);                &#125; finally &#123;                    countDownLatch.countDown();                &#125;            &#125;        &#125;);    &#125;    try &#123;        countDownLatch.await(timeoutMills, TimeUnit.MILLISECONDS);    &#125; catch (InterruptedException e) &#123;    &#125;&#125;\n\n\n\n代码：BrokerOutAPI#registerBroker\nif (oneway) &#123;    try &#123;        this.remotingClient.invokeOneway(namesrvAddr, request, timeoutMills);    &#125; catch (RemotingTooMuchRequestException e) &#123;        // Ignore    &#125;    return null;&#125;RemotingCommand response = this.remotingClient.invokeSync(namesrvAddr, request, timeoutMills);\n\n\n\n2）处理心跳包\norg.apache.rocketmq.namesrv.processor.DefaultRequestProcessor`网路处理类解析请求类型，如果请求类型是为***REGISTER_BROKER***，则将请求转发到`RouteInfoManager#regiesterBroker\n\n代码：DefaultRequestProcessor#processRequest\n//判断是注册Broker信息case RequestCode.REGISTER_BROKER:\tVersion brokerVersion = MQVersion.value2Version(request.getVersion());\tif (brokerVersion.ordinal() &gt;= MQVersion.Version.V3_0_11.ordinal()) &#123;\t    return this.registerBrokerWithFilterServer(ctx, request);\t&#125; else &#123;        //注册Broker信息\t    return this.registerBroker(ctx, request);\t&#125;\n\n\n\n代码：DefaultRequestProcessor#registerBroker\nRegisterBrokerResult result = this.namesrvController.getRouteInfoManager().registerBroker(    requestHeader.getClusterName(),    requestHeader.getBrokerAddr(),    requestHeader.getBrokerName(),    requestHeader.getBrokerId(),    requestHeader.getHaServerAddr(),    topicConfigWrapper,    null,    ctx.channel());\n\n\n\n代码：RouteInfoManager#registerBroker\n维护路由信息\n//加锁this.lock.writeLock().lockInterruptibly();//维护clusterAddrTableSet&lt;String&gt; brokerNames = this.clusterAddrTable.get(clusterName);if (null == brokerNames) &#123;    brokerNames = new HashSet&lt;String&gt;();    this.clusterAddrTable.put(clusterName, brokerNames);&#125;brokerNames.add(brokerName);\n\n\n\n//维护brokerAddrTableBrokerData brokerData = this.brokerAddrTable.get(brokerName);//第一次注册,则创建brokerDataif (null == brokerData) &#123;    registerFirst = true;    brokerData = new BrokerData(clusterName, brokerName, new HashMap&lt;Long, String&gt;());    this.brokerAddrTable.put(brokerName, brokerData);&#125;//非第一次注册,更新BrokerMap&lt;Long, String&gt; brokerAddrsMap = brokerData.getBrokerAddrs();Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerAddrsMap.entrySet().iterator();while (it.hasNext()) &#123;    Entry&lt;Long, String&gt; item = it.next();    if (null != brokerAddr &amp;&amp; brokerAddr.equals(item.getValue()) &amp;&amp; brokerId != item.getKey()) &#123;        it.remove();    &#125;&#125;String oldAddr = brokerData.getBrokerAddrs().put(brokerId, brokerAddr);registerFirst = registerFirst || (null == oldAddr);\n\n\n\n//维护topicQueueTableif (null != topicConfigWrapper &amp;&amp; MixAll.MASTER_ID == brokerId) &#123;    if (this.isBrokerTopicConfigChanged(brokerAddr, topicConfigWrapper.getDataVersion()) ||         registerFirst) &#123;        ConcurrentMap&lt;String, TopicConfig&gt; tcTable = topicConfigWrapper.getTopicConfigTable();        if (tcTable != null) &#123;            for (Map.Entry&lt;String, TopicConfig&gt; entry : tcTable.entrySet()) &#123;                this.createAndUpdateQueueData(brokerName, entry.getValue());            &#125;        &#125;    &#125;&#125;\n\n\n\n代码：RouteInfoManager#createAndUpdateQueueData\nprivate void createAndUpdateQueueData(final String brokerName, final TopicConfig topicConfig) &#123;    //创建QueueData\tQueueData queueData = new QueueData();\tqueueData.setBrokerName(brokerName);\tqueueData.setWriteQueueNums(topicConfig.getWriteQueueNums());\tqueueData.setReadQueueNums(topicConfig.getReadQueueNums());\tqueueData.setPerm(topicConfig.getPerm());\tqueueData.setTopicSynFlag(topicConfig.getTopicSysFlag());\t//获得topicQueueTable中队列集合\tList&lt;QueueData&gt; queueDataList = this.topicQueueTable.get(topicConfig.getTopicName());    //topicQueueTable为空,则直接添加queueData到队列集合\tif (null == queueDataList) &#123;\t    queueDataList = new LinkedList&lt;QueueData&gt;();\t    queueDataList.add(queueData);\t    this.topicQueueTable.put(topicConfig.getTopicName(), queueDataList);\t    log.info(&quot;new topic registered, &#123;&#125; &#123;&#125;&quot;, topicConfig.getTopicName(), queueData);\t&#125; else &#123;        //判断是否是新的队列\t    boolean addNewOne = true;\t    Iterator&lt;QueueData&gt; it = queueDataList.iterator();\t    while (it.hasNext()) &#123;\t        QueueData qd = it.next();            //如果brokerName相同,代表不是新的队列\t        if (qd.getBrokerName().equals(brokerName)) &#123;\t            if (qd.equals(queueData)) &#123;\t                addNewOne = false;\t        &#125; else &#123;\t                    log.info(&quot;topic changed, &#123;&#125; OLD: &#123;&#125; NEW: &#123;&#125;&quot;, topicConfig.getTopicName(), qd,\t                        queueData);\t                    it.remove();\t                &#125;\t            &#125;\t        &#125;\t\t//如果是新的队列,则添加队列到queueDataList        if (addNewOne) &#123;            queueDataList.add(queueData);        &#125;    &#125;&#125;\n\n\n\n//维护brokerLiveTableBrokerLiveInfo prevBrokerLiveInfo = this.brokerLiveTable.put(brokerAddr,new BrokerLiveInfo(    System.currentTimeMillis(),    topicConfigWrapper.getDataVersion(),    channel,    haServerAddr));\n\n\n\n//维护filterServerListif (filterServerList != null) &#123;    if (filterServerList.isEmpty()) &#123;        this.filterServerTable.remove(brokerAddr);    &#125; else &#123;        this.filterServerTable.put(brokerAddr, filterServerList);    &#125;&#125;if (MixAll.MASTER_ID != brokerId) &#123;    String masterAddr = brokerData.getBrokerAddrs().get(MixAll.MASTER_ID);    if (masterAddr != null) &#123;        BrokerLiveInfo brokerLiveInfo = this.brokerLiveTable.get(masterAddr);        if (brokerLiveInfo != null) &#123;            result.setHaServerAddr(brokerLiveInfo.getHaServerAddr());            result.setMasterAddr(masterAddr);        &#125;    &#125;&#125;\n\n\n\n2.2.3.3 路由删除Broker每隔30s向NameServer发送一个心跳包，心跳包包含BrokerId，Broker地址，Broker名称，Broker所属集群名称、Broker关联的FilterServer列表。但是如果Broker宕机，NameServer无法收到心跳包，此时NameServer如何来剔除这些失效的Broker呢？NameServer会每隔10s扫描brokerLiveTable状态表，如果BrokerLive的lastUpdateTimestamp的时间戳距当前时间超过120s，则认为Broker失效，移除该Broker，关闭与Broker连接，同时更新topicQueueTable、brokerAddrTable、brokerLiveTable、filterServerTable。\nRocketMQ有两个触发点来删除路由信息：\n\nNameServer定期扫描brokerLiveTable检测上次心跳包与当前系统的时间差，如果时间超过120s，则需要移除broker。\nBroker在正常关闭的情况下，会执行unregisterBroker指令\n\n这两种方式路由删除的方法都是一样的，就是从相关路由表中删除与该broker相关的信息。\n\n代码：NamesrvController#initialize\n//每隔10s扫描一次为活跃Brokerthis.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;    @Override    public void run() &#123;        NamesrvController.this.routeInfoManager.scanNotActiveBroker();    &#125;&#125;, 5, 10, TimeUnit.SECONDS);\n\n\n\n代码：RouteInfoManager#scanNotActiveBroker\npublic void scanNotActiveBroker() &#123;    //获得brokerLiveTable    Iterator&lt;Entry&lt;String, BrokerLiveInfo&gt;&gt; it = this.brokerLiveTable.entrySet().iterator();    //遍历brokerLiveTable    while (it.hasNext()) &#123;        Entry&lt;String, BrokerLiveInfo&gt; next = it.next();        long last = next.getValue().getLastUpdateTimestamp();        //如果收到心跳包的时间距当时时间是否超过120s        if ((last + BROKER_CHANNEL_EXPIRED_TIME) &lt; System.currentTimeMillis()) &#123;            //关闭连接            RemotingUtil.closeChannel(next.getValue().getChannel());            //移除broker            it.remove();            //维护路由表            this.onChannelDestroy(next.getKey(), next.getValue().getChannel());        &#125;    &#125;&#125;\n\n\n\n代码：RouteInfoManager#onChannelDestroy\n//申请写锁,根据brokerAddress从brokerLiveTable和filterServerTable移除this.lock.writeLock().lockInterruptibly();this.brokerLiveTable.remove(brokerAddrFound);this.filterServerTable.remove(brokerAddrFound);\n\n\n\n//维护brokerAddrTableString brokerNameFound = null;boolean removeBrokerName = false;Iterator&lt;Entry&lt;String, BrokerData&gt;&gt; itBrokerAddrTable =this.brokerAddrTable.entrySet().iterator();//遍历brokerAddrTablewhile (itBrokerAddrTable.hasNext() &amp;&amp; (null == brokerNameFound)) &#123;    BrokerData brokerData = itBrokerAddrTable.next().getValue();    //遍历broker地址    Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerData.getBrokerAddrs().entrySet().iterator();    while (it.hasNext()) &#123;        Entry&lt;Long, String&gt; entry = it.next();        Long brokerId = entry.getKey();        String brokerAddr = entry.getValue();        //根据broker地址移除brokerAddr        if (brokerAddr.equals(brokerAddrFound)) &#123;            brokerNameFound = brokerData.getBrokerName();            it.remove();            log.info(&quot;remove brokerAddr[&#123;&#125;, &#123;&#125;] from brokerAddrTable, because channel destroyed&quot;,                brokerId, brokerAddr);            break;        &#125;    &#125;\t//如果当前主题只包含待移除的broker,则移除该topic    if (brokerData.getBrokerAddrs().isEmpty()) &#123;        removeBrokerName = true;        itBrokerAddrTable.remove();        log.info(&quot;remove brokerName[&#123;&#125;] from brokerAddrTable, because channel destroyed&quot;,            brokerData.getBrokerName());    &#125;&#125;\n\n\n\n//维护clusterAddrTableif (brokerNameFound != null &amp;&amp; removeBrokerName) &#123;    Iterator&lt;Entry&lt;String, Set&lt;String&gt;&gt;&gt; it = this.clusterAddrTable.entrySet().iterator();    //遍历clusterAddrTable    while (it.hasNext()) &#123;        Entry&lt;String, Set&lt;String&gt;&gt; entry = it.next();        //获得集群名称        String clusterName = entry.getKey();        //获得集群中brokerName集合        Set&lt;String&gt; brokerNames = entry.getValue();        //从brokerNames中移除brokerNameFound        boolean removed = brokerNames.remove(brokerNameFound);        if (removed) &#123;            log.info(&quot;remove brokerName[&#123;&#125;], clusterName[&#123;&#125;] from clusterAddrTable, because channel destroyed&quot;,                brokerNameFound, clusterName);            if (brokerNames.isEmpty()) &#123;                log.info(&quot;remove the clusterName[&#123;&#125;] from clusterAddrTable, because channel destroyed and no broker in this cluster&quot;,                    clusterName);                //如果集群中不包含任何broker,则移除该集群                it.remove();            &#125;            break;        &#125;    &#125;&#125;\n\n\n\n//维护topicQueueTable队列if (removeBrokerName) &#123;    //遍历topicQueueTable    Iterator&lt;Entry&lt;String, List&lt;QueueData&gt;&gt;&gt; itTopicQueueTable =        this.topicQueueTable.entrySet().iterator();    while (itTopicQueueTable.hasNext()) &#123;        Entry&lt;String, List&lt;QueueData&gt;&gt; entry = itTopicQueueTable.next();        //主题名称        String topic = entry.getKey();        //队列集合        List&lt;QueueData&gt; queueDataList = entry.getValue();\t\t//遍历该主题队列        Iterator&lt;QueueData&gt; itQueueData = queueDataList.iterator();        while (itQueueData.hasNext()) &#123;            //从队列中移除为活跃broker信息            QueueData queueData = itQueueData.next();            if (queueData.getBrokerName().equals(brokerNameFound)) &#123;                itQueueData.remove();                log.info(&quot;remove topic[&#123;&#125; &#123;&#125;], from topicQueueTable, because channel destroyed&quot;,                    topic, queueData);            &#125;        &#125;\t\t//如果该topic的队列为空,则移除该topic        if (queueDataList.isEmpty()) &#123;            itTopicQueueTable.remove();            log.info(&quot;remove topic[&#123;&#125;] all queue, from topicQueueTable, because channel destroyed&quot;,                topic);        &#125;    &#125;&#125;\n\n\n\n//释放写锁finally &#123;    this.lock.writeLock().unlock();&#125;\n\n\n\n2.2.3.4 路由发现RocketMQ路由发现是非实时的，当Topic路由出现变化后，NameServer不会主动推送给客户端，而是由客户端定时拉取主题最新的路由。\n代码：DefaultRequestProcessor#getRouteInfoByTopic\npublic RemotingCommand getRouteInfoByTopic(ChannelHandlerContext ctx,    RemotingCommand request) throws RemotingCommandException &#123;    final RemotingCommand response = RemotingCommand.createResponseCommand(null);    final GetRouteInfoRequestHeader requestHeader =        (GetRouteInfoRequestHeader) request.decodeCommandCustomHeader(GetRouteInfoRequestHeader.class);\t//调用RouteInfoManager的方法,从路由表topicQueueTable、brokerAddrTable、filterServerTable中分别填充TopicRouteData的List&lt;QueueData&gt;、List&lt;BrokerData&gt;、filterServer    TopicRouteData topicRouteData = this.namesrvController.getRouteInfoManager().pickupTopicRouteData(requestHeader.getTopic());\t//如果找到主题对应你的路由信息并且该主题为顺序消息，则从NameServer KVConfig中获取关于顺序消息相关的配置填充路由信息    if (topicRouteData != null) &#123;        if (this.namesrvController.getNamesrvConfig().isOrderMessageEnable()) &#123;            String orderTopicConf =                this.namesrvController.getKvConfigManager().getKVConfig(NamesrvUtil.NAMESPACE_ORDER_TOPIC_CONFIG,                    requestHeader.getTopic());            topicRouteData.setOrderTopicConf(orderTopicConf);        &#125;        byte[] content = topicRouteData.encode();        response.setBody(content);        response.setCode(ResponseCode.SUCCESS);        response.setRemark(null);        return response;    &#125;    response.setCode(ResponseCode.TOPIC_NOT_EXIST);    response.setRemark(&quot;No topic route info in name server for the topic: &quot; + requestHeader.getTopic()        + FAQUrl.suggestTodo(FAQUrl.APPLY_TOPIC_URL));    return response;&#125;\n\n\n\n2.2.4 小结\n2.3 Producer消息生产者的代码都在client模块中，相对于RocketMQ来讲，消息生产者就是客户端，也是消息的提供者。\n\n###2.3.1 方法和属性\n####1）主要方法介绍\n\n\n//创建主题\nvoid createTopic(final String key, final String newTopic, final int queueNum) throws MQClientException;\n  - ```java  //根据时间戳从队列中查找消息偏移量  long searchOffset(final MessageQueue mq, final long timestamp)\n\n\n\n//查找消息队列中最大的偏移量\nlong maxOffset(final MessageQueue mq) throws MQClientException;\n  - ```java  //查找消息队列中最小的偏移量  long minOffset(final MessageQueue mq) \n\n\n\n//根据偏移量查找消息\nMessageExt viewMessage(final String offsetMsgId) throws RemotingException, MQBrokerException,\n        InterruptedException, MQClientException;\n  - ```java  //根据条件查找消息  QueryResult queryMessage(final String topic, final String key, final int maxNum, final long begin,          final long end) throws MQClientException, InterruptedException;\n\n\n\n//根据消息ID和主题查找消息\nMessageExt viewMessage(String topic,String msgId) throws RemotingException, MQBrokerException, InterruptedException, MQClientException;\n  ![img](https://pchaoo.gitee.io/blog/img/rocketmq/MQProducer.png)- ```java  //启动  void start() throws MQClientException;\n\n\n\n//关闭\nvoid shutdown();\n  - ```java  //查找该主题下所有消息  List&lt;MessageQueue&gt; fetchPublishMessageQueues(final String topic) throws MQClientException;\n\n\n\n//同步发送消息\nSendResult send(final Message msg) throws MQClientException, RemotingException, MQBrokerException,\n        InterruptedException;\n  - ```java  //同步超时发送消息  SendResult send(final Message msg, final long timeout) throws MQClientException,          RemotingException, MQBrokerException, InterruptedException;\n\n\n\n//异步发送消息\nvoid send(final Message msg, final SendCallback sendCallback) throws MQClientException,\n        RemotingException, InterruptedException;\n  - ```java  //异步超时发送消息  void send(final Message msg, final SendCallback sendCallback, final long timeout)      throws MQClientException, RemotingException, InterruptedException;\n\n\n\n//发送单向消息\nvoid sendOneway(final Message msg) throws MQClientException, RemotingException,\n    InterruptedException;\n  - ```java  //选择指定队列同步发送消息  SendResult send(final Message msg, final MessageQueue mq) throws MQClientException,      RemotingException, MQBrokerException, InterruptedException;\n\n\n\n//选择指定队列异步发送消息\nvoid send(final Message msg, final MessageQueue mq, final SendCallback sendCallback)\n    throws MQClientException, RemotingException, InterruptedException;\n  - ```java  //选择指定队列单项发送消息  void sendOneway(final Message msg, final MessageQueue mq) throws MQClientException,      RemotingException, InterruptedException;\n\n\n\n&#96;&#96;&#96;java&#x2F;&#x2F;批量发送消息SendResult send(final Collection msgs) throws MQClientException, RemotingException, MQBrokerException,InterruptedException;\n  \\####2）属性介绍![img](https://pchaoo.gitee.io/blog/img/rocketmq/DefaultMQProducer%E5%B1%9E%E6%80%A7.png)```javaproducerGroup：生产者所属组createTopicKey：默认TopicdefaultTopicQueueNums：默认主题在每一个Broker队列数量sendMsgTimeout：发送消息默认超时时间，默认3scompressMsgBodyOverHowmuch：消息体超过该值则启用压缩，默认4kretryTimesWhenSendFailed：同步方式发送消息重试次数，默认为2，总共执行3次retryTimesWhenSendAsyncFailed：异步方法发送消息重试次数，默认为2retryAnotherBrokerWhenNotStoreOK：消息重试时选择另外一个Broker时，是否不等待存储结果就返回，默认为falsemaxMessageSize：允许发送的最大消息长度，默认为4M\n\n2.3.2 启动流程\n代码：DefaultMQProducerImpl#start\n//检查生产者组是否满足要求this.checkConfig();//更改当前instanceName为进程IDif (!this.defaultMQProducer.getProducerGroup().equals(MixAll.CLIENT_INNER_PRODUCER_GROUP)) &#123;    this.defaultMQProducer.changeInstanceNameToPID();&#125;//获得MQ客户端实例this.mQClientFactory = MQClientManager.getInstance().getAndCreateMQClientInstance(this.defaultMQProducer, rpcHook);\n\n\n\n\n整个JVM中只存在一个MQClientManager实例，维护一个MQClientInstance缓存表\nConcurrentMap&lt;String&#x2F;* clientId *&#x2F;, MQClientInstance&gt; factoryTable &#x3D; new ConcurrentHashMap&lt;String,MQClientInstance&gt;();\n同一个clientId只会创建一个MQClientInstance。\nMQClientInstance封装了RocketMQ网络处理API，是消息生产者和消息消费者与NameServer、Broker打交道的网络通道\n\n代码：MQClientManager#getAndCreateMQClientInstance\npublic MQClientInstance getAndCreateMQClientInstance(final ClientConfig clientConfig,                                                      RPCHook rpcHook) &#123;    //构建客户端ID    String clientId = clientConfig.buildMQClientId();    //根据客户端ID或者客户端实例    MQClientInstance instance = this.factoryTable.get(clientId);    //实例如果为空就创建新的实例,并添加到实例表中    if (null == instance) &#123;        instance =            new MQClientInstance(clientConfig.cloneClientConfig(),                this.factoryIndexGenerator.getAndIncrement(), clientId, rpcHook);        MQClientInstance prev = this.factoryTable.putIfAbsent(clientId, instance);        if (prev != null) &#123;            instance = prev;            log.warn(&quot;Returned Previous MQClientInstance for clientId:[&#123;&#125;]&quot;, clientId);        &#125; else &#123;            log.info(&quot;Created new MQClientInstance for clientId:[&#123;&#125;]&quot;, clientId);        &#125;    &#125;    return instance;&#125;\n\n\n\n代码：DefaultMQProducerImpl#start\n//注册当前生产者到到MQClientInstance管理中,方便后续调用网路请求boolean registerOK = mQClientFactory.registerProducer(this.defaultMQProducer.getProducerGroup(), this);if (!registerOK) &#123;    this.serviceState = ServiceState.CREATE_JUST;    throw new MQClientException(&quot;The producer group[&quot; + this.defaultMQProducer.getProducerGroup()        + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),        null);&#125;//启动生产者if (startFactory) &#123;    mQClientFactory.start();&#125;\n\n\n\n2.3.3 消息发送\n代码：DefaultMQProducerImpl#send(Message msg)\n//发送消息public SendResult send(Message msg) &#123;    return send(msg, this.defaultMQProducer.getSendMsgTimeout());&#125;\n\n\n\n代码：DefaultMQProducerImpl#send(Message msg,long timeout)\n//发送消息,默认超时时间为3spublic SendResult send(Message msg,long timeout)&#123;    return this.sendDefaultImpl(msg, CommunicationMode.SYNC, null, timeout);&#125;\n\n\n\n代码：DefaultMQProducerImpl#sendDefaultImpl\n//校验消息Validators.checkMessage(msg, this.defaultMQProducer);\n\n\n\n####1）验证消息\n代码：Validators#checkMessage\npublic static void checkMessage(Message msg, DefaultMQProducer defaultMQProducer)    throws MQClientException &#123;    //判断是否为空    if (null == msg) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message is null&quot;);    &#125;    // 校验主题    Validators.checkTopic(msg.getTopic());\t\t    // 校验消息体    if (null == msg.getBody()) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body is null&quot;);    &#125;    if (0 == msg.getBody().length) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body length is zero&quot;);    &#125;    if (msg.getBody().length &gt; defaultMQProducer.getMaxMessageSize()) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL,            &quot;the message body size over max value, MAX: &quot; + defaultMQProducer.getMaxMessageSize());    &#125;&#125;\n\n\n\n####2）查找路由\n代码：DefaultMQProducerImpl#tryToFindTopicPublishInfo\nprivate TopicPublishInfo tryToFindTopicPublishInfo(final String topic) &#123;    //从缓存中获得主题的路由信息    TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic);    //路由信息为空,则从NameServer获取路由    if (null == topicPublishInfo || !topicPublishInfo.ok()) &#123;        this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo());        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic);        topicPublishInfo = this.topicPublishInfoTable.get(topic);    &#125;    if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) &#123;        return topicPublishInfo;    &#125; else &#123;        //如果未找到当前主题的路由信息,则用默认主题继续查找        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer);        topicPublishInfo = this.topicPublishInfoTable.get(topic);        return topicPublishInfo;    &#125;&#125;\n\n\n\n\n代码：TopicPublishInfo\npublic class TopicPublishInfo &#123;    private boolean orderTopic = false;\t//是否是顺序消息    private boolean haveTopicRouterInfo = false;     private List&lt;MessageQueue&gt; messageQueueList = new ArrayList&lt;MessageQueue&gt;();\t//该主题消息队列    private volatile ThreadLocalIndex sendWhichQueue = new ThreadLocalIndex();//每选择一次消息队列,该值+1    private TopicRouteData topicRouteData;//关联Topic路由元信息&#125;\n\n\n\n代码：MQClientInstance#updateTopicRouteInfoFromNameServer\nTopicRouteData topicRouteData;//使用默认主题从NameServer获取路由信息if (isDefault &amp;&amp; defaultMQProducer != null) &#123;    topicRouteData = this.mQClientAPIImpl.getDefaultTopicRouteInfoFromNameServer(defaultMQProducer.getCreateTopicKey(),        1000 * 3);    if (topicRouteData != null) &#123;        for (QueueData data : topicRouteData.getQueueDatas()) &#123;            int queueNums = Math.min(defaultMQProducer.getDefaultTopicQueueNums(), data.getReadQueueNums());            data.setReadQueueNums(queueNums);            data.setWriteQueueNums(queueNums);        &#125;    &#125;&#125; else &#123;    //使用指定主题从NameServer获取路由信息    topicRouteData = this.mQClientAPIImpl.getTopicRouteInfoFromNameServer(topic, 1000 * 3);&#125;\n\n\n\n代码：MQClientInstance#updateTopicRouteInfoFromNameServer\n//判断路由是否需要更改TopicRouteData old = this.topicRouteTable.get(topic);boolean changed = topicRouteDataIsChange(old, topicRouteData);if (!changed) &#123;    changed = this.isNeedUpdateTopicRouteInfo(topic);&#125; else &#123;    log.info(&quot;the topic[&#123;&#125;] route info changed, old[&#123;&#125;] ,new[&#123;&#125;]&quot;, topic, old, topicRouteData);&#125;\n\n\n\n代码：MQClientInstance#updateTopicRouteInfoFromNameServer\nif (changed) &#123;    //将topicRouteData转换为发布队列    TopicPublishInfo publishInfo = topicRouteData2TopicPublishInfo(topic, topicRouteData);    publishInfo.setHaveTopicRouterInfo(true);    //遍历生产    Iterator&lt;Entry&lt;String, MQProducerInner&gt;&gt; it = this.producerTable.entrySet().iterator();    while (it.hasNext()) &#123;        Entry&lt;String, MQProducerInner&gt; entry = it.next();        MQProducerInner impl = entry.getValue();        if (impl != null) &#123;            //生产者不为空时,更新publishInfo信息            impl.updateTopicPublishInfo(topic, publishInfo);        &#125;    &#125;&#125;\n\n\n\n代码：MQClientInstance#topicRouteData2TopicPublishInfo\npublic static TopicPublishInfo topicRouteData2TopicPublishInfo(final String topic, final TopicRouteData route) &#123;    \t//创建TopicPublishInfo对象        TopicPublishInfo info = new TopicPublishInfo();    \t//关联topicRoute        info.setTopicRouteData(route);    \t//顺序消息,更新TopicPublishInfo        if (route.getOrderTopicConf() != null &amp;&amp; route.getOrderTopicConf().length() &gt; 0) &#123;            String[] brokers = route.getOrderTopicConf().split(&quot;;&quot;);            for (String broker : brokers) &#123;                String[] item = broker.split(&quot;:&quot;);                int nums = Integer.parseInt(item[1]);                for (int i = 0; i &lt; nums; i++) &#123;                    MessageQueue mq = new MessageQueue(topic, item[0], i);                    info.getMessageQueueList().add(mq);                &#125;            &#125;            info.setOrderTopic(true);        &#125; else &#123;            //非顺序消息更新TopicPublishInfo            List&lt;QueueData&gt; qds = route.getQueueDatas();            Collections.sort(qds);            //遍历topic队列信息            for (QueueData qd : qds) &#123;                //是否是写队列                if (PermName.isWriteable(qd.getPerm())) &#123;                    BrokerData brokerData = null;                    //遍历写队列Broker                    for (BrokerData bd : route.getBrokerDatas()) &#123;                        //根据名称获得读队列对应的Broker                        if (bd.getBrokerName().equals(qd.getBrokerName())) &#123;                        brokerData = bd;                        break;                    &#125;                &#125;                if (null == brokerData) &#123;                    continue;                &#125;                if (!brokerData.getBrokerAddrs().containsKey(MixAll.MASTER_ID)) &#123;                    continue;                &#125;\t\t\t\t//封装TopicPublishInfo写队列                for (int i = 0; i &lt; qd.getWriteQueueNums(); i++) &#123;                    MessageQueue mq = new MessageQueue(topic, qd.getBrokerName(), i);                    info.getMessageQueueList().add(mq);                &#125;            &#125;        &#125;        info.setOrderTopic(false);    &#125;\t//返回TopicPublishInfo对象    return info;&#125;\n\n\n\n3）选择队列\n默认不启用Broker故障延迟机制\n\n代码：TopicPublishInfo#selectOneMessageQueue(lastBrokerName)\npublic MessageQueue selectOneMessageQueue(final String lastBrokerName) &#123;    //第一次选择队列    if (lastBrokerName == null) &#123;        return selectOneMessageQueue();    &#125; else &#123;        //sendWhichQueue        int index = this.sendWhichQueue.getAndIncrement();        //遍历消息队列集合        for (int i = 0; i &lt; this.messageQueueList.size(); i++) &#123;            //sendWhichQueue自增后取模            int pos = Math.abs(index++) % this.messageQueueList.size();            if (pos &lt; 0)                pos = 0;            //规避上次Broker队列            MessageQueue mq = this.messageQueueList.get(pos);            if (!mq.getBrokerName().equals(lastBrokerName)) &#123;                return mq;            &#125;        &#125;        //如果以上情况都不满足,返回sendWhichQueue取模后的队列        return selectOneMessageQueue();    &#125;&#125;\n\n\n\n代码：TopicPublishInfo#selectOneMessageQueue()\n//第一次选择队列public MessageQueue selectOneMessageQueue() &#123;    //sendWhichQueue自增    int index = this.sendWhichQueue.getAndIncrement();    //对队列大小取模    int pos = Math.abs(index) % this.messageQueueList.size();    if (pos &lt; 0)        pos = 0;    //返回对应的队列    return this.messageQueueList.get(pos);&#125;\n\n\n\n\n启用Broker故障延迟机制\n\npublic MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123;    //Broker故障延迟机制    if (this.sendLatencyFaultEnable) &#123;        try &#123;            //对sendWhichQueue自增            int index = tpInfo.getSendWhichQueue().getAndIncrement();            //对消息队列轮询获取一个队列            for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123;                int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size();                if (pos &lt; 0)                    pos = 0;                MessageQueue mq = tpInfo.getMessageQueueList().get(pos);                //验证该队列是否可用                if (latencyFaultTolerance.isAvailable(mq.getBrokerName())) &#123;                    //可用                    if (null == lastBrokerName || mq.getBrokerName().equals(lastBrokerName))                        return mq;                &#125;            &#125;\t\t\t//从规避的Broker中选择一个可用的Broker            final String notBestBroker = latencyFaultTolerance.pickOneAtLeast();            //获得Broker的写队列集合            int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker);            if (writeQueueNums &gt; 0) &#123;                //获得一个队列,指定broker和队列ID并返回                final MessageQueue mq = tpInfo.selectOneMessageQueue();                if (notBestBroker != null) &#123;                    mq.setBrokerName(notBestBroker);                    mq.setQueueId(tpInfo.getSendWhichQueue().getAndIncrement() % writeQueueNums);                &#125;                return mq;            &#125; else &#123;                latencyFaultTolerance.remove(notBestBroker);            &#125;        &#125; catch (Exception e) &#123;            log.error(&quot;Error occurred when selecting message queue&quot;, e);        &#125;        return tpInfo.selectOneMessageQueue();    &#125;    return tpInfo.selectOneMessageQueue(lastBrokerName);&#125;\n\n\n\n\n\n延迟机制接口规范\n\npublic interface LatencyFaultTolerance&lt;T&gt; &#123;    //更新失败条目    void updateFaultItem(final T name, final long currentLatency, final long notAvailableDuration);\t//判断Broker是否可用    boolean isAvailable(final T name);\t//移除Fault条目    void remove(final T name);\t//尝试从规避的Broker中选择一个可用的Broker    T pickOneAtLeast();&#125;\n\n\n\n\nFaultItem：失败条目\n\nclass FaultItem implements Comparable&lt;FaultItem&gt; &#123;    //条目唯一键,这里为brokerName    private final String name;    //本次消息发送延迟    private volatile long currentLatency;    //故障规避开始时间    private volatile long startTimestamp;&#125;\n\n\n\n\n消息失败策略\n\npublic class MQFaultStrategy &#123;   //根据currentLatency本地消息发送延迟,从latencyMax尾部向前找到第一个比currentLatency小的索引,如果没有找到,返回0\tprivate long[] latencyMax = &#123;50L, 100L, 550L, 1000L, 2000L, 3000L, 15000L&#125;;    //根据这个索引从notAvailableDuration取出对应的时间,在该时长内,Broker设置为不可用\tprivate long[] notAvailableDuration = &#123;0L, 0L, 30000L, 60000L, 120000L, 180000L, 600000L&#125;;&#125;\n\n\n\n原理分析\n代码：DefaultMQProducerImpl#sendDefaultImpl\nsendResult = this.sendKernelImpl(msg,                                  mq,                                  communicationMode,                                  sendCallback,                                  topicPublishInfo,                                  timeout - costTime);endTimestamp = System.currentTimeMillis();this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false);\n\n\n\n如果上述发送过程出现异常，则调用DefaultMQProducerImpl#updateFaultItem\npublic void updateFaultItem(final String brokerName, final long currentLatency, boolean isolation) &#123;    //参数一：broker名称    //参数二:本次消息发送延迟时间    //参数三:是否隔离    this.mqFaultStrategy.updateFaultItem(brokerName, currentLatency, isolation);&#125;\n\n\n\n代码：MQFaultStrategy#updateFaultItem\npublic void updateFaultItem(final String brokerName, final long currentLatency, boolean isolation) &#123;    if (this.sendLatencyFaultEnable) &#123;        //计算broker规避的时长        long duration = computeNotAvailableDuration(isolation ? 30000 : currentLatency);        //更新该FaultItem规避时长        this.latencyFaultTolerance.updateFaultItem(brokerName, currentLatency, duration);    &#125;&#125;\n\n\n\n代码：MQFaultStrategy#computeNotAvailableDuration\nprivate long computeNotAvailableDuration(final long currentLatency) &#123;    //遍历latencyMax    for (int i = latencyMax.length - 1; i &gt;= 0; i--) &#123;        //找到第一个比currentLatency的latencyMax值        if (currentLatency &gt;= latencyMax[i])            return this.notAvailableDuration[i];    &#125;    //没有找到则返回0    return 0;&#125;\n\n\n\n代码：LatencyFaultToleranceImpl#updateFaultItem\npublic void updateFaultItem(final String name, final long currentLatency, final long notAvailableDuration) &#123;    //获得原FaultItem    FaultItem old = this.faultItemTable.get(name);    //为空新建faultItem对象,设置规避时长和开始时间    if (null == old) &#123;        final FaultItem faultItem = new FaultItem(name);        faultItem.setCurrentLatency(currentLatency);        faultItem.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);        old = this.faultItemTable.putIfAbsent(name, faultItem);        if (old != null) &#123;            old.setCurrentLatency(currentLatency);            old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);        &#125;    &#125; else &#123;        //更新规避时长和开始时间        old.setCurrentLatency(currentLatency);        old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);    &#125;&#125;\n\n\n\n####4）发送消息\n消息发送API核心入口DefaultMQProducerImpl#sendKernelImpl\nprivate SendResult sendKernelImpl(    final Message msg,\t//待发送消息    final MessageQueue mq,\t//消息发送队列    final CommunicationMode communicationMode,\t\t//消息发送内模式    final SendCallback sendCallback,\tpp\t//异步消息回调函数    final TopicPublishInfo topicPublishInfo,\t//主题路由信息    final long timeout\t//超时时间    )\n\n\n\n代码：DefaultMQProducerImpl#sendKernelImpl\n//获得broker网络地址信息String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName());if (null == brokerAddr) &#123;    //没有找到从NameServer更新broker网络地址信息    tryToFindTopicPublishInfo(mq.getTopic());    brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName());&#125;\n\n\n\n//为消息分类唯一IDif (!(msg instanceof MessageBatch)) &#123;    MessageClientIDSetter.setUniqID(msg);&#125;boolean topicWithNamespace = false;if (null != this.mQClientFactory.getClientConfig().getNamespace()) &#123;    msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace());    topicWithNamespace = true;&#125;//消息大小超过4K,启用消息压缩int sysFlag = 0;boolean msgBodyCompressed = false;if (this.tryToCompressMessage(msg)) &#123;    sysFlag |= MessageSysFlag.COMPRESSED_FLAG;    msgBodyCompressed = true;&#125;//如果是事务消息,设置消息标记MessageSysFlag.TRANSACTION_PREPARED_TYPEfinal String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);if (tranMsg != null &amp;&amp; Boolean.parseBoolean(tranMsg)) &#123;    sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE;&#125;\n\n\n\n//如果注册了消息发送钩子函数,在执行消息发送前的增强逻辑if (this.hasSendMessageHook()) &#123;    context = new SendMessageContext();    context.setProducer(this);    context.setProducerGroup(this.defaultMQProducer.getProducerGroup());    context.setCommunicationMode(communicationMode);    context.setBornHost(this.defaultMQProducer.getClientIP());    context.setBrokerAddr(brokerAddr);    context.setMessage(msg);    context.setMq(mq);    context.setNamespace(this.defaultMQProducer.getNamespace());    String isTrans = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);    if (isTrans != null &amp;&amp; isTrans.equals(&quot;true&quot;)) &#123;        context.setMsgType(MessageType.Trans_Msg_Half);    &#125;    if (msg.getProperty(&quot;__STARTDELIVERTIME&quot;) != null || msg.getProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL) != null) &#123;        context.setMsgType(MessageType.Delay_Msg);    &#125;    this.executeSendMessageHookBefore(context);&#125;\n\n\n\n代码：SendMessageHook\npublic interface SendMessageHook &#123;    String hookName();    void sendMessageBefore(final SendMessageContext context);    void sendMessageAfter(final SendMessageContext context);&#125;\n\n\n\n代码：DefaultMQProducerImpl#sendKernelImpl\n//构建消息发送请求包SendMessageRequestHeader requestHeader = new SendMessageRequestHeader();//生产者组requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup());//主题requestHeader.setTopic(msg.getTopic());//默认创建主题KeyrequestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey());//该主题在单个Broker默认队列树requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums());//队列IDrequestHeader.setQueueId(mq.getQueueId());//消息系统标记requestHeader.setSysFlag(sysFlag);//消息发送时间requestHeader.setBornTimestamp(System.currentTimeMillis());//消息标记requestHeader.setFlag(msg.getFlag());//消息扩展信息requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties()));//消息重试次数requestHeader.setReconsumeTimes(0);requestHeader.setUnitMode(this.isUnitMode());//是否是批量消息等requestHeader.setBatch(msg instanceof MessageBatch);if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123;    String reconsumeTimes = MessageAccessor.getReconsumeTime(msg);    if (reconsumeTimes != null) &#123;        requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes));        MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME);    &#125;    String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg);    if (maxReconsumeTimes != null) &#123;        requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes));        MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES);    &#125;&#125;\n\n\n\ncase ASYNC:\t\t//异步发送    Message tmpMessage = msg;    boolean messageCloned = false;    if (msgBodyCompressed) &#123;        //If msg body was compressed, msgbody should be reset using prevBody.        //Clone new message using commpressed message body and recover origin massage.        //Fix bug:https://github.com/apache/rocketmq-externals/issues/66        tmpMessage = MessageAccessor.cloneMessage(msg);        messageCloned = true;        msg.setBody(prevBody);    &#125;    if (topicWithNamespace) &#123;        if (!messageCloned) &#123;            tmpMessage = MessageAccessor.cloneMessage(msg);            messageCloned = true;        &#125;        msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(),                                                     this.defaultMQProducer.getNamespace()));    &#125;\t\tlong costTimeAsync = System.currentTimeMillis() - beginStartTime;\t\tif (timeout &lt; costTimeAsync) &#123;\t\t    throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;);\t\t&#125;\t\tsendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(        \t\t\tbrokerAddr,        \t\t\tmq.getBrokerName(),        \t\t\ttmpMessage,        \t\t\trequestHeader,        \t\t\ttimeout - costTimeAsync,        \t\t\tcommunicationMode,        \t\t\tsendCallback,        \t\t\ttopicPublishInfo,        \t\t\tthis.mQClientFactory,        \t\t\tthis.defaultMQProducer.getRetryTimesWhenSendAsyncFailed(),        \t\t\tcontext,        \t\t\tthis);    \tbreak;case ONEWAY:case SYNC:\t\t//同步发送    long costTimeSync = System.currentTimeMillis() - beginStartTime;        if (timeout &lt; costTimeSync) &#123;            throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;);        &#125;        sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(            brokerAddr,            mq.getBrokerName(),            msg,            requestHeader,            timeout - costTimeSync,            communicationMode,            context,            this);        break;    default:        assert false;        break;&#125;\n\n\n\n\n//如果注册了钩子函数,则发送完毕后执行钩子函数if (this.hasSendMessageHook()) &#123;    context.setSendResult(sendResult);    this.executeSendMessageHookAfter(context);&#125;\n\n\n\n2.3.4 批量消息发送\n批量消息发送是将同一个主题的多条消息一起打包发送到消息服务端，减少网络调用次数，提高网络传输效率。当然，并不是在同一批次中发送的消息数量越多越好，其判断依据是单条消息的长度，如果单条消息内容比较长，则打包多条消息发送会影响其他线程发送消息的响应时间，并且单批次消息总长度不能超过DefaultMQProducer#maxMessageSize。\n批量消息发送要解决的问题是如何将这些消息编码以便服务端能够正确解码出每条消息的消息内容。\n代码：DefaultMQProducer#send\npublic SendResult send(Collection&lt;Message&gt; msgs)     throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123;    //压缩消息集合成一条消息,然后发送出去    return this.defaultMQProducerImpl.send(batch(msgs));&#125;\n\n\n\n代码：DefaultMQProducer#batch\nprivate MessageBatch batch(Collection&lt;Message&gt; msgs) throws MQClientException &#123;    MessageBatch msgBatch;    try &#123;        //将集合消息封装到MessageBatch        msgBatch = MessageBatch.generateFromList(msgs);        //遍历消息集合,检查消息合法性,设置消息ID,设置Topic        for (Message message : msgBatch) &#123;            Validators.checkMessage(message, this);            MessageClientIDSetter.setUniqID(message);            message.setTopic(withNamespace(message.getTopic()));        &#125;        //压缩消息,设置消息body        msgBatch.setBody(msgBatch.encode());    &#125; catch (Exception e) &#123;        throw new MQClientException(&quot;Failed to initiate the MessageBatch&quot;, e);    &#125;    //设置msgBatch的topic    msgBatch.setTopic(withNamespace(msgBatch.getTopic()));    return msgBatch;&#125;\n\n\n\n2.4 消息存储###2.4.1 消息存储核心类\n\nprivate final MessageStoreConfig messageStoreConfig;\t//消息配置属性private final CommitLog commitLog;\t\t//CommitLog文件存储的实现类private final ConcurrentMap&lt;String/* topic */, ConcurrentMap&lt;Integer/* queueId */, ConsumeQueue&gt;&gt; consumeQueueTable;\t//消息队列存储缓存表,按照消息主题分组private final FlushConsumeQueueService flushConsumeQueueService;\t//消息队列文件刷盘线程private final CleanCommitLogService cleanCommitLogService;\t//清除CommitLog文件服务private final CleanConsumeQueueService cleanConsumeQueueService;\t//清除ConsumerQueue队列文件服务private final IndexService indexService;\t//索引实现类private final AllocateMappedFileService allocateMappedFileService;\t//MappedFile分配服务private final ReputMessageService reputMessageService;//CommitLog消息分发,根据CommitLog文件构建ConsumerQueue、IndexFile文件private final HAService haService;\t//存储HA机制private final ScheduleMessageService scheduleMessageService;\t//消息服务调度线程private final StoreStatsService storeStatsService;\t//消息存储服务private final TransientStorePool transientStorePool;\t//消息堆外内存缓存private final BrokerStatsManager brokerStatsManager;\t//Broker状态管理器private final MessageArrivingListener messageArrivingListener;\t//消息拉取长轮询模式消息达到监听器private final BrokerConfig brokerConfig;\t//Broker配置类private StoreCheckpoint storeCheckpoint;\t//文件刷盘监测点private final LinkedList&lt;CommitLogDispatcher&gt; dispatcherList;\t//CommitLog文件转发请求\n\n\n\n2.4.2 消息存储流程\n消息存储入口：DefaultMessageStore#putMessage\n//判断Broker角色如果是从节点,则无需写入if (BrokerRole.SLAVE == this.messageStoreConfig.getBrokerRole()) &#123;        long value = this.printTimes.getAndIncrement();        if ((value % 50000) == 0) &#123;            log.warn(&quot;message store is slave mode, so putMessage is forbidden &quot;);        &#125;    return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);&#125;//判断当前写入状态如果是正在写入,则不能继续if (!this.runningFlags.isWriteable()) &#123;        long value = this.printTimes.getAndIncrement();    \treturn new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);&#125; else &#123;    this.printTimes.set(0);&#125;//判断消息主题长度是否超过最大限制if (msg.getTopic().length() &gt; Byte.MAX_VALUE) &#123;    log.warn(&quot;putMessage message topic length too long &quot; + msg.getTopic().length());    return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null);&#125;//判断消息属性长度是否超过限制if (msg.getPropertiesString() != null &amp;&amp; msg.getPropertiesString().length() &gt; Short.MAX_VALUE) &#123;    log.warn(&quot;putMessage message properties length too long &quot; + msg.getPropertiesString().length());    return new PutMessageResult(PutMessageStatus.PROPERTIES_SIZE_EXCEEDED, null);&#125;//判断系统PageCache缓存去是否占用if (this.isOSPageCacheBusy()) &#123;    return new PutMessageResult(PutMessageStatus.OS_PAGECACHE_BUSY, null);&#125;//将消息写入CommitLog文件PutMessageResult result = this.commitLog.putMessage(msg);\n\n\n\n代码：CommitLog#putMessage\n//记录消息存储时间msg.setStoreTimestamp(beginLockTimestamp);//判断如果mappedFile如果为空或者已满,创建新的mappedFile文件if (null == mappedFile || mappedFile.isFull()) &#123;    mappedFile = this.mappedFileQueue.getLastMappedFile(0); &#125;//如果创建失败,直接返回if (null == mappedFile) &#123;    log.error(&quot;create mapped file1 error, topic: &quot; + msg.getTopic() + &quot; clientAddr: &quot; + msg.getBornHostString());    beginTimeInLock = 0;    return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null);&#125;//写入消息到mappedFile中result = mappedFile.appendMessage(msg, this.appendMessageCallback);\n\n\n\n代码：MappedFile#appendMessagesInner\n//获得文件的写入指针int currentPos = this.wrotePosition.get();//如果指针大于文件大小则直接返回if (currentPos &lt; this.fileSize) &#123;    //通过writeBuffer.slice()创建一个与MappedFile共享的内存区,并设置position为当前指针    ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice();    byteBuffer.position(currentPos);    AppendMessageResult result = null;    if (messageExt instanceof MessageExtBrokerInner) &#123;       \t//通过回调方法写入        result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBrokerInner) messageExt);    &#125; else if (messageExt instanceof MessageExtBatch) &#123;        result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBatch) messageExt);    &#125; else &#123;        return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR);    &#125;    this.wrotePosition.addAndGet(result.getWroteBytes());    this.storeTimestamp = result.getStoreTimestamp();    return result;&#125;\n\n\n\n代码：CommitLog#doAppend\n//文件写入位置long wroteOffset = fileFromOffset + byteBuffer.position();//设置消息IDthis.resetByteBuffer(hostHolder, 8);String msgId = MessageDecoder.createMessageId(this.msgIdMemory, msgInner.getStoreHostBytes(hostHolder), wroteOffset);//获得该消息在消息队列中的偏移量keyBuilder.setLength(0);keyBuilder.append(msgInner.getTopic());keyBuilder.append(&#x27;-&#x27;);keyBuilder.append(msgInner.getQueueId());String key = keyBuilder.toString();Long queueOffset = CommitLog.this.topicQueueTable.get(key);if (null == queueOffset) &#123;    queueOffset = 0L;    CommitLog.this.topicQueueTable.put(key, queueOffset);&#125;//获得消息属性长度final byte[] propertiesData =msgInner.getPropertiesString() == null ? null : msgInner.getPropertiesString().getBytes(MessageDecoder.CHARSET_UTF8);final int propertiesLength = propertiesData == null ? 0 : propertiesData.length;if (propertiesLength &gt; Short.MAX_VALUE) &#123;    log.warn(&quot;putMessage message properties length too long. length=&#123;&#125;&quot;, propertiesData.length);    return new AppendMessageResult(AppendMessageStatus.PROPERTIES_SIZE_EXCEEDED);&#125;//获得消息主题大小final byte[] topicData = msgInner.getTopic().getBytes(MessageDecoder.CHARSET_UTF8);final int topicLength = topicData.length;//获得消息体大小final int bodyLength = msgInner.getBody() == null ? 0 : msgInner.getBody().length;//计算消息总长度final int msgLen = calMsgLength(bodyLength, topicLength, propertiesLength);\n\n\n\n代码：CommitLog#calMsgLength\nprotected static int calMsgLength(int bodyLength, int topicLength, int propertiesLength) &#123;    final int msgLen = 4 //TOTALSIZE        + 4 //MAGICCODE          + 4 //BODYCRC        + 4 //QUEUEID        + 4 //FLAG        + 8 //QUEUEOFFSET        + 8 //PHYSICALOFFSET        + 4 //SYSFLAG        + 8 //BORNTIMESTAMP        + 8 //BORNHOST        + 8 //STORETIMESTAMP        + 8 //STOREHOSTADDRESS        + 4 //RECONSUMETIMES        + 8 //Prepared Transaction Offset        + 4 + (bodyLength &gt; 0 ? bodyLength : 0) //BODY        + 1 + topicLength //TOPIC        + 2 + (propertiesLength &gt; 0 ? propertiesLength : 0) //propertiesLength        + 0;    return msgLen;&#125;\n\n\n\n代码：CommitLog#doAppend\n//消息长度不能超过4Mif (msgLen &gt; this.maxMessageSize) &#123;    CommitLog.log.warn(&quot;message size exceeded, msg total size: &quot; + msgLen + &quot;, msg body size: &quot; + bodyLength        + &quot;, maxMessageSize: &quot; + this.maxMessageSize);    return new AppendMessageResult(AppendMessageStatus.MESSAGE_SIZE_EXCEEDED);&#125;//消息是如果没有足够的存储空间则新创建CommitLog文件if ((msgLen + END_FILE_MIN_BLANK_LENGTH) &gt; maxBlank) &#123;    this.resetByteBuffer(this.msgStoreItemMemory, maxBlank);    // 1 TOTALSIZE    this.msgStoreItemMemory.putInt(maxBlank);    // 2 MAGICCODE    this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE);    // 3 The remaining space may be any value    // Here the length of the specially set maxBlank    final long beginTimeMills = CommitLog.this.defaultMessageStore.now();    byteBuffer.put(this.msgStoreItemMemory.array(), 0, maxBlank);    return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset, maxBlank, msgId, msgInner.getStoreTimestamp(),        queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills);&#125;//将消息存储到ByteBuffer中,返回AppendMessageResultfinal long beginTimeMills = CommitLog.this.defaultMessageStore.now();// Write messages to the queue bufferbyteBuffer.put(this.msgStoreItemMemory.array(), 0, msgLen);AppendMessageResult result = new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset,                                                      msgLen, msgId,msgInner.getStoreTimestamp(),                                                      queueOffset,                                                      CommitLog.this.defaultMessageStore.now()                                                      -beginTimeMills);switch (tranType) &#123;    case MessageSysFlag.TRANSACTION_PREPARED_TYPE:    case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:        break;    case MessageSysFlag.TRANSACTION_NOT_TYPE:    case MessageSysFlag.TRANSACTION_COMMIT_TYPE:        //更新消息队列偏移量        CommitLog.this.topicQueueTable.put(key, ++queueOffset);        break;    default:        break;&#125;\n\n\n\n代码：CommitLog#putMessage\n//释放锁putMessageLock.unlock();//刷盘handleDiskFlush(result, putMessageResult, msg);//执行HA主从同步handleHA(result, putMessageResult, msg);\n\n\n\n2.4.3 存储文件\n\ncommitLog：消息存储目录\nconfig：运行期间一些配置信息\nconsumerqueue：消息消费队列存储目录\nindex：消息索引文件存储目录\nabort：如果存在改文件寿命Broker非正常关闭\ncheckpoint：文件检查点，存储CommitLog文件最后一次刷盘时间戳、consumerquueue最后一次刷盘时间，index索引文件最后一次刷盘时间戳。\n\n2.4.4 存储文件内存映射RocketMQ通过使用内存映射文件提高IO访问性能，无论是CommitLog、ConsumerQueue还是IndexFile，单个文件都被设计为固定长度，如果一个文件写满以后再创建一个新文件，文件名就为该文件第一条消息对应的全局物理偏移量。\n####1）MappedFileQueue\n\nString storePath;\t//存储目录int mappedFileSize;\t// 单个文件大小CopyOnWriteArrayList&lt;MappedFile&gt; mappedFiles;\t//MappedFile文件集合AllocateMappedFileService allocateMappedFileService;\t//创建MapFile服务类long flushedWhere = 0;\t\t//当前刷盘指针long committedWhere = 0;\t//当前数据提交指针,内存中ByteBuffer当前的写指针,该值大于等于flushWhere\n\n\n\n\n根据存储时间查询MappedFile\n\npublic MappedFile getMappedFileByTime(final long timestamp) &#123;    Object[] mfs = this.copyMappedFiles(0);\t    if (null == mfs)        return null;\t//遍历MappedFile文件数组    for (int i = 0; i &lt; mfs.length; i++) &#123;        MappedFile mappedFile = (MappedFile) mfs[i];        //MappedFile文件的最后修改时间大于指定时间戳则返回该文件        if (mappedFile.getLastModifiedTimestamp() &gt;= timestamp) &#123;            return mappedFile;        &#125;    &#125;    return (MappedFile) mfs[mfs.length - 1];&#125;\n\n\n\n\n根据消息偏移量offset查找MappedFile\n\npublic MappedFile findMappedFileByOffset(final long offset, final boolean returnFirstOnNotFound) &#123;    try &#123;        //获得第一个MappedFile文件        MappedFile firstMappedFile = this.getFirstMappedFile();        //获得最后一个MappedFile文件        MappedFile lastMappedFile = this.getLastMappedFile();        //第一个文件和最后一个文件均不为空,则进行处理        if (firstMappedFile != null &amp;&amp; lastMappedFile != null) &#123;            if (offset &lt; firstMappedFile.getFileFromOffset() ||                 offset &gt;= lastMappedFile.getFileFromOffset() + this.mappedFileSize) &#123;            &#125; else &#123;                //获得文件索引                int index = (int) ((offset / this.mappedFileSize)                                    - (firstMappedFile.getFileFromOffset() / this.mappedFileSize));                MappedFile targetFile = null;                try &#123;                    //根据索引返回目标文件                    targetFile = this.mappedFiles.get(index);                &#125; catch (Exception ignored) &#123;                &#125;                if (targetFile != null &amp;&amp; offset &gt;= targetFile.getFileFromOffset()                    &amp;&amp; offset &lt; targetFile.getFileFromOffset() + this.mappedFileSize) &#123;                    return targetFile;                &#125;                for (MappedFile tmpMappedFile : this.mappedFiles) &#123;                    if (offset &gt;= tmpMappedFile.getFileFromOffset()                        &amp;&amp; offset &lt; tmpMappedFile.getFileFromOffset() + this.mappedFileSize) &#123;                        return tmpMappedFile;                    &#125;                &#125;            &#125;            if (returnFirstOnNotFound) &#123;                return firstMappedFile;            &#125;        &#125;    &#125; catch (Exception e) &#123;        log.error(&quot;findMappedFileByOffset Exception&quot;, e);    &#125;    return null;&#125;\n\n\n\n\n获取存储文件最小偏移量\n\npublic long getMinOffset() &#123;    if (!this.mappedFiles.isEmpty()) &#123;        try &#123;            return this.mappedFiles.get(0).getFileFromOffset();        &#125; catch (IndexOutOfBoundsException e) &#123;            //continue;        &#125; catch (Exception e) &#123;            log.error(&quot;getMinOffset has exception.&quot;, e);        &#125;    &#125;    return -1;&#125;\n\n\n\n\n获取存储文件最大偏移量\n\npublic long getMaxOffset() &#123;    MappedFile mappedFile = getLastMappedFile();    if (mappedFile != null) &#123;        return mappedFile.getFileFromOffset() + mappedFile.getReadPosition();    &#125;    return 0;&#125;\n\n\n\n\n返回存储文件当前写指针\n\npublic long getMaxWrotePosition() &#123;    MappedFile mappedFile = getLastMappedFile();    if (mappedFile != null) &#123;        return mappedFile.getFileFromOffset() + mappedFile.getWrotePosition();    &#125;    return 0;&#125;\n\n\n\n####2）MappedFile\n\nint OS_PAGE_SIZE = 1024 * 4;\t\t//操作系统每页大小,默认4KAtomicLong TOTAL_MAPPED_VIRTUAL_MEMORY = new AtomicLong(0);\t//当前JVM实例中MappedFile虚拟内存AtomicInteger TOTAL_MAPPED_FILES = new AtomicInteger(0);\t//当前JVM实例中MappedFile对象个数AtomicInteger wrotePosition = new AtomicInteger(0);\t//当前文件的写指针AtomicInteger committedPosition = new AtomicInteger(0);\t//当前文件的提交指针AtomicInteger flushedPosition = new AtomicInteger(0);\t//刷写到磁盘指针int fileSize;\t//文件大小FileChannel fileChannel;\t//文件通道\tByteBuffer writeBuffer = null;\t//堆外内存ByteBufferTransientStorePool transientStorePool = null;\t//堆外内存池String fileName;\t//文件名称long fileFromOffset;\t//该文件的处理偏移量File file;\t//物理文件MappedByteBuffer mappedByteBuffer;\t//物理文件对应的内存映射Buffervolatile long storeTimestamp = 0;\t//文件最后一次内容写入时间boolean firstCreateInQueue = false;\t//是否是MappedFileQueue队列中第一个文件\n\n\n\nMappedFile初始化\n\n未开启transientStorePoolEnable。transientStorePoolEnable=true为true表示数据先存储到堆外内存，然后通过Commit线程将数据提交到内存映射Buffer中，再通过Flush线程将内存映射Buffer中数据持久化磁盘。\n\nprivate void init(final String fileName, final int fileSize) throws IOException &#123;    this.fileName = fileName;    this.fileSize = fileSize;    this.file = new File(fileName);    this.fileFromOffset = Long.parseLong(this.file.getName());    boolean ok = false;\t    ensureDirOK(this.file.getParent());    try &#123;        this.fileChannel = new RandomAccessFile(this.file, &quot;rw&quot;).getChannel();        this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize);        TOTAL_MAPPED_VIRTUAL_MEMORY.addAndGet(fileSize);        TOTAL_MAPPED_FILES.incrementAndGet();        ok = true;    &#125; catch (FileNotFoundException e) &#123;        log.error(&quot;create file channel &quot; + this.fileName + &quot; Failed. &quot;, e);        throw e;    &#125; catch (IOException e) &#123;        log.error(&quot;map file &quot; + this.fileName + &quot; Failed. &quot;, e);        throw e;    &#125; finally &#123;        if (!ok &amp;&amp; this.fileChannel != null) &#123;            this.fileChannel.close();        &#125;    &#125;&#125;\n\n\n\n开启transientStorePoolEnable\npublic void init(final String fileName, final int fileSize,    final TransientStorePool transientStorePool) throws IOException &#123;    init(fileName, fileSize);    this.writeBuffer = transientStorePool.borrowBuffer();\t//初始化writeBuffer    this.transientStorePool = transientStorePool;&#125;\n\n\n\nMappedFile提交\n提交数据到FileChannel，commitLeastPages为本次提交最小的页数，如果待提交数据不满commitLeastPages，则不执行本次提交操作。如果writeBuffer如果为空，直接返回writePosition指针，无需执行commit操作，表名commit操作主体是writeBuffer。\npublic int commit(final int commitLeastPages) &#123;    if (writeBuffer == null) &#123;        //no need to commit data to file channel, so just regard wrotePosition as committedPosition.        return this.wrotePosition.get();    &#125;    //判断是否满足提交条件    if (this.isAbleToCommit(commitLeastPages)) &#123;        if (this.hold()) &#123;            commit0(commitLeastPages);            this.release();        &#125; else &#123;            log.warn(&quot;in commit, hold failed, commit offset = &quot; + this.committedPosition.get());        &#125;    &#125;    // 所有数据提交后,清空缓冲区    if (writeBuffer != null &amp;&amp; this.transientStorePool != null &amp;&amp; this.fileSize == this.committedPosition.get()) &#123;        this.transientStorePool.returnBuffer(writeBuffer);        this.writeBuffer = null;    &#125;    return this.committedPosition.get();&#125;\n\n\n\nMappedFile#isAbleToCommit\n判断是否执行commit操作，如果文件已满返回true；如果commitLeastpages大于0，则比较writePosition与上一次提交的指针commitPosition的差值，除以OS_PAGE_SIZE得到当前脏页的数量，如果大于commitLeastPages则返回true，如果commitLeastpages小于0表示只要存在脏页就提交。\nprotected boolean isAbleToCommit(final int commitLeastPages) &#123;    //已经刷盘指针    int flush = this.committedPosition.get();    //文件写指针    int write = this.wrotePosition.get();\t//写满刷盘    if (this.isFull()) &#123;        return true;    &#125;    if (commitLeastPages &gt; 0) &#123;        //文件内容达到commitLeastPages页数,则刷盘        return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) &gt;= commitLeastPages;    &#125;    return write &gt; flush;&#125;\n\n\n\nMappedFile#commit0\n具体提交的实现，首先创建WriteBuffer区共享缓存区，然后将新创建的position回退到上一次提交的位置（commitPosition），设置limit为wrotePosition（当前最大有效数据指针），然后把commitPosition到wrotePosition的数据写入到FileChannel中，然后更新committedPosition指针为wrotePosition。commit的作用就是将MappedFile的writeBuffer中数据提交到文件通道FileChannel中。\nprotected void commit0(final int commitLeastPages) &#123;    //写指针    int writePos = this.wrotePosition.get();    //上次提交指针    int lastCommittedPosition = this.committedPosition.get();    if (writePos - this.committedPosition.get() &gt; 0) &#123;        try &#123;            //复制共享内存区域            ByteBuffer byteBuffer = writeBuffer.slice();            //设置提交位置是上次提交位置            byteBuffer.position(lastCommittedPosition);            //最大提交数量            byteBuffer.limit(writePos);            //设置fileChannel位置为上次提交位置            this.fileChannel.position(lastCommittedPosition);            //将lastCommittedPosition到writePos的数据复制到FileChannel中            this.fileChannel.write(byteBuffer);            //重置提交位置            this.committedPosition.set(writePos);        &#125; catch (Throwable e) &#123;            log.error(&quot;Error occurred when commit data to FileChannel.&quot;, e);        &#125;    &#125;&#125;\n\n\n\nMappedFile#flush\n刷写磁盘，直接调用MappedByteBuffer或fileChannel的force方法将内存中的数据持久化到磁盘，那么flushedPosition应该等于MappedByteBuffer中的写指针；如果writeBuffer不为空，则flushPosition应该等于上一次的commit指针；因为上一次提交的数据就是进入到MappedByteBuffer中的数据；如果writeBuffer为空，数据时直接进入到MappedByteBuffer，wrotePosition代表的是MappedByteBuffer中的指针，故设置flushPosition为wrotePosition。\n\npublic int flush(final int flushLeastPages) &#123;    //数据达到刷盘条件    if (this.isAbleToFlush(flushLeastPages)) &#123;        //加锁，同步刷盘        if (this.hold()) &#123;            //获得读指针            int value = getReadPosition();            try &#123;                //数据从writeBuffer提交数据到fileChannel再刷新到磁盘                if (writeBuffer != null || this.fileChannel.position() != 0) &#123;                    this.fileChannel.force(false);                &#125; else &#123;                    //从mmap刷新数据到磁盘                    this.mappedByteBuffer.force();                &#125;            &#125; catch (Throwable e) &#123;                log.error(&quot;Error occurred when force data to disk.&quot;, e);            &#125;\t\t\t//更新刷盘位置            this.flushedPosition.set(value);            this.release();        &#125; else &#123;            log.warn(&quot;in flush, hold failed, flush offset = &quot; + this.flushedPosition.get());            this.flushedPosition.set(getReadPosition());        &#125;    &#125;    return this.getFlushedPosition();&#125;\n\n\n\nMappedFile#getReadPosition\n获取当前文件最大可读指针。如果writeBuffer为空，则直接返回当前的写指针；如果writeBuffer不为空，则返回上一次提交的指针。在MappedFile设置中,只有提交了的数据（写入到MappedByteBuffer或FileChannel中的数据）才是安全的数据\npublic int getReadPosition() &#123;    //如果writeBuffer为空,刷盘的位置就是应该等于上次commit的位置,如果为空则为mmap的写指针    return this.writeBuffer == null ? this.wrotePosition.get() : this.committedPosition.get();&#125;\n\n\n\nMappedFile#selectMappedBuffer\n查找pos到当前最大可读之间的数据，由于在整个写入期间都未曾改MappedByteBuffer的指针，如果mappedByteBuffer.slice()方法返回的共享缓存区空间为整个MappedFile，然后通过设置ByteBuffer的position为待查找的值，读取字节长度当前可读最大长度，最终返回的ByteBuffer的limit为size。整个共享缓存区的容量为（MappedFile#fileSize-pos）。故在操作SelectMappedBufferResult不能对包含在里面的ByteBuffer调用filp方法。\npublic SelectMappedBufferResult selectMappedBuffer(int pos) &#123;    //获得最大可读指针    int readPosition = getReadPosition();    //pos小于最大可读指针,并且大于0    if (pos &lt; readPosition &amp;&amp; pos &gt;= 0) &#123;        if (this.hold()) &#123;            //复制mappedByteBuffer读共享区            ByteBuffer byteBuffer = this.mappedByteBuffer.slice();            //设置读指针位置            byteBuffer.position(pos);            //获得可读范围            int size = readPosition - pos;            //设置最大刻度范围            ByteBuffer byteBufferNew = byteBuffer.slice();            byteBufferNew.limit(size);            return new SelectMappedBufferResult(this.fileFromOffset + pos, byteBufferNew, size, this);        &#125;    &#125;    return null;&#125;\n\n\n\nMappedFile#shutdown\nMappedFile文件销毁的实现方法为public boolean destory(long intervalForcibly)，intervalForcibly表示拒绝被销毁的最大存活时间。\npublic void shutdown(final long intervalForcibly) &#123;    if (this.available) &#123;        //关闭MapedFile        this.available = false;        //设置当前关闭时间戳        this.firstShutdownTimestamp = System.currentTimeMillis();        //释放资源        this.release();    &#125; else if (this.getRefCount() &gt; 0) &#123;        if ((System.currentTimeMillis() - this.firstShutdownTimestamp) &gt;= intervalForcibly) &#123;            this.refCount.set(-1000 - this.getRefCount());            this.release();        &#125;    &#125;&#125;\n\n\n\n3）TransientStorePool短暂的存储池。RocketMQ单独创建一个MappedByteBuffer内存缓存池，用来临时存储数据，数据先写入该内存映射中，然后由commit线程定时将数据从该内存复制到与目标物理文件对应的内存映射中。RocketMQ引入该机制主要的原因是提供一种内存锁定，将当前堆外内存一直锁定在内存中，避免被进程将内存交换到磁盘。\n\nprivate final int poolSize;\t\t//availableBuffers个数private final int fileSize;\t\t//每隔ByteBuffer大小private final Deque&lt;ByteBuffer&gt; availableBuffers;\t//ByteBuffer容器。双端队列\n\n\n\n初始化\npublic void init() &#123;    //创建poolSize个堆外内存    for (int i = 0; i &lt; poolSize; i++) &#123;        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(fileSize);        final long address = ((DirectBuffer) byteBuffer).address();        Pointer pointer = new Pointer(address);        //使用com.sun.jna.Library类库将该批内存锁定,避免被置换到交换区,提高存储性能        LibC.INSTANCE.mlock(pointer, new NativeLong(fileSize));        availableBuffers.offer(byteBuffer);    &#125;&#125;\n\n\n\n2.4.5 实时更新消息消费队列与索引文件消息消费队文件、消息属性索引文件都是基于CommitLog文件构建的，当消息生产者提交的消息存储在CommitLog文件中，ConsumerQueue、IndexFile需要及时更新，否则消息无法及时被消费，根据消息属性查找消息也会出现较大延迟。RocketMQ通过开启一个线程ReputMessageService来准实时转发CommitLog文件更新事件，相应的任务处理器根据转发的消息及时更新ConsumerQueue、IndexFile文件。\n\n\n代码：DefaultMessageStore：start\n//设置CommitLog内存中最大偏移量this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);//启动this.reputMessageService.start();\n\n\n\n代码：DefaultMessageStore：run\npublic void run() &#123;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service started&quot;);\t//每隔1毫秒就继续尝试推送消息到消息消费队列和索引文件    while (!this.isStopped()) &#123;        try &#123;            Thread.sleep(1);            this.doReput();        &#125; catch (Exception e) &#123;            DefaultMessageStore.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service end&quot;);&#125;\n\n\n\n代码：DefaultMessageStore：deReput\n//从result中循环遍历消息,一次读一条,创建DispatherRequest对象。for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123;\tDispatchRequest dispatchRequest =                               DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false);\tint size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize();\tif (dispatchRequest.isSuccess()) &#123;\t    if (size &gt; 0) &#123;\t        DefaultMessageStore.this.doDispatch(dispatchRequest);\t    &#125;    &#125;&#125;\n\n\n\nDispatchRequest\n\nString topic; //消息主题名称int queueId;  //消息队列IDlong commitLogOffset;\t//消息物理偏移量int msgSize;\t//消息长度long tagsCode;\t//消息过滤tag hashCodelong storeTimestamp;\t//消息存储时间戳long consumeQueueOffset;\t//消息队列偏移量String keys;\t//消息索引keyboolean success;\t//是否成功解析到完整的消息String uniqKey;\t//消息唯一键int sysFlag;\t//消息系统标记long preparedTransactionOffset;\t//消息预处理事务偏移量Map&lt;String, String&gt; propertiesMap;\t//消息属性byte[] bitMap;\t//位图\n\n\n\n1）转发到ConsumerQueue\nclass CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher &#123;    @Override    public void dispatch(DispatchRequest request) &#123;        final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag());        switch (tranType) &#123;            case MessageSysFlag.TRANSACTION_NOT_TYPE:            case MessageSysFlag.TRANSACTION_COMMIT_TYPE:                //消息分发                DefaultMessageStore.this.putMessagePositionInfo(request);                break;            case MessageSysFlag.TRANSACTION_PREPARED_TYPE:            case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:                break;        &#125;    &#125;&#125;\n\n\n\n代码：DefaultMessageStore#putMessagePositionInfo\npublic void putMessagePositionInfo(DispatchRequest dispatchRequest) &#123;    //获得消费队列    ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId());    //消费队列分发消息    cq.putMessagePositionInfoWrapper(dispatchRequest);&#125;\n\n\n\n代码：DefaultMessageStore#putMessagePositionInfo\n//依次将消息偏移量、消息长度、tag写入到ByteBuffer中this.byteBufferIndex.flip();this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE);this.byteBufferIndex.putLong(offset);this.byteBufferIndex.putInt(size);this.byteBufferIndex.putLong(tagsCode);//获得内存映射文件MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset);if (mappedFile != null) &#123;    //将消息追加到内存映射文件,异步输盘    return mappedFile.appendMessage(this.byteBufferIndex.array());&#125;\n\n\n\n2）转发到Index\nclass CommitLogDispatcherBuildIndex implements CommitLogDispatcher &#123;    @Override    public void dispatch(DispatchRequest request) &#123;        if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) &#123;            DefaultMessageStore.this.indexService.buildIndex(request);        &#125;    &#125;&#125;\n\n\n\n代码：DefaultMessageStore#buildIndex\npublic void buildIndex(DispatchRequest req) &#123;    //获得索引文件    IndexFile indexFile = retryGetAndCreateIndexFile();    if (indexFile != null) &#123;        //获得文件最大物理偏移量        long endPhyOffset = indexFile.getEndPhyOffset();        DispatchRequest msg = req;        String topic = msg.getTopic();        String keys = msg.getKeys();        //如果该消息的物理偏移量小于索引文件中的最大物理偏移量,则说明是重复数据,忽略本次索引构建        if (msg.getCommitLogOffset() &lt; endPhyOffset) &#123;            return;        &#125;        final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag());        switch (tranType) &#123;            case MessageSysFlag.TRANSACTION_NOT_TYPE:            case MessageSysFlag.TRANSACTION_PREPARED_TYPE:            case MessageSysFlag.TRANSACTION_COMMIT_TYPE:                break;            case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:                return;        &#125;\t\t        //如果消息ID不为空,则添加到Hash索引中        if (req.getUniqKey() != null) &#123;            indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey()));            if (indexFile == null) &#123;                return;            &#125;        &#125;\t\t//构建索引key,RocketMQ支持为同一个消息建立多个索引,多个索引键空格隔开.        if (keys != null &amp;&amp; keys.length() &gt; 0) &#123;            String[] keyset = keys.split(MessageConst.KEY_SEPARATOR);            for (int i = 0; i &lt; keyset.length; i++) &#123;                String key = keyset[i];                if (key.length() &gt; 0) &#123;                    indexFile = putKey(indexFile, msg, buildKey(topic, key));                    if (indexFile == null) &#123;                        return;                    &#125;                &#125;            &#125;        &#125;    &#125; else &#123;        log.error(&quot;build index error, stop building index&quot;);    &#125;&#125;\n\n\n\n2.4.6 消息队列和索引文件恢复由于RocketMQ存储首先将消息全量存储在CommitLog文件中，然后异步生成转发任务更新ConsumerQueue和Index文件。如果消息成功存储到CommitLog文件中，转发任务未成功执行，此时消息服务器Broker由于某个愿意宕机，导致CommitLog、ConsumerQueue、IndexFile文件数据不一致。如果不加以人工修复的话，会有一部分消息即便在CommitLog中文件中存在，但由于没有转发到ConsumerQueue，这部分消息将永远复发被消费者消费。\n\n####1）存储文件加载\n代码：DefaultMessageStore#load\n判断上一次是否异常退出。实现机制是Broker在启动时创建abort文件，在退出时通过JVM钩子函数删除abort文件。如果下次启动时存在abort文件。说明Broker时异常退出的，CommitLog与ConsumerQueue数据有可能不一致，需要进行修复。\n//判断临时文件是否存在boolean lastExitOK = !this.isTempFileExist();//根据临时文件判断当前Broker是否异常退出private boolean isTempFileExist() &#123;    String fileName = StorePathConfigHelper        .getAbortFile(this.messageStoreConfig.getStorePathRootDir());    File file = new File(fileName);    return file.exists();&#125;\n\n\n\n代码：DefaultMessageStore#load\n//加载延时队列if (null != scheduleMessageService) &#123;    result = result &amp;&amp; this.scheduleMessageService.load();&#125;// 加载CommitLog文件result = result &amp;&amp; this.commitLog.load();// 加载消费队列文件result = result &amp;&amp; this.loadConsumeQueue();if (result) &#123;\t//加载存储监测点,监测点主要记录CommitLog文件、ConsumerQueue文件、Index索引文件的刷盘点    this.storeCheckpoint =new StoreCheckpoint(StorePathConfigHelper.getStoreCheckpoint(this.messageStoreConfig.getStorePathRootDir()));\t//加载index文件    this.indexService.load(lastExitOK);\t//根据Broker是否异常退出,执行不同的恢复策略    this.recover(lastExitOK);&#125;\n\n\n\n代码：MappedFileQueue#load\n加载CommitLog到映射文件\n//指向CommitLog文件目录File dir = new File(this.storePath);//获得文件数组File[] files = dir.listFiles();if (files != null) &#123;    // 文件排序    Arrays.sort(files);    //遍历文件    for (File file : files) &#123;\t\t//如果文件大小和配置文件不一致,退出        if (file.length() != this.mappedFileSize) &#123;                        return false;        &#125;        try &#123;            //创建映射文件            MappedFile mappedFile = new MappedFile(file.getPath(), mappedFileSize);            mappedFile.setWrotePosition(this.mappedFileSize);            mappedFile.setFlushedPosition(this.mappedFileSize);            mappedFile.setCommittedPosition(this.mappedFileSize);            //将映射文件添加到队列            this.mappedFiles.add(mappedFile);            log.info(&quot;load &quot; + file.getPath() + &quot; OK&quot;);        &#125; catch (IOException e) &#123;            log.error(&quot;load file &quot; + file + &quot; error&quot;, e);            return false;        &#125;    &#125;&#125;return true;\n\n\n\n代码：DefaultMessageStore#loadConsumeQueue\n加载消息消费队列\n//执行消费队列目录File dirLogic = new File(StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()));//遍历消费队列目录File[] fileTopicList = dirLogic.listFiles();if (fileTopicList != null) &#123;    for (File fileTopic : fileTopicList) &#123;        //获得子目录名称,即topic名称        String topic = fileTopic.getName();\t\t//遍历子目录下的消费队列文件        File[] fileQueueIdList = fileTopic.listFiles();        if (fileQueueIdList != null) &#123;            //遍历文件            for (File fileQueueId : fileQueueIdList) &#123;                //文件名称即队列ID                int queueId;                try &#123;                    queueId = Integer.parseInt(fileQueueId.getName());                &#125; catch (NumberFormatException e) &#123;                    continue;                &#125;                //创建消费队列并加载到内存                ConsumeQueue logic = new ConsumeQueue(                    topic,                    queueId,                    StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()),            this.getMessageStoreConfig().getMapedFileSizeConsumeQueue(),                    this);                this.putConsumeQueue(topic, queueId, logic);                if (!logic.load()) &#123;                    return false;                &#125;            &#125;        &#125;    &#125;&#125;log.info(&quot;load logics queue all over, OK&quot;);return true;\n\n\n\n代码：IndexService#load\n加载索引文件\npublic boolean load(final boolean lastExitOK) &#123;    //索引文件目录    File dir = new File(this.storePath);    //遍历索引文件    File[] files = dir.listFiles();    if (files != null) &#123;        //文件排序        Arrays.sort(files);        //遍历文件        for (File file : files) &#123;            try &#123;                //加载索引文件                IndexFile f = new IndexFile(file.getPath(), this.hashSlotNum, this.indexNum, 0, 0);                f.load();                if (!lastExitOK) &#123;                    //索引文件上次的刷盘时间小于该索引文件的消息时间戳,该文件将立即删除                    if (f.getEndTimestamp() &gt; this.defaultMessageStore.getStoreCheckpoint()                        .getIndexMsgTimestamp()) &#123;                        f.destroy(0);                        continue;                    &#125;                &#125;\t\t\t\t//将索引文件添加到队列                log.info(&quot;load index file OK, &quot; + f.getFileName());                this.indexFileList.add(f);            &#125; catch (IOException e) &#123;                log.error(&quot;load file &#123;&#125; error&quot;, file, e);                return false;            &#125; catch (NumberFormatException e) &#123;                log.error(&quot;load file &#123;&#125; error&quot;, file, e);            &#125;        &#125;    &#125;    return true;&#125;\n\n\n\n代码：DefaultMessageStore#recover\n文件恢复，根据Broker是否正常退出执行不同的恢复策略\nprivate void recover(final boolean lastExitOK) &#123;    //获得最大的物理便宜消费队列    long maxPhyOffsetOfConsumeQueue = this.recoverConsumeQueue();    if (lastExitOK) &#123;        //正常恢复        this.commitLog.recoverNormally(maxPhyOffsetOfConsumeQueue);    &#125; else &#123;        //异常恢复        this.commitLog.recoverAbnormally(maxPhyOffsetOfConsumeQueue);    &#125;\t//在CommitLog中保存每个消息消费队列当前的存储逻辑偏移量    this.recoverTopicQueueTable();&#125;\n\n\n\n代码：DefaultMessageStore#recoverTopicQueueTable\n恢复ConsumerQueue后，将在CommitLog实例中保存每隔消息队列当前的存储逻辑偏移量，这也是消息中不仅存储主题、消息队列ID、还存储了消息队列的关键所在。\npublic void recoverTopicQueueTable() &#123;    HashMap&lt;String/* topic-queueid */, Long/* offset */&gt; table = new HashMap&lt;String, Long&gt;(1024);    //CommitLog最小偏移量    long minPhyOffset = this.commitLog.getMinOffset();    //遍历消费队列,将消费队列保存在CommitLog中    for (ConcurrentMap&lt;Integer, ConsumeQueue&gt; maps : this.consumeQueueTable.values()) &#123;        for (ConsumeQueue logic : maps.values()) &#123;            String key = logic.getTopic() + &quot;-&quot; + logic.getQueueId();            table.put(key, logic.getMaxOffsetInQueue());            logic.correctMinOffset(minPhyOffset);        &#125;    &#125;    this.commitLog.setTopicQueueTable(table);&#125;\n\n\n\n####2）正常恢复\n代码：CommitLog#recoverNormally\npublic void recoverNormally(long maxPhyOffsetOfConsumeQueue) &#123;\t    final List&lt;MappedFile&gt; mappedFiles = this.mappedFileQueue.getMappedFiles();    if (!mappedFiles.isEmpty()) &#123;         //Broker正常停止再重启时,从倒数第三个开始恢复,如果不足3个文件,则从第一个文件开始恢复。        int index = mappedFiles.size() - 3;        if (index &lt; 0)            index = 0;        MappedFile mappedFile = mappedFiles.get(index);        ByteBuffer byteBuffer = mappedFile.sliceByteBuffer();        long processOffset = mappedFile.getFileFromOffset();        //代表当前已校验通过的offset        long mappedFileOffset = 0;        while (true) &#123;            //查找消息            DispatchRequest dispatchRequest = this.checkMessageAndReturnSize(byteBuffer, checkCRCOnRecover);            //消息长度            int size = dispatchRequest.getMsgSize();           \t//查找结果为true,并且消息长度大于0,表示消息正确.mappedFileOffset向前移动本消息长度            if (dispatchRequest.isSuccess() &amp;&amp; size &gt; 0) &#123;                mappedFileOffset += size;            &#125;\t\t\t//如果查找结果为true且消息长度等于0,表示已到该文件末尾,如果还有下一个文件,则重置processOffset和MappedFileOffset重复查找下一个文件,否则跳出循环。            else if (dispatchRequest.isSuccess() &amp;&amp; size == 0) &#123;              index++;              if (index &gt;= mappedFiles.size()) &#123;                  // Current branch can not happen                  break;              &#125; else &#123;                  //取出每个文件                  mappedFile = mappedFiles.get(index);                  byteBuffer = mappedFile.sliceByteBuffer();                  processOffset = mappedFile.getFileFromOffset();                  mappedFileOffset = 0;                            \t\t&#125;            &#125;            // 查找结果为false，表明该文件未填满所有消息，跳出循环，结束循环            else if (!dispatchRequest.isSuccess()) &#123;                log.info(&quot;recover physics file end, &quot; + mappedFile.getFileName());                break;            &#125;        &#125;\t\t//更新MappedFileQueue的flushedWhere和committedWhere指针        processOffset += mappedFileOffset;        this.mappedFileQueue.setFlushedWhere(processOffset);        this.mappedFileQueue.setCommittedWhere(processOffset);        //删除offset之后的所有文件        this.mappedFileQueue.truncateDirtyFiles(processOffset);                if (maxPhyOffsetOfConsumeQueue &gt;= processOffset) &#123;            this.defaultMessageStore.truncateDirtyLogicFiles(processOffset);        &#125;    &#125; else &#123;        this.mappedFileQueue.setFlushedWhere(0);        this.mappedFileQueue.setCommittedWhere(0);        this.defaultMessageStore.destroyLogics();    &#125;&#125;\n\n\n\n代码：MappedFileQueue#truncateDirtyFiles\npublic void truncateDirtyFiles(long offset) &#123;    List&lt;MappedFile&gt; willRemoveFiles = new ArrayList&lt;MappedFile&gt;();\t//遍历目录下文件    for (MappedFile file : this.mappedFiles) &#123;        //文件尾部的偏移量        long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize;        //文件尾部的偏移量大于offset        if (fileTailOffset &gt; offset) &#123;            //offset大于文件的起始偏移量            if (offset &gt;= file.getFileFromOffset()) &#123;                //更新wrotePosition、committedPosition、flushedPosistion                file.setWrotePosition((int) (offset % this.mappedFileSize));                file.setCommittedPosition((int) (offset % this.mappedFileSize));                file.setFlushedPosition((int) (offset % this.mappedFileSize));            &#125; else &#123;                //offset小于文件的起始偏移量,说明该文件是有效文件后面创建的,释放mappedFile占用内存,删除文件                file.destroy(1000);                willRemoveFiles.add(file);            &#125;        &#125;    &#125;    this.deleteExpiredFile(willRemoveFiles);&#125;\n\n\n\n####3）异常恢复\nBroker异常停止文件恢复的实现为CommitLog#recoverAbnormally。异常文件恢复步骤与正常停止文件恢复流程基本相同，其主要差别有两个。首先，正常停止默认从倒数第三个文件开始进行恢复，而异常停止则需要从最后一个文件往前走，找到第一个消息存储正常的文件。其次，如果CommitLog目录没有消息文件，如果消息消费队列目录下存在文件，则需要销毁。\n代码：CommitLog#recoverAbnormally\nif (!mappedFiles.isEmpty()) &#123;    // Looking beginning to recover from which file    int index = mappedFiles.size() - 1;    MappedFile mappedFile = null;    for (; index &gt;= 0; index--) &#123;        mappedFile = mappedFiles.get(index);        //判断消息文件是否是一个正确的文件        if (this.isMappedFileMatchedRecover(mappedFile)) &#123;            log.info(&quot;recover from this mapped file &quot; + mappedFile.getFileName());            break;        &#125;    &#125;\t//根据索引取出mappedFile文件    if (index &lt; 0) &#123;        index = 0;        mappedFile = mappedFiles.get(index);    &#125;    //...验证消息的合法性,并将消息转发到消息消费队列和索引文件       &#125;else&#123;    //未找到mappedFile,重置flushWhere、committedWhere都为0，销毁消息队列文件    this.mappedFileQueue.setFlushedWhere(0);    this.mappedFileQueue.setCommittedWhere(0);    this.defaultMessageStore.destroyLogics();&#125;\n\n\n\n2.4.7 刷盘机制RocketMQ的存储是基于JDK NIO的内存映射机制（MappedByteBuffer）的，消息存储首先将消息追加到内存，再根据配置的刷盘策略在不同时间进行刷写磁盘。\n同步刷盘消息追加到内存后，立即将数据刷写到磁盘文件\n\n代码：CommitLog#handleDiskFlush\n//刷盘服务final GroupCommitService service = (GroupCommitService) this.flushCommitLogService;if (messageExt.isWaitStoreMsgOK()) &#123;    //封装刷盘请求    GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes());    //提交刷盘请求    service.putRequest(request);    //线程阻塞5秒，等待刷盘结束    boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout());    if (!flushOK) &#123;        putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT);    &#125;\n\n\n\nGroupCommitRequest\n\nlong nextOffset;\t//刷盘点偏移量CountDownLatch countDownLatch = new CountDownLatch(1);\t//倒计树锁存器volatile boolean flushOK = false;\t//刷盘结果;默认为false\n\n\n\n代码：GroupCommitService#run\npublic void run() &#123;    CommitLog.log.info(this.getServiceName() + &quot; service started&quot;);    while (!this.isStopped()) &#123;        try &#123;            //线程等待10ms            this.waitForRunning(10);            //执行提交            this.doCommit();        &#125; catch (Exception e) &#123;            CommitLog.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;\t...&#125;\n\n\n\n代码：GroupCommitService#doCommit\nprivate void doCommit() &#123;    //加锁    synchronized (this.requestsRead) &#123;        if (!this.requestsRead.isEmpty()) &#123;            //遍历requestsRead            for (GroupCommitRequest req : this.requestsRead) &#123;                // There may be a message in the next file, so a maximum of                // two times the flush                boolean flushOK = false;                for (int i = 0; i &lt; 2 &amp;&amp; !flushOK; i++) &#123;                    flushOK = CommitLog.this.mappedFileQueue.getFlushedWhere() &gt;= req.getNextOffset();\t\t\t\t\t//刷盘                    if (!flushOK) &#123;                        CommitLog.this.mappedFileQueue.flush(0);                    &#125;                &#125;\t\t\t\t//唤醒发送消息客户端                req.wakeupCustomer(flushOK);            &#125;\t\t\t            //更新刷盘监测点            long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();            if (storeTimestamp &gt; 0) &#123;               CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);            &#125;\t\t\t            this.requestsRead.clear();        &#125; else &#123;            // Because of individual messages is set to not sync flush, it            // will come to this process            CommitLog.this.mappedFileQueue.flush(0);        &#125;    &#125;&#125;\n\n\n\n异步刷盘在消息追加到内存后，立即返回给消息发送端。如果开启transientStorePoolEnable，RocketMQ会单独申请一个与目标物理文件（commitLog）同样大小的堆外内存，该堆外内存将使用内存锁定，确保不会被置换到虚拟内存中去，消息首先追加到堆外内存，然后提交到物理文件的内存映射中，然后刷写到磁盘。如果未开启transientStorePoolEnable，消息直接追加到物理文件直接映射文件中，然后刷写到磁盘中。\n\n开启transientStorePoolEnable后异步刷盘步骤:\n\n将消息直接追加到ByteBuffer（堆外内存）\nCommitRealTimeService线程每隔200ms将ByteBuffer新追加内容提交到MappedByteBuffer中\nMappedByteBuffer在内存中追加提交的内容，wrotePosition指针向后移动\ncommit操作成功返回，将committedPosition位置恢复\nFlushRealTimeService线程默认每500ms将MappedByteBuffer中新追加的内存刷写到磁盘\n\n代码：CommitLog$CommitRealTimeService#run\n提交线程工作机制\n//间隔时间,默认200msint interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitIntervalCommitLog();//一次提交的至少页数int commitDataLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogLeastPages();//两次真实提交的最大间隔,默认200msint commitDataThoroughInterval =CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogThoroughInterval();//上次提交间隔超过commitDataThoroughInterval,则忽略提交commitDataThoroughInterval参数,直接提交long begin = System.currentTimeMillis();if (begin &gt;= (this.lastCommitTimestamp + commitDataThoroughInterval)) &#123;    this.lastCommitTimestamp = begin;    commitDataLeastPages = 0;&#125;//执行提交操作,将待提交数据提交到物理文件的内存映射区boolean result = CommitLog.this.mappedFileQueue.commit(commitDataLeastPages);long end = System.currentTimeMillis();if (!result) &#123;    this.lastCommitTimestamp = end; // result = false means some data committed.    //now wake up flush thread.    //唤醒刷盘线程    flushCommitLogService.wakeup();&#125;if (end - begin &gt; 500) &#123;    log.info(&quot;Commit data to file costs &#123;&#125; ms&quot;, end - begin);&#125;this.waitForRunning(interval);\n\n\n\n代码：CommitLog$FlushRealTimeService#run\n刷盘线程工作机制\n//表示await方法等待,默认falseboolean flushCommitLogTimed = CommitLog.this.defaultMessageStore.getMessageStoreConfig().isFlushCommitLogTimed();//线程执行时间间隔int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushIntervalCommitLog();//一次刷写任务至少包含页数int flushPhysicQueueLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogLeastPages();//两次真实刷写任务最大间隔int flushPhysicQueueThoroughInterval =CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogThoroughInterval();...//距离上次提交间隔超过flushPhysicQueueThoroughInterval,则本次刷盘任务将忽略flushPhysicQueueLeastPages,直接提交long currentTimeMillis = System.currentTimeMillis();if (currentTimeMillis &gt;= (this.lastFlushTimestamp + flushPhysicQueueThoroughInterval)) &#123;    this.lastFlushTimestamp = currentTimeMillis;    flushPhysicQueueLeastPages = 0;    printFlushProgress = (printTimes++ % 10) == 0;&#125;...//执行一次刷盘前,先等待指定时间间隔if (flushCommitLogTimed) &#123;    Thread.sleep(interval);&#125; else &#123;    this.waitForRunning(interval);&#125;...long begin = System.currentTimeMillis();//刷写磁盘CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages);long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();if (storeTimestamp &gt; 0) &#123;//更新存储监测点文件的时间戳CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);\n\n\n\n2.4.8 过期文件删除机制由于RocketMQ操作CommitLog、ConsumerQueue文件是基于内存映射机制并在启动的时候回加载CommitLog、ConsumerQueue目录下的所有文件，为了避免内存与磁盘的浪费，不可能将消息永久存储在消息服务器上，所以要引入一种机制来删除已过期的文件。RocketMQ顺序写CommitLog、ConsumerQueue文件，所有写操作全部落在最后一个CommitLog或者ConsumerQueue文件上，之前的文件在下一个文件创建后将不会再被更新。RocketMQ清除过期文件的方法时：如果当前文件在在一定时间间隔内没有再次被消费，则认为是过期文件，可以被删除，RocketMQ不会关注这个文件上的消息是否全部被消费。默认每个文件的过期时间为72小时，通过在Broker配置文件中设置fileReservedTime来改变过期时间，单位为小时。\n代码：DefaultMessageStore#addScheduleTask\nprivate void addScheduleTask() &#123;\t//每隔10s调度一次清除文件    this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;        @Override        public void run() &#123;            DefaultMessageStore.this.cleanFilesPeriodically();        &#125;    &#125;, 1000 * 60, this.messageStoreConfig.getCleanResourceInterval(), TimeUnit.MILLISECONDS);\t...&#125;\n\n\n\n代码：DefaultMessageStore#cleanFilesPeriodically\nprivate void cleanFilesPeriodically() &#123;    //清除存储文件    this.cleanCommitLogService.run();    //清除消息消费队列文件    this.cleanConsumeQueueService.run();&#125;\n\n\n\n代码：DefaultMessageStore#deleteExpiredFiles\nprivate void deleteExpiredFiles() &#123;    //删除的数量    int deleteCount = 0;    //文件保留的时间    long fileReservedTime = DefaultMessageStore.this.getMessageStoreConfig().getFileReservedTime();    //删除物理文件的间隔    int deletePhysicFilesInterval = DefaultMessageStore.this.getMessageStoreConfig().getDeleteCommitLogFilesInterval();    //线程被占用,第一次拒绝删除后能保留的最大时间,超过该时间,文件将被强制删除    int destroyMapedFileIntervalForcibly = DefaultMessageStore.this.getMessageStoreConfig().getDestroyMapedFileIntervalForcibly();boolean timeup = this.isTimeToDelete();boolean spacefull = this.isSpaceToDelete();boolean manualDelete = this.manualDeleteFileSeveralTimes &gt; 0;if (timeup || spacefull || manualDelete) &#123;\t...执行删除逻辑&#125;else&#123;    ...无作为&#125;\n\n\n\n删除文件操作的条件\n\n指定删除文件的时间点，RocketMQ通过deleteWhen设置一天的固定时间执行一次删除过期文件操作，默认4点\n磁盘空间如果不充足，删除过期文件\n预留，手工触发。\n\n代码：CleanCommitLogService#isSpaceToDelete\n当磁盘空间不足时执行删除过期文件\nprivate boolean isSpaceToDelete() &#123;    //磁盘分区的最大使用量    double ratio = DefaultMessageStore.this.getMessageStoreConfig().getDiskMaxUsedSpaceRatio() / 100.0;\t//是否需要立即执行删除过期文件操作    cleanImmediately = false;    &#123;        String storePathPhysic = DefaultMessageStore.this.getMessageStoreConfig().getStorePathCommitLog();        //当前CommitLog目录所在的磁盘分区的磁盘使用率        double physicRatio = UtilAll.getDiskPartitionSpaceUsedPercent(storePathPhysic);        //diskSpaceWarningLevelRatio:磁盘使用率警告阈值,默认0.90        if (physicRatio &gt; diskSpaceWarningLevelRatio) &#123;            boolean diskok = DefaultMessageStore.this.runningFlags.getAndMakeDiskFull();            if (diskok) &#123;                DefaultMessageStore.log.error(&quot;physic disk maybe full soon &quot; + physicRatio + &quot;, so mark disk full&quot;);            &#125;\t\t\t//diskSpaceCleanForciblyRatio:强制清除阈值,默认0.85            cleanImmediately = true;        &#125; else if (physicRatio &gt; diskSpaceCleanForciblyRatio) &#123;            cleanImmediately = true;        &#125; else &#123;            boolean diskok = DefaultMessageStore.this.runningFlags.getAndMakeDiskOK();            if (!diskok) &#123;            DefaultMessageStore.log.info(&quot;physic disk space OK &quot; + physicRatio + &quot;, so mark disk ok&quot;);        &#125;    &#125;    if (physicRatio &lt; 0 || physicRatio &gt; ratio) &#123;        DefaultMessageStore.log.info(&quot;physic disk maybe full soon, so reclaim space, &quot; + physicRatio);        return true;    &#125;&#125;\n\n\n\n代码：MappedFileQueue#deleteExpiredFileByTime\n执行文件销毁和删除\nfor (int i = 0; i &lt; mfsLength; i++) &#123;    //遍历每隔文件    MappedFile mappedFile = (MappedFile) mfs[i];    //计算文件存活时间    long liveMaxTimestamp = mappedFile.getLastModifiedTimestamp() + expiredTime;    //如果超过72小时,执行文件删除    if (System.currentTimeMillis() &gt;= liveMaxTimestamp || cleanImmediately) &#123;        if (mappedFile.destroy(intervalForcibly)) &#123;            files.add(mappedFile);            deleteCount++;            if (files.size() &gt;= DELETE_FILES_BATCH_MAX) &#123;                break;            &#125;            if (deleteFilesInterval &gt; 0 &amp;&amp; (i + 1) &lt; mfsLength) &#123;                try &#123;                    Thread.sleep(deleteFilesInterval);                &#125; catch (InterruptedException e) &#123;                &#125;            &#125;        &#125; else &#123;            break;        &#125;    &#125; else &#123;        //avoid deleting files in the middle        break;    &#125;&#125;\n\n\n\n\n2.4.9 小结RocketMQ的存储文件包括消息文件（Commitlog）、消息消费队列文件（ConsumerQueue）、Hash索引文件（IndexFile）、监测点文件（checkPoint）、abort（关闭异常文件）。单个消息存储文件、消息消费队列文件、Hash索引文件长度固定以便使用内存映射机制进行文件的读写操作。RocketMQ组织文件以文件的起始偏移量来命令文件，这样根据偏移量能快速定位到真实的物理文件。RocketMQ基于内存映射文件机制提供了同步刷盘和异步刷盘两种机制，异步刷盘是指在消息存储时先追加到内存映射文件，然后启动专门的刷盘线程定时将内存中的文件数据刷写到磁盘。\nCommitLog，消息存储文件，RocketMQ为了保证消息发送的高吞吐量，采用单一文件存储所有主题消息，保证消息存储是完全的顺序写，但这样给文件读取带来了不便，为此RocketMQ为了方便消息消费构建了消息消费队列文件，基于主题与队列进行组织，同时RocketMQ为消息实现了Hash索引，可以为消息设置索引键，根据所以能够快速从CommitLog文件中检索消息。\n当消息达到CommitLog后，会通过ReputMessageService线程接近实时地将消息转发给消息消费队列文件与索引文件。为了安全起见，RocketMQ引入abort文件，记录Broker的停机是否是正常关闭还是异常关闭，在重启Broker时为了保证CommitLog文件，消息消费队列文件与Hash索引文件的正确性，分别采用不同策略来恢复文件。\nRocketMQ不会永久存储消息文件、消息消费队列文件，而是启动文件过期机制并在磁盘空间不足或者默认凌晨4点删除过期文件，文件保存72小时并且在删除文件时并不会判断该消息文件上的消息是否被消费。\n2.5 Consumer2.5.1 消息消费概述消息消费以组的模式开展，一个消费组内可以包含多个消费者，每一个消费者组可订阅多个主题，消费组之间有ff式和广播模式两种消费模式。集群模式，主题下的同一条消息只允许被其中一个消费者消费。广播模式，主题下的同一条消息，将被集群内的所有消费者消费一次。消息服务器与消费者之间的消息传递也有两种模式：推模式、拉模式。所谓的拉模式，是消费端主动拉起拉消息请求，而推模式是消息达到消息服务器后，推送给消息消费者。RocketMQ消息推模式的实现基于拉模式，在拉模式上包装一层，一个拉取任务完成后开始下一个拉取任务。\n集群模式下，多个消费者如何对消息队列进行负载呢？消息队列负载机制遵循一个通用思想：一个消息队列同一个时间只允许被一个消费者消费，一个消费者可以消费多个消息队列。\nRocketMQ支持局部顺序消息消费，也就是保证同一个消息队列上的消息顺序消费。不支持消息全局顺序消费，如果要实现某一个主题的全局顺序消费，可以将该主题的队列数设置为1，牺牲高可用性。\n###2.5.2 消息消费初探\n消息推送模式\n\n消息消费重要方法\nvoid sendMessageBack(final MessageExt msg, final int delayLevel, final String brokerName)：发送消息确认Set&lt;MessageQueue&gt; fetchSubscribeMessageQueues(final String topic) :获取消费者对主题分配了那些消息队列void registerMessageListener(final MessageListenerConcurrently messageListener)：注册并发事件监听器void registerMessageListener(final MessageListenerOrderly messageListener)：注册顺序消息事件监听器void subscribe(final String topic, final String subExpression)：基于主题订阅消息，消息过滤使用表达式void subscribe(final String topic, final String fullClassName,final String filterClassSource)：基于主题订阅消息，消息过滤使用类模式void subscribe(final String topic, final MessageSelector selector) ：订阅消息，并指定队列选择器void unsubscribe(final String topic)：取消消息订阅\n\n\n\nDefaultMQPushConsumer\n\n//消费者组private String consumerGroup;\t//消息消费模式private MessageModel messageModel = MessageModel.CLUSTERING;\t//指定消费开始偏移量（最大偏移量、最小偏移量、启动时间戳）开始消费private ConsumeFromWhere consumeFromWhere = ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET;//集群模式下的消息队列负载策略private AllocateMessageQueueStrategy allocateMessageQueueStrategy;//订阅信息private Map&lt;String /* topic */, String /* sub expression */&gt; subscription = new HashMap&lt;String, String&gt;();//消息业务监听器private MessageListener messageListener;//消息消费进度存储器private OffsetStore offsetStore;//消费者最小线程数量private int consumeThreadMin = 20;//消费者最大线程数量private int consumeThreadMax = 20;//并发消息消费时处理队列最大跨度private int consumeConcurrentlyMaxSpan = 2000;//每1000次流控后打印流控日志private int pullThresholdForQueue = 1000;//推模式下任务间隔时间private long pullInterval = 0;//推模式下任务拉取的条数,默认32条private int pullBatchSize = 32;//每次传入MessageListener#consumerMessage中消息的数量private int consumeMessageBatchMaxSize = 1;//是否每次拉取消息都订阅消息private boolean postSubscriptionWhenPull = false;//消息重试次数,-1代表16次private int maxReconsumeTimes = -1;//消息消费超时时间private long consumeTimeout = 15;\n\n\n\n2.5.3 消费者启动流程\n代码：DefaultMQPushConsumerImpl#start\npublic synchronized void start() throws MQClientException &#123;    switch (this.serviceState) &#123;        case CREATE_JUST:                            this.defaultMQPushConsumer.getMessageModel(), this.defaultMQPushConsumer.isUnitMode());            this.serviceState = ServiceState.START_FAILED;\t\t\t//检查消息者是否合法            this.checkConfig();\t\t\t//构建主题订阅信息            this.copySubscription();\t\t\t//设置消费者客户端实例名称为进程ID            if (this.defaultMQPushConsumer.getMessageModel() == MessageModel.CLUSTERING) &#123;                this.defaultMQPushConsumer.changeInstanceNameToPID();            &#125;\t\t\t//创建MQClient实例            this.mQClientFactory = MQClientManager.getInstance().getAndCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook);\t\t\t//构建rebalanceImpl            this.rebalanceImpl.setConsumerGroup(this.defaultMQPushConsumer.getConsumerGroup());            this.rebalanceImpl.setMessageModel(this.defaultMQPushConsumer.getMessageModel());            this.rebalanceImpl.setAllocateMessageQueueStrategy(this.defaultMQPushConsumer.getAllocateMessageQueueStrategy());            this.rebalanceImpl.setmQClientFactory(this.mQClientFactor            this.pullAPIWrapper = new PullAPIWrapper(                mQClientFactory,                this.defaultMQPushConsumer.getConsumerGroup(), isUnitMode());            this.pullAPIWrapper.registerFilterMessageHook(filterMessageHookLis            if (this.defaultMQPushConsumer.getOffsetStore() != null) &#123;                this.offsetStore = this.defaultMQPushConsumer.getOffsetStore();            &#125; else &#123;           \t\tswitch (this.defaultMQPushConsumer.getMessageModel()) &#123;                          \t    case BROADCASTING:\t //消息消费广播模式,将消费进度保存在本地           \t        this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup());           \t            break;           \t        case CLUSTERING:\t//消息消费集群模式,将消费进度保存在远端Broker           \t            this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup());           \t            break;           \t        default:           \t            break;           \t    &#125;           \t    this.defaultMQPushConsumer.setOffsetStore(this.offsetStore);           \t&#125;            this.offsetStore.load            //创建顺序消息消费服务            if (this.getMessageListenerInner() instanceof MessageListenerOrderly) &#123;                this.consumeOrderly = true;                this.consumeMessageService =                    new ConsumeMessageOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner());                //创建并发消息消费服务            &#125; else if (this.getMessageListenerInner() instanceof MessageListenerConcurrently) &#123;                this.consumeOrderly = false;                this.consumeMessageService =                    new ConsumeMessageConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner());            &#125;            //消息消费服务启动            this.consumeMessageService.start();            //注册消费者实例            boolean registerOK = mQClientFactory.registerConsumer(this.defaultMQPushConsumer.getConsumerGroup(), this);                        if (!registerOK) &#123;                this.serviceState = ServiceState.CREATE_JUST;                this.consumeMessageService.shutdown();                throw new MQClientException(&quot;The consumer group[&quot; + this.defaultMQPushConsumer.getConsumerGroup()                    + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),                    null);            //启动消费者客户端            mQClientFactory.start();            log.info(&quot;the consumer [&#123;&#125;] start OK.&quot;, this.defaultMQPushConsumer.getConsumerGroup());            this.serviceState = ServiceState.RUNNING;            break;            case RUNNING:            case START_FAILED:        case SHUTDOWN_ALREADY:            throw new MQClientException(&quot;The PushConsumer service state not OK, maybe started once, &quot;                + this.serviceState                + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK),                null);        default:            break;    &#125;    this.updateTopicSubscribeInfoWhenSubscriptionChanged();    this.mQClientFactory.checkClientInBroker();    this.mQClientFactory.sendHeartbeatToAllBrokerWithLock();    this.mQClientFactory.rebalanceImmediately();&#125;\n\n\n\n2.5.4 消息拉取消息消费模式有两种模式：广播模式与集群模式。广播模式比较简单，每一个消费者需要拉取订阅主题下所有队列的消息。本文重点讲解集群模式。在集群模式下，同一个消费者组内有多个消息消费者，同一个主题存在多个消费队列，消费者通过负载均衡的方式消费消息。\n消息队列负载均衡，通常的作法是一个消息队列在同一个时间只允许被一个消费消费者消费，一个消息消费者可以同时消费多个消息队列。\n1）PullMessageService实现机制从MQClientInstance的启动流程中可以看出，RocketMQ使用一个单独的线程PullMessageService来负责消息的拉取。\n\n代码：PullMessageService#run\npublic void run() &#123;    log.info(this.getServiceName() + &quot; service started&quot;);\t//循环拉取消息    while (!this.isStopped()) &#123;        try &#123;            //从请求队列中获取拉取消息请求            PullRequest pullRequest = this.pullRequestQueue.take();            //拉取消息            this.pullMessage(pullRequest);        &#125; catch (InterruptedException ignored) &#123;        &#125; catch (Exception e) &#123;            log.error(&quot;Pull Message Service Run Method exception&quot;, e);        &#125;    &#125;    log.info(this.getServiceName() + &quot; service end&quot;);&#125;\n\n\n\nPullRequest\n\nprivate String consumerGroup;\t//消费者组private MessageQueue messageQueue;\t//待拉取消息队列private ProcessQueue processQueue;\t//消息处理队列private long nextOffset;\t//待拉取的MessageQueue偏移量private boolean lockedFirst = false;\t//是否被锁定\n\n\n\n代码：PullMessageService#pullMessage\nprivate void pullMessage(final PullRequest pullRequest) &#123;    //获得消费者实例    final MQConsumerInner consumer = this.mQClientFactory.selectConsumer(pullRequest.getConsumerGroup());    if (consumer != null) &#123;        //强转为推送模式消费者        DefaultMQPushConsumerImpl impl = (DefaultMQPushConsumerImpl) consumer;        //推送消息        impl.pullMessage(pullRequest);    &#125; else &#123;        log.warn(&quot;No matched consumer for the PullRequest &#123;&#125;, drop it&quot;, pullRequest);    &#125;&#125;\n\n\n\n####2）ProcessQueue实现机制\nProcessQueue是MessageQueue在消费端的重现、快照。PullMessageService从消息服务器默认每次拉取32条消息，按照消息的队列偏移量顺序存放在ProcessQueue中，PullMessageService然后将消息提交到消费者消费线程池，消息成功消费后从ProcessQueue中移除。\n\n属性\n//消息容器private final TreeMap&lt;Long, MessageExt&gt; msgTreeMap = new TreeMap&lt;Long, MessageExt&gt;();//读写锁private final ReadWriteLock lockTreeMap = new ReentrantReadWriteLock();//ProcessQueue总消息树private final AtomicLong msgCount = new AtomicLong();//ProcessQueue队列最大偏移量private volatile long queueOffsetMax = 0L;//当前ProcessQueue是否被丢弃private volatile boolean dropped = false;//上一次拉取时间戳private volatile long lastPullTimestamp = System.currentTimeMillis();//上一次消费时间戳private volatile long lastConsumeTimestamp = System.currentTimeMillis();\n\n\n\n方法\n//移除消费超时消息public void cleanExpiredMsg(DefaultMQPushConsumer pushConsumer)//添加消息public boolean putMessage(final List&lt;MessageExt&gt; msgs)//获取消息最大间隔public long getMaxSpan()//移除消息public long removeMessage(final List&lt;MessageExt&gt; msgs)//将consumingMsgOrderlyTreeMap中消息重新放在msgTreeMap,并清空consumingMsgOrderlyTreeMap   public void rollback() //将consumingMsgOrderlyTreeMap消息清除,表示成功处理该批消息public long commit()//重新处理该批消息public void makeMessageToCosumeAgain(List&lt;MessageExt&gt; msgs) //从processQueue中取出batchSize条消息public List&lt;MessageExt&gt; takeMessags(final int batchSize)\n\n\n\n3）消息拉取基本流程#####1.客户端发起拉取请求\n\n代码：DefaultMQPushConsumerImpl#pullMessage\npublic void pullMessage(final PullRequest pullRequest) &#123;    //从pullRequest获得ProcessQueue    final ProcessQueue processQueue = pullRequest.getProcessQueue();    //如果处理队列被丢弃,直接返回    if (processQueue.isDropped()) &#123;        log.info(&quot;the pull request[&#123;&#125;] is dropped.&quot;, pullRequest.toString());        return;    &#125;\t//如果处理队列未被丢弃,更新时间戳    pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis());    try &#123;        this.makeSureStateOK();    &#125; catch (MQClientException e) &#123;        log.warn(&quot;pullMessage exception, consumer state not ok&quot;, e);        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);        return;    &#125;\t//如果处理队列被挂起,延迟1s后再执行    if (this.isPause()) &#123;        log.warn(&quot;consumer was paused, execute pull request later. instanceName=&#123;&#125;, group=&#123;&#125;&quot;, this.defaultMQPushConsumer.getInstanceName(), this.defaultMQPushConsumer.getConsumerGroup());        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND);        return;    &#125;\t//获得最大待处理消息数量\tlong cachedMessageCount = processQueue.getMsgCount().get();    //获得最大待处理消息大小\tlong cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024);\t//从数量进行流控\tif (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123;\t    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);\t    if ((queueFlowControlTimes++ % 1000) == 0) &#123;\t        log.warn(\t            &quot;the cached message count exceeds the threshold &#123;&#125;, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,\t            this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);\t    &#125;\t    return;\t&#125;\t//从消息大小进行流控\tif (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123;\t    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);\t    if ((queueFlowControlTimes++ % 1000) == 0) &#123;\t        log.warn(\t            &quot;the cached message size exceeds the threshold &#123;&#125; MiB, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,\t            this.defaultMQPushConsumer.getPullThresholdSizeForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);\t    &#125;\t    return;    &#125;    \t//获得订阅信息\t\t final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic());    \tif (null == subscriptionData) &#123;    \t    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);    \t    log.warn(&quot;find the consumer&#x27;s subscription failed, &#123;&#125;&quot;, pullRequest);    \t    return;\t\t//与服务端交互,获取消息\t    this.pullAPIWrapper.pullKernelImpl(\t    pullRequest.getMessageQueue(),\t    subExpression,\t    subscriptionData.getExpressionType(),\t    subscriptionData.getSubVersion(),\t    pullRequest.getNextOffset(),\t    this.defaultMQPushConsumer.getPullBatchSize(),\t    sysFlag,\t    commitOffsetValue,\t    BROKER_SUSPEND_MAX_TIME_MILLIS,\t    CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND,\t    CommunicationMode.ASYNC,\t    pullCallback\t);            &#125;\n\n\n\n#####2.消息服务端Broker组装消息\n\n代码：PullMessageProcessor#processRequest\n//构建消息过滤器MessageFilter messageFilter;if (this.brokerController.getBrokerConfig().isFilterSupportRetry()) &#123;    messageFilter = new ExpressionForRetryMessageFilter(subscriptionData, consumerFilterData,        this.brokerController.getConsumerFilterManager());&#125; else &#123;    messageFilter = new ExpressionMessageFilter(subscriptionData, consumerFilterData,        this.brokerController.getConsumerFilterManager());&#125;//调用MessageStore.getMessage查找消息final GetMessageResult getMessageResult =    this.brokerController.getMessageStore().getMessage(    \t\t\t\trequestHeader.getConsumerGroup(), //消费组名称\t\t\t\t\t\t\t\t    \t\t\t\trequestHeader.getTopic(),\t//主题名称        \t\t\trequestHeader.getQueueId(), //队列ID    \t\t\t\trequestHeader.getQueueOffset(), \t//待拉取偏移量    \t\t\t\trequestHeader.getMaxMsgNums(), \t//最大拉取消息条数    \t\t\t\tmessageFilter\t//消息过滤器    \t\t);\n\n\n\n代码：DefaultMessageStore#getMessage\nGetMessageStatus status = GetMessageStatus.NO_MESSAGE_IN_QUEUE;long nextBeginOffset = offset;\t//查找下一次队列偏移量long minOffset = 0;\t\t//当前消息队列最小偏移量long maxOffset = 0;\t\t//当前消息队列最大偏移量GetMessageResult getResult = new GetMessageResult();final long maxOffsetPy = this.commitLog.getMaxOffset();\t//当前commitLog最大偏移量//根据主题名称和队列编号获取消息消费队列ConsumeQueue consumeQueue = findConsumeQueue(topic, queueId);...minOffset = consumeQueue.getMinOffsetInQueue();maxOffset = consumeQueue.getMaxOffsetInQueue();//消息偏移量异常情况校对下一次拉取偏移量if (maxOffset == 0) &#123;\t//表示当前消息队列中没有消息    status = GetMessageStatus.NO_MESSAGE_IN_QUEUE;    nextBeginOffset = nextOffsetCorrection(offset, 0);&#125; else if (offset &lt; minOffset) &#123;\t//待拉取消息的偏移量小于队列的其实偏移量    status = GetMessageStatus.OFFSET_TOO_SMALL;    nextBeginOffset = nextOffsetCorrection(offset, minOffset);&#125; else if (offset == maxOffset) &#123;\t//待拉取偏移量为队列最大偏移量    status = GetMessageStatus.OFFSET_OVERFLOW_ONE;    nextBeginOffset = nextOffsetCorrection(offset, offset);&#125; else if (offset &gt; maxOffset) &#123;\t//偏移量越界    status = GetMessageStatus.OFFSET_OVERFLOW_BADLY;    if (0 == minOffset) &#123;        nextBeginOffset = nextOffsetCorrection(offset, minOffset);    &#125; else &#123;        nextBeginOffset = nextOffsetCorrection(offset, maxOffset);    &#125;&#125;...//根据偏移量从CommitLog中拉取32条消息SelectMappedBufferResult selectResult = this.commitLog.getMessage(offsetPy, sizePy);\n\n\n\n代码：PullMessageProcessor#processRequest\n//根据拉取结果填充responseHeaderresponse.setRemark(getMessageResult.getStatus().name());responseHeader.setNextBeginOffset(getMessageResult.getNextBeginOffset());responseHeader.setMinOffset(getMessageResult.getMinOffset());responseHeader.setMaxOffset(getMessageResult.getMaxOffset());//判断如果存在主从同步慢,设置下一次拉取任务的ID为主节点switch (this.brokerController.getMessageStoreConfig().getBrokerRole()) &#123;    case ASYNC_MASTER:    case SYNC_MASTER:        break;    case SLAVE:        if (!this.brokerController.getBrokerConfig().isSlaveReadEnable()) &#123;            response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);            responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID);        &#125;        break;&#125;...//GetMessageResult与Response的Code转换switch (getMessageResult.getStatus()) &#123;    case FOUND:\t\t\t//成功        response.setCode(ResponseCode.SUCCESS);        break;    case MESSAGE_WAS_REMOVING:\t//消息存放在下一个commitLog中        response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);\t//消息重试        break;    case NO_MATCHED_LOGIC_QUEUE:\t//未找到队列    case NO_MESSAGE_IN_QUEUE:\t//队列中未包含消息        if (0 != requestHeader.getQueueOffset()) &#123;            response.setCode(ResponseCode.PULL_OFFSET_MOVED);            requestHeader.getQueueOffset(),            getMessageResult.getNextBeginOffset(),            requestHeader.getTopic(),            requestHeader.getQueueId(),            requestHeader.getConsumerGroup()            );        &#125; else &#123;            response.setCode(ResponseCode.PULL_NOT_FOUND);        &#125;        break;    case NO_MATCHED_MESSAGE:\t//未找到消息        response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);        break;    case OFFSET_FOUND_NULL:\t//消息物理偏移量为空        response.setCode(ResponseCode.PULL_NOT_FOUND);        break;    case OFFSET_OVERFLOW_BADLY:\t//offset越界        response.setCode(ResponseCode.PULL_OFFSET_MOVED);        // XXX: warn and notify me        log.info(&quot;the request offset: &#123;&#125; over flow badly, broker max offset: &#123;&#125;, consumer: &#123;&#125;&quot;,                requestHeader.getQueueOffset(), getMessageResult.getMaxOffset(), channel.remoteAddress());        break;    case OFFSET_OVERFLOW_ONE:\t//offset在队列中未找到        response.setCode(ResponseCode.PULL_NOT_FOUND);        break;    case OFFSET_TOO_SMALL:\t//offset未在队列中        response.setCode(ResponseCode.PULL_OFFSET_MOVED);        requestHeader.getConsumerGroup(),         requestHeader.getTopic(),         requestHeader.getQueueOffset(),        getMessageResult.getMinOffset(), channel.remoteAddress());        break;    default:        assert false;        break;&#125;...//如果CommitLog标记可用,并且当前Broker为主节点,则更新消息消费进度boolean storeOffsetEnable = brokerAllowSuspend;storeOffsetEnable = storeOffsetEnable &amp;&amp; hasCommitOffsetFlag;storeOffsetEnable = storeOffsetEnable    &amp;&amp; this.brokerController.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE;if (storeOffsetEnable) &#123;    this.brokerController.getConsumerOffsetManager().commitOffset(RemotingHelper.parseChannelRemoteAddr(channel),        requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getCommitOffset());&#125;\n\n\n\n#####3.消息拉取客户端处理消息\n\n代码：MQClientAPIImpl#processPullResponse\nprivate PullResult processPullResponse(    final RemotingCommand response) throws MQBrokerException, RemotingCommandException &#123;    PullStatus pullStatus = PullStatus.NO_NEW_MSG;   \t//判断响应结果    switch (response.getCode()) &#123;        case ResponseCode.SUCCESS:            pullStatus = PullStatus.FOUND;            break;        case ResponseCode.PULL_NOT_FOUND:            pullStatus = PullStatus.NO_NEW_MSG;            break;        case ResponseCode.PULL_RETRY_IMMEDIATELY:            pullStatus = PullStatus.NO_MATCHED_MSG;            break;        case ResponseCode.PULL_OFFSET_MOVED:            pullStatus = PullStatus.OFFSET_ILLEGAL;            break;        default:            throw new MQBrokerException(response.getCode(), response.getRemark());    &#125;\t//解码响应头    PullMessageResponseHeader responseHeader =        (PullMessageResponseHeader) response.decodeCommandCustomHeader(PullMessageResponseHeader.class);\t//封装PullResultExt返回    return new PullResultExt(pullStatus, responseHeader.getNextBeginOffset(), responseHeader.getMinOffset(),        responseHeader.getMaxOffset(), null, responseHeader.getSuggestWhichBrokerId(), response.getBody());&#125;\n\n\n\nPullResult类\nprivate final PullStatus pullStatus;\t//拉取结果private final long nextBeginOffset;\t//下次拉取偏移量private final long minOffset;\t//消息队列最小偏移量private final long maxOffset;\t//消息队列最大偏移量private List&lt;MessageExt&gt; msgFoundList;\t//拉取的消息列表\n\n\n\n\n代码：DefaultMQPushConsumerImpl$PullCallback#OnSuccess\n//将拉取到的消息存入processQueueboolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList());//将processQueue提交到consumeMessageService中供消费者消费DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest(    pullResult.getMsgFoundList(),    processQueue,    pullRequest.getMessageQueue(),    dispatchToConsume);//如果pullInterval大于0,则等待pullInterval毫秒后将pullRequest对象放入到PullMessageService中的pullRequestQueue队列中if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) &#123;    DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest,        DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval());&#125; else &#123;    DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);&#125;\n\n\n\n4.消息拉取总结\n4）消息拉取长轮询机制分析RocketMQ未真正实现消息推模式，而是消费者主动向消息服务器拉取消息，RocketMQ推模式是循环向消息服务端发起消息拉取请求，如果消息消费者向RocketMQ拉取消息时，消息未到达消费队列时，如果不启用长轮询机制，则会在服务端等待shortPollingTimeMills时间后（挂起）再去判断消息是否已经到达指定消息队列，如果消息仍未到达则提示拉取消息客户端PULL—NOT—FOUND（消息不存在）；如果开启长轮询模式，RocketMQ一方面会每隔5s轮询检查一次消息是否可达，同时一有消息达到后立马通知挂起线程再次验证消息是否是自己感兴趣的消息，如果是则从CommitLog文件中提取消息返回给消息拉取客户端，否则直到挂起超时，超时时间由消息拉取方在消息拉取是封装在请求参数中，PUSH模式为15s，PULL模式通过DefaultMQPullConsumer#setBrokerSuspendMaxTimeMillis设置。RocketMQ通过在Broker客户端配置longPollingEnable为true来开启长轮询模式。\n代码：PullMessageProcessor#processRequest\n//当没有拉取到消息时，通过长轮询方式继续拉取消息case ResponseCode.PULL_NOT_FOUND:    if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123;        long pollingTimeMills = suspendTimeoutMillisLong;        if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;            pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills();        &#125;        String topic = requestHeader.getTopic();        long offset = requestHeader.getQueueOffset();        int queueId = requestHeader.getQueueId();        //构建拉取请求对象        PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills,            this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter);        //处理拉取请求        this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest);        response = null;        break;    &#125;\n\n\n\nPullRequestHoldService方式实现长轮询\n代码：PullRequestHoldService#suspendPullRequest\n//将拉取消息请求，放置在ManyPullRequest集合中public void suspendPullRequest(final String topic, final int queueId, final PullRequest pullRequest) &#123;    String key = this.buildKey(topic, queueId);    ManyPullRequest mpr = this.pullRequestTable.get(key);    if (null == mpr) &#123;        mpr = new ManyPullRequest();        ManyPullRequest prev = this.pullRequestTable.putIfAbsent(key, mpr);        if (prev != null) &#123;            mpr = prev;        &#125;    &#125;    mpr.addPullRequest(pullRequest);&#125;\n\n\n\n代码：PullRequestHoldService#run\npublic void run() &#123;    log.info(&quot;&#123;&#125; service started&quot;, this.getServiceName());    while (!this.isStopped()) &#123;        try &#123;            //如果开启长轮询每隔5秒判断消息是否到达            if (this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;                this.waitForRunning(5 * 1000);            &#125; else &#123;                //没有开启长轮询,每隔1s再次尝试              this.waitForRunning(this.brokerController.getBrokerConfig().getShortPollingTimeMills());            &#125;            long beginLockTimestamp = this.systemClock.now();            this.checkHoldRequest();            long costTime = this.systemClock.now() - beginLockTimestamp;            if (costTime &gt; 5 * 1000) &#123;                log.info(&quot;[NOTIFYME] check hold request cost &#123;&#125; ms.&quot;, costTime);            &#125;        &#125; catch (Throwable e) &#123;            log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    log.info(&quot;&#123;&#125; service end&quot;, this.getServiceName());&#125;\n\n\n\n代码：PullRequestHoldService#checkHoldRequest\n//遍历拉取任务private void checkHoldRequest() &#123;    for (String key : this.pullRequestTable.keySet()) &#123;        String[] kArray = key.split(TOPIC_QUEUEID_SEPARATOR);        if (2 == kArray.length) &#123;            String topic = kArray[0];            int queueId = Integer.parseInt(kArray[1]);            //获得消息偏移量            final long offset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId);            try &#123;                //通知有消息达到                this.notifyMessageArriving(topic, queueId, offset);            &#125; catch (Throwable e) &#123;                log.error(&quot;check hold request failed. topic=&#123;&#125;, queueId=&#123;&#125;&quot;, topic, queueId, e);            &#125;        &#125;    &#125;&#125;\n\n\n\n代码：PullRequestHoldService#notifyMessageArriving\n//如果拉取消息偏移大于请求偏移量,如果消息匹配调用executeRequestWhenWakeup处理消息if (newestOffset &gt; request.getPullFromThisOffset()) &#123;    boolean match = request.getMessageFilter().isMatchedByConsumeQueue(tagsCode,        new ConsumeQueueExt.CqExtUnit(tagsCode, msgStoreTime, filterBitMap));    // match by bit map, need eval again when properties is not null.    if (match &amp;&amp; properties != null) &#123;        match = request.getMessageFilter().isMatchedByCommitLog(null, properties);    &#125;    if (match) &#123;        try &#123;            this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(),                request.getRequestCommand());        &#125; catch (Throwable e) &#123;            log.error(&quot;execute request when wakeup failed.&quot;, e);        &#125;        continue;    &#125;&#125;//如果过期时间超时,则不继续等待将直接返回给客户端消息未找到if (System.currentTimeMillis() &gt;= (request.getSuspendTimestamp() + request.getTimeoutMillis())) &#123;    try &#123;        this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(),            request.getRequestCommand());    &#125; catch (Throwable e) &#123;        log.error(&quot;execute request when wakeup failed.&quot;, e);    &#125;    continue;&#125;\n\n\n\n如果开启了长轮询机制，PullRequestHoldService会每隔5s被唤醒去尝试检测是否有新的消息的到来才给客户端响应，或者直到超时才给客户端进行响应，消息实时性比较差，为了避免这种情况，RocketMQ引入另外一种机制：当消息到达时唤醒挂起线程触发一次检查。\nDefaultMessageStore$ReputMessageService机制\n代码：DefaultMessageStore#start\n//长轮询入口this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);this.reputMessageService.start();\n\n\n\n代码：DefaultMessageStore$ReputMessageService#run\npublic void run() &#123;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service started&quot;);    while (!this.isStopped()) &#123;        try &#123;            Thread.sleep(1);            //长轮询核心逻辑代码入口            this.doReput();        &#125; catch (Exception e) &#123;            DefaultMessageStore.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service end&quot;);&#125;\n\n\n\n代码：DefaultMessageStore$ReputMessageService#deReput\n//当新消息达到是,进行通知监听器进行处理if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole()    &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123;    DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(),        dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1,        dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),        dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());&#125;\n\n\n\n代码：NotifyMessageArrivingListener#arriving\npublic void arriving(String topic, int queueId, long logicOffset, long tagsCode,    long msgStoreTime, byte[] filterBitMap, Map&lt;String, String&gt; properties) &#123;    this.pullRequestHoldService.notifyMessageArriving(topic, queueId, logicOffset, tagsCode,        msgStoreTime, filterBitMap, properties);&#125;\n\n\n\n2.5.5 消息队列负载与重新分布机制RocketMQ消息队列重新分配是由RebalanceService线程来实现。一个MQClientInstance持有一个RebalanceService实现，并随着MQClientInstance的启动而启动。\n代码：RebalanceService#run\npublic void run() &#123;    log.info(this.getServiceName() + &quot; service started&quot;);\t//RebalanceService线程默认每隔20s执行一次mqClientFactory.doRebalance方法    while (!this.isStopped()) &#123;        this.waitForRunning(waitInterval);        this.mqClientFactory.doRebalance();    &#125;    log.info(this.getServiceName() + &quot; service end&quot;);&#125;\n\n\n\n代码：MQClientInstance#doRebalance\npublic void doRebalance() &#123;    //MQClientInstance遍历以注册的消费者,对消费者执行doRebalance()方法    for (Map.Entry&lt;String, MQConsumerInner&gt; entry : this.consumerTable.entrySet()) &#123;        MQConsumerInner impl = entry.getValue();        if (impl != null) &#123;            try &#123;                impl.doRebalance();            &#125; catch (Throwable e) &#123;                log.error(&quot;doRebalance exception&quot;, e);            &#125;        &#125;    &#125;&#125;\n\n\n\n代码：RebalanceImpl#doRebalance\n//遍历订阅消息对每个主题的订阅的队列进行重新负载public void doRebalance(final boolean isOrder) &#123;    Map&lt;String, SubscriptionData&gt; subTable = this.getSubscriptionInner();    if (subTable != null) &#123;        for (final Map.Entry&lt;String, SubscriptionData&gt; entry : subTable.entrySet()) &#123;            final String topic = entry.getKey();            try &#123;                this.rebalanceByTopic(topic, isOrder);            &#125; catch (Throwable e) &#123;                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123;                    log.warn(&quot;rebalanceByTopic Exception&quot;, e);                &#125;            &#125;        &#125;    &#125;    this.truncateMessageQueueNotMyTopic();&#125;\n\n\n\n代码：RebalanceImpl#rebalanceByTopic\n//从主题订阅消息缓存表中获取主题的队列信息Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);//查找该主题订阅组所有的消费者IDList&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);//给消费者重新分配队列if (mqSet != null &amp;&amp; cidAll != null) &#123;    List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;();    mqAll.addAll(mqSet);    Collections.sort(mqAll);    Collections.sort(cidAll);    AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;    List&lt;MessageQueue&gt; allocateResult = null;    try &#123;        allocateResult = strategy.allocate(            this.consumerGroup,            this.mQClientFactory.getClientId(),            mqAll,            cidAll);    &#125; catch (Throwable e) &#123;        log.error(&quot;AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName=&#123;&#125;&quot;, strategy.getName(),            e);        return;    &#125;\n\n\n\n\nRocketMQ默认提供5中负载均衡分配算法\nAllocateMessageQueueAveragely:平均分配举例:8个队列q1,q2,q3,q4,q5,a6,q7,q8,消费者3个:c1,c2,c3分配如下:c1:q1,q2,q3c2:q4,q5,a6c3:q7,q8AllocateMessageQueueAveragelyByCircle:平均轮询分配举例:8个队列q1,q2,q3,q4,q5,a6,q7,q8,消费者3个:c1,c2,c3分配如下:c1:q1,q4,q7c2:q2,q5,a8c3:q3,q6\n\n\n\n注意：消息队列的分配遵循一个消费者可以分配到多个队列，但同一个消息队列只会分配给一个消费者，故如果出现消费者个数大于消息队列数量，则有些消费者无法消费消息。\n2.5.6 消息消费过程PullMessageService负责对消息队列进行消息拉取，从远端服务器拉取消息后将消息存储ProcessQueue消息队列处理队列中，然后调用ConsumeMessageService#submitConsumeRequest方法进行消息消费，使用线程池来消费消息，确保了消息拉取与消息消费的解耦。ConsumeMessageService支持顺序消息和并发消息，核心类图如下：\n\n并发消息消费\n代码：ConsumeMessageConcurrentlyService#submitConsumeRequest\n//消息批次单次final int consumeBatchSize = this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize();//msgs.size()默认最多为32条。//如果msgs.size()小于consumeBatchSize,则直接将拉取到的消息放入到consumeRequest,然后将consumeRequest提交到消费者线程池中if (msgs.size() &lt;= consumeBatchSize) &#123;    ConsumeRequest consumeRequest = new ConsumeRequest(msgs, processQueue, messageQueue);    try &#123;        this.consumeExecutor.submit(consumeRequest);    &#125; catch (RejectedExecutionException e) &#123;        this.submitConsumeRequestLater(consumeRequest);    &#125;&#125;else&#123;\t//如果拉取的消息条数大于consumeBatchSize,则对拉取消息进行分页       for (int total = 0; total &lt; msgs.size(); ) &#123;   \t\t    List&lt;MessageExt&gt; msgThis = new ArrayList&lt;MessageExt&gt;(consumeBatchSize);   \t\t    for (int i = 0; i &lt; consumeBatchSize; i++, total++) &#123;   \t\t        if (total &lt; msgs.size()) &#123;   \t\t            msgThis.add(msgs.get(total));   \t\t        &#125; else &#123;   \t\t            break;   \t\t        &#125;   \t\t   \t\t    ConsumeRequest consumeRequest = new ConsumeRequest(msgThis, processQueue, messageQueue);   \t\t    try &#123;   \t\t        this.consumeExecutor.submit(consumeRequest);   \t\t    &#125; catch (RejectedExecutionException e) &#123;   \t\t        for (; total &lt; msgs.size(); total++) &#123;   \t\t            msgThis.add(msgs.get(total));   \t\t    \t\t        this.submitConsumeRequestLater(consumeRequest);   \t\t    &#125;   \t\t&#125;&#125;\n\n\n\n代码：ConsumeMessageConcurrentlyService$ConsumeRequest#run\n//检查processQueue的dropped,如果为true,则停止该队列消费。if (this.processQueue.isDropped()) &#123;    log.info(&quot;the message queue not be able to consume, because it&#x27;s dropped. group=&#123;&#125; &#123;&#125;&quot;, ConsumeMessageConcurrentlyService.this.consumerGroup, this.messageQueue);    return;&#125;...//执行消息处理的钩子函数if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123;    consumeMessageContext = new ConsumeMessageContext();    consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace());    consumeMessageContext.setConsumerGroup(defaultMQPushConsumer.getConsumerGroup());    consumeMessageContext.setProps(new HashMap&lt;String, String&gt;());    consumeMessageContext.setMq(messageQueue);    consumeMessageContext.setMsgList(msgs);    consumeMessageContext.setSuccess(false);    ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext);&#125;...//调用应用程序消息监听器的consumeMessage方法,进入到具体的消息消费业务处理逻辑status = listener.consumeMessage(Collections.unmodifiableList(msgs), context);//执行消息处理后的钩子函数if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123;    consumeMessageContext.setStatus(status.toString());    consumeMessageContext.setSuccess(ConsumeConcurrentlyStatus.CONSUME_SUCCESS == status);    ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext);&#125;\n\n\n\n2.5.7 定时消息机制定时消息是消息发送到Broker后，并不立即被消费者消费而是要等到特定的时间后才能被消费，RocketMQ并不支持任意的时间精度，如果要支持任意时间精度定时调度，不可避免地需要在Broker层做消息排序，再加上持久化方面的考量，将不可避免的带来巨大的性能消耗，所以RocketMQ只支持特定级别的延迟消息。消息延迟级别在Broker端通过messageDelayLevel配置，默认为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，delayLevel&#x3D;1表示延迟消息1s,delayLevel&#x3D;2表示延迟5s,依次类推。\nRocketMQ定时消息实现类为ScheduleMessageService，该类在DefaultMessageStore中创建。通过在DefaultMessageStore中调用load方法加载该类并调用start方法启动。\n代码：ScheduleMessageService#load\n//加载延迟消息消费进度的加载与delayLevelTable的构造。延迟消息的进度默认存储路径为/store/config/delayOffset.jsonpublic boolean load() &#123;    boolean result = super.load();    result = result &amp;&amp; this.parseDelayLevel();    return result;&#125;\n\n\n\n代码：ScheduleMessageService#start\n//遍历延迟队列创建定时任务,遍历延迟级别，根据延迟级别level从offsetTable中获取消费队列的消费进度。如果不存在，则使用0for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) &#123;    Integer level = entry.getKey();    Long timeDelay = entry.getValue();    Long offset = this.offsetTable.get(level);    if (null == offset) &#123;        offset = 0L;    &#125;    if (timeDelay != null) &#123;        this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME);    &#125;&#125;//每隔10s持久化一次延迟队列的消息消费进度this.timer.scheduleAtFixedRate(new TimerTask() &#123;    @Override    public void run() &#123;        try &#123;            if (started.get()) ScheduleMessageService.this.persist();        &#125; catch (Throwable e) &#123;            log.error(&quot;scheduleAtFixedRate flush exception&quot;, e);        &#125;    &#125;&#125;, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval());\n\n\n\n调度机制\nScheduleMessageService的start方法启动后，会为每一个延迟级别创建一个调度任务，每一个延迟级别对应SCHEDULE_TOPIC_XXXX主题下的一个消息消费队列。定时调度任务的实现类为DeliverDelayedMessageTimerTask，核心实现方法为executeOnTimeup\n代码：ScheduleMessageService$DeliverDelayedMessageTimerTask#executeOnTimeup\n//根据队列ID与延迟主题查找消息消费队列ConsumeQueue cq =    ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(SCHEDULE_TOPIC,        delayLevel2QueueId(delayLevel));...//根据偏移量从消息消费队列中获取当前队列中所有有效的消息SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(this.offset);...//遍历ConsumeQueue,解析消息队列中消息for (; i &lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) &#123;    long offsetPy = bufferCQ.getByteBuffer().getLong();    int sizePy = bufferCQ.getByteBuffer().getInt();    long tagsCode = bufferCQ.getByteBuffer().getLong();    if (cq.isExtAddr(tagsCode)) &#123;        if (cq.getExt(tagsCode, cqExtUnit)) &#123;            tagsCode = cqExtUnit.getTagsCode();        &#125; else &#123;            //can&#x27;t find ext content.So re compute tags code.            log.error(&quot;[BUG] can&#x27;t find consume queue extend file content!addr=&#123;&#125;, offsetPy=&#123;&#125;, sizePy=&#123;&#125;&quot;,                tagsCode, offsetPy, sizePy);            long msgStoreTime = defaultMessageStore.getCommitLog().pickupStoreTimestamp(offsetPy, sizePy);            tagsCode = computeDeliverTimestamp(delayLevel, msgStoreTime);        &#125;    &#125;    long now = System.currentTimeMillis();    long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode);        ...    //根据消息偏移量与消息大小,从CommitLog中查找消息.  \tMessageExt msgExt =   ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(       offsetPy, sizePy);&#125; \n\n\n\n2.5.8 顺序消息顺序消息实现类是org.apache.rocketmq.client.impl.consumer.ConsumeMessageOrderlyService\n代码：ConsumeMessageOrderlyService#start\npublic void start() &#123;    //如果消息模式为集群模式，启动定时任务，默认每隔20s执行一次锁定分配给自己的消息消费队列    if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) &#123;        this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;            @Override            public void run() &#123;                ConsumeMessageOrderlyService.this.lockMQPeriodically();            &#125;        &#125;, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS);    &#125;&#125;\n\n\n\n代码：ConsumeMessageOrderlyService#submitConsumeRequest\n//构建消息任务,并提交消费线程池中public void submitConsumeRequest(    final List&lt;MessageExt&gt; msgs,    final ProcessQueue processQueue,    final MessageQueue messageQueue,    final boolean dispathToConsume) &#123;    if (dispathToConsume) &#123;        ConsumeRequest consumeRequest = new ConsumeRequest(processQueue, messageQueue);        this.consumeExecutor.submit(consumeRequest);    &#125;&#125;\n\n\n\n代码：ConsumeMessageOrderlyService$ConsumeRequest#run\n//如果消息队列为丢弃,则停止本次消费任务if (this.processQueue.isDropped()) &#123;    log.warn(&quot;run, the message queue not be able to consume, because it&#x27;s dropped. &#123;&#125;&quot;, this.messageQueue);    return;&#125;//从消息队列中获取一个对象。然后消费消息时先申请独占objLock锁。顺序消息一个消息消费队列同一时刻只会被一个消费线程池处理final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue);synchronized (objLock) &#123;\t...&#125;\n\n\n\n2.5.9 小结RocketMQ消息消费方式分别为集群模式、广播模式。\n消息队列负载由RebalanceService线程默认每隔20s进行一次消息队列负载，根据当前消费者组内消费者个数与主题队列数量按照某一种负载算法进行队列分配，分配原则为同一个消费者可以分配多个消息消费队列，同一个消息消费队列同一个时间只会分配给一个消费者。\n消息拉取由PullMessageService线程根据RebalanceService线程创建的拉取任务进行拉取，默认每次拉取32条消息，提交给消费者消费线程后继续下一次消息拉取。如果消息消费过慢产生消息堆积会触发消息消费拉取流控。\n并发消息消费指消费线程池中的线程可以并发对同一个消息队列的消息进行消费，消费成功后，取出消息队列中最小的消息偏移量作为消息消费进度偏移量存储在于消息消费进度存储文件中，集群模式消息消费进度存储在Broker（消息服务器），广播模式消息消费进度存储在消费者端。\nRocketMQ不支持任意精度的定时调度消息，只支持自定义的消息延迟级别，例如1s、2s、5s等，可通过在broker配置文件中设置messageDelayLevel。\n顺序消息一般使用集群模式，是指对消息消费者内的线程池中的线程对消息消费队列只能串行消费。并并发消息消费最本质的区别是消息消费时必须成功锁定消息消费队列，在Broker端会存储消息消费队列的锁占用情况。\n","categories":["RocketMQ"],"tags":["消息中间件"]},{"title":"Java基础-图谱&Q/A","url":"/2023/02/19/java%20%E5%9F%BA%E7%A1%80-%E5%9B%BE%E8%B0%B1&QA/","content":"java 基础-图谱&amp;Q&#x2F;A\n本文主要对Java基础知识体系小结，同时结合一些Q&amp;A进行理解。\n\n\n[参考文档]\n[知识体系]\nQ&amp;A\n[(#java-中应该使用什么数据类型来代表价格) Java 中应该使用什么数据类型来代表价格?]\n[怎么将 byte 转换为 String?]\n[Java 中怎样将 bytes 转换为 long 类型?]\n[我们能将 int 强制转换为 byte 类型的变量吗? 如果该值大于 byte 类型的范围，将会出现什么现象?]\n[存在两个类，B 继承 A，C 继承 B，我们能将 B 转换为 C 么? 如 C &#x3D; (C) B；]\n[哪个类包含 clone 方法? 是 Cloneable 还是 Object?]\n[Java 中 ++ 操作符是线程安全的吗?]\n[a &#x3D; a + b 与 a +&#x3D; b 的区别]\n[我能在不进行强制转换的情况下将一个 double 值赋值给 long 类型的变量吗?]\n[3*0.1 &#x3D;&#x3D; 0.3 将会返回什么? true 还是 false?]\n[int 和 Integer 哪个会占用更多的内存?]\n[为什么 Java 中的 String 是不可变的(Immutable)?]\n[我们能在 Switch 中使用 String 吗?]\n[Java 中的构造器链是什么?]\n[枚举类]\n[[什么是不可变对象(immutable object)? Java 中怎么创建一个不可变对象?]\n[我们能创建一个包含可变对象的不可变对象吗?]\n[有没有可能两个不相等的对象有有相同的 hashcode?]\n[两个相同的对象会有不同的的 hash code 吗?]\n[我们可以在 hashcode() 中使用随机数字吗?]\n[Java 中，Comparator 与 Comparable 有什么不同?]\n[为什么在重写 equals 方法的时候需要重写 hashCode 方法?]\n[“a&#x3D;&#x3D;b”和”a.equals(b)”有什么区别?]\n[a.hashCode() 有什么用? 与 a.equals(b) 有什么关系?]\n[final、finalize 和 finally 的不同之处?]\n[Java 中的编译期常量是什么? 使用它又什么风险?]\n[静态内部类与顶级类有什么区别?]\n[Java 中，Serializable 与 Externalizable 的区别?]\n[说出 JDK 1.7 中的三个新特性?]\n[说出 5 个 JDK 1.8 引入的新特性?]\n[接口是什么? 为什么要使用接口而不是直接使用具体类?]\n[Java 中，抽象类与接口之间有什么不同?]\n[Object有哪些公用方法?]\n[equals与&#x3D;&#x3D;的区别]\n[String、StringBuffer与StringBuilder的区别]\n[switch能否用String做参数]\n[接口与抽象类]\n[抽象类和最终类]\n[异常]\n[关于finally]\n[受检查异常和运行时异常]\n[super出现在父类的子类中。有三种存在方式]\n[this() &amp; super()在构造方法中的区别]\n[修饰符一览]\n[构造内部类和静态内部类对象]\n[序列化]\n[正则表达式]\n[Java移位运算符]\n[形参&amp;实参]\n[局部变量为什么要初始化]\n[Java语言的鲁棒性]\n[Java语言特性]\n[包装类的equals()方法不处理数据转型，必须类型和值都一样才相等。]\n[子类可以继承父类的静态方法！但是不能覆盖。因为静态方法是在编译时确定了，不能多态，也就是不能运行时绑定。]\n[Java语法糖]\n\n\n\n参考文档\nThinking in Java (Java 编程思想) Gitbook中文文档 https://java.quanke.name/\nThinking in Java (Java 编程思想) Github https://github.com/quanke/think-in-java\nThinking in Java (Java 编程思想) Gitbook2 https://www.gitbook.com/book/wizardforcel/thinking-in-java/details\n\n知识体系\nQ&amp;A(java-中应该使用什么数据类型来代表价格) Java 中应该使用什么数据类型来代表价格?如果不是特别关心内存和性能的话，使用BigDecimal，否则使用预定义精度的 double 类型。\n怎么将 byte 转换为 String?可以使用 String 接收 byte[] 参数的构造器来进行转换，需要注意的点是要使用的正确的编码，否则会使用平台默认编码，这个编码可能跟原来的编码相同，也可能不同。\nJava 中怎样将 bytes 转换为 long 类型?String接收bytes的构造器转成String，再Long.parseLong\n我们能将 int 强制转换为 byte 类型的变量吗? 如果该值大于 byte 类型的范围，将会出现什么现象?是的，我们可以做强制转换，但是 Java 中 int 是 32 位的，而 byte 是 8 位的，所以，如果强制转化是，int 类型的高 24 位将会被丢弃，byte 类型的范围是从 -128 到 127。\n存在两个类，B 继承 A，C 继承 B，我们能将 B 转换为 C 么? 如 C &#x3D; (C) B；可以，向下转型。但是不建议使用，容易出现类型转型异常.\n哪个类包含 clone 方法? 是 Cloneable 还是 Object?java.lang.Cloneable 是一个标示性接口，不包含任何方法，clone 方法在 object 类中定义。并且需要知道 clone() 方法是一个本地方法，这意味着它是由 c 或 c++ 或 其他本地语言实现的。\nJava 中 ++ 操作符是线程安全的吗?不是线程安全的操作。它涉及到多个指令，如读取变量值，增加，然后存储回内存，这个过程可能会出现多个线程交差。还会存在竞态条件(读取-修改-写入)。\na &#x3D; a + b 与 a +&#x3D; b 的区别+&#x3D; 隐式的将加操作的结果类型强制转换为持有结果的类型。如果两这个整型相加，如 byte、short 或者 int，首先会将它们提升到 int 类型，然后在执行加法操作。\nbyte a &#x3D; 127; byte b &#x3D; 127; b &#x3D; a + b; &#x2F;&#x2F; error : cannot convert from int to byte b +&#x3D; a; &#x2F;&#x2F; ok (因为 a+b 操作会将 a、b 提升为 int 类型，所以将 int 类型赋值给 byte 就会编译出错)\n我能在不进行强制转换的情况下将一个 double 值赋值给 long 类型的变量吗?不行，你不能在没有强制类型转换的前提下将一个 double 值赋值给 long 类型的变量，因为 double 类型的范围比 long 类型更广，所以必须要进行强制转换。\n3*0.1 &#x3D;&#x3D; 0.3 将会返回什么? true 还是 false?false，因为有些浮点数不能完全精确的表示出来。\nint 和 Integer 哪个会占用更多的内存?Integer 对象会占用更多的内存。Integer 是一个对象，需要存储对象的元数据。但是 int 是一个原始类型的数据，所以占用的空间更少。\n为什么 Java 中的 String 是不可变的(Immutable)?Java 中的 String 不可变是因为 Java 的设计者认为字符串使用非常频繁，将字符串设置为不可变可以允许多个客户端之间共享相同的字符串。更详细的内容参见答案。\n我们能在 Switch 中使用 String 吗?从 Java 7 开始，我们可以在 switch case 中使用字符串，但这仅仅是一个语法糖。内部实现在 switch 中使用字符串的 hash code。\nJava 中的构造器链是什么?当你从一个构造器中调用另一个构造器，就是Java 中的构造器链。这种情况只在重载了类的构造器的时候才会出现。\n枚举类JDK1.5出现 每个枚举值都需要调用一次构造函数\n什么是不可变对象(immutable object)? Java 中怎么创建一个不可变对象?不可变对象指对象一旦被创建，状态就不能再改变。任何修改都会创建一个新的对象，如 String、Integer及其它包装类。\n如何在Java中写出Immutable的类?\n要写出这样的类，需要遵循以下几个原则:\n1)immutable对象的状态在创建之后就不能发生改变，任何对它的改变都应该产生一个新的对象。\n2)Immutable类的所有的属性都应该是final的。\n3)对象必须被正确的创建，比如: 对象引用在对象创建过程中不能泄露(leak)。\n4)对象应该是final的，以此来限制子类继承父类，以避免子类改变了父类的immutable特性。\n5)如果类中包含mutable类对象，那么返回给客户端的时候，返回该对象的一个拷贝，而不是该对象本身(该条可以归为第一条中的一个特例)\n我们能创建一个包含可变对象的不可变对象吗?是的，我们是可以创建一个包含可变对象的不可变对象的，你只需要谨慎一点，不要共享可变对象的引用就可以了，如果需要变化时，就返回原对象的一个拷贝。最常见的例子就是对象中包含一个日期对象的引用。\n有没有可能两个不相等的对象有有相同的 hashcode?有可能，两个不相等的对象可能会有相同的 hashcode 值，这就是为什么在 hashmap 中会有冲突。相等 hashcode 值的规定只是说如果两个对象相等，必须有相同的hashcode 值，但是没有关于不相等对象的任何规定。\n两个相同的对象会有不同的的 hash code 吗?不能，根据 hash code 的规定，这是不可能的。\n我们可以在 hashcode() 中使用随机数字吗?不行，因为对象的 hashcode 值必须是相同的。\nJava 中，Comparator 与 Comparable 有什么不同?Comparable 接口用于定义对象的自然顺序，而 comparator 通常用于定义用户定制的顺序。Comparable 总是只有一个，但是可以有多个 comparator 来定义对象的顺序。\n为什么在重写 equals 方法的时候需要重写 hashCode 方法?因为有强制的规范指定需要同时重写 hashcode 与 equal 是方法，许多容器类，如 HashMap、HashSet 都依赖于 hashcode 与 equals 的规定。\n“a&#x3D;&#x3D;b”和”a.equals(b)”有什么区别?如果 a 和 b 都是对象，则 a&#x3D;&#x3D;b 是比较两个对象的引用，只有当 a 和 b 指向的是堆中的同一个对象才会返回 true，而 a.equals(b) 是进行逻辑比较，所以通常需要重写该方法来提供逻辑一致性的比较。例如，String 类重写 equals() 方法，所以可以用于两个不同对象，但是包含的字母相同的比较。\na.hashCode() 有什么用? 与 a.equals(b) 有什么关系?简介: hashCode() 方法是相应对象整型的 hash 值。它常用于基于 hash 的集合类，如 Hashtable、HashMap、LinkedHashMap等等。它与 equals() 方法关系特别紧密。根据 Java 规范，两个使用 equal() 方法来判断相等的对象，必须具有相同的 hash code。\n1、hashcode的作用\nList和Set，如何保证Set不重复呢? 通过迭代使用equals方法来判断，数据量小还可以接受，数据量大怎么解决? 引入hashcode，实际上hashcode扮演的角色就是寻址，大大减少查询匹配次数。\n2、hashcode重要吗\n对于数组、List集合就是一个累赘。而对于hashmap, hashset, hashtable就异常重要了。\n3、equals方法遵循的原则\n对称性 若x.equals(y)true，则y.equals(x)true 自反性 x.equals(x)必须true 传递性 若x.equals(y)true,y.equals(z)true,则x.equals(z)必为true 一致性 只要x,y内容不变，无论调用多少次结果不变 其他 x.equals(null) 永远false，x.equals(和x数据类型不同)始终false 两者的关系\nfinal、finalize 和 finally 的不同之处?final 是一个修饰符，可以修饰变量、方法和类。如果 final 修饰变量，意味着该变量的值在初始化后不能被改变。Java 技术允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在确定这个对象没有被引用时对这个对象调用的，但是什么时候调用 finalize 没有保证。finally 是一个关键字，与 try 和 catch 一起用于异常的处理。finally 块一定会被执行，无论在 try 块中是否有发生异常。\nJava 中的编译期常量是什么? 使用它又什么风险?变量也就是我们所说的编译期常量，这里的 public 可选的。实际上这些变量在编译时会被替换掉，因为编译器知道这些变量的值，并且知道这些变量在运行时不能改变。这种方式存在的一个问题是你使用了一个内部的或第三方库中的公有编译时常量，但是这个值后面被其他人改变了，但是你的客户端仍然在使用老的值，甚至你已经部署了一个新的jar。为了避免这种情况，当你在更新依赖 JAR 文件时，确保重新编译你的程序。\n静态内部类与顶级类有什么区别?一个公共的顶级类的源文件名称与类名相同，而嵌套静态类没有这个要求。一个嵌套类位于顶级类内部，需要使用顶级类的名称来引用嵌套静态类，如 HashMap.Entry 是一个嵌套静态类，HashMap 是一个顶级类，Entry是一个嵌套静态类。\nJava 中，Serializable 与 Externalizable 的区别?Serializable 接口是一个序列化 Java 类的接口，以便于它们可以在网络上传输或者可以将它们的状态保存在磁盘上，是 JVM 内嵌的默认序列化方式，成本高、脆弱而且不安全。Externalizable 允许你控制整个序列化过程，指定特定的二进制格式，增加安全机制。\n说出 JDK 1.7 中的三个新特性?虽然 JDK 1.7 不像 JDK 5 和 8 一样的大版本，但是，还是有很多新的特性，如 try-with-resource 语句，这样你在使用流或者资源的时候，就不需要手动关闭，Java 会自动关闭。Fork-Join 池某种程度上实现 Java 版的 Map-reduce。允许 Switch 中有 String 变量和文本。菱形操作符(&lt;&gt;)用于泛型推断，不再需要在变量声明的右边申明泛型，因此可以写出可读写更强、更简洁的代码。另一个值得一提的特性是改善异常处理，如允许在同一个 catch 块中捕获多个异常。\n说出 5 个 JDK 1.8 引入的新特性?Java 8 在 Java 历史上是一个开创新的版本，下面 JDK 8 中 5 个主要的特性: Lambda 表达式，允许像对象一样传递匿名函数 Stream API，充分利用现代多核 CPU，可以写出很简洁的代码 Date 与 Time API，最终，有一个稳定、简单的日期和时间库可供你使用 扩展方法，现在，接口中可以有静态、默认方法。 重复注解，现在你可以将相同的注解在同一类型上使用多次。\n下述包含 Java 面试过程中关于 SOLID 的设计原则，OOP 基础，如类，对象，接口，继承，多态，封装，抽象以及更高级的一些概念，如组合、聚合及关联。也包含了 GOF 设计模式的问题。\n接口是什么? 为什么要使用接口而不是直接使用具体类?接口用于定义 API。它定义了类必须得遵循的规则。同时，它提供了一种抽象，因为客户端只使用接口，这样可以有多重实现，如 List 接口，你可以使用可随机访问的 ArrayList，也可以使用方便插入和删除的 LinkedList。接口中不允许普通方法，以此来保证抽象，但是 Java 8 中你可以在接口声明静态方法和默认普通方法。\nJava 中，抽象类与接口之间有什么不同?Java 中，抽象类和接口有很多不同之处，但是最重要的一个是 Java 中限制一个类只能继承一个类，但是可以实现多个接口。抽象类可以很好的定义一个家族类的默认行为，而接口能更好的定义类型，有助于后面实现多态机制 参见第六条。\nObject有哪些公用方法?clone equals hashcode wait notify notifyall finalize toString getClass 除了clone和finalize其他均为公共方法。\n11个方法，wait被重载了两次\nequals与&#x3D;&#x3D;的区别区别1. &#x3D;&#x3D;是一个运算符 equals是Object类的方法\n区别2. 比较时的区别\na. 用于基本类型的变量比较时: &#x3D;&#x3D;用于比较值是否相等，equals不能直接用于基本数据类型的比较，需要转换为其对应的包装类型。 b. 用于引用类型的比较时。&#x3D;&#x3D;和equals都是比较栈内存中的地址是否相等 。相等为true 否则为false。但是通常会重写equals方法去实现对象内容的比较。\nString、StringBuffer与StringBuilder的区别第一点: 可变和适用范围。String对象是不可变的，而StringBuffer和StringBuilder是可变字符序列。每次对String的操作相当于生成一个新的String对象，而对StringBuffer和StringBuilder的操作是对对象本身的操作，而不会生成新的对象，所以对于频繁改变内容的字符串避免使用String，因为频繁的生成对象将会对系统性能产生影响。\n第二点: 线程安全。String由于有final修饰，是immutable的，安全性是简单而纯粹的。StringBuilder和StringBuffer的区别在于StringBuilder不保证同步，也就是说如果需要线程安全需要使用StringBuffer，不需要同步的StringBuilder效率更高。\nswitch能否用String做参数Java1.7开始支持，但实际这是一颗Java语法糖。除此之外，byte，short，long，枚举，boolean均可用于switch，只有浮点型不可以。\n接口与抽象类6.1 一个子类只能继承一个抽象类,但能实现多个接口 6.2 抽象类可以有构造方法,接口没有构造方法 6.3 抽象类可以有普通成员变量,接口没有普通成员变量 6.4 抽象类和接口都可有静态成员变量,抽象类中静态成员变量访问类型任意，接口只能public static final(默认) 6.5 抽象类可以没有抽象方法,抽象类可以有普通方法,接口中都是抽象方法 6.6 抽象类可以有静态方法，接口不能有静态方法 6.7 抽象类中的方法可以是public、protected;接口方法只有public abstract\n抽象类和最终类抽象类可以没有抽象方法, 最终类可以没有最终方法\n最终类不能被继承, 最终方法不能被重写(可以重载)\n异常相关的关键字 throw、throws、try…catch、finally\nthrows 用在方法签名上, 以便抛出的异常可以被调用者处理 throw 方法内部通过throw抛出异常 try 用于检测包住的语句块, 若有异常, catch子句捕获并执行catch块\n关于finallyfinally不管有没有异常都要处理 当try和catch中有return时，finally仍然会执行，finally比return先执行 不管有木有异常抛出, finally在return返回前执行 finally是在return后面的表达式运算后执行的(此时并没有返回运算后的值，而是先把要返回的值保存起来，管finally中的代码怎么样，返回的值都不会改变，仍然是之前保存的值)，所以函数返回值是在finally执行前确定的 注意: finally中最好不要包含return，否则程序会提前退出，返回值不是try或catch中保存的返回值\nfinally不执行的几种情况: 程序提前终止如调用了System.exit, 病毒，断电\n受检查异常和运行时异常10.1 粉红色的是受检查的异常(checked exceptions),其必须被try…catch语句块所捕获, 或者在方法签名里通过throws子句声明。受检查的异常必须在编译时被捕捉处理,命名为Checked Exception是因为Java编译器要进行检查, Java虚拟机也要进行检查, 以确保这个规则得到遵守。\n常见的checked exception: ClassNotFoundException IOException FileNotFoundException EOFException\n10.2 绿色的异常是运行时异常(runtime exceptions), 需要程序员自己分析代码决定是否捕获和处理,比如空指针,被0除…\n常见的runtime exception: NullPointerException ArithmeticException ClassCastException IllegalArgumentException IllegalStateException IndexOutOfBoundsException NoSuchElementException\n10.3 而声明为Error的，则属于严重错误，如系统崩溃、虚拟机错误、动态链接失败等，这些错误无法恢复或者不可能捕捉，将导致应用程序中断，Error不需要捕获。\nsuper出现在父类的子类中。有三种存在方式super.xxx(xxx为变量名或对象名)意思是获取父类中xxx的变量或引用 super.xxx(); (xxx为方法名)意思是直接访问并调用父类中的方法 super() 调用父类构造 注: super只能指代其直接父类\nthis() &amp; super()在构造方法中的区别调用super()必须写在子类构造方法的第一行, 否则编译不通过 super从子类调用父类构造, this在同一类中调用其他构造 均需要放在第一行 尽管可以用this调用一个构造器, 却不能调用2个 this和super不能出现在同一个构造器中, 否则编译不通过 this()、super()都指的对象,不可以在static环境中使用 本质this指向本对象的指针。super是一个关键字\n修饰符一览修饰符 类内部 同一个包 子类 任何地方 private yes default yes yes protected yes yes yes public yes yes yes yes\n构造内部类和静态内部类对象public class Enclosingone { public class Insideone {} public static class Insideone{} }\npublic class Test { public static void main(String[] args) { &#x2F;&#x2F; 构造内部类对象需要外部类的引用 Enclosingone.Insideone obj1 &#x3D; new Enclosingone().new Insideone(); &#x2F;&#x2F; 构造静态内部类的对象 Enclosingone.Insideone obj2 &#x3D; new Enclosingone.Insideone(); } } 静态内部类不需要有指向外部类的引用。但非静态内部类需要持有对外部类的引用。非静态内部类能够访问外部类的静态和非静态成员。静态内部类不能访问外部类的非静态成员，只能访问外部类的静态成员。\n序列化声明为static和transient类型的数据不能被序列化， 反序列化需要一个无参构造函数\n序列化参见我的笔记Java-note-序列化.md\n正则表达式次数符号\n\n0或多次\n1或多次 ? 0或1次 {n} 恰n次 {n,m} 从n到m次 其他符号\n\n符号 等价形式\n\\d [0-9] \\D [^0-9]\\w [a-zA-Z_0-9] \\W [^a-zA-Z_0-9] \\s [\\t\\n\\r\\f] \\S [^\\t\\n\\r\\f] . 任何字符 边界匹配器\n行开头 ^ 行结尾 $ 单词边界 \\b\n贪婪模式:最大长度匹配 非贪婪模式:匹配到结果就好,最短匹配\n环视\n字符 描述 匹配对象 . 单个任意字符 […] 字符组 列出的任意字符 [^…] 未列出的任意字符 ^ caret 行的起始位置 $ dollar 行的结束位置 &lt; 单词的起始位置 &gt; 单词的结束位置 \\b 单词边界 \\B 非单词边界 (?&#x3D;Expression) 顺序肯定环视 成功,如果右边能够匹配 (?!Expression) 顺序否定环视 成功,如果右边不能够匹配 (?&lt;&#x3D;Expression) 逆序肯定环视 成功,如果左边能够匹配 (?&lt;!Expression) 逆序否定环视 成功,如果左边不能够匹配 举例:北京市(海淀区)(朝阳区)(西城区)\nRegex: .*(?&#x3D;()\n模式和匹配器的典型调用次序\n把正则表达式编译到模式中 Pattern p &#x3D; Pattern.compile(“a*b”); 创建给定输入与此模式的匹配器 Matcher m &#x3D; p.matcher(“aaab”); 尝试将整个区域与此模式匹配 boolean b &#x3D; m.matches();\n\nnull可以被强制转型为任意类型的对象\n\n19.代码执行次序\n多个静态成员变量, 静态代码块按顺序执行 单个类中: 静态代码 -&gt; main方法 -&gt; 构造块 -&gt; 构造方法 构造块在每一次创建对象时执行 涉及父类和子类的初始化过程 a.初始化父类中的静态成员变量和静态代码块 b.初始化子类中的静态成员变量和静态代码块 c.初始化父类的普通成员变量和构造代码块(按次序)，再执行父类的构造方法(注意父类构造方法中的子类方法覆盖) d.初始化子类的普通成员变量和构造代码块(按次序)，再执行子类的构造方法 20. 数组复制方法\nfor逐一复制 System.arraycopy() -&gt; 效率最高native方法 Arrays.copyOf() -&gt; 本质调用arraycopy clone方法 -&gt; 返回Object[],需要强制类型转换 21. 多态\nJava通过方法重写和方法重载实现多态 方法重写是指子类重写了父类的同名方法 方法重载是指在同一个类中，方法的名字相同，但是参数列表不同 22. Java文件\n.java文件可以包含多个类，唯一的限制就是: 一个文件中只能有一个public类， 并且此public类必须与 文件名相同。而且这些类和写在多个文件中没有区别。\nJava移位运算符java中有三种移位运算符\n&lt;&lt; :左移运算符,x &lt;&lt; 1,相当于x乘以2(不溢出的情况下),低位补0\n\n\n:带符号右移,x &gt;&gt; 1,相当于x除以2,正数高位补0,负数高位补1\n\n:无符号右移,忽略符号位,空位都以0补齐 参见我的GitHub，Java移位符\n\n\n\n形参&amp;实参形式参数可被视为local variable.形参和局部变量一样都不能离开方法。只有在方法中使用，不会在方法外可见。 形式参数只能用final修饰符，其它任何修饰符都会引起编译器错误。但是用这个修饰符也有一定的限制，就是在方法中不能对参数做任何修改。不过一般情况下，一个方法的形参不用final修饰。只有在特殊情况下，那就是: 方法内部类。一个方法内的内部类如果使用了这个方法的参数或者局部变量的话，这个参数或局部变量应该是final。 形参的值在调用时根据调用者更改，实参则用自身的值更改形参的值(指针、引用皆在此列)，也就是说真正被传递的是实参。\n局部变量为什么要初始化局部变量是指类方法中的变量，必须初始化。局部变量运行时被分配在栈中，量大，生命周期短，如果虚拟机给每个局部变量都初始化一下，是一笔很大的开销，但变量不初始化为默认值就使用是不安全的。出于速度和安全性两个方面的综合考虑，解决方案就是虚拟机不初始化，但要求编写者一定要在使用前给变量赋值。\nJava语言的鲁棒性Java在编译和运行程序时，都要对可能出现的问题进行检查，以消除错误的产生。它提供自动垃圾收集来进行内存管理，防止程序员在管理内存时容易产生的错误。通过集成的面向对象的例外处理机制，在编译时，Java揭示出可能出现但未被处理的异常，帮助程序员正确地进行选择以防止系统的崩溃。另外，Java在编译时还可捕获类型声明中的许多常见错误，防止动态运行时不匹配问题的出现。\nJava语言特性Java致力于检查程序在编译和运行时的错误 Java虚拟机实现了跨平台接口 类型检查帮助检查出许多开发早期出现的错误 Java自己操纵内存减少了内存出错的可能性 Java还实现了真数组，避免了覆盖数据的可能\n包装类的equals()方法不处理数据转型，必须类型和值都一样才相等。子类可以继承父类的静态方法！但是不能覆盖。因为静态方法是在编译时确定了，不能多态，也就是不能运行时绑定。Java语法糖Java7的switch用字符串 - hashcode方法 switch用于enum枚举 伪泛型 - List原始类型 自动装箱拆箱 - Integer.valueOf和Integer.intValue foreach遍历 - Iterator迭代器实现 条件编译 enum枚举类、内部类 可变参数 - 数组 断言语言 try语句中定义和关闭资源\n","categories":["java基础"],"tags":["Java"]},{"title":"Java基础-面向对象","url":"/2023/02/19/java%20%E5%9F%BA%E7%A1%80-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","content":"java 基础-面向对象\n本文主要介绍Java OOP 面向对象基础和相关类图。\n\n\n三大特性\n[封装]\n[继承]\n[多态]\n\n\n类图\n[泛化关系 (Generalization)]\n[实现关系 (Realization)]\n[聚合关系 (Aggregation)]\n[组合关系 (Composition)]\n[关联关系 (Association)]\n[依赖关系 (Dependency)]\n\n\n[参考资料]\n\n三大特性封装利用抽象数据类型将数据和基于数据的操作封装在一起，使其构成一个不可分割的独立实体。数据被保护在抽象数据类型的内部，尽可能地隐藏内部的细节，只保留一些对外接口使之与外部发生联系。用户无需知道对象内部的细节，但可以通过对象对外提供的接口来访问该对象。\n优点:\n\n减少耦合: 可以独立地开发、测试、优化、使用、理解和修改\n减轻维护的负担: 可以更容易被程序员理解，并且在调试的时候可以不影响其他模块\n有效地调节性能: 可以通过剖析确定哪些模块影响了系统的性能\n提高软件的可重用性\n降低了构建大型系统的风险: 即使整个系统不可用，但是这些独立的模块却有可能是可用的\n\n以下 Person 类封装 name、gender、age 等属性，外界只能通过 get() 方法获取一个 Person 对象的 name 属性和 gender 属性，而无法获取 age 属性，但是 age 属性可以供 work() 方法使用。\n注意到 gender 属性使用 int 数据类型进行存储，封装使得用户注意不到这种实现细节。并且在需要修改 gender 属性使用的数据类型时，也可以在不影响客户端代码的情况下进行。\npublic class Person &#123;    private String name;    private int gender;    private int age;    public String getName() &#123;        return name;    &#125;    public String getGender() &#123;        return gender == 0 ? &quot;man&quot; : &quot;woman&quot;;    &#125;    public void work() &#123;        if (18 &lt;= age &amp;&amp; age &lt;= 50) &#123;            System.out.println(name + &quot; is working very hard!&quot;);        &#125; else &#123;            System.out.println(name + &quot; can&#x27;t work any more!&quot;);        &#125;    &#125;&#125;\n\n\n\n继承继承实现了 IS-A 关系，例如 Cat 和 Animal 就是一种 IS-A 关系，因此 Cat 可以继承自 Animal，从而获得 Animal 非 private 的属性和方法。\n继承应该遵循里氏替换原则，子类对象必须能够替换掉所有父类对象。\nCat 可以当做 Animal 来使用，也就是说可以使用 Animal 引用 Cat 对象。父类引用指向子类对象称为 向上转型 。\nAnimal animal = new Cat();\n\n多态多态分为编译时多态和运行时多态:\n\n编译时多态主要指方法的重载\n运行时多态指程序中定义的对象引用所指向的具体类型在运行期间才确定\n\n运行时多态有三个条件:\n\n继承\n覆盖(重写)\n向上转型\n\n下面的代码中，乐器类(Instrument)有两个子类: Wind 和 Percussion，它们都覆盖了父类的 play() 方法，并且在 main() 方法中使用父类 Instrument 来引用 Wind 和 Percussion 对象。在 Instrument 引用调用 play() 方法时，会执行实际引用对象所在类的 play() 方法，而不是 Instrument 类的方法。\npublic class Instrument &#123;    public void play() &#123;        System.out.println(&quot;Instument is playing...&quot;);    &#125;&#125;public class Wind extends Instrument &#123;    public void play() &#123;        System.out.println(&quot;Wind is playing...&quot;);    &#125;&#125;public class Percussion extends Instrument &#123;    public void play() &#123;        System.out.println(&quot;Percussion is playing...&quot;);    &#125;&#125;public class Music &#123;    public static void main(String[] args) &#123;        List&lt;Instrument&gt; instruments = new ArrayList&lt;&gt;();        instruments.add(new Wind());        instruments.add(new Percussion());        for(Instrument instrument : instruments) &#123;            instrument.play();        &#125;    &#125;&#125;\n\n\n\n类图以下类图使用 PlantUML 绘制，更多语法及使用请参考: http://plantuml.com/ 。\n泛化关系 (Generalization)用来描述继承关系，在 Java 中使用 extends 关键字。\n\n@startumltitle Generalizationclass Vihicalclass Carclass TrunckVihical &lt;|-- CarVihical &lt;|-- Trunck@enduml\n\n\n\n实现关系 (Realization)用来实现一个接口，在 Java 中使用 implement 关键字。\n\n@startumltitle Realizationinterface MoveBehaviorclass Flyclass RunMoveBehavior &lt;|.. FlyMoveBehavior &lt;|.. Run@enduml\n\n\n\n聚合关系 (Aggregation)表示整体由部分组成，但是整体和部分不是强依赖的，整体不存在了部分还是会存在。\n\n@startumltitle Aggregationclass Computerclass Keyboardclass Mouseclass ScreenComputer o-- KeyboardComputer o-- MouseComputer o-- Screen@enduml\n\n\n\n组合关系 (Composition)和聚合不同，组合中整体和部分是强依赖的，整体不存在了部分也不存在了。比如公司和部门，公司没了部门就不存在了。但是公司和员工就属于聚合关系了，因为公司没了员工还在。\n\n@startumltitle Compositionclass Companyclass DepartmentAclass DepartmentBCompany *-- DepartmentACompany *-- DepartmentB@enduml\n\n\n\n关联关系 (Association)表示不同类对象之间有关联，这是一种静态关系，与运行过程的状态无关，在最开始就可以确定。因此也可以用 1 对 1、多对 1、多对多这种关联关系来表示。比如学生和学校就是一种关联关系，一个学校可以有很多学生，但是一个学生只属于一个学校，因此这是一种多对一的关系，在运行开始之前就可以确定。\n\n@startumltitle Associationclass Schoolclass StudentSchool &quot;1&quot; - &quot;n&quot; Student@enduml\n\n\n\n依赖关系 (Dependency)和关联关系不同的是，依赖关系是在运行过程中起作用的。A 类和 B 类是依赖关系主要有三种形式:\n\nA 类是 B 类中的(某中方法的)局部变量；\nA 类是 B 类方法当中的一个参数；\nA 类向 B 类发送消息，从而影响 B 类发生变化；\n\n\n@startumltitle Dependencyclass Vihicle &#123;    move(MoveBehavior)&#125;interface MoveBehavior &#123;    move()&#125;note &quot;MoveBehavior.move()&quot; as NVihicle ..&gt; MoveBehaviorVihicle .. N@enduml\n\n\n\n参考资料\nJava 编程思想\n敏捷软件开发: 原则、模式与实践\n面向对象设计的 SOLID 原则\n看懂 UML 类图和时序图\nUML 系列——时序图(顺序图)sequence diagram\n面向对象编程三大特性 —— 封装、继承、多态\njavaoop基础知识总结\nJava实现OOP(面向对象编程)\nJava 抽象类与oop三大特征\n\n","categories":["java基础"],"tags":["Java"]},{"title":"Java基础-知识点","url":"/2023/02/19/java%20%E5%9F%BA%E7%A1%80-%E7%9F%A5%E8%AF%86%E7%82%B9/","content":"java 基础-知识点\n本文主要对Java基础知识点进行总结。\n\n\n数据类型\n包装类型\n缓存池\n\n\nString\n概览\n不可变的好处\nString, StringBuffer and StringBuilder\nString.intern()\n\n\n运算\n参数传递\nfloat 与 double\n隐式类型转换\nswitch\n\n\n继承\n访问权限\n抽象类与接口\nsuper\n重写与重载\n\n\nObject 通用方法\n概览\nequals()\nhashCode()\ntoString()\nclone()\n\n\n关键字\nfinal\nstatic\n\n\n反射\n异常\n泛型\n注解\n特性\nJava 各版本的新特性\nJava 与 C++ 的区别\nJRE or JDK\n\n\n参考资料\n\n数据类型包装类型八个基本类型:\n\nboolean&#x2F;1\nbyte&#x2F;8\nchar&#x2F;16\nshort&#x2F;16\nint&#x2F;32\nfloat&#x2F;32\nlong&#x2F;64\ndouble&#x2F;64\n\n基本类型都有对应的包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。\nInteger x = 2;     // 装箱int y = x;         // 拆箱 \n\n缓存池new Integer(123) 与 Integer.valueOf(123) 的区别在于:\n\nnew Integer(123) 每次都会新建一个对象\nInteger.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。\n\nInteger x = new Integer(123);Integer y = new Integer(123);System.out.println(x == y);    // falseInteger z = Integer.valueOf(123);Integer k = Integer.valueOf(123);System.out.println(z == k);   // true\n\n\n\nvalueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。\npublic static Integer valueOf(int i) &#123;    if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)        return IntegerCache.cache[i + (-IntegerCache.low)];    return new Integer(i);&#125;\n\n\n\n在 Java 8 中，Integer 缓存池的大小默认为 -128~127。\nstatic final int low = -128;static final int high;static final Integer cache[];static &#123;    // high value may be configured by property    int h = 127;    String integerCacheHighPropValue =        sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;);    if (integerCacheHighPropValue != null) &#123;        try &#123;            int i = parseInt(integerCacheHighPropValue);            i = Math.max(i, 127);            // Maximum array size is Integer.MAX_VALUE            h = Math.min(i, Integer.MAX_VALUE - (-low) -1);        &#125; catch( NumberFormatException nfe) &#123;            // If the property cannot be parsed into an int, ignore it.        &#125;    &#125;    high = h;    cache = new Integer[(high - low) + 1];    int j = low;    for(int k = 0; k &lt; cache.length; k++)        cache[k] = new Integer(j++);    // range [-128, 127] must be interned (JLS7 5.1.7)    assert IntegerCache.high &gt;= 127;&#125;\n\n\n\n编译器会在自动装箱过程调用 valueOf() 方法，因此多个 Integer 实例使用自动装箱来创建并且值相同，那么就会引用相同的对象。\nInteger m = 123;Integer n = 123;System.out.println(m == n); // true\n\n\n\n基本类型对应的缓冲池如下:\n\nboolean values true and false\nall byte values\nshort values between -128 and 127\nint values between -128 and 127\nchar in the range \\u0000 to \\u007F\n\n在使用这些基本类型对应的包装类型时，就可以直接使用缓冲池中的对象。\nStackOverflow : Differences between new Integer(123), Integer.valueOf(123) and just 123\nString概览String 被声明为 final，因此它不可被继承。\n内部使用 char 数组存储数据，该数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。\npublic final class String &#123;    implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123;    /** The value is used for character storage. */    private final char value[];&#125;\n\n\n\n不可变的好处1. 可以缓存 hash 值\n因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。\n2. String Pool 的需要\n如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。\n\n3. 安全性\nString 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 对象的那一方以为现在连接的是其它主机，而实际情况却不一定是。\n4. 线程安全\nString 不可变性天生具备线程安全，可以在多个线程中安全地使用。\nProgram Creek : Why String is immutable in Java?\nString, StringBuffer and StringBuilder1. 可变性\n\nString 不可变\nStringBuffer 和 StringBuilder 可变\n\n2. 线程安全\n\nString 不可变，因此是线程安全的\nStringBuilder 不是线程安全的\nStringBuffer 是线程安全的，内部使用 synchronized 进行同步\n\nStackOverflow : String, StringBuffer, and StringBuilder\nString.intern()使用 String.intern() 可以保证相同内容的字符串变量引用同一的内存对象。\n下面示例中，s1 和 s2 采用 new String() 的方式新建了两个不同对象，而 s3 是通过 s1.intern() 方法取得一个对象引用。intern() 首先把 s1 引用的对象放到 String Pool(字符串常量池)中，然后返回这个对象引用。因此 s3 和 s1 引用的是同一个字符串常量池的对象。\nString s1 = new String(&quot;aaa&quot;);String s2 = new String(&quot;aaa&quot;);System.out.println(s1 == s2);           // falseString s3 = s1.intern();System.out.println(s1.intern() == s3);  // true\n\n\n\n如果是采用 “bbb” 这种使用双引号的形式创建字符串实例，会自动地将新建的对象放入 String Pool 中。\nString s4 = &quot;bbb&quot;;String s5 = &quot;bbb&quot;;System.out.println(s4 == s5);  // true\n\n\n\n在 Java 7 之前，字符串常量池被放在运行时常量池中，它属于永久代。而在 Java 7，字符串常量池被移到 Native Method 中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。\n\nStackOverflow : What is String interning?\n深入解析 String#intern\n\n运算参数传递Java 的参数是以值传递的形式传入方法中，而不是引用传递。\n以下代码中 Dog dog 的 dog 是一个指针，存储的是对象的地址。在将一个参数传入一个方法时，本质上是将对象的地址以值的方式传递到形参中。因此在方法中改变指针引用的对象，那么这两个指针此时指向的是完全不同的对象，一方改变其所指向对象的内容对另一方没有影响。\npublic class Dog &#123;    String name;    Dog(String name) &#123;        this.name = name;    &#125;    String getName() &#123;        return this.name;    &#125;    void setName(String name) &#123;        this.name = name;    &#125;    String getObjectAddress() &#123;        return super.toString();    &#125;&#125;\n\n\n\npublic class PassByValueExample &#123;    public static void main(String[] args) &#123;        Dog dog = new Dog(&quot;A&quot;);        System.out.println(dog.getObjectAddress()); // Dog@4554617c        func(dog);        System.out.println(dog.getObjectAddress()); // Dog@4554617c        System.out.println(dog.getName());          // A    &#125;    private static void func(Dog dog) &#123;        System.out.println(dog.getObjectAddress()); // Dog@4554617c        dog = new Dog(&quot;B&quot;);        System.out.println(dog.getObjectAddress()); // Dog@74a14482        System.out.println(dog.getName());          // B    &#125;&#125;\n\n\n\n但是如果在方法中改变对象的字段值会改变原对象该字段值，因为改变的是同一个地址指向的内容。\nclass PassByValueExample &#123;    public static void main(String[] args) &#123;        Dog dog = new Dog(&quot;A&quot;);        func(dog);        System.out.println(dog.getName());          // B    &#125;    private static void func(Dog dog) &#123;        dog.setName(&quot;B&quot;);    &#125;&#125;\n\n\n\nStackOverflow: Is Java “pass-by-reference” or “pass-by-value”?\nfloat 与 double1.1 字面量属于 double 类型，不能直接将 1.1 直接赋值给 float 变量，因为这是向下转型。Java 不能隐式执行向下转型，因为这会使得精度降低。\n// float f = 1.1;\n\n1.1f 字面量才是 float 类型。\nfloat f = 1.1f;  \n\n隐式类型转换因为字面量 1 是 int 类型，它比 short 类型精度要高，因此不能隐式地将 int 类型下转型为 short 类型。\nshort s1 = 1;// s1 = s1 + 1;\n\n但是使用 +&#x3D; 运算符可以执行隐式类型转换。\ns1 += 1;\n\n上面的语句相当于将 s1 + 1 的计算结果进行了向下转型:\ns1 = (short) (s1 + 1);\n\nStackOverflow : Why don’t Java’s +&#x3D;, -&#x3D;, *&#x3D;, &#x2F;&#x3D; compound assignment operators require casting?\nswitch从 Java 7 开始，可以在 switch 条件判断语句中使用 String 对象。\nString s = &quot;a&quot;;switch (s) &#123;    case &quot;a&quot;:        System.out.println(&quot;aaa&quot;);        break;    case &quot;b&quot;:        System.out.println(&quot;bbb&quot;);        break;&#125;\n\n\n\nswitch 不支持 long，是因为 switch 的设计初衷是对那些只有少数的几个值进行等值判断，如果值过于复杂，那么还是用 if 比较合适。\n// long x = 111;// switch (x) &#123; // Incompatible types. Found: &#x27;long&#x27;, required: &#x27;char, byte, short, int, Character, Byte, Short, Integer, String, or an enum&#x27;//     case 111://         System.out.println(111);//         break;//     case 222://         System.out.println(222);//         break;// &#125;\n\nStackOverflow : Why can’t your switch statement data type be long, Java?\n继承访问权限Java 中有三个访问权限修饰符: private、protected 以及 public，如果不加访问修饰符，表示包级可见。\n可以对类或类中的成员(字段以及方法)加上访问修饰符。\n\n类可见表示其它类可以用这个类创建实例对象。\n成员可见表示其它类可以用这个类的实例对象访问到该成员；\n\nprotected 用于修饰成员，表示在继承体系中成员对于子类可见，但是这个访问修饰符对于类没有意义。\n设计良好的模块会隐藏所有的实现细节，把它的 API 与它的实现清晰地隔离开来。模块之间只通过它们的 API 进行通信，一个模块不需要知道其他模块的内部工作情况，这个概念被称为信息隐藏或封装。因此访问权限应当尽可能地使每个类或者成员不被外界访问。\n如果子类的方法重写了父类的方法，那么子类中该方法的访问级别不允许低于父类的访问级别。这是为了确保可以使用父类实例的地方都可以使用子类实例，也就是确保满足里氏替换原则。\n字段决不能是公有的，因为这么做的话就失去了对这个字段修改行为的控制，客户端可以对其随意修改。例如下面的例子中，AccessExample 拥有 id 共有字段，如果在某个时刻，我们想要使用 int 去存储 id 字段，那么就需要去修改所有的客户端代码。\npublic class AccessExample &#123;    public String id;&#125;\n\n可以使用公有的 getter 和 setter 方法来替换公有字段，这样的话就可以控制对字段的修改行为。\npublic class AccessExample &#123;    private int id;    public String getId() &#123;        return id + &quot;&quot;;    &#125;    public void setId(String id) &#123;        this.id = Integer.valueOf(id);    &#125;&#125;\n\n\n\n但是也有例外，如果是包级私有的类或者私有的嵌套类，那么直接暴露成员不会有特别大的影响。\npublic class AccessWithInnerClassExample &#123;    private class InnerClass &#123;        int x;    &#125;    private InnerClass innerClass;    public AccessWithInnerClassExample() &#123;        innerClass = new InnerClass();    &#125;    public int getValue() &#123;        return innerClass.x;  // 直接访问    &#125;&#125;\n\n\n\n抽象类与接口1. 抽象类\n抽象类和抽象方法都使用 abstract 关键字进行声明。抽象类一般会包含抽象方法，抽象方法一定位于抽象类中。\n抽象类和普通类最大的区别是，抽象类不能被实例化，需要继承抽象类才能实例化其子类。\npublic abstract class AbstractClassExample &#123;    protected int x;    private int y;    public abstract void func1();    public void func2() &#123;        System.out.println(&quot;func2&quot;);    &#125;&#125;\n\n\n\npublic class AbstractExtendClassExample extends AbstractClassExample &#123;    @Override    public void func1() &#123;        System.out.println(&quot;func1&quot;);    &#125;&#125;\n\n\n\n// AbstractClassExample ac1 = new AbstractClassExample(); // &#x27;AbstractClassExample&#x27; is abstract; cannot be instantiatedAbstractClassExample ac2 = new AbstractExtendClassExample();ac2.func1();\n\n\n\n2. 接口\n接口是抽象类的延伸，在 Java 8 之前，它可以看成是一个完全抽象的类，也就是说它不能有任何的方法实现。\n从 Java 8 开始，接口也可以拥有默认的方法实现，这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前，如果一个接口想要添加新的方法，那么要修改所有实现了该接口的类。\n接口的成员(字段 + 方法)默认都是 public 的，并且不允许定义为 private 或者 protected。\n接口的字段默认都是 static 和 final 的。\npublic interface InterfaceExample &#123;    void func1();    default void func2()&#123;        System.out.println(&quot;func2&quot;);    &#125;    int x = 123;    // int y;               // Variable &#x27;y&#x27; might not have been initialized    public int z = 0;       // Modifier &#x27;public&#x27; is redundant for interface fields    // private int k = 0;   // Modifier &#x27;private&#x27; not allowed here    // protected int l = 0; // Modifier &#x27;protected&#x27; not allowed here    // private void fun3(); // Modifier &#x27;private&#x27; not allowed here&#125;\n\n\n\npublic class InterfaceImplementExample implements InterfaceExample &#123;    @Override    public void func1() &#123;        System.out.println(&quot;func1&quot;);    &#125;&#125;\n\n\n\n// InterfaceExample ie1 = new InterfaceExample(); // &#x27;InterfaceExample&#x27; is abstract; cannot be instantiatedInterfaceExample ie2 = new InterfaceImplementExample();ie2.func1();System.out.println(InterfaceExample.x);\n\n\n\n3. 比较\n\n从设计层面上看，抽象类提供了一种 IS-A 关系，那么就必须满足里式替换原则，即子类对象必须能够替换掉所有父类对象。而接口更像是一种 LIKE-A 关系，它只是提供一种方法实现契约，并不要求接口和实现接口的类具有 IS-A 关系。\n从使用上来看，一个类可以实现多个接口，但是不能继承多个抽象类。\n接口的字段只能是 static 和 final 类型的，而抽象类的字段没有这种限制。\n接口的成员只能是 public 的，而抽象类的成员可以有多种访问权限。\n\n4. 使用选择\n使用接口:\n\n需要让不相关的类都实现一个方法，例如不相关的类都可以实现 Compareable 接口中的 compareTo() 方法；\n需要使用多重继承。\n\n使用抽象类:\n\n需要在几个相关的类中共享代码。\n需要能控制继承来的成员的访问权限，而不是都为 public。\n需要继承非静态和非常量字段。\n\n在很多情况下，接口优先于抽象类，因为接口没有抽象类严格的类层次结构要求，可以灵活地为一个类添加行为。并且从 Java 8 开始，接口也可以有默认的方法实现，使得修改接口的成本也变的很低。\n\n深入理解 abstract class 和 interface\nWhen to Use Abstract Class and Interface\n\nsuper\n访问父类的构造函数: 可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。\n\n访问父类的成员: 如果子类重写了父类的中某个方法的实现，可以通过使用 super 关键字来引用父类的方法实现。\npublic class SuperExample &#123;    protected int x;    protected int y;    public SuperExample(int x, int y) &#123;        this.x = x;        this.y = y;    &#125;    public void func() &#123;        System.out.println(&quot;SuperExample.func()&quot;);    &#125;&#125;\n\npublic class SuperExtendExample extends SuperExample &#123;    private int z;    public SuperExtendExample(int x, int y, int z) &#123;        super(x, y);        this.z = z;    &#125;    @Override    public void func() &#123;        super.func();        System.out.println(&quot;SuperExtendExample.func()&quot;);    &#125;&#125;\n\n\n\nSuperExample e = new SuperExtendExample(1, 2, 3);e.func();\n\n\n\nSuperExample.func()SuperExtendExample.func()\n\n\n\nUsing the Keyword super\n重写与重载1. 重写(Override)\n存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。\n为了满足里式替换原则，重写有有以下两个限制:\n\n子类方法的访问权限必须大于等于父类方法；\n子类方法的返回类型必须是父类方法返回类型或为其子类型。\n\n使用 @Override 注解，可以让编译器帮忙检查是否满足上面的两个限制条件。\n2. 重载(Overload)\n存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。\n应该注意的是，返回值不同，其它都相同不算是重载。\nObject 通用方法概览public final native Class&lt;?&gt; getClass()public native int hashCode()public boolean equals(Object obj)protected native Object clone() throws CloneNotSupportedExceptionpublic String toString()public final native void notify()public final native void notifyAll()public final native void wait(long timeout) throws InterruptedExceptionpublic final void wait(long timeout, int nanos) throws InterruptedExceptionpublic final void wait() throws InterruptedExceptionprotected void finalize() throws Throwable &#123;&#125;\n\n\n\nequals()1. 等价关系\n(一)自反性\nx.equals(x); // true\n\n\n\n(二)对称性\nx.equals(y) == y.equals(x); // true\n\n\n\n(三)传递性\nif (x.equals(y) &amp;&amp; y.equals(z))    x.equals(z); // true;\n\n\n\n(四)一致性\n多次调用 equals() 方法结果不变\nx.equals(y) == x.equals(y); // true\n\n\n\n(五)与 null 的比较\n对任何不是 null 的对象 x 调用 x.equals(null) 结果都为 false\nx.equals(null); // false;\n\n\n\n2. equals() 与 &#x3D;&#x3D;\n\n对于基本类型，&#x3D;&#x3D; 判断两个值是否相等，基本类型没有 equals() 方法。\n\n对于引用类型，&#x3D;&#x3D; 判断两个变量是否引用同一个对象，而 equals() 判断引用的对象是否等价。\nInteger x = new Integer(1);Integer y = new Integer(1);System.out.println(x.equals(y)); // trueSystem.out.println(x == y);      // false\n\n3. 实现\n\n检查是否为同一个对象的引用，如果是直接返回 true；\n\n检查是否是同一个类型，如果不是，直接返回 false；\n\n将 Object 对象进行转型；\n\n判断每个关键域是否相等。\npublic class EqualExample &#123;    private int x;    private int y;    private int z;    public EqualExample(int x, int y, int z) &#123;        this.x = x;        this.y = y;        this.z = z;    &#125;    @Override    public boolean equals(Object o) &#123;        if (this == o) return true;        if (o == null || getClass() != o.getClass()) return false;        EqualExample that = (EqualExample) o;        if (x != that.x) return false;        if (y != that.y) return false;        return z == that.z;    &#125;    &#125;\n\nhashCode()hashCode() 返回散列值，而 equals() 是用来判断两个对象是否等价。等价的两个对象散列值一定相同，但是散列值相同的两个对象不一定等价。\n在覆盖 equals() 方法时应当总是覆盖 hashCode() 方法，保证等价的两个对象散列值也相等。\n下面的代码中，新建了两个等价的对象，并将它们添加到 HashSet 中。我们希望将这两个对象当成一样的，只在集合中添加一个对象，但是因为 EqualExample 没有实现 hasCode() 方法，因此这两个对象的散列值是不同的，最终导致集合添加了两个等价的对象。\nEqualExample e1 = new EqualExample(1, 1, 1);EqualExample e2 = new EqualExample(1, 1, 1);System.out.println(e1.equals(e2)); // trueHashSet&lt;EqualExample&gt; set = new HashSet&lt;&gt;();set.add(e1);set.add(e2);System.out.println(set.size());   // 2\n\n\n\n理想的散列函数应当具有均匀性，即不相等的对象应当均匀分布到所有可能的散列值上。这就要求了散列函数要把所有域的值都考虑进来，可以将每个域都当成 R 进制的某一位，然后组成一个 R 进制的整数。R 一般取 31，因为它是一个奇素数，如果是偶数的话，当出现乘法溢出，信息就会丢失，因为与 2 相乘相当于向左移一位。\n一个数与 31 相乘可以转换成移位和减法: 31*x == (x&lt;&lt;5)-x，编译器会自动进行这个优化。\n@Overridepublic int hashCode() &#123;    int result = 17;    result = 31 * result + x;    result = 31 * result + y;    result = 31 * result + z;    return result;&#125;\n\n\n\ntoString()默认返回 ToStringExample@4554617c 这种形式，其中 @ 后面的数值为散列码的无符号十六进制表示。\npublic class ToStringExample &#123;    private int number;    public ToStringExample(int number) &#123;        this.number = number;    &#125;&#125;\n\n\n\nToStringExample example = new ToStringExample(123);System.out.println(example.toString());\n\n\n\nToStringExample@4554617c\n\n\n\nclone()1. cloneable\nclone() 是 Object 的 protected 方法，它不是 public，一个类不显式去重写 clone()，其它类就不能直接去调用该类实例的 clone() 方法。\npublic class CloneExample &#123;    private int a;    private int b;&#125;\n\n\n\nCloneExample e1 = new CloneExample();// CloneExample e2 = e1.clone(); // &#x27;clone()&#x27; has protected access in &#x27;java.lang.Object&#x27;\n\n\n\n重写 clone() 得到以下实现:\npublic class CloneExample &#123;    private int a;    private int b;    @Override    protected CloneExample clone() throws CloneNotSupportedException &#123;        return (CloneExample)super.clone();    &#125;&#125;\n\n\n\nCloneExample e1 = new CloneExample();try &#123;    CloneExample e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123;    e.printStackTrace();&#125;\n\n\n\njava.lang.CloneNotSupportedException: CloneExample\n\n1\n以上抛出了 CloneNotSupportedException，这是因为 CloneExample 没有实现 Cloneable 接口。\n应该注意的是，clone() 方法并不是 Cloneable 接口的方法，而是 Object 的一个 protected 方法。Cloneable 接口只是规定，如果一个类没有实现 Cloneable 接口又调用了 clone() 方法，就会抛出 CloneNotSupportedException。\npublic class CloneExample implements Cloneable &#123;    private int a;    private int b;    @Override    protected Object clone() throws CloneNotSupportedException &#123;        return super.clone();    &#125;&#125;\n\n\n\n2. 浅拷贝\n拷贝对象和原始对象的引用类型引用同一个对象。\npublic class ShallowCloneExample implements Cloneable &#123;    private int[] arr;    public ShallowCloneExample() &#123;        arr = new int[10];        for (int i = 0; i &lt; arr.length; i++) &#123;            arr[i] = i;        &#125;    &#125;    public void set(int index, int value) &#123;        arr[index] = value;    &#125;    public int get(int index) &#123;        return arr[index];    &#125;    @Override    protected ShallowCloneExample clone() throws CloneNotSupportedException &#123;        return (ShallowCloneExample) super.clone();    &#125;&#125;\n\n\n\nShallowCloneExample e1 = new ShallowCloneExample();ShallowCloneExample e2 = null;try &#123;    e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123;    e.printStackTrace();&#125;e1.set(2, 222);System.out.println(e2.get(2)); // 222\n\n\n\n3. 深拷贝\n拷贝对象和原始对象的引用类型引用不同对象。\npublic class DeepCloneExample implements Cloneable &#123;    private int[] arr;    public DeepCloneExample() &#123;        arr = new int[10];        for (int i = 0; i &lt; arr.length; i++) &#123;            arr[i] = i;        &#125;    &#125;    public void set(int index, int value) &#123;        arr[index] = value;    &#125;    public int get(int index) &#123;        return arr[index];    &#125;    @Override    protected DeepCloneExample clone() throws CloneNotSupportedException &#123;        DeepCloneExample result = (DeepCloneExample) super.clone();        result.arr = new int[arr.length];        for (int i = 0; i &lt; arr.length; i++) &#123;            result.arr[i] = arr[i];        &#125;        return result;    &#125;&#125;\n\n\n\n\nDeepCloneExample e1 = new DeepCloneExample();DeepCloneExample e2 = null;try &#123;    e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123;    e.printStackTrace();&#125;e1.set(2, 222);System.out.println(e2.get(2)); // 2\n\n\n\n4. clone() 的替代方案\n使用 clone() 方法来拷贝一个对象即复杂又有风险，它会抛出异常，并且还需要类型转换。Effective Java 书上讲到，最好不要去使用 clone()，可以使用拷贝构造函数或者拷贝工厂来拷贝一个对象。\npublic class CloneConstructorExample &#123;    private int[] arr;    public CloneConstructorExample() &#123;        arr = new int[10];        for (int i = 0; i &lt; arr.length; i++) &#123;            arr[i] = i;        &#125;    &#125;    public CloneConstructorExample(CloneConstructorExample original) &#123;        arr = new int[original.arr.length];        for (int i = 0; i &lt; original.arr.length; i++) &#123;            arr[i] = original.arr[i];        &#125;    &#125;    public void set(int index, int value) &#123;        arr[index] = value;    &#125;    public int get(int index) &#123;        return arr[index];    &#125;&#125;\n\n\n\nCloneConstructorExample e1 = new CloneConstructorExample();CloneConstructorExample e2 = new CloneConstructorExample(e1);e1.set(2, 222);System.out.println(e2.get(2)); // 2\n\n\n\n关键字final1. 数据\n声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。\n\n对于基本类型，final 使数值不变；\n\n对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。\nfinal int x = 1;// x = 2;  // cannot assign value to final variable &#x27;x&#x27;final A y = new A();y.a = 1;\n\n2. 方法\n声明方法不能被子类重写。\nprivate 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。\n3. 类\n声明类不允许被继承。\nstatic1. 静态变量\n\n静态变量: 又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它；静态变量在内存中只存在一份。\n\n实例变量: 每创建一个实例就会产生一个实例变量，它与该实例同生共死。\npublic class A &#123;    private int x;         // 实例变量    private static int y;  // 静态变量    public static void main(String[] args) &#123;    // int x = A.x;  // Non-static field &#x27;x&#x27; cannot be referenced from a static context        A a = new A();        int x = a.x;        int y = A.y;    &#125;&#125;\n\n静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法(abstract)。\njavajavajavapublic abstract class A &#123;    public static void func1()&#123;    &#125;    // public abstract static void func2();  // Illegal combination of modifiers: &#x27;abstract&#x27; and &#x27;static&#x27;&#125;javajavajava\n\n\n\n只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字。\npublic class A &#123;    private static int x;    private int y;    public static void func1()&#123;        int a = x;        // int b = y;  // Non-static field &#x27;y&#x27; cannot be referenced from a static context        // int b = this.y;     // &#x27;A.this&#x27; cannot be referenced from a static context    &#125;&#125;\n\n\n\n3. 静态语句块\n静态语句块在类初始化时运行一次。\npublic class A &#123;    static &#123;        System.out.println(&quot;123&quot;);    &#125;    public static void main(String[] args) &#123;        A a1 = new A();        A a2 = new A();    &#125;&#125;\n\n123\n\n\n\n4. 静态内部类\n非静态内部类依赖于外部类的实例，而静态内部类不需要。\npublic class OuterClass &#123;    class InnerClass &#123;    &#125;    static class StaticInnerClass &#123;    &#125;    public static void main(String[] args) &#123;        // InnerClass innerClass = new InnerClass(); // &#x27;OuterClass.this&#x27; cannot be referenced from a static context        OuterClass outerClass = new OuterClass();        InnerClass innerClass = outerClass.new InnerClass();        StaticInnerClass staticInnerClass = new StaticInnerClass();    &#125;&#125;\n\n静态内部类不能访问外部类的非静态的变量和方法。\n5. 静态导包\n在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。\nimport static com.xxx.ClassName.*\n\n6. 初始化顺序\n静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。\npublic static String staticField = &quot;静态变量&quot;;\n\n\n\nstatic &#123;    System.out.println(&quot;静态语句块&quot;);&#125;\n\n\n\npublic String field = &quot;实例变量&quot;;\n\n\n\n&#123;    System.out.println(&quot;普通语句块&quot;);&#125;\n\n\n\n最后才是构造函数的初始化。\npublic InitialOrderTest() &#123;    System.out.println(&quot;构造函数&quot;);&#125;\n\n存在继承的情况下，初始化顺序为:\n\n父类(静态变量、静态语句块)\n子类(静态变量、静态语句块)\n父类(实例变量、普通语句块)\n父类(构造函数)\n子类(实例变量、普通语句块)\n子类(构造函数)\n\n反射每个类都有一个 Class 对象，包含了与类有关的信息。当编译一个新类时，会产生一个同名的 .class 文件，该文件内容保存着 Class 对象。\n类加载相当于 Class 对象的加载。类在第一次使用时才动态加载到 JVM 中，可以使用 Class.forName(&quot;com.mysql.jdbc.Driver&quot;) 这种方式来控制类的加载，该方法会返回一个 Class 对象。\n反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class 不存在也可以加载进来。\nClass 和 java.lang.reflect 一起对反射提供了支持，java.lang.reflect 类库主要包含了以下三个类:\n\nField : 可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段；\nMethod : 可以使用 invoke() 方法调用与 Method 对象关联的方法；\nConstructor : 可以用 Constructor 创建新的对象。\n\nAdvantages of Using Reflection:\n\nExtensibility Features : An application may make use of external, user-defined classes by creating instances of extensibility objects using their fully-qualified names.\nClass Browsers and Visual Development Environments : A class browser needs to be able to enumerate the members of classes. Visual development environments can benefit from making use of type information available in reflection to aid the developer in writing correct code.\nDebuggers and Test Tools : Debuggers need to be able to examine private members on classes. Test harnesses can make use of reflection to systematically call a discoverable set APIs defined on a class, to insure a high level of code coverage in a test suite.\n\nDrawbacks of Reflection:\nReflection is powerful, but should not be used indiscriminately. If it is possible to perform an operation without using reflection, then it is preferable to avoid using it. The following concerns should be kept in mind when accessing code via reflection.\n\nPerformance Overhead : Because reflection involves types that are dynamically resolved, certain Java virtual machine optimizations can not be performed. Consequently, reflective operations have slower performance than their non-reflective counterparts, and should be avoided in sections of code which are called frequently in performance-sensitive applications.\nSecurity Restrictions : Reflection requires a runtime permission which may not be present when running under a security manager. This is in an important consideration for code which has to run in a restricted security context, such as in an Applet.\nExposure of Internals :Since reflection allows code to perform operations that would be illegal in non-reflective code, such as accessing private fields and methods, the use of reflection can result in unexpected side-effects, which may render code dysfunctional and may destroy portability. Reflective code breaks abstractions and therefore may change behavior with upgrades of the platform.\nTrail: The Reflection API\n深入解析 Java 反射(1)- 基础\n\n异常Throwable 可以用来表示任何可以作为异常抛出的类，分为两种: Error 和 Exception。其中 Error 用来表示 JVM 无法处理的错误，Exception 分为两种:\n\n受检异常 : 需要用 try…catch… 语句捕获并进行处理，并且可以从异常中恢复；\n非受检异常 : 是程序运行时错误，例如除 0 会引发 Arithmetic Exception，此时程序崩溃并且无法恢复。\n\n\n\nJava 入门之异常处理\nJava 异常的面试问题及答案 -Part 1\n\n泛型public class Box&lt;T&gt; &#123;    // T stands for &quot;Type&quot;    private T t;    public void set(T t) &#123; this.t = t; &#125;    public T get() &#123; return t; &#125;&#125;\n\n\nJava 泛型详解\n10 道 Java 泛型面试题\n\n注解Java 注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。\n注解 Annotation 实现原理与自定义注解例子\n特性Java 各版本的新特性New highlights in Java SE 8\n\nLambda Expressions\nPipelines and Streams\nDate and Time API\nDefault Methods\nType Annotations\nNashhorn JavaScript Engine\nConcurrent Accumulators\nParallel operations\nPermGen Error Removed\n\nNew highlights in Java SE 7\n\nStrings in Switch Statement\nType Inference for Generic Instance Creation\nMultiple Exception Handling\nSupport for Dynamic Languages\nTry with Resources\nJava nio Package\nBinary Literals, Underscore in literals\nDiamond Syntax\n\n\nDifference between Java 1.8 and Java 1.7?\nJava 8 特性\n\nJava 与 C++ 的区别\nJava 是纯粹的面向对象语言，所有的对象都继承自 java.lang.Object，C++ 为了兼容 C 即支持面向对象也支持面向过程。\nJava 通过虚拟机从而实现跨平台特性，但是 C++ 依赖于特定的平台。\nJava 没有指针，它的引用可以理解为安全指针，而 C++ 具有和 C 一样的指针。\nJava 支持自动垃圾回收，而 C++ 需要手动回收。\nJava 不支持多重继承，只能通过实现多个接口来达到相同目的，而 C++ 支持多重继承。\nJava 不支持操作符重载，虽然可以对两个 String 对象支持加法运算，但是这是语言内置支持的操作，不属于操作符重载，而 C++ 可以。\nJava 的 goto 是保留字，但是不可用，C++ 可以使用 goto。\nJava 不支持条件编译，C++ 通过 #ifdef #ifndef 等预处理命令从而实现条件编译。\n\nWhat are the main differences between Java and C++?\nJRE or JDK\nJRE is the JVM program, Java application need to run on JRE.\nJDK is a superset of JRE, JRE + tools for developing java programs. e.g, it provides the compiler “javac”\n\n参考资料\nEckel B. Java 编程思想[M]. 机械工业出版社, 2002.\nBloch J. Effective java[M]. Addison-Wesley Professional, 2017.11\n\n","categories":["java基础"],"tags":["Java"]},{"title":"Springboot核心知识","url":"/2023/02/19/Springboot%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86/","content":"Springboot核心知识\n1、Spring Boot 简介\n2、微服务\n3、环境准备\n1、MAVEN设置；\n2、IDEA设置\n\n\n4、Spring Boot HelloWorld\n1、创建一个maven工程；（jar）\n2、导入spring boot相关的依赖\n3、编写一个主程序；启动Spring Boot应用\n4、编写相关的Controller、Service\n5、运行主程序测试\n6、简化部署\n\n\n5、Hello World探究\n1、POM文件\n2、主程序类，主入口类\n\n\n6、使用Spring Initializer快速创建Spring Boot项目\n1、IDEA：使用 Spring Initializer快速创建项目\n2、STS使用 Spring Starter Project快速创建项目\n\n\n1、配置文件\n2、YAML语法：\n1、基本语法\n2、值的写法\n\n\n3、配置文件值注入\n1、随机数\n2、占位符获取之前配置的值，如果没有可以是用:指定默认值\n\n\n5、Profile\n1、多Profile文件\n2、yml支持多文档块方式\n3、激活指定profile\n\n\n6、配置文件加载位置\n7、外部配置加载顺序\n8、自动配置原理\n1、自动配置原理：\n2、细节\n\n\n1、日志框架\n2、SLF4j使用\n1、如何在系统中使用SLF4j https://www.slf4j.org\n2、遗留问题\n\n\n3、SpringBoot日志关系\n4、日志使用；\n1、默认配置\n2、指定配置\n\n\n5、切换日志框架\n1、简介\n2、SpringBoot对静态资源的映射规则；\n3、模板引擎\n1、引入thymeleaf；\n2、Thymeleaf使用\n3、语法规则\n\n\n4、SpringMVC自动配置\n\nSpring MVC auto-configuration\n\n\n2、扩展SpringMVC\n3、全面接管SpringMVC；\n\n\n5、如何修改SpringBoot的默认配置\n6、RestfulCRUD\n1）、默认访问首页\n2）、国际化\n3）、登陆\n4）、拦截器进行登陆检查\n5）、CRUD-员工列表\n6）、CRUD-员工添加\n7）、CRUD-员工修改\n8）、CRUD-员工删除\n\n\n7、错误处理机制\n1）、SpringBoot默认的错误处理机制\n2）、如果定制错误响应：\n\n\n8、配置嵌入式Servlet容器\n1）、如何定制和修改Servlet容器的相关配置；\n2）、注册Servlet三大组件【Servlet、Filter、Listener】\n3）、替换为其他嵌入式Servlet容器\n4）、嵌入式Servlet容器自动配置原理；\n\n\n9、使用外置的Servlet容器\n步骤\n原理\n\n\n1、简介\n2、核心概念\n3、安装Docker\n4、Docker常用命令&amp;操作\n1）、镜像操作\n2）、容器操作\n3）、安装MySQL示例\n\n\n1、JDBC\n2、整合Druid数据源\n3、整合MyBatis\n4）、注解版\n5）、配置文件版\n\n\n4、整合SpringData JPA\n1）、SpringData简介\n2）、整合SpringData JPA\n\n\n1、创建SpringApplication对象\n2、运行run方法\n3、事件监听机制\n\n一、Spring Boot 入门1、Spring Boot 简介\n简化Spring应用开发的一个框架；\n整个Spring技术栈的一个大整合；\nJ2EE开发的一站式解决方案；\n\n2、微服务2014，martin fowler\n微服务：架构风格（服务微化）\n一个应用应该是一组小型服务；可以通过HTTP的方式进行互通；\n单体应用：ALL IN ONE\n微服务：每一个功能元素最终都是一个可独立替换和独立升级的软件单元；\n详细参照微服务文档\n3、环境准备http://www.gulixueyuan.com/ 谷粒学院\n环境约束\n–jdk1.8：Spring Boot 推荐jdk1.7及以上；java version “1.8.0_112”\n–maven3.x：maven 3.3以上版本；Apache Maven 3.3.9\n–IntelliJIDEA2017：IntelliJ IDEA 2017.2.2 x64、STS\n–SpringBoot 1.5.9.RELEASE：1.5.9；\n统一环境；\n1、MAVEN设置；给maven 的settings.xml配置文件的profiles标签添加\n&lt;profile&gt;  &lt;id&gt;jdk-1.8&lt;/id&gt;  &lt;activation&gt;    &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;    &lt;jdk&gt;1.8&lt;/jdk&gt;  &lt;/activation&gt;  &lt;properties&gt;    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;    &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt;  &lt;/properties&gt;&lt;/profile&gt;\n\n\n\n2、IDEA设置整合maven进来；\n\n\n4、Spring Boot HelloWorld一个功能：\n浏览器发送hello请求，服务器接受请求并处理，响应Hello World字符串；\n1、创建一个maven工程；（jar）2、导入spring boot相关的依赖&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n\n\n3、编写一个主程序；启动Spring Boot应用/** *  @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication &#123;    public static void main(String[] args) &#123;        // Spring应用启动起来        SpringApplication.run(HelloWorldMainApplication.class,args);    &#125;&#125;\n\n\n\n4、编写相关的Controller、Service@Controllerpublic class HelloController &#123;    @ResponseBody    @RequestMapping(&quot;/hello&quot;)    public String hello()&#123;        return &quot;Hello World!&quot;;    &#125;&#125;\n\n\n\n5、运行主程序测试6、简化部署&lt;!-- 这个插件，可以将应用打包成一个可执行的jar包；--&gt;   &lt;build&gt;       &lt;plugins&gt;           &lt;plugin&gt;               &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;               &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;           &lt;/plugin&gt;       &lt;/plugins&gt;   &lt;/build&gt;\n\n\n\n将这个应用打成jar包，直接使用java -jar的命令进行执行；\n5、Hello World探究1、POM文件1、父项目&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;他的父项目是&lt;parent&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;  &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;  &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;&lt;/parent&gt;他来真正管理Spring Boot应用里面的所有依赖版本；\n\n\n\nSpring Boot的版本仲裁中心；\n以后我们导入依赖默认是不需要写版本；（没有在dependencies里面管理的依赖自然需要声明版本号）\n2、启动器&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;\n\n\n\nspring-boot-starter-&#x3D;&#x3D;web&#x3D;&#x3D;：\n spring-boot-starter：spring-boot场景启动器；帮我们导入了web模块正常运行所依赖的组件；\nSpring Boot将所有的功能场景都抽取出来，做成一个个的starters（启动器），只需要在项目里面引入这些starter相关场景的所有依赖都会导入进来。要用什么功能就导入什么场景的启动器\n2、主程序类，主入口类/** *  @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication &#123;    public static void main(String[] args) &#123;        // Spring应用启动起来        SpringApplication.run(HelloWorldMainApplication.class,args);    &#125;&#125;\n\n\n\n@SpringBootApplication: Spring Boot应用标注在某个类上说明这个类是SpringBoot的主配置类，SpringBoot就应该运行这个类的main方法来启动SpringBoot应用；\n@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123;      @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),      @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123;\n\n\n\n@SpringBootConfiguration:Spring Boot的配置类；\n 标注在某个类上，表示这是一个Spring Boot的配置类；\n @Configuration:配置类上来标注这个注解；\n 配置类 —– 配置文件；配置类也是容器中的一个组件；@Component\n@EnableAutoConfiguration：开启自动配置功能；\n 以前我们需要配置的东西，Spring Boot帮我们自动配置；@EnableAutoConfiguration告诉SpringBoot开启自动配置功能；这样自动配置才能生效；\n@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123;\n\n\n\n @AutoConfigurationPackage：自动配置包\n @Import(AutoConfigurationPackages.Registrar.class)：\n Spring的底层注解@Import，给容器中导入一个组件；导入的组件由AutoConfigurationPackages.Registrar.class；\n&#x3D;&#x3D;将主配置类（@SpringBootApplication标注的类）的所在包及下面所有子包里面的所有组件扫描到Spring容器；&#x3D;&#x3D;\n @Import(EnableAutoConfigurationImportSelector.class)；\n 给容器中导入组件？\n EnableAutoConfigurationImportSelector：导入哪些组件的选择器；\n 将所有需要导入的组件以全类名的方式返回；这些组件就会被添加到容器中；\n 会给容器中导入非常多的自动配置类（xxxAutoConfiguration）；就是给容器中导入这个场景需要的所有组件，并配置好这些组件； \n有了自动配置类，免去了我们手动编写配置注入功能组件等的工作；\n SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class,classLoader)；\n&#x3D;&#x3D;Spring Boot在启动的时候从类路径下的META-INF&#x2F;spring.factories中获取EnableAutoConfiguration指定的值，将这些值作为自动配置类导入到容器中，自动配置类就生效，帮我们进行自动配置工作；&#x3D;&#x3D;以前我们需要自己配置的东西，自动配置类都帮我们；\nJ2EE的整体整合解决方案和自动配置都在spring-boot-autoconfigure-1.5.9.RELEASE.jar；\n&#x3D;&#x3D;Spring注解版（谷粒学院）&#x3D;&#x3D;\n6、使用Spring Initializer快速创建Spring Boot项目1、IDEA：使用 Spring Initializer快速创建项目IDE都支持使用Spring的项目创建向导快速创建一个Spring Boot项目；\n选择我们需要的模块；向导会联网创建Spring Boot项目；\n默认生成的Spring Boot项目；\n\n主程序已经生成好了，我们只需要我们自己的逻辑\nresources文件夹中目录结构\nstatic：保存所有的静态资源； js css &#x2F;blog&#x2F;img&#x2F;springboot；\ntemplates：保存所有的模板页面；（Spring Boot默认jar包使用嵌入式的Tomcat，默认不支持JSP页面）；可以使用模板引擎（freemarker、thymeleaf）；\napplication.properties：Spring Boot应用的配置文件；可以修改一些默认设置；\n\n\n\n2、STS使用 Spring Starter Project快速创建项目\n二、配置文件1、配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的；\n•application.properties\n•application.yml\n配置文件的作用：修改SpringBoot自动配置的默认值；SpringBoot在底层都给我们自动配置好；\nYAML（YAML Ain’t Markup Language）\n YAML A Markup Language：是一个标记语言\n YAML isn’t Markup Language：不是一个标记语言；\n标记语言：\n 以前的配置文件；大多都使用的是 xxxx.xml文件；\n YAML：以数据为中心，比json、xml等更适合做配置文件；\n YAML：配置例子\nserver:  port: 8081\n\n\n\n XML：\n&lt;server&gt;\t&lt;port&gt;8081&lt;/port&gt;&lt;/server&gt;\n\n\n\n2、YAML语法：1、基本语法k:(空格)v：表示一对键值对（空格必须有）；\n以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的\nserver:    port: 8081    path: /hello\n\n\n\n属性和值也是大小写敏感；\n2、值的写法字面量：普通的值（数字，字符串，布尔） k: v：字面直接来写；\n 字符串默认不用加上单引号或者双引号；\n “”：双引号；不会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思\n name: “zhangsan \\n lisi”：输出；zhangsan 换行 lisi\n ‘’：单引号；会转义特殊字符，特殊字符最终只是一个普通的字符串数据\n name: ‘zhangsan \\n lisi’：输出；zhangsan \\n lisi\n对象、Map（属性和值）（键值对）： k: v：在下一行来写对象的属性和值的关系；注意缩进\n 对象还是k: v的方式\nfriends:\t\tlastName: zhangsan\t\tage: 20\n\n\n\n行内写法：\nfriends: &#123;lastName: zhangsan,age: 18&#125;\n\n\n\n数组（List、Set）：用- 值表示数组中的一个元素\npets: - cat - dog - pig\n\n\n\n行内写法\npets: [cat,dog,pig]\n\n\n\n3、配置文件值注入配置文件\nperson:    lastName: hello    age: 18    boss: false    birth: 2017/12/12    maps: &#123;k1: v1,k2: 12&#125;    lists:      - lisi      - zhaoliu    dog:      name: 小狗      age: 12\n\n\n\njavaBean：\n/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； *      prefix = &quot;person&quot;：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * */@Component@ConfigurationProperties(prefix = &quot;person&quot;)public class Person &#123;    private String lastName;    private Integer age;    private Boolean boss;    private Date birth;    private Map&lt;String,Object&gt; maps;    private List&lt;Object&gt; lists;    private Dog dog;\n\n\n\n我们可以导入配置文件处理器，以后编写配置就有提示了\n&lt;!--导入配置文件处理器，配置文件进行绑定就会有提示--&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;\t\t\t&lt;optional&gt;true&lt;/optional&gt;\t\t&lt;/dependency&gt;\n\n\n\n1、properties配置文件在idea中默认utf-8可能会乱码调整\n\n2、@Value获取值和@ConfigurationProperties获取值比较\n\n\n\n@ConfigurationProperties\n@Value\n\n\n\n功能\n批量注入配置文件中的属性\n一个个指定\n\n\n松散绑定（松散语法）\n支持\n不支持\n\n\nSpEL\n不支持\n支持\n\n\nJSR303数据校验\n支持\n不支持\n\n\n复杂类型封装\n支持\n不支持\n\n\n配置文件yml还是properties他们都能获取到值；\n如果说，我们只是在某个业务逻辑中需要获取一下配置文件中的某项值，使用@Value；\n如果说，我们专门编写了一个javaBean来和配置文件进行映射，我们就直接使用@ConfigurationProperties；\n3、配置文件注入值数据校验@Component@ConfigurationProperties(prefix = &quot;person&quot;)@Validatedpublic class Person &#123;    /**     * &lt;bean class=&quot;Person&quot;&gt;     *      &lt;property name=&quot;lastName&quot; value=&quot;字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;&quot;&gt;&lt;/property&gt;     * &lt;bean/&gt;     */   //lastName必须是邮箱格式    @Email    //@Value(&quot;$&#123;person.last-name&#125;&quot;)    private String lastName;    //@Value(&quot;#&#123;11*2&#125;&quot;)    private Integer age;    //@Value(&quot;true&quot;)    private Boolean boss;    private Date birth;    private Map&lt;String,Object&gt; maps;    private List&lt;Object&gt; lists;    private Dog dog;\n\n\n\n\n4、@PropertySource&amp;@ImportResource&amp;@Bean@PropertySource：加载指定的配置文件；\n/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； *      prefix = &quot;person&quot;：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； *  @ConfigurationProperties(prefix = &quot;person&quot;)默认从全局配置文件中获取值； * */@PropertySource(value = &#123;&quot;classpath:person.properties&quot;&#125;)@Component@ConfigurationProperties(prefix = &quot;person&quot;)//@Validatedpublic class Person &#123;    /**     * &lt;bean class=&quot;Person&quot;&gt;     *      &lt;property name=&quot;lastName&quot; value=&quot;字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;&quot;&gt;&lt;/property&gt;     * &lt;bean/&gt;     */   //lastName必须是邮箱格式   // @Email    //@Value(&quot;$&#123;person.last-name&#125;&quot;)    private String lastName;    //@Value(&quot;#&#123;11*2&#125;&quot;)    private Integer age;    //@Value(&quot;true&quot;)    private Boolean boss;\n\n\n\n@ImportResource：导入Spring的配置文件，让配置文件里面的内容生效；\nSpring Boot里面没有Spring的配置文件，我们自己编写的配置文件，也不能自动识别；\n想让Spring的配置文件生效，加载进来；@ImportResource标注在一个配置类上\n@ImportResource(locations = &#123;&quot;classpath:beans.xml&quot;&#125;)导入Spring的配置文件让其生效\n\n\n\n不来编写Spring的配置文件\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;bean id=&quot;helloService&quot; class=&quot;com.atguigu.springboot.service.HelloService&quot;&gt;&lt;/bean&gt;&lt;/beans&gt;\n\n\n\nSpringBoot推荐给容器中添加组件的方式；推荐使用全注解的方式\n1、配置类**@Configuration**——&gt;Spring配置文件\n2、使用**@Bean**给容器中添加组件\n/** * @Configuration：指明当前类是一个配置类；就是来替代之前的Spring配置文件 * * 在配置文件中用&lt;bean&gt;&lt;bean/&gt;标签添加组件 * */@Configurationpublic class MyAppConfig &#123;    //将方法的返回值添加到容器中；容器中这个组件默认的id就是方法名    @Bean    public HelloService helloService02()&#123;        System.out.println(&quot;配置类@Bean给容器中添加组件了...&quot;);        return new HelloService();    &#125;&#125;\n\n\n\n##4、配置文件占位符\n1、随机数$&#123;random.value&#125;、$&#123;random.int&#125;、$&#123;random.long&#125;$&#123;random.int(10)&#125;、$&#123;random.int[1024,65536]&#125;\n\n\n\n2、占位符获取之前配置的值，如果没有可以是用:指定默认值person.last-name=张三$&#123;random.uuid&#125;person.age=$&#123;random.int&#125;person.birth=2017/12/15person.boss=falseperson.maps.k1=v1person.maps.k2=14person.lists=a,b,cperson.dog.name=$&#123;person.hello:hello&#125;_dogperson.dog.age=15\n\n\n\n5、Profile1、多Profile文件我们在主配置文件编写的时候，文件名可以是 application-{profile}.properties&#x2F;yml\n默认使用application.properties的配置；\n2、yml支持多文档块方式server:  port: 8081spring:  profiles:    active: prod---server:  port: 8083spring:  profiles: dev---server:  port: 8084spring:  profiles: prod  #指定属于哪个环境\n\n\n\n3、激活指定profile 1、在配置文件中指定 spring.profiles.active&#x3D;dev\n 2、命令行：\n java -jar spring-boot-02-config-0.0.1-SNAPSHOT.jar –spring.profiles.active&#x3D;dev；\n 可以直接在测试的时候，配置传入命令行参数\n 3、虚拟机参数；\n -Dspring.profiles.active&#x3D;dev\n6、配置文件加载位置springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件\n–file:.&#x2F;config&#x2F;\n–file:.&#x2F;\n–classpath:&#x2F;config&#x2F;\n–classpath:&#x2F;\n优先级由高到底，高优先级的配置会覆盖低优先级的配置；\nSpringBoot会从这四个位置全部加载主配置文件；互补配置；\n&#x3D;&#x3D;我们还可以通过spring.config.location来改变默认的配置文件位置&#x3D;&#x3D;\n项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置；\njava -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –spring.config.location&#x3D;G:&#x2F;application.properties\n7、外部配置加载顺序&#x3D;&#x3D;SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置&#x3D;&#x3D;\n1.命令行参数\n所有的配置都可以在命令行上进行指定\njava -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –server.port&#x3D;8087 –server.context-path&#x3D;&#x2F;abc\n多个配置用空格分开； –配置项&#x3D;值\n2.来自java:comp&#x2F;env的JNDI属性\n3.Java系统属性（System.getProperties()）\n4.操作系统环境变量\n5.RandomValuePropertySource配置的random.*属性值\n&#x3D;&#x3D;由jar包外向jar包内进行寻找；&#x3D;&#x3D;\n&#x3D;&#x3D;优先加载带profile&#x3D;&#x3D;\n6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件\n7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件\n&#x3D;&#x3D;再来加载不带profile&#x3D;&#x3D;\n8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件\n9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件\n10.@Configuration注解类上的@PropertySource\n11.通过SpringApplication.setDefaultProperties指定的默认属性\n所有支持的配置加载来源；\n参考官方文档\n8、自动配置原理配置文件到底能写什么？怎么写？自动配置原理；\n配置文件能配置的属性参照\n1、自动配置原理：1）、SpringBoot启动的时候加载主配置类，开启了自动配置功能 &#x3D;&#x3D;@EnableAutoConfiguration&#x3D;&#x3D;\n2）、@EnableAutoConfiguration 作用：\n\n利用EnableAutoConfigurationImportSelector给容器中导入一些组件？\n\n可以查看selectImports()方法的内容；\n\nList configurations &#x3D; getCandidateConfigurations(annotationMetadata, attributes);获取候选的配置\n\n&#96;&#96;&#96;javaSpringFactoriesLoader.loadFactoryNames()扫描所有jar包类路径下  META-INF&#x2F;spring.factories把扫描到的这些文件的内容包装成properties对象从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后把他们添加在容器中        **==将 类路径下 META-INF/spring.factories 里面配置的所有EnableAutoConfiguration的值加入到了容器中；==**```properties# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\\org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\\org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\\org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\\org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration\n\n\n\n每一个这样的 xxxAutoConfiguration类都是容器中的一个组件，都加入到容器中；用他们来做自动配置；\n3）、每一个自动配置类进行自动配置功能；\n4）、以HttpEncodingAutoConfiguration（Http编码自动配置）为例解释自动配置原理；\n@Configuration   //表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@EnableConfigurationProperties(HttpEncodingProperties.class)  //启动指定类的ConfigurationProperties功能；将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncodingProperties加入到ioc容器中@ConditionalOnWebApplication //Spring底层@Conditional注解（Spring注解版），根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效；    判断当前应用是否是web应用，如果是，当前配置类生效@ConditionalOnClass(CharacterEncodingFilter.class)  //判断当前项目有没有这个类CharacterEncodingFilter；SpringMVC中进行乱码解决的过滤器；@ConditionalOnProperty(prefix = &quot;spring.http.encoding&quot;, value = &quot;enabled&quot;, matchIfMissing = true)  //判断配置文件中是否存在某个配置  spring.http.encoding.enabled；如果不存在，判断也是成立的//即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的；public class HttpEncodingAutoConfiguration &#123;    \t//他已经和SpringBoot的配置文件映射了  \tprivate final HttpEncodingProperties properties;     //只有一个有参构造器的情况下，参数的值就会从容器中拿  \tpublic HttpEncodingAutoConfiguration(HttpEncodingProperties properties) &#123;\t\tthis.properties = properties;\t&#125;      @Bean   //给容器中添加一个组件，这个组件的某些值需要从properties中获取\t@ConditionalOnMissingBean(CharacterEncodingFilter.class) //判断容器没有这个组件？\tpublic CharacterEncodingFilter characterEncodingFilter() &#123;\t\tCharacterEncodingFilter filter = new OrderedCharacterEncodingFilter();\t\tfilter.setEncoding(this.properties.getCharset().name());\t\tfilter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST));\t\tfilter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE));\t\treturn filter;\t&#125;\n\n\n\n根据当前不同的条件判断，决定这个配置类是否生效？\n一但这个配置类生效；这个配置类就会给容器中添加各种组件；这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的；\n5）、所有在配置文件中能配置的属性都是在xxxxProperties类中封装者‘；配置文件能配置什么就可以参照某个功能对应的这个属性类\n@ConfigurationProperties(prefix = &quot;spring.http.encoding&quot;)  //从配置文件中获取指定的值和bean的属性进行绑定public class HttpEncodingProperties &#123;   public static final Charset DEFAULT_CHARSET = Charset.forName(&quot;UTF-8&quot;);\n\n\n\n精髓：\n 1）、SpringBoot启动会加载大量的自动配置类\n 2）、我们看我们需要的功能有没有SpringBoot默认写好的自动配置类；\n 3）、我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了）\n 4）、给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值；\nxxxxAutoConfigurartion：自动配置类；\n给容器中添加组件\nxxxxProperties:封装配置文件中相关属性；\n2、细节1、@Conditional派生注解（Spring注解版原生的@Conditional作用）作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效；\n\n\n\n@Conditional扩展注解\n作用（判断是否满足当前指定条件）\n\n\n\n@ConditionalOnJava\n系统的java版本是否符合要求\n\n\n@ConditionalOnBean\n容器中存在指定Bean；\n\n\n@ConditionalOnMissingBean\n容器中不存在指定Bean；\n\n\n@ConditionalOnExpression\n满足SpEL表达式指定\n\n\n@ConditionalOnClass\n系统中有指定的类\n\n\n@ConditionalOnMissingClass\n系统中没有指定的类\n\n\n@ConditionalOnSingleCandidate\n容器中只有一个指定的Bean，或者这个Bean是首选Bean\n\n\n@ConditionalOnProperty\n系统中指定的属性是否有指定的值\n\n\n@ConditionalOnResource\n类路径下是否存在指定资源文件\n\n\n@ConditionalOnWebApplication\n当前是web环境\n\n\n@ConditionalOnNotWebApplication\n当前不是web环境\n\n\n@ConditionalOnJndi\nJNDI存在指定项\n\n\n自动配置类必须在一定的条件下才能生效；\n我们怎么知道哪些自动配置类生效；\n**&#x3D;&#x3D;我们可以通过启用 debug&#x3D;true属性；来让控制台打印自动配置报告&#x3D;&#x3D;**，这样我们就可以很方便的知道哪些自动配置类生效；\n=========================AUTO-CONFIGURATION REPORT=========================Positive matches:（自动配置类启用的）-----------------   DispatcherServletAutoConfiguration matched:      - @ConditionalOnClass found required class &#x27;org.springframework.web.servlet.DispatcherServlet&#x27;; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition)      - @ConditionalOnWebApplication (required) found StandardServletEnvironment (OnWebApplicationCondition)            Negative matches:（没有启动，没有匹配成功的自动配置类）-----------------   ActiveMQAutoConfiguration:      Did not match:         - @ConditionalOnClass did not find required classes &#x27;javax.jms.ConnectionFactory&#x27;, &#x27;org.apache.activemq.ActiveMQConnectionFactory&#x27; (OnClassCondition)   AopAutoConfiguration:      Did not match:         - @ConditionalOnClass did not find required classes &#x27;org.aspectj.lang.annotation.Aspect&#x27;, &#x27;org.aspectj.lang.reflect.Advice&#x27; (OnClassCondition)        \n\n\n\n\n三、日志1、日志框架小张；开发一个大型系统；\n 1、System.out.println(“”)；将关键数据打印在控制台；去掉？写在一个文件？\n 2、框架来记录系统的一些运行时信息；日志框架 ； zhanglogging.jar；\n 3、高大上的几个功能？异步模式？自动归档？xxxx？ zhanglogging-good.jar？\n 4、将以前框架卸下来？换上新的框架，重新修改之前相关的API；zhanglogging-prefect.jar；\n 5、JDBC—数据库驱动；\n 写了一个统一的接口层；日志门面（日志的一个抽象层）；logging-abstract.jar；\n 给项目中导入具体的日志实现就行了；我们之前的日志框架都是实现的抽象层；\n市面上的日志框架；\nJUL、JCL、Jboss-logging、logback、log4j、log4j2、slf4j….\n\n\n\n日志门面 （日志的抽象层）\n日志实现\n\n\n\nJCL（Jakarta Commons Logging） SLF4j（Simple Logging Facade for Java） jboss-logging\nLog4j JUL（java.util.logging） Log4j2 Logback\n\n\n左边选一个门面（抽象层）、右边来选一个实现；\n日志门面： SLF4J；\n日志实现：Logback；\nSpringBoot：底层是Spring框架，Spring框架默认是用JCL；‘\n &#x3D;&#x3D;SpringBoot选用 SLF4j和logback；&#x3D;&#x3D;\n2、SLF4j使用1、如何在系统中使用SLF4j https://www.slf4j.org以后开发的时候，日志记录方法的调用，不应该来直接调用日志的实现类，而是调用日志抽象层里面的方法；\n给系统里面导入slf4j的jar和 logback的实现jar\nimport org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld &#123;  public static void main(String[] args) &#123;    Logger logger = LoggerFactory.getLogger(HelloWorld.class);    logger.info(&quot;Hello World&quot;);  &#125;&#125;\n\n\n\n图示；\n\n每一个日志的实现框架都有自己的配置文件。使用slf4j以后，配置文件还是做成日志实现框架自己本身的配置文件；\n2、遗留问题a（slf4j+logback）: Spring（commons-logging）、Hibernate（jboss-logging）、MyBatis、xxxx\n统一日志记录，即使是别的框架和我一起统一使用slf4j进行输出？\n\n如何让系统中所有的日志都统一到slf4j；\n&#x3D;&#x3D;1、将系统中其他日志框架先排除出去；&#x3D;&#x3D;\n&#x3D;&#x3D;2、用中间包来替换原有的日志框架；&#x3D;&#x3D;\n&#x3D;&#x3D;3、我们导入slf4j其他的实现&#x3D;&#x3D;\n3、springboot日志关系3、SpringBoot日志关系&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t&lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;\n\n\n\nSpringBoot使用它来做日志功能；\n&lt;dependency&gt;\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t&lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;\t&lt;/dependency&gt;\n\n\n\n底层依赖关系\n\n总结：\n 1）、SpringBoot底层也是使用slf4j+logback的方式进行日志记录\n 2）、SpringBoot也把其他的日志都替换成了slf4j；\n 3）、中间替换包？\n@SuppressWarnings(&quot;rawtypes&quot;)public abstract class LogFactory &#123;    static String UNSUPPORTED_OPERATION_IN_JCL_OVER_SLF4J = &quot;http://www.slf4j.org/codes.html#unsupported_operation_in_jcl_over_slf4j&quot;;    static LogFactory logFactory = new SLF4JLogFactory();\n\n\n\n\n 4）、如果我们要引入其他框架？一定要把这个框架的默认日志依赖移除掉？\n Spring框架用的是commons-logging；\n&lt;dependency&gt;\t&lt;groupId&gt;org.springframework&lt;/groupId&gt;\t&lt;artifactId&gt;spring-core&lt;/artifactId&gt;\t&lt;exclusions&gt;\t\t&lt;exclusion&gt;\t\t\t&lt;groupId&gt;commons-logging&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;commons-logging&lt;/artifactId&gt;\t\t&lt;/exclusion&gt;\t&lt;/exclusions&gt;&lt;/dependency&gt;\n\n\n\n&#x3D;&#x3D;SpringBoot能自动适配所有的日志，而且底层使用slf4j+logback的方式记录日志，引入其他框架的时候，只需要把这个框架依赖的日志框架排除掉即可；&#x3D;&#x3D;\n4、日志使用；1、默认配置SpringBoot默认帮我们配置好了日志；\n//记录器Logger logger = LoggerFactory.getLogger(getClass());@Testpublic void contextLoads() &#123;\t//System.out.println();\t//日志的级别；\t//由低到高   trace&lt;debug&lt;info&lt;warn&lt;error\t//可以调整输出的日志级别；日志就只会在这个级别以以后的高级别生效\tlogger.trace(&quot;这是trace日志...&quot;);\tlogger.debug(&quot;这是debug日志...&quot;);\t//SpringBoot默认给我们使用的是info级别的，没有指定级别的就用SpringBoot默认规定的级别；root级别\tlogger.info(&quot;这是info日志...&quot;);\tlogger.warn(&quot;这是warn日志...&quot;);\tlogger.error(&quot;这是error日志...&quot;);&#125;\n\n\n\n  日志输出格式：%d表示日期时间，%thread表示线程名，%-5level：级别从左显示5个字符宽度%logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息，%n是换行符  --&gt;  %d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n\n\nSpringBoot修改日志的默认配置\nlogging.level.com.atguigu=trace#logging.path=# 不指定路径在当前项目下生成springboot.log日志# 可以指定完整的路径；#logging.file=G:/springboot.log# 在当前磁盘的根路径下创建spring文件夹和里面的log文件夹；使用 spring.log 作为默认文件logging.path=/spring/log#  在控制台输出的日志的格式logging.pattern.console=%d&#123;yyyy-MM-dd&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n# 指定文件中日志输出的格式logging.pattern.file=%d&#123;yyyy-MM-dd&#125; === [%thread] === %-5level === %logger&#123;50&#125; ==== %msg%n\n\n\n\n\n\n\nlogging.file\nlogging.path\nExample\nDescription\n\n\n\n(none)\n(none)\n\n只在控制台输出\n\n\n指定文件名\n(none)\nmy.log\n输出日志到my.log文件\n\n\n(none)\n指定目录\n&#x2F;var&#x2F;log\n输出到指定目录的 spring.log 文件中\n\n\n2、指定配置给类路径下放上每个日志框架自己的配置文件即可；SpringBoot就不使用他默认配置的了\n\n\n\nLogging System\nCustomization\n\n\n\nLogback\nlogback-spring.xml, logback-spring.groovy, logback.xml or logback.groovy\n\n\nLog4j2\nlog4j2-spring.xml or log4j2.xml\n\n\nJDK (Java Util Logging)\nlogging.properties\n\n\nlogback.xml：直接就被日志框架识别了；\nlogback-spring.xml：日志框架就不直接加载日志的配置项，由SpringBoot解析日志配置，可以使用SpringBoot的高级Profile功能\n&lt;springProfile name=&quot;staging&quot;&gt;    &lt;!-- configuration to be enabled when the &quot;staging&quot; profile is active --&gt;  \t可以指定某段配置只在某个环境下生效&lt;/springProfile&gt;\n\n\n\n如：\n&lt;appender name=&quot;stdout&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;!--        日志输出格式：\t\t\t%d表示日期时间，\t\t\t%thread表示线程名，\t\t\t%-5level：级别从左显示5个字符宽度\t\t\t%logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 \t\t\t%msg：日志消息，\t\t\t%n是换行符        --&gt;        &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt;            &lt;springProfile name=&quot;dev&quot;&gt;                &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ----&gt; [%thread] ---&gt; %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;            &lt;/springProfile&gt;            &lt;springProfile name=&quot;!dev&quot;&gt;                &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ==== [%thread] ==== %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;            &lt;/springProfile&gt;        &lt;/layout&gt;    &lt;/appender&gt;\n\n\n\n如果使用logback.xml作为日志配置文件，还要使用profile功能，会有以下错误\nno applicable action for [springProfile]\n\n5、切换日志框架可以按照slf4j的日志适配图，进行相关的切换；\nslf4j+log4j的方式；\n&lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  &lt;exclusions&gt;    &lt;exclusion&gt;      &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;      &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;    &lt;/exclusion&gt;    &lt;exclusion&gt;      &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;      &lt;groupId&gt;org.slf4j&lt;/groupId&gt;    &lt;/exclusion&gt;  &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;org.slf4j&lt;/groupId&gt;  &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;/dependency&gt;\n\n\n\n切换为log4j2\n   &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt;\n\n\n\n\n四、Web开发1、简介使用SpringBoot；\n1）、创建SpringBoot应用，选中我们需要的模块；\n2）、SpringBoot已经默认将这些场景配置好了，只需要在配置文件中指定少量配置就可以运行起来\n3）、自己编写业务代码；\n自动配置原理？\n这个场景SpringBoot帮我们配置了什么？能不能修改？能修改哪些配置？能不能扩展？xxx\nxxxxAutoConfiguration：帮我们给容器中自动配置组件；xxxxProperties:配置类来封装配置文件的内容；\n\n\n\n2、SpringBoot对静态资源的映射规则；@ConfigurationProperties(prefix = &quot;spring.resources&quot;, ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware &#123;  //可以设置和静态资源有关的参数，缓存时间等\n\n\n\nWebMvcAuotConfiguration：\t@Override\tpublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123;\t\tif (!this.resourceProperties.isAddMappings()) &#123;\t\t\tlogger.debug(&quot;Default resource handling disabled&quot;);\t\t\treturn;\t\t&#125;\t\tInteger cachePeriod = this.resourceProperties.getCachePeriod();\t\tif (!registry.hasMappingForPattern(&quot;/webjars/**&quot;)) &#123;\t\t\tcustomizeResourceHandlerRegistration(\t\t\t\t\tregistry.addResourceHandler(&quot;/webjars/**&quot;)\t\t\t\t\t\t\t.addResourceLocations(\t\t\t\t\t\t\t\t\t&quot;classpath:/META-INF/resources/webjars/&quot;)\t\t\t\t\t.setCachePeriod(cachePeriod));\t\t&#125;\t\tString staticPathPattern = this.mvcProperties.getStaticPathPattern();         \t//静态资源文件夹映射\t\tif (!registry.hasMappingForPattern(staticPathPattern)) &#123;\t\t\tcustomizeResourceHandlerRegistration(\t\t\t\t\tregistry.addResourceHandler(staticPathPattern)\t\t\t\t\t\t\t.addResourceLocations(\t\t\t\t\t\t\t\t\tthis.resourceProperties.getStaticLocations())\t\t\t\t\t.setCachePeriod(cachePeriod));\t\t&#125;\t&#125;       //配置欢迎页映射\t@Bean\tpublic WelcomePageHandlerMapping welcomePageHandlerMapping(\t\t\tResourceProperties resourceProperties) &#123;\t\treturn new WelcomePageHandlerMapping(resourceProperties.getWelcomePage(),\t\t\t\tthis.mvcProperties.getStaticPathPattern());\t&#125;      //配置喜欢的图标\t@Configuration\t@ConditionalOnProperty(value = &quot;spring.mvc.favicon.enabled&quot;, matchIfMissing = true)\tpublic static class FaviconConfiguration &#123;\t\tprivate final ResourceProperties resourceProperties;\t\tpublic FaviconConfiguration(ResourceProperties resourceProperties) &#123;\t\t\tthis.resourceProperties = resourceProperties;\t\t&#125;\t\t@Bean\t\tpublic SimpleUrlHandlerMapping faviconHandlerMapping() &#123;\t\t\tSimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping();\t\t\tmapping.setOrder(Ordered.HIGHEST_PRECEDENCE + 1);             \t//所有  **/favicon.ico \t\t\tmapping.setUrlMap(Collections.singletonMap(&quot;**/favicon.ico&quot;,\t\t\t\t\tfaviconRequestHandler()));\t\t\treturn mapping;\t\t&#125;\t\t@Bean\t\tpublic ResourceHttpRequestHandler faviconRequestHandler() &#123;\t\t\tResourceHttpRequestHandler requestHandler = new ResourceHttpRequestHandler();\t\t\trequestHandler\t\t\t\t\t.setLocations(this.resourceProperties.getFaviconLocations());\t\t\treturn requestHandler;\t\t&#125;\t&#125;\n\n\n\n&#x3D;&#x3D;1）、所有 &#x2F;webjars&#x2F;** ，都去 classpath:&#x2F;META-INF&#x2F;resources&#x2F;webjars&#x2F; 找资源；&#x3D;&#x3D;\n webjars：以jar包的方式引入静态资源；\nhttp://www.webjars.org/\n\nlocalhost:8080&#x2F;webjars&#x2F;jquery&#x2F;3.3.1&#x2F;jquery.js\n&lt;!--引入jquery-webjar--&gt;在访问的时候只需要写webjars下面资源的名称即可\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.webjars&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;jquery&lt;/artifactId&gt;\t\t\t&lt;version&gt;3.3.1&lt;/version&gt;\t\t&lt;/dependency&gt;\n\n\n\n&#x3D;&#x3D;2）、”&#x2F;**” 访问当前项目的任何资源，都去（静态资源的文件夹）找映射&#x3D;&#x3D;\n&quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;,&quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &quot;/&quot;：当前项目的根路径\n\n\n\nlocalhost:8080&#x2F;abc &#x3D;&#x3D;&#x3D; 去静态资源文件夹里面找abc\n&#x3D;&#x3D;3）、欢迎页； 静态资源文件夹下的所有index.html页面；被”&#x2F;**”映射；&#x3D;&#x3D;\n localhost:8080&#x2F; 找index页面\n&#x3D;&#x3D;4）、所有的 **&#x2F;favicon.ico 都是在静态资源文件下找；&#x3D;&#x3D;\n3、模板引擎JSP、Velocity、Freemarker、Thymeleaf\n\nSpringBoot推荐的Thymeleaf；\n语法更简单，功能更强大；\n1、引入thymeleaf；\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;          \t2.1.6\t\t&lt;/dependency&gt;切换thymeleaf版本&lt;properties&gt;\t\t&lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt;\t\t&lt;!-- 布局功能的支持程序  thymeleaf3主程序  layout2以上版本 --&gt;\t\t&lt;!-- thymeleaf2   layout1--&gt;\t\t&lt;thymeleaf-layout-dialect.version&gt;2.2.2&lt;/thymeleaf-layout-dialect.version&gt;  &lt;/properties&gt;\n\n\n\n2、Thymeleaf使用@ConfigurationProperties(prefix = &quot;spring.thymeleaf&quot;)public class ThymeleafProperties &#123;\tprivate static final Charset DEFAULT_ENCODING = Charset.forName(&quot;UTF-8&quot;);\tprivate static final MimeType DEFAULT_CONTENT_TYPE = MimeType.valueOf(&quot;text/html&quot;);\tpublic static final String DEFAULT_PREFIX = &quot;classpath:/templates/&quot;;\tpublic static final String DEFAULT_SUFFIX = &quot;.html&quot;;  \t//\n\n\n\n只要我们把HTML页面放在classpath:&#x2F;templates&#x2F;，thymeleaf就能自动渲染；\n使用：\n1、导入thymeleaf的名称空间\n&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;\n\n1\n2、使用thymeleaf语法；\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;h1&gt;成功！&lt;/h1&gt;    &lt;!--th:text 将div里面的文本内容设置为 --&gt;    &lt;div th:text=&quot;$&#123;hello&#125;&quot;&gt;这是显示欢迎信息&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n3、语法规则1）、th:text；改变当前元素里面的文本内容；\n th：任意html属性；来替换原生属性的值\n\n2）、表达式？\nSimple expressions:（表达式语法）    Variable Expressions: $&#123;...&#125;：获取变量值；OGNL；    \t\t1）、获取对象的属性、调用方法    \t\t2）、使用内置的基本对象：    \t\t\t#ctx : the context object.    \t\t\t#vars: the context variables.                #locale : the context locale.                #request : (only in Web Contexts) the HttpServletRequest object.                #response : (only in Web Contexts) the HttpServletResponse object.                #session : (only in Web Contexts) the HttpSession object.                #servletContext : (only in Web Contexts) the ServletContext object.                                $&#123;session.foo&#125;            3）、内置的一些工具对象：#execInfo : information about the template being processed.#messages : methods for obtaining externalized messages inside variables expressions, in the same way as they would be obtained using #&#123;…&#125; syntax.#uris : methods for escaping parts of URLs/URIs#conversions : methods for executing the configured conversion service (if any).#dates : methods for java.util.Date objects: formatting, component extraction, etc.#calendars : analogous to #dates , but for java.util.Calendar objects.#numbers : methods for formatting numeric objects.#strings : methods for String objects: contains, startsWith, prepending/appending, etc.#objects : methods for objects in general.#bools : methods for boolean evaluation.#arrays : methods for arrays.#lists : methods for lists.#sets : methods for sets.#maps : methods for maps.#aggregates : methods for creating aggregates on arrays or collections.#ids : methods for dealing with id attributes that might be repeated (for example, as a result of an iteration).    Selection Variable Expressions: *&#123;...&#125;：选择表达式：和$&#123;&#125;在功能上是一样；    \t补充：配合 th:object=&quot;$&#123;session.user&#125;：   &lt;div th:object=&quot;$&#123;session.user&#125;&quot;&gt;    &lt;p&gt;Name: &lt;span th:text=&quot;*&#123;firstName&#125;&quot;&gt;Sebastian&lt;/span&gt;.&lt;/p&gt;    &lt;p&gt;Surname: &lt;span th:text=&quot;*&#123;lastName&#125;&quot;&gt;Pepper&lt;/span&gt;.&lt;/p&gt;    &lt;p&gt;Nationality: &lt;span th:text=&quot;*&#123;nationality&#125;&quot;&gt;Saturn&lt;/span&gt;.&lt;/p&gt;    &lt;/div&gt;        Message Expressions: #&#123;...&#125;：获取国际化内容    Link URL Expressions: @&#123;...&#125;：定义URL；    \t\t@&#123;/order/process(execId=$&#123;execId&#125;,execType=&#x27;FAST&#x27;)&#125;    Fragment Expressions: ~&#123;...&#125;：片段引用表达式    \t\t&lt;div th:insert=&quot;~&#123;commons :: main&#125;&quot;&gt;...&lt;/div&gt;    \t\tLiterals（字面量）      Text literals: &#x27;one text&#x27; , &#x27;Another one!&#x27; ,…      Number literals: 0 , 34 , 3.0 , 12.3 ,…      Boolean literals: true , false      Null literal: null      Literal tokens: one , sometext , main ,…Text operations:（文本操作）    String concatenation: +    Literal substitutions: |The name is $&#123;name&#125;|Arithmetic operations:（数学运算）    Binary operators: + , - , * , / , %    Minus sign (unary operator): -Boolean operations:（布尔运算）    Binary operators: and , or    Boolean negation (unary operator): ! , notComparisons and equality:（比较运算）    Comparators: &gt; , &lt; , &gt;= , &lt;= ( gt , lt , ge , le )    Equality operators: == , != ( eq , ne )Conditional operators:条件运算（三元运算符）    If-then: (if) ? (then)    If-then-else: (if) ? (then) : (else)    Default: (value) ?: (defaultvalue)Special tokens:    No-Operation: _ \n\n\n\n4、SpringMVC自动配置https://docs.spring.io/spring-boot/docs/1.5.10.RELEASE/reference/htmlsingle/#boot-features-developing-web-applications\n1. Spring MVC auto-configurationSpring Boot 自动配置好了SpringMVC\n以下是SpringBoot对SpringMVC的默认配置:&#x3D;&#x3D;（WebMvcAutoConfiguration）&#x3D;&#x3D;\n\nInclusion of ContentNegotiatingViewResolver and BeanNameViewResolver beans.\n\n自动配置了ViewResolver（视图解析器：根据方法的返回值得到视图对象（View），视图对象决定如何渲染（转发？重定向？））\nContentNegotiatingViewResolver：组合所有的视图解析器的；\n&#x3D;&#x3D;如何定制：我们可以自己给容器中添加一个视图解析器；自动的将其组合进来；&#x3D;&#x3D;\n\n\nSupport for serving static resources, including support for WebJars (see below).静态资源文件夹路径,webjars\n\nStatic index.html support. 静态首页访问\n\nCustom Favicon support (see below). favicon.ico\n\n自动注册了 of Converter, GenericConverter, Formatter beans.\n\nConverter：转换器； public String hello(User user)：类型转换使用Converter\nFormatter 格式化器； 2017.12.17&#x3D;&#x3D;&#x3D;Date；\n\n\n\n@Bean@ConditionalOnProperty(prefix = &quot;spring.mvc&quot;, name = &quot;date-format&quot;)//在文件中配置日期格式化的规则public Formatter&lt;Date&gt; dateFormatter() &#123;\treturn new DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件&#125;\n\n\n\n &#x3D;&#x3D;自己添加的格式化器转换器，我们只需要放在容器中即可&#x3D;&#x3D;\n\nSupport for HttpMessageConverters (see below).\n\nHttpMessageConverter：SpringMVC用来转换Http请求和响应的；User—Json；\n\nHttpMessageConverters 是从容器中确定；获取所有的HttpMessageConverter；\n&#x3D;&#x3D;自己给容器中添加HttpMessageConverter，只需要将自己的组件注册容器中（@Bean,@Component）&#x3D;&#x3D;\n\n\n\nAutomatic registration of MessageCodesResolver (see below).定义错误代码生成规则\n\nAutomatic use of a ConfigurableWebBindingInitializer bean (see below).\n&#x3D;&#x3D;我们可以配置一个ConfigurableWebBindingInitializer来替换默认的；（添加到容器）&#x3D;&#x3D;\n初始化WebDataBinder；请求数据=====JavaBean；\n\norg.springframework.boot.autoconfigure.web：web的所有自动场景；\nIf you want to keep Spring Boot MVC features, and you just want to add additional MVC configuration (interceptors, formatters, view controllers etc.) you can add your own @Configuration class of type WebMvcConfigurerAdapter, but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter or ExceptionHandlerExceptionResolver you can declare a WebMvcRegistrationsAdapter instance providing such components.\nIf you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc.\n2、扩展SpringMVC&lt;mvc:view-controller path=&quot;/hello&quot; view-name=&quot;success&quot;/&gt;&lt;mvc:interceptors&gt;    &lt;mvc:interceptor&gt;        &lt;mvc:mapping path=&quot;/hello&quot;/&gt;        &lt;bean&gt;&lt;/bean&gt;    &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;\n\n\n\n&#x3D;&#x3D;编写一个配置类（@Configuration），是WebMvcConfigurerAdapter类型；不能标注@EnableWebMvc&#x3D;&#x3D;;\n既保留了所有的自动配置，也能用我们扩展的配置；\n//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123;    @Override    public void addViewControllers(ViewControllerRegistry registry) &#123;       // super.addViewControllers(registry);        //浏览器发送 /atguigu 请求来到 success        registry.addViewController(&quot;/atguigu&quot;).setViewName(&quot;success&quot;);    &#125;&#125;\n\n\n\n原理：\n 1）、WebMvcAutoConfiguration是SpringMVC的自动配置类\n 2）、在做其他自动配置时会导入；@Import(EnableWebMvcConfiguration.class)\n   @Configurationpublic static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration &#123;     private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); //从容器中获取所有的WebMvcConfigurer     @Autowired(required = false)     public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) &#123;         if (!CollectionUtils.isEmpty(configurers)) &#123;             this.configurers.addWebMvcConfigurers(configurers);           \t//一个参考实现；将所有的WebMvcConfigurer相关配置都来一起调用；             \t@Override            // public void addViewControllers(ViewControllerRegistry registry) &#123;             //    for (WebMvcConfigurer delegate : this.delegates) &#123;              //       delegate.addViewControllers(registry);              //   &#125;             &#125;         &#125;&#125;\n\n\n\n 3）、容器中所有的WebMvcConfigurer都会一起起作用；\n 4）、我们的配置类也会被调用；\n 效果：SpringMVC的自动配置和我们的扩展配置都会起作用；\n3、全面接管SpringMVC；SpringBoot对SpringMVC的自动配置不需要了，所有都是我们自己配置；所有的SpringMVC的自动配置都失效了\n我们需要在配置类中添加@EnableWebMvc即可；\n//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@EnableWebMvc@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123;    @Override    public void addViewControllers(ViewControllerRegistry registry) &#123;       // super.addViewControllers(registry);        //浏览器发送 /atguigu 请求来到 success        registry.addViewController(&quot;/atguigu&quot;).setViewName(&quot;success&quot;);    &#125;&#125;\n\n\n\n原理：\n为什么@EnableWebMvc自动配置就失效了；\n1）@EnableWebMvc的核心\n@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123;\n\n\n\n2）、\n@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123;\n\n\n\n3）、\n@Configuration@ConditionalOnWebApplication@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class,\t\tWebMvcConfigurerAdapter.class &#125;)//容器中没有这个组件的时候，这个自动配置类才生效@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class,\t\tValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123;\n\n\n\n4）、@EnableWebMvc将WebMvcConfigurationSupport组件导入进来；\n5）、导入的WebMvcConfigurationSupport只是SpringMVC最基本的功能；\n5、如何修改SpringBoot的默认配置模式：\n 1）、SpringBoot在自动配置很多组件的时候，先看容器中有没有用户自己配置的（@Bean、@Component）如果有就用用户配置的，如果没有，才自动配置；如果有些组件可以有多个（ViewResolver）将用户配置的和自己默认的组合起来；\n 2）、在SpringBoot中会有非常多的xxxConfigurer帮助我们进行扩展配置\n 3）、在SpringBoot中会有很多的xxxCustomizer帮助我们进行定制配置\n6、RestfulCRUD1）、默认访问首页//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能//@EnableWebMvc   不要接管SpringMVC@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123;    @Override    public void addViewControllers(ViewControllerRegistry registry) &#123;       // super.addViewControllers(registry);        //浏览器发送 /atguigu 请求来到 success        registry.addViewController(&quot;/atguigu&quot;).setViewName(&quot;success&quot;);    &#125;    //所有的WebMvcConfigurerAdapter组件都会一起起作用    @Bean //将组件注册在容器    public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123;        WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123;            @Override            public void addViewControllers(ViewControllerRegistry registry) &#123;                registry.addViewController(&quot;/&quot;).setViewName(&quot;login&quot;);                registry.addViewController(&quot;/index.html&quot;).setViewName(&quot;login&quot;);            &#125;        &#125;;        return adapter;    &#125;&#125;\n\n\n\n2）、国际化1）、编写国际化配置文件；\n2）、使用ResourceBundleMessageSource管理国际化资源文件\n3）、在页面使用fmt:message取出国际化内容\n步骤：\n1）、编写国际化配置文件，抽取页面需要显示的国际化消息\n\n2）、SpringBoot自动配置好了管理国际化资源文件的组件；\n@ConfigurationProperties(prefix = &quot;spring.messages&quot;)public class MessageSourceAutoConfiguration &#123;        /**\t * Comma-separated list of basenames (essentially a fully-qualified classpath\t * location), each following the ResourceBundle convention with relaxed support for\t * slash based locations. If it doesn&#x27;t contain a package qualifier (such as\t * &quot;org.mypackage&quot;), it will be resolved from the classpath root.\t */\tprivate String basename = &quot;messages&quot;;      //我们的配置文件可以直接放在类路径下叫messages.properties；        @Bean\tpublic MessageSource messageSource() &#123;\t\tResourceBundleMessageSource messageSource = new ResourceBundleMessageSource();\t\tif (StringUtils.hasText(this.basename)) &#123;            //设置国际化资源文件的基础名（去掉语言国家代码的）\t\t\tmessageSource.setBasenames(StringUtils.commaDelimitedListToStringArray(\t\t\t\t\tStringUtils.trimAllWhitespace(this.basename)));\t\t&#125;\t\tif (this.encoding != null) &#123;\t\t\tmessageSource.setDefaultEncoding(this.encoding.name());\t\t&#125;\t\tmessageSource.setFallbackToSystemLocale(this.fallbackToSystemLocale);\t\tmessageSource.setCacheSeconds(this.cacheSeconds);\t\tmessageSource.setAlwaysUseMessageFormat(this.alwaysUseMessageFormat);\t\treturn messageSource;\t&#125;\n\n\n\n3）、去页面获取国际化的值；\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;  xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;\t&lt;head&gt;\t\t&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;\t\t&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;&gt;\t\t&lt;meta name=&quot;description&quot; content=&quot;&quot;&gt;\t\t&lt;meta name=&quot;author&quot; content=&quot;&quot;&gt;\t\t&lt;title&gt;Signin Template for Bootstrap&lt;/title&gt;\t\t&lt;!-- Bootstrap core CSS --&gt;\t\t&lt;link href=&quot;asserts/css/bootstrap.min.css&quot; th:href=&quot;@&#123;/webjars/bootstrap/4.0.0/css/bootstrap.css&#125;&quot; rel=&quot;stylesheet&quot;&gt;\t\t&lt;!-- Custom styles for this template --&gt;\t\t&lt;link href=&quot;asserts/css/signin.css&quot; th:href=&quot;@&#123;/asserts/css/signin.css&#125;&quot; rel=&quot;stylesheet&quot;&gt;\t&lt;/head&gt;\t&lt;body class=&quot;text-center&quot;&gt;\t\t&lt;form class=&quot;form-signin&quot; action=&quot;dashboard.html&quot;&gt;\t\t\t&lt;img class=&quot;mb-4&quot; th:src=&quot;@&#123;/asserts/img/bootstrap-solid.svg&#125;&quot; src=&quot;asserts/img/bootstrap-solid.svg&quot; alt=&quot;&quot; width=&quot;72&quot; height=&quot;72&quot;&gt;\t\t\t&lt;h1 class=&quot;h3 mb-3 font-weight-normal&quot; th:text=&quot;#&#123;login.tip&#125;&quot;&gt;Please sign in&lt;/h1&gt;\t\t\t&lt;label class=&quot;sr-only&quot; th:text=&quot;#&#123;login.username&#125;&quot;&gt;Username&lt;/label&gt;\t\t\t&lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;Username&quot; th:placeholder=&quot;#&#123;login.username&#125;&quot; required=&quot;&quot; autofocus=&quot;&quot;&gt;\t\t\t&lt;label class=&quot;sr-only&quot; th:text=&quot;#&#123;login.password&#125;&quot;&gt;Password&lt;/label&gt;\t\t\t&lt;input type=&quot;password&quot; class=&quot;form-control&quot; placeholder=&quot;Password&quot; th:placeholder=&quot;#&#123;login.password&#125;&quot; required=&quot;&quot;&gt;\t\t\t&lt;div class=&quot;checkbox mb-3&quot;&gt;\t\t\t\t&lt;label&gt;          \t\t&lt;input type=&quot;checkbox&quot; value=&quot;remember-me&quot;/&gt; [[#&#123;login.remember&#125;]]        &lt;/label&gt;\t\t\t&lt;/div&gt;\t\t\t&lt;button class=&quot;btn btn-lg btn-primary btn-block&quot; type=&quot;submit&quot; th:text=&quot;#&#123;login.btn&#125;&quot;&gt;Sign in&lt;/button&gt;\t\t\t&lt;p class=&quot;mt-5 mb-3 text-muted&quot;&gt;© 2017-2018&lt;/p&gt;\t\t\t&lt;a class=&quot;btn btn-sm&quot;&gt;中文&lt;/a&gt;\t\t\t&lt;a class=&quot;btn btn-sm&quot;&gt;English&lt;/a&gt;\t\t&lt;/form&gt;\t&lt;/body&gt;&lt;/html&gt;\n\n\n\n效果：根据浏览器语言设置的信息切换了国际化；\n原理：\n 国际化Locale（区域信息对象）；LocaleResolver（获取区域信息对象）；\n\t\t@Bean\t\t@ConditionalOnMissingBean\t\t@ConditionalOnProperty(prefix = &quot;spring.mvc&quot;, name = &quot;locale&quot;)\t\tpublic LocaleResolver localeResolver() &#123;\t\t\tif (this.mvcProperties\t\t\t\t\t.getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) &#123;\t\t\t\treturn new FixedLocaleResolver(this.mvcProperties.getLocale());\t\t\t&#125;\t\t\tAcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver();\t\t\tlocaleResolver.setDefaultLocale(this.mvcProperties.getLocale());\t\t\treturn localeResolver;\t\t&#125;默认的就是根据请求头带来的区域信息获取Locale进行国际化\n\n\n\n4）、点击链接切换国际化\n/** * 可以在连接上携带区域信息 */public class MyLocaleResolver implements LocaleResolver &#123;        @Override    public Locale resolveLocale(HttpServletRequest request) &#123;        String l = request.getParameter(&quot;l&quot;);        Locale locale = Locale.getDefault();        if(!StringUtils.isEmpty(l))&#123;            String[] split = l.split(&quot;_&quot;);            locale = new Locale(split[0],split[1]);        &#125;        return locale;    &#125;    @Override    public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) &#123;    &#125;&#125; @Bean    public LocaleResolver localeResolver()&#123;        return new MyLocaleResolver();    &#125;&#125;\n\n\n\n[#](https://pchaoo.gitee.io/blog/views/springboot/Spring Boot.html#_3）、登陆)3）、登陆开发期间模板引擎页面修改以后，要实时生效\n1）、禁用模板引擎的缓存\n# 禁用缓存spring.thymeleaf.cache=false \n\n12\n2）、页面修改完成以后ctrl+f9：重新编译；\n登陆错误消息的显示\n&lt;p style=&quot;color: red&quot; th:text=&quot;$&#123;msg&#125;&quot; th:if=&quot;$&#123;not #strings.isEmpty(msg)&#125;&quot;&gt;&lt;/p&gt;\n\n\n\n4）、拦截器进行登陆检查拦截器\n/** * 登陆检查， */public class LoginHandlerInterceptor implements HandlerInterceptor &#123;    //目标方法执行之前    @Override    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;        Object user = request.getSession().getAttribute(&quot;loginUser&quot;);        if(user == null)&#123;            //未登陆，返回登陆页面            request.setAttribute(&quot;msg&quot;,&quot;没有权限请先登陆&quot;);            request.getRequestDispatcher(&quot;/index.html&quot;).forward(request,response);            return false;        &#125;else&#123;            //已登陆，放行请求            return true;        &#125;    &#125;    @Override    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123;    &#125;    @Override    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123;    &#125;&#125;\n\n\n\n注册拦截器\n//所有的WebMvcConfigurerAdapter组件都会一起起作用  @Bean //将组件注册在容器  public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123;      WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123;          @Override          public void addViewControllers(ViewControllerRegistry registry) &#123;              registry.addViewController(&quot;/&quot;).setViewName(&quot;login&quot;);              registry.addViewController(&quot;/index.html&quot;).setViewName(&quot;login&quot;);              registry.addViewController(&quot;/main.html&quot;).setViewName(&quot;dashboard&quot;);          &#125;          //注册拦截器          @Override          public void addInterceptors(InterceptorRegistry registry) &#123;              //super.addInterceptors(registry);              //静态资源；  *.css , *.js              //SpringBoot已经做好了静态资源映射              registry.addInterceptor(new LoginHandlerInterceptor()).addPathPatterns(&quot;/**&quot;)                      .excludePathPatterns(&quot;/index.html&quot;,&quot;/&quot;,&quot;/user/login&quot;);          &#125;      &#125;;      return adapter;  &#125;\n\n\n\n5）、CRUD-员工列表实验要求：\n1）、RestfulCRUD：CRUD满足Rest风格；\nURI： &#x2F;资源名称&#x2F;资源标识 HTTP请求方式区分对资源CRUD操作\n\n\n\n\n普通CRUD（uri来区分操作）\nRestfulCRUD\n\n\n\n查询\ngetEmp\nemp—GET\n\n\n添加\naddEmp?xxx\nemp—POST\n\n\n修改\nupdateEmp?id&#x3D;xxx&amp;xxx&#x3D;xx\nemp&#x2F;{id}—PUT\n\n\n删除\ndeleteEmp?id&#x3D;1\nemp&#x2F;{id}—DELETE\n\n\n2）、实验的请求架构;\n\n\n\n实验功能\n请求URI\n请求方式\n\n\n\n查询所有员工\nemps\nGET\n\n\n查询某个员工(来到修改页面)\nemp&#x2F;1\nGET\n\n\n来到添加页面\nemp\nGET\n\n\n添加员工\nemp\nPOST\n\n\n来到修改页面（查出员工进行信息回显）\nemp&#x2F;1\nGET\n\n\n修改员工\nemp\nPUT\n\n\n删除员工\nemp&#x2F;1\nDELETE\n\n\n3）、员工列表：\nthymeleaf公共页面元素抽取1、抽取公共片段&lt;div th:fragment=&quot;copy&quot;&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt;2、引入公共片段&lt;div th:insert=&quot;~&#123;footer :: copy&#125;&quot;&gt;&lt;/div&gt;~&#123;templatename::selector&#125;：模板名::选择器~&#123;templatename::fragmentname&#125;:模板名::片段名3、默认效果：insert的公共片段在div标签中如果使用th:insert等属性进行引入，可以不用写~&#123;&#125;：行内写法可以加上：[[~&#123;&#125;]];[(~&#123;&#125;)]；\n\n\n\n三种引入公共片段的th属性：\nth:insert：将公共片段整个插入到声明引入的元素中\nth:replace：将声明引入的元素替换为公共片段\nth:include：将被引入的片段的内容包含进这个标签中\n&lt;footer th:fragment=&quot;copy&quot;&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;引入方式&lt;div th:insert=&quot;footer :: copy&quot;&gt;&lt;/div&gt;&lt;div th:replace=&quot;footer :: copy&quot;&gt;&lt;/div&gt;&lt;div th:include=&quot;footer :: copy&quot;&gt;&lt;/div&gt;效果&lt;div&gt;    &lt;footer&gt;    &amp;copy; 2011 The Good Thymes Virtual Grocery    &lt;/footer&gt;&lt;/div&gt;&lt;footer&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;&lt;div&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt;\n\n\n\n引入片段的时候传入参数：\n&lt;nav class=&quot;col-md-2 d-none d-md-block bg-light sidebar&quot; id=&quot;sidebar&quot;&gt;    &lt;div class=&quot;sidebar-sticky&quot;&gt;        &lt;ul class=&quot;nav flex-column&quot;&gt;            &lt;li class=&quot;nav-item&quot;&gt;                &lt;a class=&quot;nav-link active&quot;                   th:class=&quot;$&#123;activeUri==&#x27;main.html&#x27;?&#x27;nav-link active&#x27;:&#x27;nav-link&#x27;&#125;&quot;                   href=&quot;#&quot; th:href=&quot;@&#123;/main.html&#125;&quot;&gt;                    &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;24&quot; height=&quot;24&quot; viewBox=&quot;0 0 24 24&quot; fill=&quot;none&quot; stroke=&quot;currentColor&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot; class=&quot;feather feather-home&quot;&gt;                        &lt;path d=&quot;M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z&quot;&gt;&lt;/path&gt;                        &lt;polyline points=&quot;9 22 9 12 15 12 15 22&quot;&gt;&lt;/polyline&gt;                    &lt;/svg&gt;                    Dashboard &lt;span class=&quot;sr-only&quot;&gt;(current)&lt;/span&gt;                &lt;/a&gt;            &lt;/li&gt;&lt;!--引入侧边栏;传入参数--&gt;&lt;div th:replace=&quot;commons/bar::#sidebar(activeUri=&#x27;emps&#x27;)&quot;&gt;&lt;/div&gt;\n\n\n\n6）、CRUD-员工添加添加页面\n&lt;form&gt;    &lt;div class=&quot;form-group&quot;&gt;        &lt;label&gt;LastName&lt;/label&gt;        &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot;&gt;    &lt;/div&gt;    &lt;div class=&quot;form-group&quot;&gt;        &lt;label&gt;Email&lt;/label&gt;        &lt;input type=&quot;email&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan@atguigu.com&quot;&gt;    &lt;/div&gt;    &lt;div class=&quot;form-group&quot;&gt;        &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt;        &lt;div class=&quot;form-check form-check-inline&quot;&gt;            &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot;  value=&quot;1&quot;&gt;            &lt;label class=&quot;form-check-label&quot;&gt;男&lt;/label&gt;        &lt;/div&gt;        &lt;div class=&quot;form-check form-check-inline&quot;&gt;            &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot;  value=&quot;0&quot;&gt;            &lt;label class=&quot;form-check-label&quot;&gt;女&lt;/label&gt;        &lt;/div&gt;    &lt;/div&gt;    &lt;div class=&quot;form-group&quot;&gt;        &lt;label&gt;department&lt;/label&gt;        &lt;select class=&quot;form-control&quot;&gt;            &lt;option&gt;1&lt;/option&gt;            &lt;option&gt;2&lt;/option&gt;            &lt;option&gt;3&lt;/option&gt;            &lt;option&gt;4&lt;/option&gt;            &lt;option&gt;5&lt;/option&gt;        &lt;/select&gt;    &lt;/div&gt;    &lt;div class=&quot;form-group&quot;&gt;        &lt;label&gt;Birth&lt;/label&gt;        &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot;&gt;    &lt;/div&gt;    &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;添加&lt;/button&gt;&lt;/form&gt;\n\n\n\n提交的数据格式不对：生日：日期；\n2017-12-12；2017&#x2F;12&#x2F;12；2017.12.12；\n日期的格式化；SpringMVC将页面提交的值需要转换为指定的类型;\n2017-12-12—Date； 类型转换，格式化;\n默认日期是按照&#x2F;的方式；\n7）、CRUD-员工修改修改添加二合一表单\n&lt;!--需要区分是员工修改还是添加；--&gt;&lt;form th:action=&quot;@&#123;/emp&#125;&quot; method=&quot;post&quot;&gt;    &lt;!--发送put请求修改员工数据--&gt;    &lt;!--1、SpringMVC中配置HiddenHttpMethodFilter;（SpringBoot自动配置好的）2、页面创建一个post表单3、创建一个input项，name=&quot;_method&quot;;值就是我们指定的请求方式--&gt;    &lt;input type=&quot;hidden&quot; name=&quot;_method&quot; value=&quot;put&quot; th:if=&quot;$&#123;emp!=null&#125;&quot;/&gt;    &lt;input type=&quot;hidden&quot; name=&quot;id&quot; th:if=&quot;$&#123;emp!=null&#125;&quot; th:value=&quot;$&#123;emp.id&#125;&quot;&gt;    &lt;div class=&quot;form-group&quot;&gt;        &lt;label&gt;LastName&lt;/label&gt;        &lt;input name=&quot;lastName&quot; type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot; th:value=&quot;$&#123;emp!=null&#125;?$&#123;emp.lastName&#125;&quot;&gt;    &lt;/div&gt;    &lt;div class=&quot;form-group&quot;&gt;        &lt;label&gt;Email&lt;/label&gt;        &lt;input name=&quot;email&quot; type=&quot;email&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan@atguigu.com&quot; th:value=&quot;$&#123;emp!=null&#125;?$&#123;emp.email&#125;&quot;&gt;    &lt;/div&gt;    &lt;div class=&quot;form-group&quot;&gt;        &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt;        &lt;div class=&quot;form-check form-check-inline&quot;&gt;            &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;1&quot; th:checked=&quot;$&#123;emp!=null&#125;?$&#123;emp.gender==1&#125;&quot;&gt;            &lt;label class=&quot;form-check-label&quot;&gt;男&lt;/label&gt;        &lt;/div&gt;        &lt;div class=&quot;form-check form-check-inline&quot;&gt;            &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;0&quot; th:checked=&quot;$&#123;emp!=null&#125;?$&#123;emp.gender==0&#125;&quot;&gt;            &lt;label class=&quot;form-check-label&quot;&gt;女&lt;/label&gt;        &lt;/div&gt;    &lt;/div&gt;    &lt;div class=&quot;form-group&quot;&gt;        &lt;label&gt;department&lt;/label&gt;        &lt;!--提交的是部门的id--&gt;        &lt;select class=&quot;form-control&quot; name=&quot;department.id&quot;&gt;            &lt;option th:selected=&quot;$&#123;emp!=null&#125;?$&#123;dept.id == emp.department.id&#125;&quot; th:value=&quot;$&#123;dept.id&#125;&quot; th:each=&quot;dept:$&#123;depts&#125;&quot; th:text=&quot;$&#123;dept.departmentName&#125;&quot;&gt;1&lt;/option&gt;        &lt;/select&gt;    &lt;/div&gt;    &lt;div class=&quot;form-group&quot;&gt;        &lt;label&gt;Birth&lt;/label&gt;        &lt;input name=&quot;birth&quot; type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot; th:value=&quot;$&#123;emp!=null&#125;?$&#123;#dates.format(emp.birth, &#x27;yyyy-MM-dd HH:mm&#x27;)&#125;&quot;&gt;    &lt;/div&gt;    &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot; th:text=&quot;$&#123;emp!=null&#125;?&#x27;修改&#x27;:&#x27;添加&#x27;&quot;&gt;添加&lt;/button&gt;&lt;/form&gt;\n\n\n\n8）、CRUD-员工删除&lt;tr th:each=&quot;emp:$&#123;emps&#125;&quot;&gt;    &lt;td th:text=&quot;$&#123;emp.id&#125;&quot;&gt;&lt;/td&gt;    &lt;td&gt;[[$&#123;emp.lastName&#125;]]&lt;/td&gt;    &lt;td th:text=&quot;$&#123;emp.email&#125;&quot;&gt;&lt;/td&gt;    &lt;td th:text=&quot;$&#123;emp.gender&#125;==0?&#x27;女&#x27;:&#x27;男&#x27;&quot;&gt;&lt;/td&gt;    &lt;td th:text=&quot;$&#123;emp.department.departmentName&#125;&quot;&gt;&lt;/td&gt;    &lt;td th:text=&quot;$&#123;#dates.format(emp.birth, &#x27;yyyy-MM-dd HH:mm&#x27;)&#125;&quot;&gt;&lt;/td&gt;    &lt;td&gt;        &lt;a class=&quot;btn btn-sm btn-primary&quot; th:href=&quot;@&#123;/emp/&#125;+$&#123;emp.id&#125;&quot;&gt;编辑&lt;/a&gt;        &lt;button th:attr=&quot;del_uri=@&#123;/emp/&#125;+$&#123;emp.id&#125;&quot; class=&quot;btn btn-sm btn-danger deleteBtn&quot;&gt;删除&lt;/button&gt;    &lt;/td&gt;&lt;/tr&gt;&lt;script&gt;    $(&quot;.deleteBtn&quot;).click(function()&#123;        //删除当前员工的        $(&quot;#deleteEmpForm&quot;).attr(&quot;action&quot;,$(this).attr(&quot;del_uri&quot;)).submit();        return false;    &#125;);&lt;/script&gt;\n\n\n\n7、错误处理机制1）、SpringBoot默认的错误处理机制默认效果：\n 1）、浏览器，返回一个默认的错误页面\n\n浏览器发送请求的请求头：\n\n 2）、如果是其他客户端，默认响应一个json数据\n\n \n原理：\n 可以参照ErrorMvcAutoConfiguration；错误处理的自动配置；\n给容器中添加了以下组件\n\n 1、DefaultErrorAttributes：\n帮我们在页面共享信息；@Override\tpublic Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes,\t\t\tboolean includeStackTrace) &#123;\t\tMap&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;String, Object&gt;();\t\terrorAttributes.put(&quot;timestamp&quot;, new Date());\t\taddStatus(errorAttributes, requestAttributes);\t\taddErrorDetails(errorAttributes, requestAttributes, includeStackTrace);\t\taddPath(errorAttributes, requestAttributes);\t\treturn errorAttributes;\t&#125;\n\n\n\n 2、BasicErrorController：处理默认&#x2F;error请求\n@Controller@RequestMapping(&quot;$&#123;server.error.path:$&#123;error.path:/error&#125;&#125;&quot;)public class BasicErrorController extends AbstractErrorController &#123;        @RequestMapping(produces = &quot;text/html&quot;)//产生html类型的数据；浏览器发送的请求来到这个方法处理\tpublic ModelAndView errorHtml(HttpServletRequest request,\t\t\tHttpServletResponse response) &#123;\t\tHttpStatus status = getStatus(request);\t\tMap&lt;String, Object&gt; model = Collections.unmodifiableMap(getErrorAttributes(\t\t\t\trequest, isIncludeStackTrace(request, MediaType.TEXT_HTML)));\t\tresponse.setStatus(status.value());                //去哪个页面作为错误页面；包含页面地址和页面内容\t\tModelAndView modelAndView = resolveErrorView(request, response, status, model);\t\treturn (modelAndView == null ? new ModelAndView(&quot;error&quot;, model) : modelAndView);\t&#125;\t@RequestMapping\t@ResponseBody    //产生json数据，其他客户端来到这个方法处理；\tpublic ResponseEntity&lt;Map&lt;String, Object&gt;&gt; error(HttpServletRequest request) &#123;\t\tMap&lt;String, Object&gt; body = getErrorAttributes(request,\t\t\t\tisIncludeStackTrace(request, MediaType.ALL));\t\tHttpStatus status = getStatus(request);\t\treturn new ResponseEntity&lt;Map&lt;String, Object&gt;&gt;(body, status);\t&#125;\n\n\n\n 3、ErrorPageCustomizer：\n@Value(&quot;$&#123;error.path:/error&#125;&quot;)private String path = &quot;/error&quot;;  系统出现错误以后来到error请求进行处理；（web.xml注册的错误页面规则）\n\n\n\n 4、DefaultErrorViewResolver：\n@Override\tpublic ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status,\t\t\tMap&lt;String, Object&gt; model) &#123;\t\tModelAndView modelAndView = resolve(String.valueOf(status), model);\t\tif (modelAndView == null &amp;&amp; SERIES_VIEWS.containsKey(status.series())) &#123;\t\t\tmodelAndView = resolve(SERIES_VIEWS.get(status.series()), model);\t\t&#125;\t\treturn modelAndView;\t&#125;\tprivate ModelAndView resolve(String viewName, Map&lt;String, Object&gt; model) &#123;        //默认SpringBoot可以去找到一个页面？  error/404\t\tString errorViewName = &quot;error/&quot; + viewName;                //模板引擎可以解析这个页面地址就用模板引擎解析\t\tTemplateAvailabilityProvider provider = this.templateAvailabilityProviders\t\t\t\t.getProvider(errorViewName, this.applicationContext);\t\tif (provider != null) &#123;            //模板引擎可用的情况下返回到errorViewName指定的视图地址\t\t\treturn new ModelAndView(errorViewName, model);\t\t&#125;        //模板引擎不可用，就在静态资源文件夹下找errorViewName对应的页面   error/404.html\t\treturn resolveResource(errorViewName, model);\t&#125;\n\n\n\n\n 步骤：\n 一但系统出现4xx或者5xx之类的错误；ErrorPageCustomizer就会生效（定制错误的响应规则）；就会来到&#x2F;error请求；就会被BasicErrorController处理；\n 1）响应页面；去哪个页面是由DefaultErrorViewResolver解析得到的；\nprotected ModelAndView resolveErrorView(HttpServletRequest request,      HttpServletResponse response, HttpStatus status, Map&lt;String, Object&gt; model) &#123;    //所有的ErrorViewResolver得到ModelAndView   for (ErrorViewResolver resolver : this.errorViewResolvers) &#123;      ModelAndView modelAndView = resolver.resolveErrorView(request, status, model);      if (modelAndView != null) &#123;         return modelAndView;      &#125;   &#125;   return null;&#125;\n\n\n\n2）、如果定制错误响应：1）、如何定制错误的页面； 1）、有模板引擎的情况下；error&#x2F;状态码; 【将错误页面命名为 错误状态码.html 放在模板引擎文件夹里面的 error文件夹下】，发生此状态码的错误就会来到 对应的页面；\n 我们可以使用4xx和5xx作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码.html）；\n 页面能获取的信息；\n timestamp：时间戳\n status：状态码\n error：错误提示\n exception：异常对象\n message：异常消息\n errors：JSR303数据校验的错误都在这里\n 2）、没有模板引擎（模板引擎找不到这个错误页面），静态资源文件夹下找；\n 3）、以上都没有错误页面，就是默认来到SpringBoot默认的错误提示页面；\n2）、如何定制错误的json数据； 1）、自定义异常处理&amp;返回定制json数据；\n@ControllerAdvicepublic class MyExceptionHandler &#123;    @ResponseBody    @ExceptionHandler(UserNotExistException.class)    public Map&lt;String,Object&gt; handleException(Exception e)&#123;        Map&lt;String,Object&gt; map = new HashMap&lt;&gt;();        map.put(&quot;code&quot;,&quot;user.notexist&quot;);        map.put(&quot;message&quot;,e.getMessage());        return map;    &#125;&#125;//没有自适应效果...\n\n\n\n 2）、转发到&#x2F;error进行自适应响应效果处理\n@ExceptionHandler(UserNotExistException.class)   public String handleException(Exception e, HttpServletRequest request)&#123;       Map&lt;String,Object&gt; map = new HashMap&lt;&gt;();       //传入我们自己的错误状态码  4xx 5xx，否则就不会进入定制错误页面的解析流程       /**        * Integer statusCode = (Integer) request        .getAttribute(&quot;javax.servlet.error.status_code&quot;);        */       request.setAttribute(&quot;javax.servlet.error.status_code&quot;,500);       map.put(&quot;code&quot;,&quot;user.notexist&quot;);       map.put(&quot;message&quot;,e.getMessage());       //转发到/error       return &quot;forward:/error&quot;;   &#125;\n\n\n\n3）、将我们的定制数据携带出去；出现错误以后，会来到&#x2F;error请求，会被BasicErrorController处理，响应出去可以获取的数据是由getErrorAttributes得到的（是AbstractErrorController（ErrorController）规定的方法）；\n 1、完全来编写一个ErrorController的实现类【或者是编写AbstractErrorController的子类】，放在容器中；\n 2、页面上能用的数据，或者是json返回能用的数据都是通过errorAttributes.getErrorAttributes得到；\n 容器中DefaultErrorAttributes.getErrorAttributes()；默认进行数据处理的；\n自定义ErrorAttributes\n//给容器中加入我们自己定义的ErrorAttributes@Componentpublic class MyErrorAttributes extends DefaultErrorAttributes &#123;    @Override    public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123;        Map&lt;String, Object&gt; map = super.getErrorAttributes(requestAttributes, includeStackTrace);        map.put(&quot;company&quot;,&quot;atguigu&quot;);        return map;    &#125;&#125;\n\n\n\n最终的效果：响应是自适应的，可以通过定制ErrorAttributes改变需要返回的内容，\n\n8、配置嵌入式Servlet容器SpringBoot默认使用Tomcat作为嵌入式的Servlet容器；\n\n问题？\n1）、如何定制和修改Servlet容器的相关配置；1、修改和server有关的配置（ServerProperties【也是EmbeddedServletContainerCustomizer】）；\nserver.port=8081server.context-path=/crudserver.tomcat.uri-encoding=UTF-8//通用的Servlet容器设置server.xxx//Tomcat的设置server.tomcat.xxx\n\n\n\n2、编写一个EmbeddedServletContainerCustomizer：嵌入式的Servlet容器的定制器；来修改Servlet容器的配置\n@Bean  //一定要将这个定制器加入到容器中public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer()&#123;    return new EmbeddedServletContainerCustomizer() &#123;        //定制嵌入式的Servlet容器相关的规则        @Override        public void customize(ConfigurableEmbeddedServletContainer container) &#123;            container.setPort(8083);        &#125;    &#125;;&#125;\n\n\n\n2）、注册Servlet三大组件【Servlet、Filter、Listener】由于SpringBoot默认是以jar包的方式启动嵌入式的Servlet容器来启动SpringBoot的web应用，没有web.xml文件。\n注册三大组件用以下方式\nServletRegistrationBean\n//注册三大组件@Beanpublic ServletRegistrationBean myServlet()&#123;    ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(),&quot;/myServlet&quot;);    return registrationBean;&#125;\n\n\n\nFilterRegistrationBean\n@Beanpublic FilterRegistrationBean myFilter()&#123;    FilterRegistrationBean registrationBean = new FilterRegistrationBean();    registrationBean.setFilter(new MyFilter());    registrationBean.setUrlPatterns(Arrays.asList(&quot;/hello&quot;,&quot;/myServlet&quot;));    return registrationBean;&#125;\n\n\n\nServletListenerRegistrationBean\n@Beanpublic ServletListenerRegistrationBean myListener()&#123;    ServletListenerRegistrationBean&lt;MyListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;&gt;(new MyListener());    return registrationBean;&#125;\n\n\n\nSpringBoot帮我们自动SpringMVC的时候，自动的注册SpringMVC的前端控制器；DIspatcherServlet；\nDispatcherServletAutoConfiguration中：\n@Bean(name = DEFAULT_DISPATCHER_SERVLET_REGISTRATION_BEAN_NAME)@ConditionalOnBean(value = DispatcherServlet.class, name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)public ServletRegistrationBean dispatcherServletRegistration(      DispatcherServlet dispatcherServlet) &#123;   ServletRegistrationBean registration = new ServletRegistrationBean(         dispatcherServlet, this.serverProperties.getServletMapping());    //默认拦截： /  所有请求；包静态资源，但是不拦截jsp请求；   /*会拦截jsp    //可以通过server.servletPath来修改SpringMVC前端控制器默认拦截的请求路径       registration.setName(DEFAULT_DISPATCHER_SERVLET_BEAN_NAME);   registration.setLoadOnStartup(         this.webMvcProperties.getServlet().getLoadOnStartup());   if (this.multipartConfig != null) &#123;      registration.setMultipartConfig(this.multipartConfig);   &#125;   return registration;&#125;\n\n\n\n2）、SpringBoot能不能支持其他的Servlet容器；\n3）、替换为其他嵌入式Servlet容器\n默认支持：\nTomcat（默认使用）\n&lt;dependency&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;   &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;   引入web模块默认就是使用嵌入式的Tomcat作为Servlet容器；&lt;/dependency&gt;\n\n\n\nJetty\n&lt;!-- 引入web模块 --&gt;&lt;dependency&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;   &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;   &lt;exclusions&gt;      &lt;exclusion&gt;         &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;         &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;/exclusion&gt;   &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt;   &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt;\n\n\n\nUndertow\n&lt;!-- 引入web模块 --&gt;&lt;dependency&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;   &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;   &lt;exclusions&gt;      &lt;exclusion&gt;         &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;         &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;/exclusion&gt;   &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt;   &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt;\n\n\n\n4）、嵌入式Servlet容器自动配置原理；EmbeddedServletContainerAutoConfiguration：嵌入式的Servlet容器自动配置？\n@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication@Import(BeanPostProcessorsRegistrar.class)//导入BeanPostProcessorsRegistrar：Spring注解版；给容器中导入一些组件//导入了EmbeddedServletContainerCustomizerBeanPostProcessor：//后置处理器：bean初始化前后（创建完对象，还没赋值赋值）执行初始化工作public class EmbeddedServletContainerAutoConfiguration &#123;        @Configuration\t@ConditionalOnClass(&#123; Servlet.class, Tomcat.class &#125;)//判断当前是否引入了Tomcat依赖；\t@ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)//判断当前容器没有用户自己定义EmbeddedServletContainerFactory：嵌入式的Servlet容器工厂；作用：创建嵌入式的Servlet容器\tpublic static class EmbeddedTomcat &#123;\t\t@Bean\t\tpublic TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() &#123;\t\t\treturn new TomcatEmbeddedServletContainerFactory();\t\t&#125;\t&#125;        /**\t * Nested configuration if Jetty is being used.\t */\t@Configuration\t@ConditionalOnClass(&#123; Servlet.class, Server.class, Loader.class,\t\t\tWebAppContext.class &#125;)\t@ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)\tpublic static class EmbeddedJetty &#123;\t\t@Bean\t\tpublic JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() &#123;\t\t\treturn new JettyEmbeddedServletContainerFactory();\t\t&#125;\t&#125;\t/**\t * Nested configuration if Undertow is being used.\t */\t@Configuration\t@ConditionalOnClass(&#123; Servlet.class, Undertow.class, SslClientAuthMode.class &#125;)\t@ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)\tpublic static class EmbeddedUndertow &#123;\t\t@Bean\t\tpublic UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() &#123;\t\t\treturn new UndertowEmbeddedServletContainerFactory();\t\t&#125;\t&#125;\n\n\n\n1）、EmbeddedServletContainerFactory（嵌入式Servlet容器工厂）\npublic interface EmbeddedServletContainerFactory &#123;   //获取嵌入式的Servlet容器   EmbeddedServletContainer getEmbeddedServletContainer(         ServletContextInitializer... initializers);&#125;\n\n\n\n\n2）、EmbeddedServletContainer：（嵌入式的Servlet容器）\n\n3）、以TomcatEmbeddedServletContainerFactory为例\n@Overridepublic EmbeddedServletContainer getEmbeddedServletContainer(      ServletContextInitializer... initializers) &#123;    //创建一个Tomcat   Tomcat tomcat = new Tomcat();        //配置Tomcat的基本环节   File baseDir = (this.baseDirectory != null ? this.baseDirectory         : createTempDir(&quot;tomcat&quot;));   tomcat.setBaseDir(baseDir.getAbsolutePath());   Connector connector = new Connector(this.protocol);   tomcat.getService().addConnector(connector);   customizeConnector(connector);   tomcat.setConnector(connector);   tomcat.getHost().setAutoDeploy(false);   configureEngine(tomcat.getEngine());   for (Connector additionalConnector : this.additionalTomcatConnectors) &#123;      tomcat.getService().addConnector(additionalConnector);   &#125;   prepareContext(tomcat.getHost(), initializers);        //将配置好的Tomcat传入进去，返回一个EmbeddedServletContainer；并且启动Tomcat服务器   return getTomcatEmbeddedServletContainer(tomcat);&#125;\n\n\n\n4）、我们对嵌入式容器的配置修改是怎么生效？\nServerProperties、EmbeddedServletContainerCustomizer\n\n\n\nEmbeddedServletContainerCustomizer：定制器帮我们修改了Servlet容器的配置？\n怎么修改的原理？\n5）、容器中导入了EmbeddedServletContainerCustomizerBeanPostProcessor\n//初始化之前@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName)      throws BeansException &#123;    //如果当前初始化的是一个ConfigurableEmbeddedServletContainer类型的组件   if (bean instanceof ConfigurableEmbeddedServletContainer) &#123;       //      postProcessBeforeInitialization((ConfigurableEmbeddedServletContainer) bean);   &#125;   return bean;&#125;private void postProcessBeforeInitialization(\t\t\tConfigurableEmbeddedServletContainer bean) &#123;    //获取所有的定制器，调用每一个定制器的customize方法来给Servlet容器进行属性赋值；    for (EmbeddedServletContainerCustomizer customizer : getCustomizers()) &#123;        customizer.customize(bean);    &#125;&#125;private Collection&lt;EmbeddedServletContainerCustomizer&gt; getCustomizers() &#123;    if (this.customizers == null) &#123;        // Look up does not include the parent context        this.customizers = new ArrayList&lt;EmbeddedServletContainerCustomizer&gt;(            this.beanFactory            //从容器中获取所有这葛类型的组件：EmbeddedServletContainerCustomizer            //定制Servlet容器，给容器中可以添加一个EmbeddedServletContainerCustomizer类型的组件            .getBeansOfType(EmbeddedServletContainerCustomizer.class,                            false, false)            .values());        Collections.sort(this.customizers, AnnotationAwareOrderComparator.INSTANCE);        this.customizers = Collections.unmodifiableList(this.customizers);    &#125;    return this.customizers;&#125;ServerProperties也是定制器\n\n\n\n步骤：\n1）、SpringBoot根据导入的依赖情况，给容器中添加相应的EmbeddedServletContainerFactory【TomcatEmbeddedServletContainerFactory】\n2）、容器中某个组件要创建对象就会惊动后置处理器；EmbeddedServletContainerCustomizerBeanPostProcessor；\n只要是嵌入式的Servlet容器工厂，后置处理器就工作；\n3）、后置处理器，从容器中获取所有的EmbeddedServletContainerCustomizer，调用定制器的定制方法\n###5）、嵌入式Servlet容器启动原理；\n什么时候创建嵌入式的Servlet容器工厂？什么时候获取嵌入式的Servlet容器并启动Tomcat；\n获取嵌入式的Servlet容器工厂：\n1）、SpringBoot应用启动运行run方法\n2）、refreshContext(context);SpringBoot刷新IOC容器【创建IOC容器对象，并初始化容器，创建容器中的每一个组件】；如果是web应用创建AnnotationConfigEmbeddedWebApplicationContext，否则：AnnotationConfigApplicationContext\n3）、refresh(context);刷新刚才创建好的ioc容器；\npublic void refresh() throws BeansException, IllegalStateException &#123;   synchronized (this.startupShutdownMonitor) &#123;      // Prepare this context for refreshing.      prepareRefresh();      // Tell the subclass to refresh the internal bean factory.      ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();      // Prepare the bean factory for use in this context.      prepareBeanFactory(beanFactory);      try &#123;         // Allows post-processing of the bean factory in context subclasses.         postProcessBeanFactory(beanFactory);         // Invoke factory processors registered as beans in the context.         invokeBeanFactoryPostProcessors(beanFactory);         // Register bean processors that intercept bean creation.         registerBeanPostProcessors(beanFactory);         // Initialize message source for this context.         initMessageSource();         // Initialize event multicaster for this context.         initApplicationEventMulticaster();         // Initialize other special beans in specific context subclasses.         onRefresh();         // Check for listener beans and register them.         registerListeners();         // Instantiate all remaining (non-lazy-init) singletons.         finishBeanFactoryInitialization(beanFactory);         // Last step: publish corresponding event.         finishRefresh();      &#125;      catch (BeansException ex) &#123;         if (logger.isWarnEnabled()) &#123;            logger.warn(&quot;Exception encountered during context initialization - &quot; +                  &quot;cancelling refresh attempt: &quot; + ex);         &#125;         // Destroy already created singletons to avoid dangling resources.         destroyBeans();         // Reset &#x27;active&#x27; flag.         cancelRefresh(ex);         // Propagate exception to caller.         throw ex;      &#125;      finally &#123;         // Reset common introspection caches in Spring&#x27;s core, since we         // might not ever need metadata for singleton beans anymore...         resetCommonCaches();      &#125;   &#125;&#125;\n\n\n\n4）、 onRefresh(); web的ioc容器重写了onRefresh方法\n5）、webioc容器会创建嵌入式的Servlet容器；createEmbeddedServletContainer();\n6）、获取嵌入式的Servlet容器工厂：\nEmbeddedServletContainerFactory containerFactory &#x3D; getEmbeddedServletContainerFactory();\n 从ioc容器中获取EmbeddedServletContainerFactory 组件；TomcatEmbeddedServletContainerFactory创建对象，后置处理器一看是这个对象，就获取所有的定制器来先定制Servlet容器的相关配置；\n7）、使用容器工厂获取嵌入式的Servlet容器：this.embeddedServletContainer &#x3D; containerFactory .getEmbeddedServletContainer(getSelfInitializer());\n8）、嵌入式的Servlet容器创建对象并启动Servlet容器；\n先启动嵌入式的Servlet容器，再将ioc容器中剩下没有创建出的对象获取出来；\n&#x3D;&#x3D;IOC容器启动创建嵌入式的Servlet容器&#x3D;&#x3D;\n9、使用外置的Servlet容器嵌入式Servlet容器：应用打成可执行的jar\n 优点：简单、便携；\n 缺点：默认不支持JSP、优化定制比较复杂（使用定制器【ServerProperties、自定义EmbeddedServletContainerCustomizer】，自己编写嵌入式Servlet容器的创建工厂【EmbeddedServletContainerFactory】）；\n外置的Servlet容器：外面安装Tomcat—应用war包的方式打包；\n步骤1）、必须创建一个war项目；（利用idea创建好目录结构）\n2）、将嵌入式的Tomcat指定为provided；\n&lt;dependency&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;   &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;   &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;\n\n\n\n3）、必须编写一个SpringBootServletInitializer的子类，并调用configure方法\npublic class ServletInitializer extends SpringBootServletInitializer &#123;   @Override   protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123;       //传入SpringBoot应用的主程序      return application.sources(SpringBoot04WebJspApplication.class);   &#125;&#125;\n\n\n\n4）、启动服务器就可以使用；\n原理jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器；\nwar包：启动服务器，服务器启动SpringBoot应用【SpringBootServletInitializer】，启动ioc容器；\nservlet3.0（Spring注解版）：\n8.2.4 Shared libraries &#x2F; runtimes pluggability：\n规则：\n 1）、服务器启动（web应用启动）会创建当前web应用里面每一个jar包里面ServletContainerInitializer实例：\n 2）、ServletContainerInitializer的实现放在jar包的META-INF&#x2F;services文件夹下，有一个名为javax.servlet.ServletContainerInitializer的文件，内容就是ServletContainerInitializer的实现类的全类名\n 3）、还可以使用@HandlesTypes，在应用启动的时候加载我们感兴趣的类；\n流程：\n1）、启动Tomcat\n2）、org\\springframework\\spring-web\\4.3.14.RELEASE\\spring-web-4.3.14.RELEASE.jar!\\META-INF\\services\\javax.servlet.ServletContainerInitializer：\nSpring的web模块里面有这个文件：org.springframework.web.SpringServletContainerInitializer\n3）、SpringServletContainerInitializer将@HandlesTypes(WebApplicationInitializer.class)标注的所有这个类型的类都传入到onStartup方法的Set&lt;Class&lt;?&gt;&gt;；为这些WebApplicationInitializer类型的类创建实例；\n4）、每一个WebApplicationInitializer都调用自己的onStartup；\n\n5）、相当于我们的SpringBootServletInitializer的类会被创建对象，并执行onStartup方法\n6）、SpringBootServletInitializer实例执行onStartup的时候会createRootApplicationContext；创建容器\nprotected WebApplicationContext createRootApplicationContext(      ServletContext servletContext) &#123;    //1、创建SpringApplicationBuilder   SpringApplicationBuilder builder = createSpringApplicationBuilder();   StandardServletEnvironment environment = new StandardServletEnvironment();   environment.initPropertySources(servletContext, null);   builder.environment(environment);   builder.main(getClass());   ApplicationContext parent = getExistingRootWebApplicationContext(servletContext);   if (parent != null) &#123;      this.logger.info(&quot;Root context already created (using as parent).&quot;);      servletContext.setAttribute(            WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null);      builder.initializers(new ParentContextApplicationContextInitializer(parent));   &#125;   builder.initializers(         new ServletContextApplicationContextInitializer(servletContext));   builder.contextClass(AnnotationConfigEmbeddedWebApplicationContext.class);        //调用configure方法，子类重写了这个方法，将SpringBoot的主程序类传入了进来   builder = configure(builder);        //使用builder创建一个Spring应用   SpringApplication application = builder.build();   if (application.getSources().isEmpty() &amp;&amp; AnnotationUtils         .findAnnotation(getClass(), Configuration.class) != null) &#123;      application.getSources().add(getClass());   &#125;   Assert.state(!application.getSources().isEmpty(),         &quot;No SpringApplication sources have been defined. Either override the &quot;               + &quot;configure method or add an @Configuration annotation&quot;);   // Ensure error pages are registered   if (this.registerErrorPageFilter) &#123;      application.getSources().add(ErrorPageFilterConfiguration.class);   &#125;    //启动Spring应用   return run(application);&#125;\n\n\n\n7）、Spring的应用就启动并且创建IOC容器\npublic ConfigurableApplicationContext run(String... args) &#123;   StopWatch stopWatch = new StopWatch();   stopWatch.start();   ConfigurableApplicationContext context = null;   FailureAnalyzers analyzers = null;   configureHeadlessProperty();   SpringApplicationRunListeners listeners = getRunListeners(args);   listeners.starting();   try &#123;      ApplicationArguments applicationArguments = new DefaultApplicationArguments(            args);      ConfigurableEnvironment environment = prepareEnvironment(listeners,            applicationArguments);      Banner printedBanner = printBanner(environment);      context = createApplicationContext();      analyzers = new FailureAnalyzers(context);      prepareContext(context, environment, listeners, applicationArguments,            printedBanner);              //刷新IOC容器      refreshContext(context);      afterRefresh(context, applicationArguments);      listeners.finished(context, null);      stopWatch.stop();      if (this.logStartupInfo) &#123;         new StartupInfoLogger(this.mainApplicationClass)               .logStarted(getApplicationLog(), stopWatch);      &#125;      return context;   &#125;   catch (Throwable ex) &#123;      handleRunFailure(context, listeners, analyzers, ex);      throw new IllegalStateException(ex);   &#125;&#125;\n\n\n\n\n&#x3D;&#x3D;启动Servlet容器，再启动SpringBoot应用&#x3D;&#x3D;\n五、Docker1、简介Docker是一个开源的应用容器引擎；是一个轻量级容器技术；\nDocker支持将软件编译成一个镜像；然后在镜像中各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像；\n运行中的这个镜像称为容器，容器启动是非常快速的。\n\n\n2、核心概念docker主机(Host)：安装了Docker程序的机器（Docker直接安装在操作系统之上）；\ndocker客户端(Client)：连接docker主机进行操作；\ndocker仓库(Registry)：用来保存各种打包好的软件镜像；\ndocker镜像(&#x2F;blog&#x2F;img&#x2F;springboot)：软件打包好的镜像；放在docker仓库中；\ndocker容器(Container)：镜像启动后的实例称为一个容器；容器是独立运行的一个或一组应用\n\n使用Docker的步骤：\n1）、安装Docker\n2）、去Docker仓库找到这个软件对应的镜像；\n3）、使用Docker运行这个镜像，这个镜像就会生成一个Docker容器；\n4）、对容器的启动停止就是对软件的启动停止；\n3、安装Docker1）、安装linux虚拟机 1）、VMWare、VirtualBox（安装）；\n 2）、导入虚拟机文件centos7-atguigu.ova；\n 3）、双击启动linux虚拟机;使用 root&#x2F; 123456登陆\n 4）、使用客户端连接linux服务器进行命令操作；\n 5）、设置虚拟机网络；\n 桥接网络&#x3D;&#x3D;&#x3D;选好网卡&#x3D;&#x3D;&#x3D;&#x3D;接入网线；\n 6）、设置好网络以后使用命令重启虚拟机的网络\nservice network restart\n\n\n\n 7）、查看linux的ip地址\nip addr\n\n\n\n 8）、使用客户端连接linux；\n2）、在linux虚拟机上安装docker步骤：\n1、检查内核版本，必须是3.10及以上uname -r2、安装dockeryum install docker3、输入y确认安装4、启动docker[root@localhost ~]# systemctl start docker[root@localhost ~]# docker -vDocker version 1.12.6, build 3e8e77d/1.12.65、开机启动docker[root@localhost ~]# systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.6、停止dockersystemctl stop docker\n\n\n\n4、Docker常用命令&amp;操作1）、镜像操作\n\n\n操作\n命令\n说明\n\n\n\n检索\ndocker search 关键字 eg：docker search redis\n我们经常去docker hub上检索镜像的详细信息，如镜像的TAG。\n\n\n拉取\ndocker pull 镜像名:tag\n:tag是可选的，tag表示标签，多为软件的版本，默认是latest\n\n\n列表\ndocker &#x2F;blog&#x2F;img&#x2F;springboot\n查看所有本地镜像\n\n\n删除\ndocker rmi image-id\n删除指定的本地镜像\n\n\nhttps://hub.docker.com/\n2）、容器操作软件镜像（QQ安装程序）—-运行镜像—-产生一个容器（正在运行的软件，运行的QQ）；\n步骤：\n1、搜索镜像[root@localhost ~]# docker search tomcat2、拉取镜像[root@localhost ~]# docker pull tomcat3、根据镜像启动容器docker run --name mytomcat -d tomcat:latest4、docker ps  查看运行中的容器5、 停止运行中的容器docker stop  容器的id6、查看所有的容器docker ps -a7、启动容器docker start 容器id8、删除一个容器 docker rm 容器id9、启动一个做了端口映射的tomcat[root@localhost ~]# docker run -d -p 8888:8080 tomcat-d：后台运行-p: 将主机的端口映射到容器的一个端口    主机端口:容器内部的端口10、为了演示简单关闭了linux的防火墙service firewalld status ；查看防火墙状态service firewalld stop：关闭防火墙11、查看容器的日志docker logs container-name/container-id更多命令参看https://docs.docker.com/engine/reference/commandline/docker/可以参考每一个镜像的文档\n\n\n\n3）、安装MySQL示例docker pull mysql\n\n\n\n错误的启动\n[root@localhost ~]# docker run --name mysql01 -d mysql42f09819908bb72dd99ae19e792e0a5d03c48638421fa64cce5f8ba0f40f5846mysql退出了[root@localhost ~]# docker ps -aCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                           PORTS               NAMES42f09819908b        mysql               &quot;docker-entrypoint.sh&quot;   34 seconds ago      Exited (1) 33 seconds ago                            mysql01538bde63e500        tomcat              &quot;catalina.sh run&quot;        About an hour ago   Exited (143) About an hour ago                       compassionate_goldstinec4f1ac60b3fc        tomcat              &quot;catalina.sh run&quot;        About an hour ago   Exited (143) About an hour ago                       lonely_fermi81ec743a5271        tomcat              &quot;catalina.sh run&quot;        About an hour ago   Exited (143) About an hour ago                       sick_ramanujan//错误日志[root@localhost ~]# docker logs 42f09819908berror: database is uninitialized and password option is not specified   You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD；这个三个参数必须指定一个\n\n\n\n正确的启动\n[root@localhost ~]# docker run --name mysql01 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlb874c56bec49fb43024b3805ab51e9097da779f2f572c22c695305dedd684c5f[root@localhost ~]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMESb874c56bec49        mysql               &quot;docker-entrypoint.sh&quot;   4 seconds ago       Up 3 seconds        3306/tcp            mysql01\n\n\n\n做了端口映射\n[root@localhost ~]# docker run -p 3306:3306 --name mysql02 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlad10e4bc5c6a0f61cbad43898de71d366117d120e39db651844c0e73863b9434[root@localhost ~]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMESad10e4bc5c6a        mysql               &quot;docker-entrypoint.sh&quot;   4 seconds ago       Up 2 seconds        0.0.0.0:3306-&gt;3306/tcp   mysql02\n\n\n\n几个其他的高级操作\ndocker run --name mysql03 -v /conf/mysql:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag把主机的/conf/mysql文件夹挂载到 mysqldocker容器的/etc/mysql/conf.d文件夹里面改mysql的配置文件就只需要把mysql配置文件放在自定义的文件夹下（/conf/mysql）docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci指定mysql的一些配置参数\n\n\n\n六、SpringBoot与数据访问1、JDBC&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;mysql&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;\t\t\t&lt;scope&gt;runtime&lt;/scope&gt;\t\t&lt;/dependency&gt;\n\n\n\nspring:  datasource:    username: root    password: 123456    url: jdbc:mysql://192.168.15.22:3306/jdbc    driver-class-name: com.mysql.jdbc.Driver\n\n\n\n效果：\n 默认是用org.apache.tomcat.jdbc.pool.DataSource作为数据源；\n 数据源的相关配置都在DataSourceProperties里面；\n自动配置原理：\norg.springframework.boot.autoconfigure.jdbc：\n1、参考DataSourceConfiguration，根据配置创建数据源，默认使用Tomcat连接池；可以使用spring.datasource.type指定自定义的数据源类型；\n2、SpringBoot默认可以支持；\norg.apache.tomcat.jdbc.pool.DataSource、HikariDataSource、BasicDataSource、\n\n\n\n3、自定义数据源类型\n/** * Generic DataSource configuration. */@ConditionalOnMissingBean(DataSource.class)@ConditionalOnProperty(name = &quot;spring.datasource.type&quot;)static class Generic &#123;   @Bean   public DataSource dataSource(DataSourceProperties properties) &#123;       //使用DataSourceBuilder创建数据源，利用反射创建响应type的数据源，并且绑定相关属性      return properties.initializeDataSourceBuilder().build();   &#125;&#125;\n\n\n\n4、DataSourceInitializer：ApplicationListener；\n 作用：\n 1）、runSchemaScripts();运行建表语句；\n 2）、runDataScripts();运行插入数据的sql语句；\n默认只需要将文件命名为：\nschema-*.sql、data-*.sql默认规则：schema.sql，schema-all.sql；可以使用   \tschema:      - classpath:department.sql      指定位置\n\n\n\n5、操作数据库：自动配置了JdbcTemplate操作数据库\n2、整合Druid数据源导入druid数据源@Configurationpublic class DruidConfig &#123;    @ConfigurationProperties(prefix = &quot;spring.datasource&quot;)    @Bean    public DataSource druid()&#123;       return  new DruidDataSource();    &#125;    //配置Druid的监控    //1、配置一个管理后台的Servlet    @Bean    public ServletRegistrationBean statViewServlet()&#123;        ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), &quot;/druid/*&quot;);        Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;();        initParams.put(&quot;loginUsername&quot;,&quot;admin&quot;);        initParams.put(&quot;loginPassword&quot;,&quot;123456&quot;);        initParams.put(&quot;allow&quot;,&quot;&quot;);//默认就是允许所有访问        initParams.put(&quot;deny&quot;,&quot;192.168.15.21&quot;);        bean.setInitParameters(initParams);        return bean;    &#125;    //2、配置一个web监控的filter    @Bean    public FilterRegistrationBean webStatFilter()&#123;        FilterRegistrationBean bean = new FilterRegistrationBean();        bean.setFilter(new WebStatFilter());        Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;();        initParams.put(&quot;exclusions&quot;,&quot;*.js,*.css,/druid/*&quot;);        bean.setInitParameters(initParams);        bean.setUrlPatterns(Arrays.asList(&quot;/*&quot;));        return  bean;    &#125;&#125;\n\n\n\n3、整合MyBatis&lt;dependency&gt;\t&lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;\t&lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;\t&lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;\n\n\n\n\n步骤：\n 1）、配置数据源相关属性（见上一节Druid）\n 2）、给数据库建表\n 3）、创建JavaBean\n4）、注解版//指定这是一个操作数据库的mapper@Mapperpublic interface DepartmentMapper &#123;    @Select(&quot;select * from department where id=#&#123;id&#125;&quot;)    public Department getDeptById(Integer id);    @Delete(&quot;delete from department where id=#&#123;id&#125;&quot;)    public int deleteDeptById(Integer id);    @Options(useGeneratedKeys = true,keyProperty = &quot;id&quot;)    @Insert(&quot;insert into department(departmentName) values(#&#123;departmentName&#125;)&quot;)    public int insertDept(Department department);    @Update(&quot;update department set departmentName=#&#123;departmentName&#125; where id=#&#123;id&#125;&quot;)    public int updateDept(Department department);&#125;\n\n\n\n问题：\n自定义MyBatis的配置规则；给容器中添加一个ConfigurationCustomizer；\n@org.springframework.context.annotation.Configurationpublic class MyBatisConfig &#123;    @Bean    public ConfigurationCustomizer configurationCustomizer()&#123;        return new ConfigurationCustomizer()&#123;            @Override            public void customize(Configuration configuration) &#123;                configuration.setMapUnderscoreToCamelCase(true);            &#125;        &#125;;    &#125;&#125;\n\n\n\n使用MapperScan批量扫描所有的Mapper接口；@MapperScan(value = &quot;com.atguigu.springboot.mapper&quot;)@SpringBootApplicationpublic class SpringBoot06DataMybatisApplication &#123;\tpublic static void main(String[] args) &#123;\t\tSpringApplication.run(SpringBoot06DataMybatisApplication.class, args);\t&#125;&#125;\n\n\n\n5）、配置文件版mybatis:  config-location: classpath:mybatis/mybatis-config.xml 指定全局配置文件的位置  mapper-locations: classpath:mybatis/mapper/*.xml  指定sql映射文件的位置\n\n\n\n更多使用参照\nhttp://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/\n4、整合SpringData JPA1）、SpringData简介\n2）、整合SpringData JPAJPA:ORM（Object Relational Mapping）；\n1）、编写一个实体类（bean）和数据表进行映射，并且配置好映射关系；\n//使用JPA注解配置映射关系@Entity //告诉JPA这是一个实体类（和数据表映射的类）@Table(name = &quot;tbl_user&quot;) //@Table来指定和哪个数据表对应;如果省略默认表名就是user；public class User &#123;    @Id //这是一个主键    @GeneratedValue(strategy = GenerationType.IDENTITY)//自增主键    private Integer id;    @Column(name = &quot;last_name&quot;,length = 50) //这是和数据表对应的一个列    private String lastName;    @Column //省略默认列名就是属性名    private String email;\n\n\n\n2）、编写一个Dao接口来操作实体类对应的数据表（Repository）\n//继承JpaRepository来完成对数据库的操作public interface UserRepository extends JpaRepository&lt;User,Integer&gt; &#123;&#125;\n\n\n\n3）、基本的配置JpaProperties\nspring:   jpa:    hibernate:#     更新或者创建数据表结构      ddl-auto: update#    控制台显示SQL    show-sql: true\n\n\n\n七、启动配置原理几个重要的事件回调机制\n配置在META-INF&#x2F;spring.factories\nApplicationContextInitializer\nSpringApplicationRunListener\n只需要放在ioc容器中\nApplicationRunner\nCommandLineRunner\n启动流程：\n1、创建SpringApplication对象initialize(sources);private void initialize(Object[] sources) &#123;    //保存主配置类    if (sources != null &amp;&amp; sources.length &gt; 0) &#123;        this.sources.addAll(Arrays.asList(sources));    &#125;    //判断当前是否一个web应用    this.webEnvironment = deduceWebEnvironment();    //从类路径下找到META-INF/spring.factories配置的所有ApplicationContextInitializer；然后保存起来    setInitializers((Collection) getSpringFactoriesInstances(        ApplicationContextInitializer.class));    //从类路径下找到ETA-INF/spring.factories配置的所有ApplicationListener    setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));    //从多个配置类中找到有main方法的主配置类    this.mainApplicationClass = deduceMainApplicationClass();&#125;\n\n\n\n\n\n\n2、运行run方法public ConfigurableApplicationContext run(String... args) &#123;   StopWatch stopWatch = new StopWatch();   stopWatch.start();   ConfigurableApplicationContext context = null;   FailureAnalyzers analyzers = null;   configureHeadlessProperty();       //获取SpringApplicationRunListeners；从类路径下META-INF/spring.factories   SpringApplicationRunListeners listeners = getRunListeners(args);    //回调所有的获取SpringApplicationRunListener.starting()方法   listeners.starting();   try &#123;       //封装命令行参数      ApplicationArguments applicationArguments = new DefaultApplicationArguments(            args);      //准备环境      ConfigurableEnvironment environment = prepareEnvironment(listeners,            applicationArguments);       \t\t//创建环境完成后回调SpringApplicationRunListener.environmentPrepared()；表示环境准备完成             Banner printedBanner = printBanner(environment);              //创建ApplicationContext；决定创建web的ioc还是普通的ioc      context = createApplicationContext();             analyzers = new FailureAnalyzers(context);       //准备上下文环境;将environment保存到ioc中；而且applyInitializers()；       //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法       //回调所有的SpringApplicationRunListener的contextPrepared()；       //      prepareContext(context, environment, listeners, applicationArguments,            printedBanner);       //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）；              //s刷新容器；ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat）；Spring注解版       //扫描，创建，加载所有组件的地方；（配置类，组件，自动配置）      refreshContext(context);       //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调       //ApplicationRunner先回调，CommandLineRunner再回调      afterRefresh(context, applicationArguments);       //所有的SpringApplicationRunListener回调finished方法      listeners.finished(context, null);      stopWatch.stop();      if (this.logStartupInfo) &#123;         new StartupInfoLogger(this.mainApplicationClass)               .logStarted(getApplicationLog(), stopWatch);      &#125;       //整个SpringBoot应用启动完成以后返回启动的ioc容器；      return context;   &#125;   catch (Throwable ex) &#123;      handleRunFailure(context, listeners, analyzers, ex);      throw new IllegalStateException(ex);   &#125;&#125;\n\n\n\n\n3、事件监听机制配置在META-INF&#x2F;spring.factories\nApplicationContextInitializer\npublic class HelloApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123;    @Override    public void initialize(ConfigurableApplicationContext applicationContext) &#123;        System.out.println(&quot;ApplicationContextInitializer...initialize...&quot;+applicationContext);    &#125;&#125;\n\n\n\nSpringApplicationRunListener\npublic class HelloSpringApplicationRunListener implements SpringApplicationRunListener &#123;    //必须有的构造器    public HelloSpringApplicationRunListener(SpringApplication application, String[] args)&#123;    &#125;    @Override    public void starting() &#123;        System.out.println(&quot;SpringApplicationRunListener...starting...&quot;);    &#125;    @Override    public void environmentPrepared(ConfigurableEnvironment environment) &#123;        Object o = environment.getSystemProperties().get(&quot;os.name&quot;);        System.out.println(&quot;SpringApplicationRunListener...environmentPrepared..&quot;+o);    &#125;    @Override    public void contextPrepared(ConfigurableApplicationContext context) &#123;        System.out.println(&quot;SpringApplicationRunListener...contextPrepared...&quot;);    &#125;    @Override    public void contextLoaded(ConfigurableApplicationContext context) &#123;        System.out.println(&quot;SpringApplicationRunListener...contextLoaded...&quot;);    &#125;    @Override    public void finished(ConfigurableApplicationContext context, Throwable exception) &#123;        System.out.println(&quot;SpringApplicationRunListener...finished...&quot;);    &#125;&#125;\n\n\n\n\n配置（META-INF&#x2F;spring.factories）\norg.springframework.context.ApplicationContextInitializer=\\com.atguigu.springboot.listener.HelloApplicationContextInitializerorg.springframework.boot.SpringApplicationRunListener=\\com.atguigu.springboot.listener.HelloSpringApplicationRunListener\n\n\n\n只需要放在ioc容器中\nApplicationRunner\n@Componentpublic class HelloApplicationRunner implements ApplicationRunner &#123;    @Override    public void run(ApplicationArguments args) throws Exception &#123;        System.out.println(&quot;ApplicationRunner...run....&quot;);    &#125;&#125;\n\n\n\nCommandLineRunner\n@Componentpublic class HelloCommandLineRunner implements CommandLineRunner &#123;    @Override    public void run(String... args) throws Exception &#123;        System.out.println(&quot;CommandLineRunner...run...&quot;+ Arrays.asList(args));    &#125;&#125;\n\n\n\n八、自定义starterstarter：\n 1、这个场景需要使用到的依赖是什么？\n 2、如何编写自动配置\n@Configuration  //指定这个类是一个配置类@ConditionalOnXXX  //在指定条件成立的情况下自动配置类生效@AutoConfigureAfter  //指定自动配置类的顺序@Bean  //给容器中添加组件@ConfigurationPropertie结合相关xxxProperties类来绑定相关的配置@EnableConfigurationProperties //让xxxProperties生效加入到容器中自动配置类要能加载将需要启动就加载的自动配置类，配置在META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\\n\n\n\n 3、模式：\n启动器只用来做依赖导入；\n专门来写一个自动配置模块；\n启动器依赖自动配置；别人只需要引入启动器（starter）\nmybatis-spring-boot-starter；自定义启动器名-spring-boot-starter\n步骤：\n1）、启动器模块\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt;    &lt;artifactId&gt;atguigu-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;!--启动器--&gt;    &lt;dependencies&gt;        &lt;!--引入自动配置模块--&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt;            &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt;            &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;\n\n\n\n2）、自动配置模块\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;   xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;   &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;   &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt;   &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt;   &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;   &lt;packaging&gt;jar&lt;/packaging&gt;   &lt;name&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/name&gt;   &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;   &lt;parent&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;      &lt;version&gt;1.5.10.RELEASE&lt;/version&gt;      &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;   &lt;/parent&gt;   &lt;properties&gt;      &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;      &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;      &lt;java.version&gt;1.8&lt;/java.version&gt;   &lt;/properties&gt;   &lt;dependencies&gt;      &lt;!--引入spring-boot-starter；所有starter的基本配置--&gt;      &lt;dependency&gt;         &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;         &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;      &lt;/dependency&gt;   &lt;/dependencies&gt;&lt;/project&gt;\n\n\n\npackage com.atguigu.starter;import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix = &quot;atguigu.hello&quot;)public class HelloProperties &#123;    private String prefix;    private String suffix;    public String getPrefix() &#123;        return prefix;    &#125;    public void setPrefix(String prefix) &#123;        this.prefix = prefix;    &#125;    public String getSuffix() &#123;        return suffix;    &#125;    public void setSuffix(String suffix) &#123;        this.suffix = suffix;    &#125;&#125;\n\n\n\npackage com.atguigu.starter;public class HelloService &#123;    HelloProperties helloProperties;    public HelloProperties getHelloProperties() &#123;        return helloProperties;    &#125;    public void setHelloProperties(HelloProperties helloProperties) &#123;        this.helloProperties = helloProperties;    &#125;    public String sayHellAtguigu(String name)&#123;        return helloProperties.getPrefix()+&quot;-&quot; +name + helloProperties.getSuffix();    &#125;&#125;\n\n\n\npackage com.atguigu.starter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration@ConditionalOnWebApplication //web应用才生效@EnableConfigurationProperties(HelloProperties.class)public class HelloServiceAutoConfiguration &#123;    @Autowired    HelloProperties helloProperties;    @Bean    public HelloService helloService()&#123;        HelloService service = new HelloService();        service.setHelloProperties(helloProperties);        return service;    &#125;&#125;\n\n\n\n更多SpringBoot整合示例https://github.com/spring-projects/spring-boot/tree/master/spring-boot-samples\n","categories":["Springboot"],"tags":["Springboot"]},{"title":"安装Jenkins 的方式","url":"/2023/03/22/%E5%AE%89%E8%A3%85Jenkins-%E7%9A%84%E6%96%B9%E5%BC%8F/","content":"安装Jenkins 的方式1.Docker安装# 常见Linux本地目录并赋权mkdir -p /var/jenkins_datachmod 777 /var/jenkins_data# 拉取镜像 目前  对应 jenkins 官方 2.332.3docker pull jenkinsci/blueocean:1.25.3   # 对应 jenkins 官方 2.346.1 LTS 支持JDK8-11-17 docker pull jenkinsci/blueocean:1.25.5   # 一定要挂载Maven和JDK8 自带JDK11也可以用docker run \\  -u root \\  -d \\  --name jenkins \\  --restart always \\  -p 8090:8080 \\  -p 8091:50000 \\  -v /var/jenkins_data:/var/jenkins_home \\  -v /usr/local/java/jdk1.8.0_221:/usr/local/java/jdk1.8.0_221 \\  -v /usr/local/maven/apache-maven-3.9.0:/usr/local/maven/apache-maven-3.9.0 \\   jenkinsci/blueocean:1.25.5   # 进入容器获取密码   cat /var/jenkins_home/secrets/initialAdminPassword   # 配置文件目录  获取JDK目录   echo $JAVA_HOME    /opt/java/openjdk   /usr/local/java/jdk1.8.0_221   /usr/local/maven/apache-maven-3.9.0   /usr/local/maven/apache-maven-3.9.0/conf/settings.xml   # 修改为国内的清华大学官方镜像地址，最终内容如下：   # 找到这个配置文件hudson.model.UpdateCenter.xml   &lt;?xml version=&#x27;1.1&#x27; encoding=&#x27;UTF-8&#x27;?&gt;&lt;sites&gt;  &lt;site&gt;    &lt;id&gt;default&lt;/id&gt;    &lt;!--清华镜像--&gt;    &lt;url&gt;https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json&lt;/url&gt;    &lt;!--官方镜像    &lt;url&gt;https://updates.jenkins.io/update-center.json&lt;/url&gt;--&gt;  &lt;/site&gt;&lt;/sites&gt;\t#插件管理高级里更改URL地址    https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json\n\n2.war包安装方式# 下载jenkins.war包 安装目录 Java-jar启动java -jar jenkins.war --httpPort=8081\n\n3.安装版jenkins看链接https://developer.aliyun.com/article/885497\n","categories":["Jenkins 自动化部署"],"tags":["Jenkins部署"]},{"title":"后端架构师技术图谱","url":"/2023/02/19/%E5%90%8E%E7%AB%AF%E6%9E%B6%E6%9E%84%E5%B8%88%E6%8A%80%E6%9C%AF%E5%9B%BE%E8%B0%B1/","content":"后端架构师技术图谱👍 👍 👍 推荐一个在线搜课程的神器，“课程搜”：https://www.kcsou.com/s_架构师/\n\n\n队列\n集合\n链表、数组\n字典、关联数组\n栈\n树\n二叉树\n完全二叉树\n平衡二叉树\n二叉查找树（BST）\n红黑树\nB，B+，B*树\nLSM 树\n\n\nBitSet\n排序、查找算法\n选择排序\n冒泡排序\n插入排序\n快速排序\n归并排序\n希尔排序\n堆排序\n计数排序\n桶排序\n基数排序\n二分查找\nJava 中的排序工具\n\n\n布隆过滤器\n字符串比较\nKMP 算法\n\n\n深度优先、广度优先\n贪心算法\n回溯算法\n剪枝算法\n动态规划\n朴素贝叶斯\n推荐算法\n最小生成树算法\n最短路径算法\nJava 并发\n多线程\n线程安全\n一致性、事务\n事务 ACID 特性\n事务的隔离级别\nMVCC\n\n\n锁\nJava中的锁和同步类\n公平锁 &amp; 非公平锁\n悲观锁\n乐观锁 &amp; CAS\nABA 问题\nCopyOnWrite容器\nRingBuffer\n可重入锁 &amp; 不可重入锁\n互斥锁 &amp; 共享锁\n死锁\n\n\n计算机原理\nCPU\n多级缓存\n\n\n进程\n线程\n协程\nLinux\n设计模式的六大原则\n23种常见设计模式\n应用场景\n单例模式\n责任链模式\nMVC\nIOC\nAOP\nUML\n微服务思想\n康威定律\n\n\n常规监控\nAPM\n统计分析\n持续集成(CI&#x2F;CD)\nJenkins\n环境分离\n\n\n自动化运维\nAnsible\npuppet\nchef\n\n\n测试\nTDD 理论\n单元测试\n压力测试\n全链路压测\nA&#x2F;B 、灰度、蓝绿测试\n\n\n虚拟化\nKVM\nXen\nOpenVZ\n\n\n容器技术\nDocker\n\n\n云技术\nOpenStack\n\n\nDevOps\n文档管理\nWeb Server\nNginx\nOpenResty\nTengine\nApache Httpd\nTomcat\nJetty\n\n\n缓存\n本地缓存\n\n\n客户端缓存\n服务端缓存\nWeb缓存\nMemcached\nRedis\nTair\n\n\n消息队列\n消息总线\n消息的顺序\nRabbitMQ\nRocketMQ\nActiveMQ\nKafka\nRedis 消息推送\nZeroMQ\n\n\n定时调度\n单机定时调度\n分布式定时调度\n\n\nRPC\nDubbo\nThrift\ngRPC\n\n\n数据库中间件\nSharding Jdbc\n\n\n日志系统\n日志搜集\n\n\n配置中心\nAPI 网关\n协议\nOSI 七层协议\nTCP&#x2F;IP\nHTTP\nHTTP2.0\nHTTPS\n\n\n网络模型\nEpoll\nJava NIO\nkqueue\n\n\n连接和短连接\n框架\n零拷贝（Zero-copy）\n序列化(二进制协议)\nHessian\nProtobuf\n\n\n基础理论\n关系数据库设计的三大范式\n\n\nMySQL\n原理\nInnoDB\n优化\n索引\nexplain\n\n\nNoSQL\nMongoDB\nHbase\n\n\n搜索引擎原理\nLucene\nElasticsearch\nSolr\nsphinx\n性能优化方法论\n容量评估\nCDN 网络\n连接池\n性能调优\n流式计算\nStorm\nFlink\nKafka Stream\n应用场景\n\n\nHadoop\nHDFS\nMapReduce\nYarn\n\n\nSpark\nweb 安全\nXSS\nCSRF\nSQL 注入\nHash Dos\n脚本注入\n漏洞扫描工具\n验证码\n\n\nDDoS 防范\n用户隐私信息保护\n序列化漏洞\n加密解密\n对称加密\n哈希算法\n非对称加密\n\n\n服务器安全\n数据安全\n数据备份\n\n\n网络隔离\n内外网分离\n登录跳板机\n\n\n授权、认证\nRBAC\nOAuth2.0\nOIDC\nSAML\n双因素认证（2FA）\n单点登录(SSO)\n\n\n开源协议\n日志框架\nLog4j、Log4j2\nLogback\n\n\nORM\n网络框架\nWeb 框架\nSpring 家族\n\n\n工具框架\n扩展性设计\n稳定性 &amp; 高可用\n硬件负载均衡\n软件负载均衡\n限流\n应用层容灾\n跨机房容灾\n容灾演练流程\n平滑启动\n\n\n数据库扩展\n读写分离模式\n分片模式\n\n\n服务治理\n服务注册与发现\n服务路由控制\n\n\n分布式一致\nCAP 与 BASE 理论\n分布式锁\n分布式一致性算法\n幂等\n分布式一致方案\n分布式 Leader 节点选举\nTCC(Try&#x2F;Confirm&#x2F;Cancel) 柔性事务\n\n\n分布式文件系统\n唯一ID 生成\n全局唯一ID\n\n\n一致性Hash算法\nDDD(Domain-driven Design - 领域驱动设计)\n命令查询职责分离(CQRS)\n贫血，充血模型\n\n\nActor 模式\n响应式编程\nReactor\nRxJava\nVert.x\n\n\nDODAF2.0\nServerless\nService Mesh\n架构评审\n重构\n代码规范\n代码 Review\nRUP\n看板管理\nSCRUM\n敏捷开发\n极限编程（XP）\n结对编程\nPDCA 循环质量管理\nFMEA管理模式\n法律\n严格遵守刑法253法条\n避风港原则\n\n\n招聘\n行业资讯\n公众号列表\n博客\n团队博客\n个人博客\n\n\n综合门户、社区\n问答、讨论类社区\n行业数据分析\n专项网站\n其他类\n推荐参考书\n在线电子书\n纸质书\n\n\n开源资源\n手册、文档、教程\n在线课堂\n会议、活动\n常用APP\n找工作\n工具\n代码托管\n文件服务\n综合云服务商\nVPS\n\n\n\n数据结构队列\n《java队列——queue详细分析》\n非阻塞队列：ConcurrentLinkedQueue(无界线程安全)，采用CAS机制（compareAndSwapObject原子操作）。\n阻塞队列：ArrayBlockingQueue(有界)、LinkedBlockingQueue（无界）、DelayQueue、PriorityBlockingQueue，采用锁机制；使用 ReentrantLock 锁。\n\n\n《LinkedList、ConcurrentLinkedQueue、LinkedBlockingQueue对比分析》\n\n集合\n《Java Set集合的详解》\n\n链表、数组\n《Java集合详解–什么是List》\n\n字典、关联数组\n《Java map 详解 - 用法、遍历、排序、常用API等》\n\n栈\n《java数据结构与算法之栈（Stack）设计与实现》\n《Java Stack 类》\n《java stack的详细实现分析》\nStack 是线程安全的。\n内部使用数组保存数据，不够时翻倍。\n\n\n\n树二叉树每个节点最多有两个叶子节点。\n\n《二叉树》\n\n完全二叉树\n《完全二叉树》\n叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。\n\n\n\n平衡二叉树左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。\n\n《浅谈数据结构-平衡二叉树》\n《浅谈算法和数据结构: 八 平衡查找树之2-3树》\n\n二叉查找树（BST）二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree）。\n\n《浅谈算法和数据结构: 七 二叉查找树》\n\n红黑树\n《最容易懂得红黑树》\n添加阶段后，左旋或者右旋从而再次达到平衡。\n\n\n《浅谈算法和数据结构: 九 平衡查找树之红黑树》\n\nB，B+，B*树MySQL是基于B+树聚集索引组织表\n\n《B-树，B+树，B*树详解》\n《B-树，B+树与B*树的优缺点比较》\nB+树的叶子节点链表结构相比于 B-树便于扫库，和范围检索。\n\n\n\nLSM 树LSM（Log-Structured Merge-Trees）和 B+ 树相比，是牺牲了部分读的性能来换取写的性能(通过批量写入)，实现读写之间的平衡。 Hbase、LevelDB、Tair（Long DB）、nessDB 采用 LSM 树的结构。LSM可以快速建立索引。\n\n《LSM树 VS B+树》\nB+ 树读性能好，但由于需要有序结构，当key比较分散时，磁盘寻道频繁，造成写性能较差。\nLSM 是将一个大树拆分成N棵小树，先写到内存（无寻道问题，性能高），在内存中构建一颗有序小树（有序树），随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历（二分查找）所有的小树，但在每颗小树内部数据是有序的。\n\n\n《LSM树（Log-Structured Merge Tree）存储引擎》\n极端的说，基于LSM树实现的HBase的写性能比MySQL高了一个数量级，读性能低了一个数量级。\n优化方式：Bloom filter 替代二分查找；compact 小数位大树，提高查询性能。\nHbase 中，内存中达到一定阈值后，整体flush到磁盘上、形成一个文件（B+数），HDFS不支持update操作，所以Hbase做整体flush而不是merge update。flush到磁盘上的小树，定期会合并成一个大树。\n\n\n\nBitSet经常用于大规模数据的排重检查。\n\n《Java Bitset类》\n《Java BitSet（位集）》\n\n常用算法\n《常见排序算法及对应的时间复杂度和空间复杂度》\n\n排序、查找算法\n《常见排序算法及对应的时间复杂度和空间复杂度》\n\n选择排序\n《Java中的经典算法之选择排序（SelectionSort）》\n每一趟从待排序的记录中选出最小的元素，顺序放在已排好序的序列最后，直到全部记录排序完毕。\n\n\n\n冒泡排序\n《冒泡排序的2种写法》\n相邻元素前后交换、把最大的排到最后。\n时间复杂度 O(n²)\n\n\n\n插入排序\n《排序算法总结之插入排序》\n\n快速排序\n《坐在马桶上看算法：快速排序》\n一侧比另外一侧都大或小。\n\n\n\n归并排序\n《图解排序算法(四)之归并排序》\n分而治之，分成小份排序，在合并(重建一个新空间进行复制)。\n\n\n\n希尔排序TODO\n堆排序\n《图解排序算法(三)之堆排序》\n排序过程就是构建最大堆的过程，最大堆：每个结点的值都大于或等于其左右孩子结点的值，堆顶元素是最大值。\n\n\n\n计数排序\n《计数排序和桶排序》\n和桶排序过程比较像，差别在于桶的数量。\n\n\n\n桶排序\n《【啊哈！算法】最快最简单的排序——桶排序》\n《排序算法（三）：计数排序与桶排序》\n桶排序将[0,1)区间划分为n个相同的大小的子区间，这些子区间被称为桶。\n每个桶单独进行排序，然后再遍历每个桶。\n\n\n\n基数排序按照个位、十位、百位、…依次来排。\n\n《排序算法系列：基数排序》\n《基数排序》\n\n二分查找\n《二分查找(java实现)》\n要求待查找的序列有序。\n时间复杂度 O(logN)。\n\n\n《java实现二分查找-两种方式》\nwhile + 递归。\n\n\n\nJava 中的排序工具\n《Arrays.sort和Collections.sort实现原理解析》\nCollections.sort算法调用的是合并排序。\nArrays.sort() 采用了2种排序算法 – 基本类型数据使用快速排序法，对象数组使用归并排序。\n\n\n\n布隆过滤器常用于大数据的排重，比如email，url 等。 核心原理：将每条数据通过计算产生一个指纹（一个字节或多个字节，但一定比原始数据要少很多），其中每一位都是通过随机计算获得，在将指纹映射到一个大的按位存储的空间中。注意：会有一定的错误率。 优点：空间和时间效率都很高。 缺点：随着存入的元素数量增加，误算率随之增加。\n\n《布隆过滤器 – 空间效率很高的数据结构》\n《大量数据去重：Bitmap和布隆过滤器(Bloom Filter)》\n《基于Redis的布隆过滤器的实现》\n基于 Redis 的 Bitmap 数据结构。\n\n\n《网络爬虫：URL去重策略之布隆过滤器(BloomFilter)的使用》\n使用Java中的 BitSet 类 和 加权和hash算法。\n\n\n\n字符串比较KMP 算法KMP：Knuth-Morris-Pratt算法（简称KMP） 核心原理是利用一个“部分匹配表”，跳过已经匹配过的元素。\n\n《字符串匹配的KMP算法》\n\n深度优先、广度优先\n《广度优先搜索BFS和深度优先搜索DFS》\n\n贪心算法\n《算法：贪婪算法基础》\n《常见算法及问题场景——贪心算法》\n\n回溯算法\n《 五大常用算法之四：回溯法》\n\n剪枝算法\n《α-β剪枝算法》\n\n动态规划\n《详解动态规划——邹博讲动态规划》\n《动态规划算法的个人理解》\n\n朴素贝叶斯\n《带你搞懂朴素贝叶斯分类算法》\nP(B|A)&#x3D;P(A|B)P(B)&#x2F;P(A)\n\n\n《贝叶斯推断及其互联网应用1》\n《贝叶斯推断及其互联网应用2》\n\n推荐算法\n《推荐算法综述》\n《TOP 10 开源的推荐系统简介》\n\n最小生成树算法\n《算法导论–最小生成树（Kruskal和Prim算法）》\n\n最短路径算法\n《Dijkstra算法详解》\n\n并发Java 并发\nJava 并发知识合集\nJAVA并发知识图谱\n\n多线程\n《40个Java多线程问题总结》\n\n线程安全\n《Java并发编程——线程安全及解决机制简介》\n\n一致性、事务事务 ACID 特性\n《数据库事务ACID特性》\n\n事务的隔离级别\n未提交读：一个事务可以读取另一个未提交的数据，容易出现脏读的情况。\n读提交：一个事务等另外一个事务提交之后才可以读取数据，但会出现不可重复读的情况（多次读取的数据不一致），读取过程中出现UPDATE操作，会多。（大多数数据库默认级别是RC，比如SQL Server，Oracle），读取的时候不可以修改。\n可重复读： 同一个事务里确保每次读取的时候，获得的是同样的数据，但不保障原始数据被其他事务更新（幻读），Mysql InnoDB 就是这个级别。\n序列化：所有事物串行处理（牺牲了效率）\n《理解事务的4种隔离级别》\n数据库事务的四大特性及事务隔离级别\n《MySQL的InnoDB的幻读问题 》\n幻读的例子非常清楚。\n通过 SELECT … FOR UPDATE 解决。\n\n\n《一篇文章带你读懂MySQL和InnoDB》\n图解脏读、不可重复读、幻读问题。\n\n\n\nMVCC\n《【mysql】关于innodb中MVCC的一些理解》\ninnodb 中 MVCC 用在 Repeatable-Read 隔离级别。\nMVCC 会产生幻读问题（更新时异常。）\n\n\n《轻松理解MYSQL MVCC 实现机制》\n通过隐藏版本列来实现 MVCC 控制，一列记录创建时间、一列记录删除时间，这里的时间\n每次只操作比当前版本小（或等于）的 行。\n\n\n\n锁Java中的锁和同步类\n《Java中的锁分类》\n主要包括 synchronized、ReentrantLock、和 ReadWriteLock。\n\n\n《Java并发之AQS详解》\n《Java中信号量 Semaphore》\n有数量控制\n申请用 acquire，申请不要则阻塞；释放用 release。\n\n\n《java开发中的Mutex vs Semaphore》\n简单的说 就是Mutex是排它的，只有一个可以获取到资源， Semaphore也具有排它性，但可以定义多个可以获取的资源的对象。\n\n\n\n公平锁 &amp; 非公平锁公平锁的作用就是严格按照线程启动的顺序来执行的，不允许其他线程插队执行的；而非公平锁是允许插队的。\n\n《公平锁与非公平锁》\n默认情况下 ReentrantLock 和 synchronized 都是非公平锁。ReentrantLock 可以设置成公平锁。\n\n\n\n悲观锁悲观锁如果使用不当（锁的条数过多），会引起服务大面积等待。推荐优先使用乐观锁+重试。\n\n《【MySQL】悲观锁&amp;乐观锁》\n乐观锁的方式：版本号+重试方式\n悲观锁：通过 select … for update 进行行锁(不可读、不可写，share 锁可读不可写)。\n\n\n《Mysql查询语句使用select.. for update导致的数据库死锁分析》\nmysql的innodb存储引擎实务锁虽然是锁行，但它内部是锁索引的。\n锁相同数据的不同索引条件可能会引起死锁。\n\n\n《Mysql并发时经典常见的死锁原因及解决方法》\n\n乐观锁 &amp; CAS\n《乐观锁的一种实现方式——CAS》\n和MySQL乐观锁方式相似，只不过是通过和原值进行比较。\n\n\n\nABA 问题由于高并发，在CAS下，更新后可能此A非彼A。通过版本号可以解决，类似于上文Mysql 中提到的的乐观锁。\n\n《Java CAS 和ABA问题》\n《Java 中 ABA问题及避免》\nAtomicStampedReference 和 AtomicStampedReference。\n\n\n\nCopyOnWrite容器可以对CopyOnWrite容器进行并发的读，而不需要加锁。CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，不适合需要数据强一致性的场景。\n\n《JAVA中写时复制(Copy-On-Write)Map实现》\n实现读写分离，读取发生在原始数据上，写入发生在副本上。\n不用加锁，通过最终一致实现一致性。\n\n\n《聊聊并发-Java中的Copy-On-Write容器》\n\nRingBuffer\n《线程安全的无锁RingBuffer的实现【一个读线程，一个写线程】》\n\n可重入锁 &amp; 不可重入锁\n《可重入锁和不可重入锁》\n通过简单代码举例说明可重入锁和不可重入锁。\n可重入锁指同一个线程可以再次获得之前已经获得的锁。\n可重入锁可以用户避免死锁。\nJava中的可重入锁：synchronized 和 java.util.concurrent.locks.ReentrantLock\n\n\n《ReenTrantLock可重入锁（和synchronized的区别）总结》\nsynchronized 使用方便，编译器来加锁，是非公平锁。\nReenTrantLock 使用灵活，锁的公平性可以定制。\n相同加锁场景下，推荐使用 synchronized。\n\n\n\n互斥锁 &amp; 共享锁互斥锁：同时只能有一个线程获得锁。比如，ReentrantLock 是互斥锁，ReadWriteLock 中的写锁是互斥锁。 共享锁：可以有多个线程同时或的锁。比如，Semaphore、CountDownLatch 是共享锁，ReadWriteLock 中的读锁是共享锁。\n\n《ReadWriteLock场景应用》\n\n死锁\n《“死锁”四个必要条件的合理解释》\n互斥、持有、不可剥夺、环形等待。\n\n\nJava如何查看死锁？\nJConsole 可以识别死锁。\n\n\njava多线程系列：死锁及检测\njstack 可以显示死锁。\n\n\n\n操作系统计算机原理\n《操作系统基础知识——操作系统的原理，类型和结构》\n\nCPU多级缓存典型的 CPU 有三级缓存，距离核心越近，速度越快，空间越小。L1 一般 32k，L2 一般 256k，L3 一般12M。内存速度需要200个 CPU 周期，CPU 缓存需要1个CPU周期。\n\n《从Java视角理解CPU缓存和伪共享》\n\n进程TODO\n线程\n《线程的生命周期及状态转换详解》\n\n协程\n《终结python协程—-从yield到actor模型的实现》\n线程的调度是由操作系统负责，协程调度是程序自行负责\n与线程相比，协程减少了无谓的操作系统切换.\n实际上当遇到IO操作时做切换才更有意义，（因为IO操作不用占用CPU），如果没遇到IO操作，按照时间片切换.\n\n\n\nLinux\n《Linux 命令大全》\n\n设计模式设计模式的六大原则\n《设计模式的六大原则》\n开闭原则：对扩展开放,对修改关闭，多使用抽象类和接口。\n里氏替换原则：基类可以被子类替换，使用抽象类继承,不使用具体类继承。\n依赖倒转原则：要依赖于抽象,不要依赖于具体，针对接口编程,不针对实现编程。\n接口隔离原则：使用多个隔离的接口,比使用单个接口好，建立最小的接口。\n迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用，通过中间类建立联系。\n合成复用原则：尽量使用合成&#x2F;聚合,而不是使用继承。\n\n\n\n23种常见设计模式\n《设计模式》\n《23种设计模式全解析》\n《设计模式类图与示例》\n\n应用场景\n《细数JDK里的设计模式》\n结构型模式：\n适配器：用来把一个接口转化成另一个接口，如 java.util.Arrays#asList()。\n桥接模式：这个模式将抽象和抽象操作的实现进行了解耦，这样使得抽象和实现可以独立地变化，如JDBC；\n组合模式：使得客户端看来单个对象和对象的组合是同等的。换句话说，某个类型的方法同时也接受自身类型作为参数，如 Map.putAll，List.addAll、Set.addAll。\n装饰者模式：动态的给一个对象附加额外的功能，这也是子类的一种替代方式，如 java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap。\n享元模式：使用缓存来加速大量小对象的访问时间，如 valueOf(int)。\n代理模式：代理模式是用一个简单的对象来代替一个复杂的或者创建耗时的对象，如 java.lang.reflect.Proxy\n\n\n创建模式:\n抽象工厂模式：抽象工厂模式提供了一个协议来生成一系列的相关或者独立的对象，而不用指定具体对象的类型，如 java.util.Calendar#getInstance()。\n建造模式(Builder)：定义了一个新的类来构建另一个类的实例，以简化复杂对象的创建，如：java.lang.StringBuilder#append()。\n工厂方法：就是 一个返回具体对象的方法，而不是多个，如 java.lang.Object#toString()、java.lang.Class#newInstance()。\n原型模式：使得类的实例能够生成自身的拷贝、如：java.lang.Object#clone()。\n单例模式：全局只有一个实例，如 java.lang.Runtime#getRuntime()。\n\n\n行为模式：\n责任链模式：通过把请求从一个对象传递到链条中下一个对象的方式，直到请求被处理完毕，以实现对象间的解耦。如 javax.servlet.Filter#doFilter()。\n命令模式：将操作封装到对象内，以便存储，传递和返回，如：java.lang.Runnable。\n解释器模式：定义了一个语言的语法，然后解析相应语法的语句，如，java.text.Format，java.text.Normalizer。\n迭代器模式：提供一个一致的方法来顺序访问集合中的对象，如 java.util.Iterator。\n中介者模式：通过使用一个中间对象来进行消息分发以及减少类之间的直接依赖，java.lang.reflect.Method#invoke()。\n空对象模式：如 java.util.Collections#emptyList()。\n观察者模式：它使得一个对象可以灵活的将消息发送给感兴趣的对象，如 java.util.EventListener。\n模板方法模式：让子类可以重写方法的一部分，而不是整个重写，如 java.util.Collections#sort()。\n\n\n\n\n《Spring-涉及到的设计模式汇总》\n《Mybatis使用的设计模式》\n\n单例模式\n《单例模式的三种实现 以及各自的优缺点》\n《单例模式－－反射－－防止序列化破坏单例模式》\n使用枚举类型。\n\n\n\n责任链模式TODO\nMVC\n《MVC 模式》\n模型(model)－视图(view)－控制器(controller)\n\n\n\nIOC\n《理解 IOC》\n《IOC 的理解与解释》\n正向控制：传统通过new的方式。反向控制，通过容器注入对象。\n作用：用于模块解耦。\nDI：Dependency Injection，即依赖注入，只关心资源使用，不关心资源来源。\n\n\n\nAOP\n《轻松理解AOP(面向切面编程)》\n《Spring AOP详解》\n《Spring AOP的实现原理》\nSpring AOP使用的动态代理，主要有两种方式：JDK动态代理和CGLIB动态代理。\n\n\n《Spring AOP 实现原理与 CGLIB 应用》\nSpring AOP 框架对 AOP 代理类的处理原则是：如果目标对象的实现类实现了接口，Spring AOP 将会采用 JDK 动态代理来生成 AOP 代理类；如果目标对象的实现类没有实现接口，Spring AOP 将会采用 CGLIB 来生成 AOP 代理类\n\n\n\nUML\n《UML教程》\n\n微服务思想\n《微服务架构设计》\n《微服务架构技术栈选型手册》\n\n康威定律\n《微服务架构的理论基础 - 康威定律》\n定律一：组织沟通方式会通过系统设计表达出来，就是说架构的布局和组织结构会有相似。\n定律二：时间再多一件事情也不可能做的完美，但总有时间做完一件事情。一口气吃不成胖子，先搞定能搞定的。\n定律三：线型系统和线型组织架构间有潜在的异质同态特性。种瓜得瓜，做独立自治的子系统减少沟通成本。\n定律四：大的系统组织总是比小系统更倾向于分解。合久必分，分而治之。\n\n\n《微服务架构核⼼20讲》\n\n运维 &amp; 统计 &amp; 技术支持常规监控\n《腾讯业务系统监控的修炼之路》\n监控的方式：主动、被动、旁路(比如舆情监控)\n监控类型： 基础监控、服务端监控、客户端监控、 监控、用户端监控\n监控的目标：全、块、准\n核心指标：请求量、成功率、耗时\n\n\n《开源还是商用？十大云运维监控工具横评》\nZabbix、Nagios、Ganglia、Zenoss、Open-falcon、监控宝、 360网站服务监控、阿里云监控、百度云观测、小蜜蜂网站监测等。\n\n\n《监控报警系统搭建及二次开发经验》\n\n命令行监控工具\n\n《常用命令行监控工具》\ntop、sar、tsar、nload\n\n\n《20个命令行工具监控 Linux 系统性能》\n《JVM性能调优监控工具jps、jstack、jmap、jhat、jstat、hprof使用详解》\n\nAPMAPM — Application Performance Management\n\n《Dapper，大规模分布式系统的跟踪系统》\nCNCF OpenTracing，中文版\n主要开源软件，按字母排序\nApache SkyWalking\nCAT\nCNCF jaeger\nPinpoint\nZipkin\n\n\n《开源APM技术选型与实战》\n主要基于 Google的Dapper（大规模分布式系统的跟踪系统） 思想。\n\n\n\n统计分析\n《流量统计的基础：埋点》\n常用指标：访问与访客、停留时长、跳出率、退出率、转化率、参与度\n\n\n《APP埋点常用的统计工具、埋点目标和埋点内容》\n第三方统计：友盟、百度移动、魔方、App Annie、talking data、神策数据等。\n\n\n《美团点评前端无痕埋点实践》\n所谓无痕、即通过可视化工具配置采集节点，在前端自动解析配置并上报埋点数据，而非硬编码。\n\n\n\n持续集成(CI&#x2F;CD)\n《持续集成是什么？》\n《8个流行的持续集成工具》\n\nJenkins\n《使用Jenkins进行持续集成》\n\n环境分离开发、测试、生成环境分离。\n\n《开发环境、生产环境、测试环境的基本理解和区》\n\n自动化运维Ansible\n《Ansible中文权威指南》\n《Ansible基础配置和企业级项目实用案例》\n\npuppet\n《自动化运维工具——puppet详解》\n\nchef\n《Chef 的安装与使用》\n\n测试TDD 理论\n《深度解读 - TDD（测试驱动开发）》\n基于测试用例编码功能代码，XP（Extreme Programming）的核心实践.\n好处：一次关注一个点，降低思维负担；迎接需求变化或改善代码的设计；提前澄清需求；快速反馈；\n\n\n\n单元测试\n《Java单元测试之JUnit篇》\n《JUnit 4 与 TestNG 对比》\nTestNG 覆盖 JUnit 功能，适用于更复杂的场景。\n\n\n《单元测试主要的测试功能点》\n模块接口测试、局部数据结构测试、路径测试 、错误处理测试、边界条件测试 。\n\n\n\n压力测试\n《Apache ab 测试使用指南》\n《大型网站压力测试及优化方案》\n《10大主流压力&#x2F;负载&#x2F;性能测试工具推荐》\n《真实流量压测工具 tcpcopy应用浅析》\n《nGrinder 简易使用教程》\n\n全链路压测\n《京东618：升级全链路压测方案，打造军演机器人ForceBot》\n《饿了么全链路压测的探索与实践》\n《四大语言，八大框架｜滴滴全链路压测解决之道》\n《全链路压测经验》\n\nA&#x2F;B 、灰度、蓝绿测试\n《技术干货 | AB 测试和灰度发布探索及实践》\n《nginx 根据IP 进行灰度发布》\n《蓝绿部署、A&#x2F;B 测试以及灰度发布》\n\n虚拟化\n《VPS的三种虚拟技术OpenVZ、Xen、KVM优缺点比较》\n\nKVM\n《KVM详解，太详细太深入了，经典》\n《【图文】KVM 虚拟机安装详解》\n\nXen\n《Xen虚拟化基本原理详解》\n\nOpenVZ\n《开源Linux容器 OpenVZ 快速上手指南》\n\n容器技术Docker\n《几张图帮你理解 docker 基本原理及快速入门》\n《Docker 核心技术与实现原理》\n《Docker 教程》\n\n云技术OpenStack\n《OpenStack构架知识梳理》\n\nDevOps\n《一分钟告诉你究竟DevOps是什么鬼？》\n《DevOps详解》\n\n文档管理\nConfluence-收费文档管理系统\nGitLab?\nWiki\n\n中间件Web ServerNginx\n《Ngnix的基本学习-多进程和Apache的比较》\nNginx 通过异步非阻塞的事件处理机制实现高并发。Apache 每个请求独占一个线程，非常消耗系统资源。\n事件驱动适合于IO密集型服务(Nginx)，多进程或线程适合于CPU密集型服务(Apache)，所以Nginx适合做反向代理，而非web服务器使用。\n\n\n《nginx与Apache的对比以及优缺点》\nnginx只适合静态和反向代理，不适合处理动态请求。\n\n\n\nOpenResty\n官方网站\n《浅谈 OpenResty》\n通过 Lua 模块可以在Nginx上进行开发。\n\n\nagentzh 的 Nginx 教程\n\nTengine\n官方网站\n\nApache Httpd\n官方网站\n\nTomcat架构原理\n《TOMCAT原理详解及请求过程》\n《Tomcat服务器原理详解》\n《Tomcat 系统架构与设计模式,第 1 部分: 工作原理》\n《四张图带你了解Tomcat系统架构》\n《JBoss vs. Tomcat: Choosing A Java Application Server》\nTomcat 是轻量级的 Serverlet 容器，没有实现全部 JEE 特性（比如持久化和事务处理），但可以通过其他组件代替，比如Spring。\nJboss 实现全部了JEE特性，软件开源免费、文档收费。\n\n\n\n调优方案\n《Tomcat 调优方案》\n启动NIO模式（或者APR）；调整线程池；禁用AJP连接器（Nginx+tomcat的架构，不需要AJP）；\n\n\n《tomcat http协议与ajp协议》\n《AJP与HTTP比较和分析》\nAJP 协议（8009端口）用于降低和前端Server（如Apache，而且需要支持AJP协议）的连接数(前端)，通过长连接提高性能。\n并发高时，AJP协议优于HTTP协议。\n\n\n\nJetty\n《Jetty 的工作原理以及与 Tomcat 的比较》\n《jetty和tomcat优势比较》\n架构比较:Jetty的架构比Tomcat的更为简单。\n性能比较：Jetty和Tomcat性能方面差异不大，Jetty默认采用NIO结束在处理I&#x2F;O请求上更占优势，Tomcat默认采用BIO处理I&#x2F;O请求，Tomcat适合处理少数非常繁忙的链接，处理静态资源时性能较差。\n其他方面：Jetty的应用更加快速，修改简单，对新的Servlet规范的支持较好;Tomcat 对JEE和Servlet 支持更加全面。\n\n\n\n缓存\n《缓存失效策略（FIFO 、LRU、LFU三种算法的区别）》\n\n本地缓存\n《HashMap本地缓存》\n《EhCache本地缓存》\n堆内、堆外、磁盘三级缓存。\n可按照缓存空间容量进行设置。\n按照时间、次数等过期策略。\n\n\n《Guava Cache》\n简单轻量、无堆外、磁盘缓存。\n\n\n《Nginx本地缓存》\n《Pagespeed—懒人工具，服务器端加速》\n\n客户端缓存\n《浏览器端缓存》\n主要是利用 Cache-Control 参数。\n\n\n《H5 和移动端 WebView 缓存机制解析与实战》\n\n服务端缓存Web缓存\nnuster - nuster cache\nvarnish - varnish cache\nsquid - squid cache\n\nMemcached\n《Memcached 教程》\n《深入理解Memcached原理》\n采用多路复用技术提高并发性。\nslab分配算法： memcached给Slab分配内存空间，默认是1MB。分配给Slab之后 把slab的切分成大小相同的chunk，Chunk是用于缓存记录的内存空间，Chunk 的大小默认按照1.25倍的速度递增。好处是不会频繁申请内存，提高IO效率，坏处是会有一定的内存浪费。\n\n\n《Memcached软件工作原理》\n《Memcache技术分享：介绍、使用、存储、算法、优化、命中率》\n《memcache 中 add 、 set 、replace 的区别》\n区别在于当key存在还是不存在时，返回值是true和false的。\n\n\n[**《memcached全面剖析》**](https://pan.baidu.com/s/1qX00Lti?errno=0&amp;errmsg=Auth Login Sucess&amp;&amp;bduss&#x3D;&amp;ssnerror&#x3D;0&amp;traceid&#x3D;)\n\nRedis\n《Redis 教程》\n《redis底层原理》\n使用 ziplist 存储链表，ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。\n使用 skiplist(跳跃表)来存储有序集合对象、查找上先从高Level查起、时间复杂度和红黑树相当，实现容易，无锁、并发性好。\n\n\n《Redis持久化方式》\nRDB方式：定期备份快照，常用于灾难恢复。优点：通过fork出的进程进行备份，不影响主进程、RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。缺点：会丢数据。\nAOF方式：保存操作日志方式。优点：恢复时数据丢失少，缺点：文件大，回复慢。\n也可以两者结合使用。\n\n\n《分布式缓存–序列3–原子操作与CAS乐观锁》\n\n架构\n《Redis单线程架构》\n\n回收策略\n《redis的回收策略》\n\nTair\n官方网站\n《Tair和Redis的对比》\n特点：可以配置备份节点数目，通过异步同步到备份节点\n一致性Hash算法。\n架构：和Hadoop 的设计思想类似，有Configserver，DataServer，Configserver 通过心跳来检测，Configserver也有主备关系。\n\n几种存储引擎:\n\nMDB，完全内存性，可以用来存储Session等数据。\nRdb（类似于Redis），轻量化，去除了aof之类的操作，支持Restfull操作\nLDB（LevelDB存储引擎），持久化存储，LDB 作为rdb的持久化，google实现，比较高效，理论基础是LSM(Log-Structured-Merge Tree)算法，现在内存中修改数据，达到一定量时（和内存汇总的旧数据一同写入磁盘）再写入磁盘，存储更加高效，县比喻Hash算法。\nTair采用共享内存来存储数据，如果服务挂掉（非服务器），重启服务之后，数据亦然还在。\n\n消息队列\n《消息队列-推&#x2F;拉模式学习 &amp; ActiveMQ及JMS学习》\nRabbitMQ 消费者默认是推模式（也支持拉模式）。\nKafka 默认是拉模式。\nPush方式：优点是可以尽可能快地将消息发送给消费者，缺点是如果消费者处理能力跟不上，消费者的缓冲区可能会溢出。\nPull方式：优点是消费端可以按处理能力进行拉去，缺点是会增加消息延迟。\n\n\n《Kafka、RabbitMQ、RocketMQ等消息中间件的对比 —— 消息发送性能和区别》\n\n消息总线消息总线相当于在消息队列之上做了一层封装，统一入口，统一管控、简化接入成本。\n\n《消息总线VS消息队列》\n\n消息的顺序\n《如何保证消费者接收消息的顺序》\n\nRabbitMQ支持事务，推拉模式都是支持、适合需要可靠性消息传输的场景。\n\n《RabbitMQ的应用场景以及基本原理介绍》\n《消息队列之 RabbitMQ》\n《RabbitMQ之消息确认机制（事务+Confirm）》\n\nRocketMQJava实现，推拉模式都是支持，吞吐量逊于Kafka。可以保证消息顺序。\n\n《RocketMQ 实战之快速入门》\n《RocketMQ 源码解析》\n\nActiveMQ纯Java实现，兼容JMS，可以内嵌于Java应用中。\n\n《ActiveMQ消息队列介绍》\n\nKafka高吞吐量、采用拉模式。适合高IO场景，比如日志同步。\n\n官方网站\n《各消息队列对比，Kafka深度解析，众人推荐，精彩好文！》\n《Kafka分区机制介绍与示例》\n\nRedis 消息推送生产者、消费者模式完全是客户端行为，list 和 拉模式实现，阻塞等待采用 blpop 指令。\n\n《Redis学习笔记之十：Redis用作消息队列》\n\nZeroMQTODO\n定时调度单机定时调度\n《linux定时任务cron配置》\n《Linux cron运行原理》\nfork 进程 + sleep 轮询\n\n\n《Quartz使用总结》\n《Quartz源码解析 —- 触发器按时启动原理》\n《quartz原理揭秘和源码解读》\n定时调度在 QuartzSchedulerThread 代码中，while()无限循环，每次循环取出时间将到的trigger，触发对应的job，直到调度器线程被关闭。\n\n\n\n分布式定时调度\n《这些优秀的国产分布式任务调度系统，你用过几个？》\nopencron、LTS、XXL-JOB、Elastic-Job、Uncode-Schedule、Antares\n\n\n《Quartz任务调度的基本实现原理》\nQuartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的\n\n\n《Elastic-Job-Lite 源码解析》\n《Elastic-Job-Cloud 源码解析》\n\nRPC\n《从零开始实现RPC框架 - RPC原理及实现》\n核心角色：Server: 暴露服务的服务提供方、Client: 调用远程服务的服务消费方、Registry: 服务注册与发现的注册中心。\n\n\n《分布式RPC框架性能大比拼 dubbo、motan、rpcx、gRPC、thrift的性能比较》\n\nDubbo\n官方网站\ndubbo实现原理简单介绍\n\n** SPI ** TODO\nThrift\n官方网站\n《Thrift RPC详解》\n支持多语言，通过中间语言定义接口。\n\n\n\ngRPC服务端可以认证加密，在外网环境下，可以保证数据安全。\n\n官方网站\n《你应该知道的RPC原理》\n\n数据库中间件Sharding Jdbc\n官网\n源码解析\n\n日志系统日志搜集\n《从零开始搭建一个ELKB日志收集系统》\n《用ELK搭建简单的日志收集分析系统》\n《日志收集系统-探究》\n\n配置中心\nApollo - 携程开源的配置中心应用\nSpring Boot 和 Spring Cloud\n支持推、拉模式更新配置\n支持多种语言\n\n\n《基于zookeeper实现统一配置管理》\n《 Spring Cloud Config 分布式配置中心使用教程》\n\nservlet 3.0 异步特性可用于配置中心的客户端\n\n《servlet3.0 新特性——异步处理》\n\nAPI 网关主要职责：请求转发、安全认证、协议转换、容灾。\n\n《API网关那些儿》\n《谈API网关的背景、架构以及落地方案》\n《使用Zuul构建API Gateway》\n《Spring Cloud Gateway 源码解析》\n《HTTP API网关选择之一Kong介绍》\n\n网络协议OSI 七层协议\n《OSI七层协议模型、TCP&#x2F;IP四层模型学习笔记》\n\nTCP&#x2F;IP\n《深入浅出 TCP&#x2F;IP 协议》\n《TCP协议中的三次握手和四次挥手》\n\nHTTP\n《http协议详解(超详细)》\n\nHTTP2.0\n《HTTP 2.0 原理详细分析》\n《HTTP2.0的基本单位为二进制帧》\n利用二进制帧负责传输。\n多路复用。\n\n\n\nHTTPS\n《https原理通俗了解》\n使用非对称加密协商加密算法\n使用对称加密方式传输数据\n使用第三方机构签发的证书，来加密公钥，用于公钥的安全传输、防止被中间人串改。\n\n\n《八大免费SSL证书-给你的网站免费添加Https安全加密》\n\n网络模型\n《web优化必须了解的原理之I&#x2F;o的五种模型和web的三种工作模式》\n五种I&#x2F;O模型：阻塞I&#x2F;O，非阻塞I&#x2F;O，I&#x2F;O复用、事件(信号)驱动I&#x2F;O、异步I&#x2F;O，前四种I&#x2F;O属于同步操作，I&#x2F;O的第一阶段不同、第二阶段相同，最后的一种则属于异步操作。\n三种 Web Server 工作方式：Prefork(多进程)、Worker方式(线程方式)、Event方式。\n\n\n《select、poll、epoll之间的区别总结》\nselect，poll，epoll本质上都是同步I&#x2F;O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。\nselect 有打开文件描述符数量限制，默认1024（2048 for x64），100万并发，就要用1000个进程、切换开销大；poll采用链表结构，没有数量限制。\nselect，poll “醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，通过回调机制节省大量CPU时间；select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，而epoll只要一次拷贝。\npoll会随着并发增加，性能逐渐下降，epoll采用红黑树结构，性能稳定，不会随着连接数增加而降低。\n\n\n《select，poll，epoll比较 》\n在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。\n\n\n《深入理解Java NIO》\nNIO 是一种同步非阻塞的 IO 模型。同步是指线程不断轮询 IO 事件是否就绪，非阻塞是指线程在等待 IO 的时候，可以同时做其他任务\n\n\n《BIO与NIO、AIO的区别》\n《两种高效的服务器设计模型：Reactor和Proactor模型》\n\nEpoll\n《epoll使用详解（精髓）》\n\nJava NIO\n《深入理解Java NIO》\n《Java NIO编写Socket服务器的一个例子》\n\nkqueue\n《kqueue用法简介》\n\n连接和短连接\n《TCP&#x2F;IP系列——长连接与短连接的区别》\n\n框架\n《Netty原理剖析》\nReactor 模式介绍。\nNetty 是 Reactor 模式的一种实现。\n\n\n\n零拷贝（Zero-copy）\n《对于 Netty ByteBuf 的零拷贝(Zero Copy) 的理解》\n多个物理分离的buffer，通过逻辑上合并成为一个，从而避免了数据在内存之间的拷贝。\n\n\n\n序列化(二进制协议)Hessian\n《Hessian原理分析》 Binary-RPC;不仅仅是序列化\n\nProtobuf\n《Protobuf协议的Java应用例子》 Goolge出品、占用空间和效率完胜其他序列化类库，如Hessian；需要编写 .proto 文件。\n《Protocol Buffers序列化协议及应用》\n关于协议的解释；缺点：可读性差;\n\n\n《简单的使用 protobuf 和 protostuff》\nprotostuff 的好处是不用写 .proto 文件，Java 对象直接就可以序列化。\n\n\n\n数据库基础理论关系数据库设计的三大范式\n《数据库的三大范式以及五大约束》\n第一范式：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性；\n第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；\n第三范式：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；\n\n\n\nMySQL原理\n《MySQL的InnoDB索引原理详解》\n《MySQL存储引擎－－MyISAM与InnoDB区别》\n两种类型最主要的差别就是Innodb 支持事务处理与外键和行级锁\n\n\n《myisam和innodb索引实现的不同》\n\nInnoDB\n《一篇文章带你读懂Mysql和InnoDB》\n\n优化\n《MySQL36条军规》\n《MYSQL性能优化的最佳20+条经验》\n《SQL优化之道》\n《mysql数据库死锁的产生原因及解决办法》\n《导致索引失效的可能情况》\n《 MYSQL分页limit速度太慢优化方法》\n原则上就是缩小扫描范围。\n\n\n\n索引聚集索引, 非聚集索引\n《MySQL 聚集索引&#x2F;非聚集索引简述》\n《MyISAM和InnoDB的索引实现》\n\nMyISAM 是非聚集，InnoDB 是聚集\n复合索引\n《复合索引的优点和注意事项》\n\n文中有一处错误：\n\n\n对于复合索引,在查询使用时,最好将条件顺序按找索引的顺序,这样效率最高; select * from table1 where col1&#x3D;A AND col2&#x3D;B AND col3&#x3D;D 如果使用 where col2&#x3D;B AND col1&#x3D;A 或者 where col2&#x3D;B 将不会使用索引\n\n\n原文中提到索引是按照“col1，col2，col3”的顺序创建的，而mysql在按照最左前缀的索引匹配原则，且会自动优化 where 条件的顺序，当条件中只有 col2&#x3D;B AND col1&#x3D;A 时，会自动转化为 col1&#x3D;A AND col2&#x3D;B，所以依然会使用索引。\n\n\n《MySQL查询where条件的顺序对查询效率的影响》\n\n\n自适应哈希索引(AHI)\n《InnoDB存储引擎——自适应哈希索引》\n\nexplain\n《MySQL 性能优化神器 Explain 使用分析》\n\nNoSQLMongoDB\nMongoDB 教程\n《Mongodb相对于关系型数据库的优缺点》\n优点：弱一致性（最终一致），更能保证用户的访问速度；内置GridFS，支持大容量的存储；Schema-less 数据库，不用预先定义结构；内置Sharding；相比于其他NoSQL，第三方支持丰富；性能优越；\n缺点：mongodb不支持事务操作；mongodb占用空间过大；MongoDB没有如MySQL那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方；\n\n\n\nHbase\n《简明 HBase 入门教程（开篇）》\n《深入学习HBase架构原理》\n《传统的行存储和（HBase）列存储的区别》\n《Hbase与传统数据库的区别》\n空数据不存储，节省空间，且适用于并发。\n\n\n《HBase Rowkey设计》\nrowkey 按照字典顺序排列，便于批量扫描。\n通过散列可以避免热点。\n\n\n\n搜索引擎搜索引擎原理\n《倒排索引–搜索引擎入门》\n\nLucene\n《Lucene入门简介》\n\nElasticsearch\n《Elasticsearch学习，请先看这一篇！》\n《Elasticsearch索引原理》\n\nSolr\n《 Apache Solr入门教程》\n《elasticsearch与solr比较》\n\nsphinx\n《Sphinx 的介绍和原理探索》\n\n性能性能优化方法论\n《15天的性能优化工作，5方面的调优经验》\n代码层面、业务层面、数据库层面、服务器层面、前端优化。\n\n\n《系统性能优化的几个方面》\n\n容量评估\n《联网性能与容量评估的方法论和典型案例》\n《互联网架构，如何进行容量设计？》\n评估总访问量、评估平均访问量QPS、评估高峰QPS、评估系统、单机极限QPS\n\n\n\nCDN 网络\n《CDN加速原理》\n《国内有哪些比较好的 CDN？》\n\n连接池\n《主流Java数据库连接池比较与开发配置实战》\n\n性能调优\n《九大Java性能调试工具，必备至少一款》\n\n大数据流式计算Storm\n官方网站\n《最详细的Storm入门教程》\n\nFlink\n《Flink之一 Flink基本原理介绍》\n\nKafka Stream\n《Kafka Stream调研：一种轻量级流计算模式》\n\n应用场景例如：\n\n广告相关实时统计；\n推荐系统用户画像标签实时更新；\n线上服务健康状况实时监测；\n实时榜单；\n实时数据统计。\n\nHadoop\n《用通俗易懂的话说下hadoop是什么,能做什么》\n《史上最详细的Hadoop环境搭建》\n\nHDFS\n《【Hadoop学习】HDFS基本原理》\n\nMapReduce\n《用通俗易懂的大白话讲解Map&#x2F;Reduce原理》\n《 简单的map-reduce的java例子》\n\nYarn\n《初步掌握Yarn的架构及原理》\n\nSpark\n《Spark(一): 基本架构及原理》\n《子雨大数据之Spark入门教程(Python版)》\n\n安全web 安全XSS\n《xss攻击原理与解决方法》\n\nCSRF\n《CSRF原理及防范》\n\nSQL 注入\n《SQL注入》\n\nHash Dos\n《邪恶的JAVA HASH DOS攻击》\n利用JsonObject 上传大Json，JsonObject 底层使用HashMap；不同的数据产生相同的hash值，使得构建Hash速度变慢，耗尽CPU。\n\n\n《一种高级的DoS攻击-Hash碰撞攻击》\n《关于Hash Collision DoS漏洞：解析与解决方案》\n\n脚本注入\n《上传文件漏洞原理及防范》\n\n漏洞扫描工具\n《DVWA》\nW3af\nOpenVAS详解\n\n验证码\n《验证码原理分析及实现》\n《详解滑动验证码的实现原理》\n滑动验证码是根据人在滑动滑块的响应时间，拖拽速度，时间，位置，轨迹，重试次数等来评估风险。\n\n\n《淘宝滑动验证码研究》\n\nDDoS 防范\n《学习手册：DDoS的攻击方式及防御手段》\n《免费DDoS攻击测试工具大合集》\n\n用户隐私信息保护\n用户密码非明文保存，加动态salt。\n身份证号，手机号如果要显示，用 “*” 替代部分字符。\n联系方式在的显示与否由用户自己控制。\nTODO\n\n\n《个人隐私包括哪些》\n《在互联网上，隐私的范围包括哪些？》\n《用户密码保存》\n\n序列化漏洞\n《Lib之过？Java反序列化漏洞通用利用分析》\n\n加密解密对称加密\n《常见对称加密算法》\nDES、3DES、Blowfish、AES\nDES 采用 56位秘钥，Blowfish 采用1到448位变长秘钥，AES 128，192和256位长度的秘钥。\nDES 秘钥太短（只有56位）算法目前已经被 AES 取代，并且 AES 有硬件加速，性能很好。\n\n\n\n哈希算法\n《常用的哈希算法》\nMD5 和 SHA-1 已经不再安全，已被弃用。\n目前 SHA-256 是比较安全的。\n\n\n《基于Hash摘要签名的公网URL签名验证设计方案》\n\n非对称加密\n《常见非对称加密算法》\n\nRSA、DSA、ECDSA(螺旋曲线加密算法)\n\n和 RSA 不同的是 DSA 仅能用于数字签名，不能进行数据加密解密，其安全性和RSA相当，但其性能要比RSA快。\n\n256位的ECC秘钥的安全性等同于3072位的RSA秘钥。\n《区块链的加密技术》\n\n\n\n\n服务器安全\n《Linux强化论：15步打造一个安全的Linux服务器》\n\n数据安全数据备份TODO\n网络隔离内外网分离TODO\n登录跳板机在内外环境中通过跳板机登录到线上主机。\n\n《搭建简易堡垒机》\n\n授权、认证\n授权认证知识库\n\nRBAC\n《基于组织角色的权限设计》\n《权限系统与RBAC模型概述》\n《Spring整合Shiro做权限控制模块详细案例分析》\n\nOAuth2.0\n《理解OAuth 2.0》\n《一张图搞定OAuth2.0》\n\nOIDC\n理解 OIDC\n\nSAML\n理解 SAML\n\n双因素认证（2FA）2FA - Two-factor authentication，用于加强登录验证\n常用做法是 登录密码 + 手机验证码（或者令牌Key，类似于与网银的 USB key）\n\n【《双因素认证（2FA）教程》】(http://www.ruanyifeng.com/blog/2017/11/2fa-tutorial.html)\n\n单点登录(SSO)\n《单点登录原理与简单实现》\nCAS单点登录框架\n使用 Authing 实现单点登录\n\n常用开源框架开源协议\n《开源协议的选择》\n如何选择一个开源软件协议\n\n日志框架Log4j、Log4j2\n《log4j 详细讲解》\n《log4j2 实际使用详解》\n《Log4j1,Logback以及Log4j2性能测试对比》\nLog4J 异步日志性能优异。\n\n\n\nLogback\n《最全LogBack 详解、含java案例和配置说明》\n\nORM\n《ORM框架使用优缺点》\n主要目的是为了提高开发效率。\n\n\n\nMyBatis：\n\n《mybatis缓存机制详解》\n一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效\n二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的；使用 LRU 机制清理缓存，通过 cacheEnabled 参数开启。\n\n\n《MyBatis学习之代码生成器Generator》\n\n网络框架TODO\nWeb 框架Spring 家族Spring\n\nSpring 简明教程\n\nSpring Boot\n\n官方网站\n《Spring Boot基础教程》\n\nSpring Cloud\n\nSpring Boot 中文索引站\nSpring Cloud 中文文档\n《Spring Cloud基础教程》\n\n工具框架\n《Apache Commons 工具类介绍及简单使用》\n《Google guava 中文教程》\n\n分布式设计扩展性设计\n《架构师不可不知的十大可扩展架构》\n总结下来，通用的套路就是分布、缓存及异步处理。\n\n\n《可扩展性设计之数据切分》\n水平切分+垂直切分\n利用中间件进行分片如，MySQL Proxy。\n利用分片策略进行切分，如按照ID取模。\n\n\n《说说如何实现可扩展性的大型网站架构》\n分布式服务+消息队列。\n\n\n《大型网站技术架构（七）–网站的可扩展性架构》\n\n稳定性 &amp; 高可用\n《系统设计：关于高可用系统的一些技术方案》\n可扩展：水平扩展、垂直扩展。 通过冗余部署，避免单点故障。\n隔离：避免单一业务占用全部资源。避免业务之间的相互影响 2. 机房隔离避免单点故障。\n解耦：降低维护成本，降低耦合风险。减少依赖，减少相互间的影响。\n限流：滑动窗口计数法、漏桶算法、令牌桶算法等算法。遇到突发流量时，保证系统稳定。\n降级：紧急情况下释放非核心功能的资源。牺牲非核心业务，保证核心业务的高可用。\n熔断：异常情况超出阈值进入熔断状态，快速失败。减少不稳定的外部依赖对核心服务的影响。\n自动化测试：通过完善的测试，减少发布引起的故障。\n灰度发布：灰度发布是速度与安全性作为妥协，能够有效减少发布故障。\n\n\n《关于高可用的系统》\n设计原则：数据不丢(持久化)；服务高可用(服务副本)；绝对的100%高可用很难，目标是做到尽可能多的9，如99.999%（全年累计只有5分钟）。\n\n\n\n硬件负载均衡\n《转！！负载均衡器技术Nginx和F5的优缺点对比》\n主要是和F5对比。\n\n\n《软&#x2F;硬件负载均衡产品 你知多少？》\n\n软件负载均衡\n《几种负载均衡算法》 轮寻、权重、负载、最少连接、QoS\n《DNS负载均衡》\n配置简单，更新速度慢。\n\n\n《Nginx负载均衡》\n简单轻量、学习成本低；主要适用于web应用。\n\n\n《借助LVS+Keepalived实现负载均衡 》\n配置比较负载、只支持到4层，性能较高。\n\n\n《HAProxy用法详解 全网最详细中文文档》\n支持到七层（比如HTTP）、功能比较全面，性能也不错。\n\n\n《Haproxy+Keepalived+MySQL实现读均衡负载》\n主要是用户读请求的负载均衡。\n\n\n《rabbitmq+haproxy+keepalived实现高可用集群搭建》\n\n限流\n《谈谈高并发系统的限流》\n计数器：通过滑动窗口计数器，控制单位时间内的请求次数，简单粗暴。\n漏桶算法：固定容量的漏桶，漏桶满了就丢弃请求，比较常用。\n令牌桶算法：固定容量的令牌桶，按照一定速率添加令牌，处理请求前需要拿到令牌，拿不到令牌则丢弃请求，或进入丢队列，可以通过控制添加令牌的速率，来控制整体速度。Guava 中的 RateLimiter 是令牌桶的实现。\nNginx 限流：通过 limit_req 等模块限制并发连接数。\n\n\n\n应用层容灾\n《防雪崩利器：熔断器 Hystrix 的原理与使用》\n雪崩效应原因：硬件故障、硬件故障、程序Bug、重试加大流量、用户大量请求。\n雪崩的对策：限流、改进缓存模式(缓存预加载、同步调用改异步)、自动扩容、降级。\nHystrix设计原则：\n资源隔离：Hystrix通过将每个依赖服务分配独立的线程池进行资源隔离, 从而避免服务雪崩。\n熔断开关：服务的健康状况 &#x3D; 请求失败数 &#x2F; 请求总数，通过阈值设定和滑动窗口控制开关。\n命令模式：通过继承 HystrixCommand 来包装服务调用逻辑。\n\n\n\n\n《缓存穿透，缓存击穿，缓存雪崩解决方案分析》\n《缓存击穿、失效以及热点key问题》\n主要策略：失效瞬间：单机使用锁；使用分布式锁；不过期；\n热点数据：热点数据单独存储；使用本地缓存；分成多个子key；\n\n\n\n跨机房容灾\n《“异地多活”多机房部署经验谈》\n通过自研中间件进行数据同步。\n\n\n《异地多活（异地双活）实践经验》\n注意延迟问题，多次跨机房调用会将延时放大数倍。\n建房间专线很大概率会出现问题，做好运维和程序层面的容错。\n不能依赖于程序端数据双写，要有自动同步方案。\n数据永不在高延迟和较差网络质量下，考虑同步质量问题。\n核心业务和次要业务分而治之，甚至只考虑核心业务。\n异地多活监控部署、测试也要跟上。\n业务允许的情况下考虑用户分区，尤其是游戏、邮箱业务。\n控制跨机房消息体大小，越小越好。\n考虑使用docker容器虚拟化技术，提高动态调度能力。\n\n\n容灾技术及建设经验介绍\n\n容灾演练流程\n《依赖治理、灰度发布、故障演练，阿里电商故障演练系统的设计与实战经验》\n常见故障画像\n案例：预案有效性、预案有效性、故障复现、架构容灾测试、参数调优、参数调优、故障突袭、联合演练。\n\n\n\n平滑启动\n平滑重启应用思路 1.端流量（如vip层）、2. flush 数据(如果有)、3, 重启应用\n《JVM安全退出（如何优雅的关闭java服务）》 推荐推出方式：System.exit，Kill SIGTERM；不推荐 kill-9；用 Runtime.addShutdownHook 注册钩子。\n《常见Java应用如何优雅关闭》 Java、Spring、Dubbo 优雅关闭方式。\n\n数据库扩展读写分离模式\n《Mysql主从方案的实现》\n《搭建MySQL主从复制经典架构》\n《Haproxy+多台MySQL从服务器(Slave) 实现负载均衡》\n《DRBD+Heartbeat+Mysql高可用读写分离架构》\nDRDB 进行磁盘复制，避免单点问题。\n\n\n《MySQL Cluster 方式》\n\n分片模式\n《分库分表需要考虑的问题及方案》\n中间件： 轻量级：sharding-jdbc、TSharding；重量级：Atlas、MyCAT、Vitess等。\n问题：事务、Join、迁移、扩容、ID、分页等。\n事务补偿：对数据进行对帐检查;基于日志进行比对;定期同标准数据来源进行同步等。\n分库策略：数值范围；取模；日期等。\n分库数量：通常 MySQL 单库 5千万条、Oracle 单库一亿条需要分库。\n\n\n《MySql分表和表分区详解》\n分区：是MySQL内部机制，对客户端透明，数据存储在不同文件中，表面上看是同一个表。\n分表：物理上创建不同的表、客户端需要管理分表路由。\n\n\n\n服务治理服务注册与发现\n《永不失联！如何实现微服务架构中的服务发现？》\n客户端服务发现模式：客户端直接查询注册表，同时自己负责负载均衡。Eureka 采用这种方式。\n服务器端服务发现模式：客户端通过负载均衡查询服务实例。\n\n\n《SpringCloud服务注册中心比较:Consul vs Zookeeper vs Etcd vs Eureka》\nCAP支持：Consul（CA）、zookeeper（cp）、etcd（cp） 、euerka（ap）\n作者认为目前 Consul 对 Spring cloud 的支持比较好。\n\n\n《基于Zookeeper的服务注册与发现》\n优点：API简单、Pinterest，Airbnb 在用、多语言、通过watcher机制来实现配置PUSH，能快速响应配置变化。\n\n\n\n服务路由控制\n《分布式服务框架学习笔记4 服务路由》\n原则：透明化路由\n负载均衡策略：随机、轮询、服务调用延迟、一致性哈希、粘滞连接\n本地路由优先策略：injvm(优先调用jvm内部的服务)，innative(优先使用相同物理机的服务),原则上找距离最近的服务。\n配置方式：统一注册表；本地配置；动态下发。\n\n\n\n分布式一致CAP 与 BASE 理论\n《从分布式一致性谈到CAP理论、BASE理论》\n一致性分类：强一致(立即一致)；弱一致(可在单位时间内实现一致，比如秒级)；最终一致(弱一致的一种，一定时间内最终一致)\nCAP：一致性、可用性、分区容错性(网络故障引起)\nBASE：Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）\nBASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。\n\n\n\n分布式锁\n《分布式锁的几种实现方式》\n基于数据库的分布式锁：优点：操作简单、容易理解。缺点：存在单点问题、数据库性能够开销较大、不可重入；\n基于缓存的分布式锁：优点：非阻塞、性能好。缺点：操作不好容易造成锁无法释放的情况。\nZookeeper 分布式锁：通过有序临时节点实现锁机制，自己对应的节点需要最小，则被认为是获得了锁。优点：集群可以透明解决单点问题，避免锁不被释放问题，同时锁可以重入。缺点：性能不如缓存方式，吞吐量会随着zk集群规模变大而下降。\n\n\n《基于Zookeeper的分布式锁》\n清楚的原理描述 + Java 代码示例。\n\n\n《jedisLock—redis分布式锁实现》\n基于 setnx(set if ont exists)，有则返回false，否则返回true。并支持过期时间。\n\n\n《Memcached 和 Redis 分布式锁方案》\n利用 memcached 的 add（有别于set）操作，当key存在时，返回false。\n\n\n\n分布式一致性算法PAXOS\n《分布式系列文章——Paxos算法原理与推导》\n《Paxos–&gt;Fast Paxos–&gt;Zookeeper分析》\n《【分布式】Zookeeper与Paxos》\n\nZab\n《Zab：Zookeeper 中的分布式一致性协议介绍》\n\nRaft\n《Raft 为什么是更易理解的分布式一致性算法》\n三种角色：Leader（领袖）、Follower（群众）、Candidate（候选人）\n通过随机等待的方式发出投票，得票多的获胜。\n\n\n\nGossip\n《Gossip算法》\n\n两阶段提交、多阶段提交\n《关于分布式事务、两阶段提交协议、三阶提交协议》\n\n幂等\n《分布式系统—幂等性设计》\n幂等特性的作用：该资源具备幂等性，请求方无需担心重复调用会产生错误。\n常见保证幂等的手段：MVCC（类似于乐观锁）、去重表(唯一索引)、悲观锁、一次性token、序列号方式。\n\n\n\n分布式一致方案\n《分布式系统事务一致性解决方案》\n《保证分布式系统数据一致性的6种方案》\n\n分布式 Leader 节点选举\n《利用zookeeper实现分布式leader节点选举》\n\nTCC(Try&#x2F;Confirm&#x2F;Cancel) 柔性事务\n《传统事务与柔性事务》\n基于BASE理论：基本可用、柔性状态、最终一致。\n解决方案：记录日志+补偿（正向补充或者回滚）、消息重试(要求程序要幂等)；“无锁设计”、采用乐观锁机制。\n\n\n\n分布式文件系统\n说说分布式文件存储系统-基本架构 ？\n\n《各种分布式文件系统的比较》\n？\n\nHDFS：大批量数据读写，用于高吞吐量的场景，不适合小文件。\nFastDFS：轻量级、适合小文件。\n\n\n\n唯一ID 生成全局唯一ID\n《高并发分布式系统中生成全局唯一Id汇总》\nTwitter 方案（Snowflake 算法）：41位时间戳+10位机器标识（比如IP，服务器名称等）+12位序列号(本地计数器)\nFlicker 方案：MySQL自增ID + “REPLACE INTO XXX:SELECT LAST_INSERT_ID();”\nUUID：缺点，无序，字符串过长，占用空间，影响检索性能。\nMongoDB 方案：利用 ObjectId。缺点：不能自增。\n\n\n《TDDL 在分布式下的SEQUENCE原理》\n在数据库中创建 sequence 表，用于记录，当前已被占用的id最大值。\n每台客户端主机取一个id区间（比如 1000~2000）缓存在本地，并更新 sequence 表中的id最大值记录。\n客户端主机之间取不同的id区间，用完再取，使用乐观锁机制控制并发。\n\n\n\n一致性Hash算法\n《一致性哈希算法》\n\n设计思想 &amp; 开发模式DDD(Domain-driven Design - 领域驱动设计)\n《浅谈我对DDD领域驱动设计的理解》\n概念：DDD 主要对传统软件开发流程(分析-设计-编码)中各阶段的割裂问题而提出，避免由于一开始分析不明或在软件开发过程中的信息流转不一致而造成软件无法交付（和需求方设想不一致）的问题。DDD 强调一切以领域（Domain）为中心，强调领域专家（Domain Expert）的作用，强调先定义好领域模型之后在进行开发，并且领域模型可以指导开发（所谓的驱动）。\n过程：理解领域、拆分领域、细化领域，模型的准确性取决于模型的理解深度。\n设计：DDD 中提出了建模工具，比如聚合、实体、值对象、工厂、仓储、领域服务、领域事件来帮助领域建模。\n\n\n《领域驱动设计的基础知识总结》\n领域（Doamin）本质上就是问题域，比如一个电商系统，一个论坛系统等。\n界限上下文（Bounded Context）：阐述子域之间的关系，可以简单理解成一个子系统或组件模块。\n领域模型（Domain Model）：DDD的核心是建立（用通用描述语言、工具—领域通用语言）正确的领域模型；反应业务需求的本质，包括实体和过程；其贯穿软件分析、设计、开发 的整个过程；常用表达领域模型的方式：图、代码或文字；\n领域通用语言：领域专家、开发设计人员都能立即的语言或工具。\n经典分层架构：用户界面&#x2F;展示层、应用层、领域层、基础设施层，是四层架构模式。\n使用的模式：\n关联尽量少，尽量单项，尽量降低整体复杂度。\n实体（Entity）：领域中的唯一标示，一个实体的属性尽量少，少则清晰。\n值对象（Value Object）：没有唯一标识，且属性值不可变，小二简单的对象，比如Date。\n领域服务（Domain Service）： 协调多个领域对象，只有方法没有状态(不存数据)；可以分为应用层服务，领域层服务、基础层服务。\n聚合及聚合根（Aggregate，Aggregate Root）：聚合定义了一组具有内聚关系的相关对象的集合；聚合根是对聚合引用的唯一元素；当修改一个聚合时，必须在事务级别；大部分领域模型中，有70%的聚合通常只有一个实体，30%只有2~3个实体；如果一个聚合只有一个实体，那么这个实体就是聚合根；如果有多个实体，那么我们可以思考聚合内哪个对象有独立存在的意义并且可以和外部直接进行交互；\n工厂（Factory）：类似于设计模式中的工厂模式。\n仓储（Repository）：持久化到DB，管理对象，且只对聚合设计仓储。\n\n\n\n\n《领域驱动设计(DDD)实现之路》\n聚合：比如一辆汽车（Car）包含了引擎（Engine）、车轮（Wheel）和油箱（Tank）等组件，缺一不可。\n\n\n《领域驱动设计系列（2）浅析VO、DTO、DO、PO的概念、区别和用处》\n\n命令查询职责分离(CQRS)CQRS — Command Query Responsibility Seperation\n\n《领域驱动设计系列 (六)：CQRS》\n核心思想：读写分离（查询和更新在不同的方法中），不同的流程只是不同的设计方式，CQ代码分离，分布式环境中会有明显体现（有冗余数据的情况下），目的是为了高性能。\n\n\n《DDD CQRS架构和传统架构的优缺点比较》\n最终一致的设计理念；依赖于高可用消息中间件。\n\n\n《CQRS架构简介》\n一个实现 CQRS 的抽象案例。\n\n\n《深度长文：我对CQRS&#x2F;EventSourcing架构的思考》\nCQRS 模式分析 + 12306 抢票案例\n\n\n\n贫血，充血模型\n《贫血，充血模型的解释以及一些经验》\n失血模型：老子和儿子分别定义，相互不知道，二者实体定义中完全没有业务逻辑，通过外部Service进行关联。\n贫血模型：老子知道儿子，儿子也知道老子；部分业务逻辑放到实体中；优点：各层单项依赖，结构清楚，易于维护；缺点：不符合OO思想，相比于充血模式，Service层较为厚重；\n充血模型：和贫血模型类似，区别在于如何划分业务逻辑。优点：Service层比较薄，只充当Facade的角色，不和DAO打交道、复合OO思想；缺点：非单项依赖，DO和DAO之间双向依赖、和Service层的逻辑划分容易造成混乱。\n肿胀模式：是一种极端情况，取消Service层、全部业务逻辑放在DO中；优点：符合OO思想、简化了分层；缺点：暴露信息过多、很多非DO逻辑也会强行并入DO。这种模式应该避免。\n作者主张使用贫血模式。\n\n\n\nActor 模式TODO\n响应式编程ReactorTODO\nRxJavaTODO\nVert.xTODO\nDODAF2.0\n《DODAF2.0方法论》\n《DODAF2.0之能力视角如何落地》\n\nServerless无需过多关系服务器的服务架构理念。\n\n《什么是Serverless无服务器架构？》\nServerless 不代表出去服务器，而是去除对服务器运行状态的关心。\nServerless 代表一思维方式的转变，从“构建一套服务在一台服务器上，对对个事件进行响应转变为构建一个为服务器，来响应一个事件”。\nServerless 不代表某个具体的框架。\n\n\n《如何理解Serverless？》\n依赖于 Baas （(Mobile) Backend as a Service） 和 Faas （Functions as a service）\n\n\n\nService Mesh\n《什么是Service Mesh？》\n《初识 Service Mesh》\n\n项目管理架构评审\n《架构设计之如何评审架构设计说明书》\n《人人都是架构师：非功能性需求》\n\n重构\n《架构之重构的12条军规》\n\n代码规范\n《阿里巴巴Java开发手册》\n\n代码 Review制度还是制度! 另外，每个公司需要根据自己的需求和目标制定自己的 check list\n\n《为什么你做不好 Code Review？》\n代码 review 做的好，在于制度建设。\n\n\n《从零开始Code Review》\n《Code Review Checklist》\n《Java Code Review Checklist》\n《如何用 gitlab 做 code review》\n\nRUP\n《运用RUP 4+1视图方法进行软件架构设计》\n\n看板管理\n《说说看板在项目中的应用》\n\nSCRUMSCRUM - 争球\n\n3个角色:Product Owner(PO) 产品负责人;Scrum Master（SM），推动Scrum执行;Team 开发团队。\n3个工件：Product Backlog 产品TODOLIST，含优先级;Sprint Backlog 功能开发 TODO LIST；燃尽图；\n五个价值观：专注、勇气、公开、承诺、尊重。\n《敏捷项目管理流程-Scrum框架最全总结！》\n《敏捷其实很简单3—敏捷方法之scrum》\n\n敏捷开发TODO\n极限编程（XP）XP - eXtreme Programming\n\n《主流敏捷开发方法：极限编程XP》\n是一种指导开发人员的方法论。\n4大价值：\n沟通：鼓励口头沟通，提高效率。\n简单：够用就好。\n反馈：及时反馈、通知相关人。\n勇气：提倡拥抱变化，敢于重构。\n\n\n5个原则：快速反馈、简单性假设、逐步修改、提倡更改（小步快跑）、优质工作（保证质量的前提下保证小步快跑）。\n5个工作：阶段性冲刺；冲刺计划会议；每日站立会议；冲刺后review；回顾会议。\n\n\n\n结对编程边写码，边review。能够增强代码质量、减少bug。\n\n《结对编程》\n\nPDCA 循环质量管理P——PLAN 策划，D——DO 实施，C——CHECK 检查，A——ACT 改进\n\n《PDCA》\n\nFMEA管理模式TODO\n通用业务术语TODO\n技术趋势TODO\n政策、法规法律\n《中华人民共和国网络安全法》\n\n2016年11月7日发布，自2017年6月1日起施行\n\n\n《个人信息保护法》\n\n个人信息保护法是一部保护个人信息的法律条款，现尚在制订中，2019全国两会信息安全相关提案中，有政协委员呼吁关注大数据时代隐私保护，加速立法。\n\n\n《最高人民法院、最高人民检察院关于办理侵犯公民个人信息刑事案件适用法律若干问题的解释》\n\n《解释》共十三条，自2017年6月1日起施行\n\n\n\n1、对于行踪轨迹信息、通信内容、征信信息、财产信息，非法获取、出售或者提供50条以上即算“情节严重”；\n2、对于住宿信息、通信记录、健康生理信息、交易信息等其他可能影响人身、财产安全的公民个人信息，标准则是 500条以上；\n3、对于其他公民个人信息，标准为 5000条以上。\n\n\n\n《中华人民共和国电子商务法》\n\n2018年8月31日，十三届全国人大常委会第五次会议表决通过《电子商务法》，自2019年1月1日起施行\n解读电子商务法（一）什么是电商\n解读电子商务法（二）电商经营者\n解读电子商务法（三）电商行为规范\n解读电子商务法（四）电商的法律关系\n解读电子商务法（外传）电商挣钱的秘密\n解读电子商务法（外传）电商模式\n\n\n程序员需要知道的法律常识\n\n白话法律42讲-为程序员打造的专属法律武器\n\n\n严格遵守刑法253法条我国刑法第253条之一规定：\n\n\n国家机关或者金融、电信、交通、教育、医疗等单位的工作人员，违反国家规定，将本单位在履行职责或者提供服务过程中获得的公民个人信息，出售或者非法提供给他人，情节严重的，处3年以下有期徒刑或者拘役，并处或者单处罚金。\n窃取或者以其他方法非法获取上述信息，情节严重的，依照前款的规定处罚。\n单位犯前两款罪的，对单位判处罚金，并对其直接负责的主管人员和其他直接责任人员，依照各该款的规定处罚。\n\n\n最高人民法院、最高人民检察院关于执行《中华人民共和国刑法》确定罪名的补充规定（四）规定：触犯刑法第253条之一第1款之规定，构成“出售、非法提供公民个人信息罪”；触犯刑法第253条之一第2款之规定，构成“非法获取公民个人信息罪”\n\n《非法获取公民个人信息罪》\n\n避风港原则“避风港”原则是指在发生著作权侵权案件时，当ISP（网络服务提供商）只提供空间服务，并不制作网页内容，如果ISP被告知侵权，则有删除的义务，否则就被视为侵权。如果侵权内容既不在ISP的服务器上存储，又没有被告知哪些内容应该删除，则ISP不承担侵权责任。 后来避风港原则也被应用在搜索引擎、网络存储、在线图书馆等方面。\n\n《避风港原则》\n\n架构师素质\n《架构师画像》\n业务理解和抽象能力\nNB的代码能力\n全面：1. 在面对业务问题上，架构师脑海里是否会浮现出多种技术方案；2. 在做系统设计时是否考虑到了足够多的方方面面；3. 在做系统设计时是否考虑到了足够多的方方面面；\n全局：是否考虑到了对上下游的系统的影响。\n权衡：权衡投入产出比；优先级和节奏控制；\n\n\n《关于架构优化和设计，架构师必须知道的事情》\n要去考虑的细节：模块化、轻耦合、无共享架构；减少各个组件之前的依赖、注意服务之间依赖所有造成的链式失败及影响等。\n基础设施、配置、测试、开发、运维综合考虑。\n考虑人、团队、和组织的影响。\n\n\n《如何才能真正的提高自己，成为一名出色的架构师？》\n《架构师的必备素质和成长途径》\n素质：业务理解、技术广度、技术深度、丰富经验、沟通能力、动手能力、美学素养。\n成长路径：2年积累知识、4年积累技能和组内影响力、7年积累部门内影响力、7年以上积累跨部门影响力。\n\n\n《架构设计师—你在哪层楼？》\n第一层的架构师看到的只是产品本身\n第二层的架构师不仅看到自己的产品，还看到了整体的方案\n第三层的架构师看到的是商业价值\n\n\n\n团队管理TODO\n招聘资讯行业资讯\n36kr\nTechweb\n\n公众号列表TODO\n博客团队博客\n阿里中间件博客\n美团点评技术团队博客\n\n个人博客\n阮一峰的网络日志\n酷壳 - COOLSHELL-陈皓\nhellojava-阿里毕玄\nCm’s Blog\n程序猿DD-翟永超-《Spring Cloud微服务实战》作者\n\n综合门户、社区国内：\n\nCSDN 老牌技术社区、不必解释。\n51cto.com\nITeye\n偏 Java 方向\n\n\n博客园\nChinaUnix\n偏 Linux 方向\n\n\n开源中国社区\nInfoQ\n深度开源\n伯乐在线\n涵盖 IT职场、Web前端、后端、移动端、数据库等方面内容，偏技术端。\n\n\nITPUB\n腾讯云— 云+社区\n阿里云— 云栖社区\nIBM DeveloperWorks\n开发者头条\nLinkedKeeper\n\n国外：\n\nDZone\nReddit\n\n问答、讨论类社区\nsegmentfault\n问答+专栏\n\n\n知乎\nstackoverflow\n\n行业数据分析\n艾瑞网\nQUEST MOBILE\n国家数据\nTalkingData\n\n专项网站\n测试:\n领测国际\n测试窝\nTesterHome\n\n\n运维:\n运维派\nAbcdocker\n\n\nJava:\nImportNew\n专注于 Java 技术分享\n\n\nHowToDoInJava\n英文博客\n\n\n\n\n安全\n红黑联盟\nFreeBuf\n\n\n大数据\n中国大数据\n\n\n其他专题网站：\nInfoQ\n偏重于基础架构、运维方向\n\n\nDockerInfo\n专注于 Docker 应用及咨询、教程的网站\n\n\nLinux公社\nLinux 主题社区\n\n\n\n\n\n其他类\n程序员技能图谱\n\n推荐参考书在线电子书\n《深入理解Spring Cloud与微服务构建》\n《阿里技术参考图册-研发篇》\n《阿里技术参考图册-算法篇》\n《2018美团点评技术年货（合辑）》70M\nInfoQ《架构师》月刊\n《架构师之路》\n\n纸质书更多架构方面书籍参考: awesome-java-books\n开发方面\n《阿里巴巴Java开发手册》详情\n\n架构方面\n《软件架构师的12项修炼：技术技能篇》详情\n《架构之美》详情\n《分布式服务架构》详情\n《聊聊架构》 详情\n《云原生应用架构实践》详情\n《亿级流量网站架构核心技术》详情\n《淘宝技术这十年》详情\n《企业IT架构转型之道-中台战略思想与架构实战》 详情\n《高可用架构（第1卷）》详情\n\n技术管理方面\n《CTO说》详情\n《技术管理之巅》详情\n《网易一千零一夜：互联网产品项目管理实战》详情\n\n基础理论\n《数学之美》详情\n《编程珠玑》详情\n\n工具方面TODO\n大数据方面技术资源开源资源\ngithub\nApache 软件基金会\n\n手册、文档、教程国内：\n\nW3Cschool\nRunoob.com\nHTML 、 CSS、XML、Java、Python、PHP、设计模式等入门手册。\n\n\nLove2.io\n很多很多中文在线电子书，是一个全新的开源技术文档分享平台。\n\n\ngitbook.cn\n付费电子书。\n\n\nApacheCN\nAI、大数据方面系列中文文档。\n\n\n\n国外：\n\nQuick Code\n免费在线技术教程。\n\n\ngitbook.com\n有部分中文电子书。\n\n\nCheatography\nCheat Sheets 大全，单页文档网站。\n\n\nTutorialspoint\n知名教程网站，提供Java、Python、JS、SQL、大数据等高质量入门教程。\n\n\nLeetCode\n知名题库网站，提供Java、Python、C#、C++、算法、SQL、等高质量各程度题库和解决办法。\n\n\n\n在线课堂\n学徒无忧\n极客时间\nsegmentfault\n斯达克学院\n牛客网\n极客学院\n51CTO学院\n\n会议、活动\nQCon\nArchSummit\nGITC全球互联网技术大会\n\n活动发布平台:\n\n活动行\n\n常用APP\n极客时间\n得到\n\n找工作\nBoss直聘\n拉勾网\n猎聘\n100Offer\n\n工具\n极客搜索\n技术文章搜索引擎。\n\n\n\n代码托管\nCoding\n码云\n\n文件服务\n七牛\n又拍云\n\n综合云服务商\n阿里云\n腾讯云\n百度云\n新浪云\n金山云\n亚马逊云(AWS)\n谷歌云\n微软云\n\nVPS\nLinode\nDigitalOcean\nVultr\n\n\n","categories":["后端架构师技术"],"tags":["后端架构师"]},{"title":"Java 并发 - 知识专题","url":"/2023/02/19/java%E5%B9%B6%E5%8F%91%E7%9F%A5%E8%AF%86%E4%B8%93%E9%A2%98/","content":"java并发知识专题\n努力的意义，就是，在以后的日子里，放眼望去全是自己喜欢的人和事！\n整个系列文章为Java并发专题，一是自己的兴趣，二是，这部分在实际理解上很有难度，另外在面试过程中也是经常被问到。所以在学习过程中，记录了Java并发相关的基础知识，一是自己对知识能够建立体系，同时也希望有幸能够对其他人有用。\n关于Java并发专题：\n（1）包含了并发的基础知识，每个标题链接到一篇具体的文章；\n（2）包含了秋招面试的问题，弄懂了会让你有所收获（也祝大家都能找到心仪的工作 😃 ）\n（3）在阅读过程中，如果有所帮助，麻烦点赞，算是对我码字的这份坚持的鼓励。\n\n基础知识\n1.1 并发编程的优缺点\n知识点：（1）为什么要用到并发？（优点）；（2）并发编程的缺点；（3）易混淆的概念\n1.2 线程的状态和基本操作\n知识点：（1）如何新建线程；（2）线程状态的转换；（3）线程的基本操作；（4）守护线程Daemon；\n\n并发理论（JMM）\njava内存模型以及happens-before规则\n知识点：（1）JMM内存结构；（2）重排序；（3）happens-before规则\n\n并发关键字\n3.1 让你彻底理解Synchronized\n知识点：（1）如何使用synchronized；（2）monitor机制；（3）synchronized的happens-before关系；（4）synchronized的内存语义；（5）锁优化；（6）锁升级策略\n3.2 让你彻底理解volatile\n知识点：（1）实现原理；（2）happens-before的关系推导；（3）内存语义；（4）内存语义的实现\n3.3 你以为你真的了解final吗？\n知识点：（1）如何使用；（2）final的重排序规则；（3）final实现原理；（4）final引用不能从构造函数中“溢出”（this逃逸）\n3.4 三大性质总结：原子性，有序性，可见性\n知识点：（1）原子性：synchronized；（2）可见性：synchronized，volatile；（3）有序性：synchronized，volatile\n\nLock体系\n4.1 初识Lock与AbstractQueuedSynchronizer(AQS)\n知识点：（1）Lock和synchronized的比较；（2）AQS设计意图；（3）如何使用AQS实现自定义同步组件；（4）可重写的方法；（5）AQS提供的模板方法；\n4.2 深入理解AbstractQueuedSynchronizer(AQS)\n知识点：（1）AQS同步队列的数据结构；（2）独占式锁；（3）共享式锁；\n4.3 再一次理解ReentrantLock\n知识点：（1）重入锁的实现原理；（2）公平锁的实现原理；（3）非公平锁的实现原理；（4）公平锁和非公平锁的比较\n4.4 深入理解读写锁ReentrantReadWriteLock\n知识点：（1）如何表示读写状态；（2）WriteLock的获取和释放；（3）ReadLock的获取和释放；（4）锁降级策略；（5）生成Condition等待队列；（6）应用场景\n4.5 详解Condition的await和signal等待&#x2F;通知机制\n知识点：（1）与Object的wait&#x2F;notify机制相比具有的特性；（2）与Object的wait&#x2F;notify相对应的方法；（3）底层数据结构；（4）await实现原理；（5）signal&#x2F;signalAll实现原理；（6）await和signal&#x2F;signalAll的结合使用；\n4.6 LockSupport工具\n知识点：（1）主要功能；（2）与synchronized阻塞唤醒相比具有的特色；\n\n并发容器\n5.1 并发容器之ConcurrentHashMap(JDK 1.8版本)\n知识点：（1）关键属性；（2）重要内部类；（3）涉及到的CAS操作；（4）构造方法；（5）put执行流程；（6）get执行流程；（7）扩容机制；（8）用于统计size的方法的执行流程；（9）1.8版本的ConcurrentHashMap与之前版本的比较\n5.2 并发容器之CopyOnWriteArrayList\n知识点：（1）实现原理；（2）COW和ReentrantReadWriteLock的区别；（3）应用场景；（4）为什么具有弱一致性；（5）COW的缺点；\n5.3 并发容器之ConcurrentLinkedQueue\n知识点：（1）实现原理；（2）数据结构；（3）核心方法；（4）HOPS延迟更新的设计意图\n5.4 并发容器之ThreadLocal\n知识点：（1）实现原理；（2）set方法原理；（3）get方法原理；（4）remove方法原理；（5）ThreadLocalMap\n一篇文章，从源码深入详解ThreadLocal内存泄漏问题\n知识点：（1）ThreadLocal内存泄漏原理；（2）ThreadLocal的最佳实践；（3）应用场景\n5.5 并发容器之BlockingQueue\n知识点：（1）BlockingQueue的基本操作；（2）常用的BlockingQueue；\n并发容器之ArrayBlockingQueue和LinkedBlockingQueue实现原理详解\n\n线程池（Executor体系）\n6.1 线程池实现原理\n知识点：（1）为什么要用到线程池？（2）执行流程；（3）构造器各个参数的意义；（4）如何关闭线程池；（5）如何配置线程池；\n6.2 线程池之ScheduledThreadPoolExecutor\n知识点：（1）类结构；（2）常用方法；（3）ScheduledFutureTask；（3）DelayedWorkQueue;\n6.3 FutureTask基本操作总结\n知识点：（1）FutureTask的几种状态；（2）get方法；（3）cancel方法；（4）应用场景；（5）实现 Runnable接口\n\n原子操作类\n7.1 Java中atomic包中的原子操作类总结\n知识点：（1）实现原理；（2）原子更新基本类型；（3）原子更新数组类型；（4）原子更新引用类型；（5）原子更新字段类型\n\n并发工具\n8.1 大白话说java并发工具类-CountDownLatch，CyclicBarrier\n知识点：（1）倒计时器CountDownLatch；（2）循环栅栏CyclicBarrier；（3）CountDownLatch与CyclicBarrier的比较\n8.2 大白话说java并发工具类-Semaphore，Exchanger\n知识点：（1）资源访问控制Semaphore；（2）数据交换Exchanger\n\n并发实践\n9.1 一篇文章，让你彻底弄懂生产者–消费者问题\n\n\n\nJAVA并发知识图谱\n\n可移动到新窗口，放大查看效果更好或者查看原图\n知识图谱原图链接，如果有用，可克隆给自己使用\n","categories":["Java多线程"],"tags":["Java高并发"]},{"title":"宝塔面板","url":"/2023/03/16/%E5%AE%9D%E5%A1%94Linux%E9%9D%A2%E6%9D%BF/","content":"宝塔面板Centos安装脚本\nyum install -y wget &amp;&amp; wget -O install.sh https://download.bt.cn/install/install_6.0.sh &amp;&amp; sh install.sh ed8484bec\n\n\n\n一键卸载宝塔Linux面板及运行环境命令注：卸载环境可能会影响服务器数据 请谨慎操作！\n 1.进入ssh 输入以下命令下载脚本\nwget http://download.bt.cn/install/bt-uninstall.sh\n\n2.执行脚本 （若是ubutnu用户请在前面加sudo 例子sudo sh bt-uninstall.sh）\nsh bt-uninstall.sh\n\n\n\n外网面板地址: https://101.86.227.152:36726/29b6342f内网面板地址: https://192.168.1.10:36726/29b6342f 已改为soberusername: gduslnen 已改为soberpassword: c813af86  已改为sober123If you cannot access the panel,release the following panel port [36726] in the security group若无法访问面板，请检查防火墙&#x2F;安全组是否有放行面板[36726]端口因已开启面板自签证书，访问面板会提示不匹配证书，请参考以下链接配置证书https://www.bt.cn/bbs/thread-105443-1-1.html\n防火墙命令\n1）查看防火墙的版本。firewall-cmd –version2）查看firewall的状态。firewall-cmd –state3）查看firewall服务状态（普通用户可执行）。systemctl status firewalld4）查看防火墙全部的信息。firewall-cmd –list-all5）查看防火墙已开通的端口。firewall-cmd –list-port6）查看防火墙已开通的服务。firewall-cmd –list-service7）查看全部的服务列表（普通用户可执行）。firewall-cmd –get-services8）查看防火墙服务是否开机启动。systemctl is-enabled firewalld2、配置防火墙的命令 1）启动、重启、关闭防火墙服务。\n启动systemctl start firewalld\n重启systemctl restart firewalld\n关闭systemctl stop firewalld2）开放、移去某个端口。\n开放80端口firewall-cmd –zone&#x3D;public –add-port&#x3D;80&#x2F;tcp –permanent\n移去80端口firewall-cmd –zone&#x3D;public –remove-port&#x3D;80&#x2F;tcp –permanent3）开放、移去范围端口。\n开放5000-5500之间的端口firewall-cmd –zone&#x3D;public –add-port&#x3D;5000-5500&#x2F;tcp –permanent\n移去5000-5500之间的端口firewall-cmd –zone&#x3D;public –remove-port&#x3D;5000-5500&#x2F;tcp –permanent4）开放、移去服务。\n开放ftp服务firewall-cmd –zone&#x3D;public –add-service&#x3D;ftp –permanent\n移去http服务firewall-cmd –zone&#x3D;public –remove-service&#x3D;ftp –permanent5）重新加载防火墙配置（修改配置后要重新加载防火墙配置或重启防火墙服务）。firewall-cmd –reload6）设置开机时启用、禁用防火墙服务。\n启用服务systemctl enable firewalld\n禁用服务systemctl disable firewalld\n","categories":["宝塔面板"],"tags":["宝塔Linux面板"]},{"title":"宝塔安装的redis开启远程连接","url":"/2023/03/19/%E5%AE%9D%E5%A1%94%E5%AE%89%E8%A3%85%E7%9A%84redis%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/","content":"宝塔安装的Redis开启远程连接第一步，打开配置文件&#x2F;www&#x2F;server&#x2F;redis&#x2F;redis.conf\n搜索bind，修改自己的IP地址\nbind 192.168.1.16\n\n搜索protected-mode，将保护模式yes改成no\nprotected-mode no\n\n将 requirepass foobared 的 foobared 改为自己需要设置的Redis密码\nrequirepass sober\n\n最后重启配置\n","categories":["Redis"],"tags":["Redis开启远程连接"]},{"title":"微信小程序开发资源汇总","url":"/2023/02/19/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/","content":"微信小程序开发资源汇总本文收集了微信小程序开发过程中会使用到的资料、问题以及第三方组件库。本文不是一遍关于如何学习微信小程序的入门指南，也非参考手册，只是一些资料的整理。\n本仓库中的资料整理自网络，也有一些来自网友的推荐。在这里可以看到项目贡献者的完整名单。\n如果这个仓库对你有帮助，欢迎 star。如果这个仓库帮你提升了技能找到了工作，可以请我喝杯咖啡：\nQQ交流群\n微信小程序1号群：593495800 （已满）\n微信小程序2号群：578063690\n微信小程序3号群：682463867\n\n目录\n官方文档\n工具\n插件\n组件\nDemo\n\n置顶\nWePY：组件化的小程序开发框架 💯\nWePY 开发资源汇总 💯\n\n官方文档\n小程序设计指南\n小程序开发教程\n小程序框架\n小程序组件\n小程序 API\n小程序开发者工具\n\n↑ 返回目录 ↑\n工具\nTaro ★24k+ - 使用 React 的方式开发小程序的框架，同时支持生成多端应用\nWePY ★20k+ - 支持组件化的小程序开发框架\nuni-app ★20k+ - 使用 Vue 语法开发小程序、H5、App的统一框架\nmpvue ★19k+ - 基于 Vue.js 的小程序开发框架，从底层支持 Vue.js 语法和构建工具体系\nchameleon ★7k+ - 一套代码运行多端，一端所见即多端所见\nkbone ★2.8k+ - Web 与小程序同构解决方案\nRemax ★2.4k+ - 使用真正的 React 构建小程序\nwept ★2.3k - 微信小程序实时运行环境\nwechat_web_devtools ★2.3k+ - Linux 下微信开发者工具\nwafer ★2.1k - 快速构建具备弹性能力的微信小程序\nMPX ★2.1k+ - 增强型小程序框架，深度性能优化，支持跨小程序平台开发，完全兼容原生小程序组件\nLabrador ★1.7k - 支持 ES6&#x2F;7 的微信小程序组件化开发框架\nlicia ★1.7k - 支持小程序的 JS 工具库\nmegalo ★1.6k - 基于 Vue 的小程序开发框架\ntina ★1k+ - 轻巧的渐进式微信小程序框架\nminapp ★800+ - TypeScript 版小程序开发框架（兼容原生小程序代码）\nOkam ★300+ - 使用类 Vue 方式开发小程序的渐进增强框架，支持生成微信&#x2F;百度等主流平台的小程序\nxpmjs ★100+ - 微信小程序云端增强 SDK\nWeApp-Workflow ★100+ - 基于 Gulp 的微信小程序前端开发工作流\ngulp-wxa-copy-npm - 微信小程序 gulp 插件，解决 npm 包管理和 babel-runtime\nweact - 用 JSX 快速开发小程序\nsocket.io-mp-client - 微信小程序 socket.io 客户端\n@wxa - AOP小程序开发框架\npostcss-pxtorpx-pro - postcss px 转 rpx 插件\npx2rpx - Px 转 Rpx 在线工具\nwxml-parser - JavaScript WXML parser\nweappx - 基于 redux 的数据层管理框架\nweapp-start - 基于插件机制的开发脚手架，改善原生小程序开发体验\nEgret Wing - 支持微信小程序实时预览的 IDE\nwxapp-graphql - 小程序 GraphQL 客户端\ngulp-wxapp-boilerplate - 小程序+小程序云 Gulp 开发脚手架，支持云函数 mock\nwenaox - 小程序数据层管理 ，轻量性能好，支持中间件\nauthing-wxapp-sdk - 身份认证 for 微信小程序\nweapp-eslint-boilerplate - 微信小程序 Eslint 通用模板文件，节省自己配置的时间\nAnka - 渐进式小程序开发工具集，提供通用的开发函数库及组件\nWeAppBunXin - 微信小程序开发之影分身术，一套代码生成多个小程序\nminiprogram-build - 小程序命令行编译工具(支持typescript,原生npm,资源文件压缩…)\nwcc.js - wcc.js 是wxml文件和wxs文件编译器的nodejs实现\nwcsc.js - wcsc.js 是wxss文件编译器的nodejs实现\nweapp-gulp - Gulp高效构建微信小程序，让开发变得更简单\n\n插件\nwxapp.vim - 提供微信小程序开发全方位支持的 vim 插件\nweapp-snippet-for-sublime-text-2-3 - 为 sublime text 2&amp;3 准备的微信小程序 snippet(停更)\nMatchmaker - IntelliJ IDEA 插件，注入方法\nwechatCode-complete - webstorm 插件（代码提示）\nwxapp - sublime plugin\nminapp - vscode 插件（支持 原生&#x2F;mpvue&#x2F;wepy 框架）\nvscode 插件(代码提示)\\\nvscode-live-sass-compiler - vscode插件根据.scss文件自动生成wxss文件\nWePY Plugin For IntelliJ Platform - 让PhpStorm&#x2F;WebStorm全面支持WePY的开发，包括API(原生&#x2F;WePY)和组件(官方&#x2F;自定义)的自动完成&#x2F;错误检查&#x2F;高亮&#x2F;不依赖Vue&#x2F;…\nwxml - vscode插件–微信小程序格式化以及高亮组件(高度自定义)\nvim-vue-plugin - vim 插件，.vue 和 .wpy 文件的语法高亮和缩进\nwux-weapp-snippets - Wux Weapp Snippets for VS Code.\nwux-weapp-atom-snippets - Wux Weapp Snippets for Atom.\nwux-weapp-sublime-snippets - Wux Weapp Snippets Plugin for Sublime Text 2&#x2F;3.\n\n组件\nweui-wxss ★12.4K+ - 同微信原生视觉体验一致的基础样式库\nvant-weapp ★12.3k+ - 高颜值、好用、易扩展的微信小程序 UI 库\nwxParse ★7.2K+ - 微信小程序富文本解析自定义组件，支持 HTML 及 markdown 解析\niview-weapp ★5.5k+ - 一套高质量的微信小程序 UI 组件库\nwux-weapp ★4.2k+ - 一套组件化、可复用、易扩展的微信小程序 UI 组件库\nwx-charts ★4.1k+ - 微信小程序图表 charts 组件\nwemark ★1.100+ - 微信小程序 Markdown 渲染库\nwxapp-img-loader ★400+ - 微信小程序图片预加载组件\nwe-cropper ★400+ - 微信小程序图片裁剪工具\nwxa-plugin-canvas ★300+ - 微信小程序朋友圈海报生成组件\nWeZRender ★300+ - 微信小程序 Canvas 开发\nwx_calendar ★300+ - 小程序日历\nwxapp ★300+ - 微信小程序组件\nWa-UI ★200+ - 针对微信小程序整合的一套 UI 库\nwxSearch ★200+ - 微信小程序优雅的搜索框\nwx-scrollable-tab-view ★200+ - 小程序可滑动得 tab-view\nwetoast ★100+ - 微信小程序 toast 增强插件\nwx-alphabetical-listview ★100+ - 微信小程序带字母滑动的 listview\nwx-drawer ★100+ - 小程序模仿 QQ6.0 侧滑菜单\nwxapp-charts ★100+ - 微信小程序图表 charts 组件\nchartjs-wechat-mini-app ★100+ - chartjs 微信小程序适配\nwx-promise-request ★100+ - 微信小程序请求队列管理库\nwe-swiper ★100+ - 微信小程序触摸内容滑动解决方案\nwxDraw ★100+ - 微信小程序 2D 动画库\ncitySelect ★100+ ★42 - 微信小程序城市选择器\nweapp-cookie ★100+ - 一行代码让微信小程序支持 cookie 🍪🚀\nWeiXinProject - 微信小程序列表上拉刷新和上拉加载\nwepy-com-charts - 微信小程序 wepy 图表控件\nwxapp-lock - 微信小程序手势解锁\nmini-gesture-lock - 微信小程序手势解锁(无Android Canvas卡顿问题)\nweapp.socket.io - socket.io 风格的 websocket 类库\nweapp-polyfill - [w3c 标准 API polyfill\nwxPromise - 微信小程序 Promise 库\nwxMD5 - 微信小程序 MD5 库\nwxBase64 - 微信小程序base64 库\nxing-weapp-component - 微信小程序基础组件扩展\nwx-statuslayout - 小程序页面状态切换组件\nminapp-api-promise - 微信小程序所有 API promise 化\nminapp-slider-left - 微信小程序左划删除组件\nmp_canvas_drawer - canvas绘制图片助手，一个json就制作分享朋友圈图片\nxing-weapp-editor - 小程序图文编辑组件\ncue - A WX Compontent Tools\nwuss-weapp - 一款高质量，组件齐全，高自定义的微信小程序UI组件库\nminiprogram-datepicker - 小程序日期选择器（支持农历）\nwx-api-promisify - 优雅地将微信小程序API Promise化\nanka-brush - 一款为简化小程序里canvas画图操作而创建的工具库\nanka-tracker - 小程序打点库，用于统计用户行为数据\nmpvue-calendar - 微信小程序&#x2F;浏览器端的日历组件mpvue-calendar；基于mpvue平台 支持农历、按周切换、可自定义。\nmp-swipe-card - 小程序卡片滑动组件,类似探探的效果，貌似现在只支持左右滑动\nweapp.request - 为微信小程序提供的网络请求组件，是 wx.request 的扩展，基于 Promise API，添加缓存控制。\nminiprogram-network - Redefine the Network API of MiniProgram(小程序网络请求库)\nwe-validator - 简单灵活的表单验证插件，支持小程序、浏览器以及Nodejs端使用。\nwx-pulltorefresh-view - 简单灵活的下拉上拉刷新组件，支持微信小程序\nsol-weapp ★300+ -微信小程序营销组件:红包雨、大转盘等营销组件\nweapp-input-frame - 微信小程序验证码输入框组件\nwe-debug - 一款灵活、易于拓展的微信小程序调试工具\n\n)\nDemo\nEastWorld&#x2F;wechat-app-mall ★3000+ - 微信小程序商城\ntumobi&#x2F;nideshop-mini-program ★2000+ - 基于 Node.js + MySQL 开发的开源微信小程序商城\nRebeccaHanjw&#x2F;weapp-wechat-zhihu ★800+ - 仿知乎\nhuangjianke&#x2F;Gitter ★700+ - Gitter for GitHub - 可能是目前颜值最高的GitHub小程序客户端\nlypeer&#x2F;wechat-weapp-gank ★600+) - Gank 客户端\nwangmingjob&#x2F;weapp-weipiao ★300+ - 微票\ncharleyw&#x2F;wechat-weapp-redux ★300+ - Redux 绑定库\njectychen&#x2F;wechat-v2ex ★300+) - V2EX\n18380435477&#x2F;WeApp ★300+ - 仿微信\nzce&#x2F;weapp-boilerplate ★300+ - 微信小程序快速开发骨架\nbayetech&#x2F;wechat_mall_applet ★300+ - 电商平台\nlanshan-studio&#x2F;wecqupt ★300+ - We 重邮\nimageslr&#x2F;weapp-library ★300+ - 在线借书平台（WeUI设计规范、前后端开源、RESTful API文档）\nmyronliu347&#x2F;wechat-app-zhihudaily ★200+ - 知乎日报\nharveyqing&#x2F;BearDiary ★200+ - 小熊の日记\nleancloud&#x2F;leantodo-weapp ★200+ - 集成 LeanCloud 实现的 Todo list\nSuperKieran&#x2F;weapp-artand ★200+ - Artand\ndongweiming&#x2F;weapp-zhihulive ★200+ - 知乎 Live\neyasliu&#x2F;wechat-app-music ★200+ - 音乐播放器\nahonn&#x2F;weapp-one ★200+ - 仿 ONE\ngiscafer&#x2F;wechat-weapp-mapdemo ★200+ - 地图导航、marker标注 （不再维护）\nyaoshanliang&#x2F;weapp-ssha ★200+ - 企业宣传小程序\nhilongjw&#x2F;weapp-gold ★100+ - 掘金主页信息流\nzce&#x2F;weapp-douban ★100+ - 豆瓣电影\nhingsir&#x2F;weapp-douban-film ★100+ - 豆瓣电影\nkunkun12&#x2F;weapp - 小程序 hello world 尝鲜\nnatee&#x2F;wxapp-2048 ★100+ - 2048 小游戏\nSeptemberMaples&#x2F;wechat-weapp-demo ★100+ - 购物车\nhijiangtao&#x2F;weapp-newsapp - 公众号热门文章信息流\ncharleyw&#x2F;wechat-weapp-redux-todos ★100+ - 集成 Redux 实现的Todo list\nkraaas&#x2F;timer ★100+ - 番茄时钟\nericzyh&#x2F;wechat-chat ★100+ - 聊天室\nBelinChung&#x2F;wxapp-hiapp ★100+ - HiApp\nhardog&#x2F;wechat-app-flexlayout ★100+ - flexlayout\ndunizb&#x2F;wxapp-sCalc ★100+ - 简易计算器\nlitt1e-p&#x2F;weapp-girls ★100+ - 豆瓣美女&#x2F;妹子图\nliumulin614&#x2F;BeautifulGirl - 美女模特\nromoo&#x2F;weapp-demo-breadtrip ★100+ - 面包旅行\nzhuweiyou&#x2F;fetop100 ★100+ - 前端TOP100\nvace&#x2F;wechatapp-news-reader ★100+ - 新闻阅读器\nyaoshanliang&#x2F;weapp-jump ★100+ - 跳一跳\nyaoshanliang&#x2F;weapp-monument-valley ★100+ - 纪念碑谷\nSymous&#x2F;WechatApp-BaisiSister - 百思不得姐\ngithinkcn&#x2F;Giteer - Giteer For 码云，基于Taro + Taro UI + Dva的小程序。\nDengKe1994&#x2F;weapp-calculator - IOS 计算器\nmonkindey&#x2F;wx-github - GitHub 简历\nfluency03&#x2F;weapp-500px - 国外摄影社区 500px\nweapp-film - 淘票票\nxujinyang&#x2F;CoderCalendar-WeApp - 程序员老黄历\nzhengxiaowai&#x2F;weapp-github - github\nSeahub&#x2F;PigRaising - PigRaising\nbrucevanfdm&#x2F;WeChatMeiZhi - 妹子图\nzhijieeeeee&#x2F;wechat-app-joke - 开心一刻\nuniquexiaobai&#x2F;wechat-app-githubfeed - GitHubFeed\nzce&#x2F;weapp-todos - TODOS 任务清单\nbruintong&#x2F;wechat-webapp-douban-movie - 豆瓣电影\nbruintong&#x2F;wechat-webapp-douban-location - 豆瓣同城\narkilis&#x2F;weapp-jandan - 煎蛋\nbodekjan&#x2F;wechat-weather - 微信天气\njasscia&#x2F;ChristmasHat - 我要圣诞帽\nnanwangjkl&#x2F;sliding_puzzle - 滑块拼图\nkaiwu&#x2F;weui-scalajs - 使用Scala.js开发\ntinajs&#x2F;tina-hackernews - Hacker News 热点\nmohuishou&#x2F;scuplus-wechat - We 川大\nhankzhuo&#x2F;wx-v2ex - v2ex\nHongye567&#x2F;weapp-mark - 仿 Mark 影单的微信小程序\nw1109790800&#x2F;We-Todo - 基于LeanCloud的Todo-List\njae-jae&#x2F;weapp-github-trending - Github今日榜单\nsteedos&#x2F;mini-vip - 华炎微站、微商城\nalex1504&#x2F;wx-guita_tab - 口袋吉他\nlonnng&#x2F;etym - 芒果词源助手\nwuhou123&#x2F;wxxcx - 武侯的猫，基于wepy构建,整合了n多查询工具（快递，天气，记账，搞笑视频等）\nupupming&#x2F;HITMers - 博物馆小助手（统计值班表、签到、值班日历及备忘录、国际化、Streamable.com 视频上传等）\nLDouble&#x2F;WeOUC - WeOUC(教务小程序)\nAirmole&#x2F;ShellBox - 贝壳小盒子（校园教务信息查询类工具，获2019高校小程序开发大赛华北区二等奖）\naquanlerou&#x2F;WeHalo ★200+ - 爱敲代码的猫（WeHalo 简约风 的微信小程序版博客✨）\nWarpPrism&#x2F;SubwayRoutineMP - 【东京首尔曼谷新加坡巴黎地铁线路图🚄】\nGoKu-gaga&#x2F;today - 口袋工具（一个小工具的集合）\ncy920820&#x2F;weapp-motor-movies - 马达电影助手（一个院线电影小助手）\nGwokhov&#x2F;chronus - Chronus 目标日记（一款能帮助你管理生活目标的云开发微信小程序）\nimliubo&#x2F;Wechat_MQTT_ESP8266_BaiduIoT - 微信智能小管家 (使用微信小程序控制你的硬件设备)\nyuzexia&#x2F;iw3cplus - 前端社区www.w3cplus.com的微信小程序\nRAOE&#x2F;show-videos - 秀视频（微信小程序短视频社交软件，视频上传，音视频合成，评论，点赞，转发，分享等）\nNewFuture&#x2F;miniprogram-template - 原生API纯TypeScript开发小程序(VSCode as IDE)与完整开发流程\nZhuPeng&#x2F;mp-githubtrending - 以 Feed 流形式查看 GitHub Trending 仓库集合的工具\nyociduo&#x2F;scrum-planning-poker - Scrum敏捷估算,基于wepy构建\nlsqy&#x2F;taro-music - 🎉基于taro + taro-ui + redux + typescript 开发的网易云音乐小程序\n仿喜马拉雅lite - 微信小程序原生开发的仿喜马拉雅小程序（极度适合新手入门）\nbranliang&#x2F;game-stop-app - PSN降价了（一个可以订阅PS4游戏价格的工具）\n\n","categories":["微信小程序"],"tags":["资源"]},{"title":"Linux 配置 JDK Maven 环境变量","url":"/2023/03/22/%E9%85%8D%E7%BD%AEMaven%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","content":"使用命令 java 、javac 、 java -version 来查看是否安装了JDK\nrpm -qa | grep java 或 rpm -qa | grep jdk 命令来查询出系统自带的jdk（蓝框的四个就是系统自带的）注：其余的不要删\n然后通过    rpm -e –nodeps   后面跟系统自带的jdk名    这个命令来删除系统自带的jdk，\n# 卸载 CentOS 7.9 自带JDKrpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.262.b10-1.el7.x86_64rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.261-2.6.22.2.el7_8.x86_64rpm -e --nodeps java-1.8.0-openjdk-1.8.0.262.b10-1.el7.x86_64rpm -e --nodeps java-1.7.0-openjdk-1.7.0.261-2.6.22.2.el7_8.x86_64\n\n\n\n\n\n配置Java环境变量解压下载好的JDK安装包解压路径：&#x2F;usr&#x2F;local&#x2F;java&#x2F;\n# 配置Java环境变量export JAVA_HOME=/usr/local/java/jdk1.8.0_221export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib:$CLASSPATHexport JAVA_PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JRE_HOME&#125;/binexport PATH=$PATH:$&#123;JAVA_PATH&#125;\n\n配置Maven环境变量解压下载好的maven安装包解压路径：&#x2F;usr&#x2F;local&#x2F;maven&#x2F;\n# 配置Maven环境变量export MAVEN_HOME=/usr/local/maven/apache-maven-3.9.0export PATH=$&#123;MAVEN_HOME&#125;/bin:$PATH\n\n\n\nLinux： 解决每次重启机器环境变量都需要 source &#x2F;etc&#x2F;profile 才生效\n1、将环境变量配置在~&#x2F;.bashrc里面。\n2、在~&#x2F;.bashrc里面加一句source &#x2F;etc&#x2F;profile\n\n.bashrc 文件说明：bash 在每次启动时都会自动载入 bashrc 配置文件中的内容，.bashrc 文件可以执行一些命令以及脚本，有以下两种解决方法解决每次重启机器环境变量都需要 source &#x2F;etc&#x2F;profile 才生效\n1、将环境变量配置在~&#x2F;.bashrc里面。~代表当前用户目录，我是root用户登录的，如可以使用如下命令进入\nvi /root/.bashrc或vi ~/.bashrc\n\n2.添加环境变量# 配置Java环境变量export JAVA_HOME=/usr/local/java/jdk1.8.0_221export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib:$CLASSPATHexport JAVA_PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JRE_HOME&#125;/binexport PATH=$PATH:$&#123;JAVA_PATH&#125;\n\n","categories":["JDK Maven 环境变量"],"tags":["JDK Maven 环境变量"]}]